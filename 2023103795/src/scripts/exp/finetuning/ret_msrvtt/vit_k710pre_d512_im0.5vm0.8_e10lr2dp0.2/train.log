2023-09-17T06:22:21 | INFO | umt : Logging to: ./exp/finetuning/ret_msrvtt/vit_k710pre_d512_im0.5vm0.8_e10lr2dp0.2/train.log
2023-09-17T06:22:21 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  your_msrvtt_path: /data1/DATASET/MSRVTT/videos
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_train9k.json', '/data1/DATASET/MSRVTT/videos', 'video']
  test_file: {
      test: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_test1k.json', '/data1/DATASET/MSRVTT/videos', 'video'] }
  test_types: ['test']
  num_workers: 6
  stop_key: test/
  is_paragraph_retrieval: False
  num_frames: 12
  num_frames_test: 12
  batch_size: 32
  max_txt_l: 32
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 12
          sample_type: rand
          num_frames_test: 12
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 32
          video: 32 }
      batch_size: {
          image: 32
          video: 32 }
      batch_size_test: {
          image: 32
          video: 32 } }
  text_enc: bert
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_b16
          img_size: 224
          patch_size: 16
          d_model: 768
          encoder_embed_dim: 768
          encoder_depth: 12
          encoder_num_heads: 12
          drop_path_rate: 0.2
          num_frames: 12
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 12
          clip_decoder_embed_dim: 768
          clip_output_dim: 512
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_model/Unmasked_Teacher/b16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 224
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      multimodal: {
          enable: True }
      embed_dim: 512
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 2e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 10
      min_lr_multi: 0.01
      warmup_epochs: 0 }
  evaluate: False
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: True
      entity: user
      project: umt_ret }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: ./exp/finetuning/ret_msrvtt/vit_k710pre_d512_im0.5vm0.8_e10lr2dp0.2
  resume: False
  debug: False
  log_freq: 100
  seed: 42
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_model/Unmasked_Teacher/multimodality//b16_5m.pth
  rank: 0
  world_size: 1
  gpu: 0
  distributed: True
  dist_backend: nccl }
2023-09-17T06:22:41 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'your_msrvtt_path': '/data1/DATASET/MSRVTT/videos', 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_train9k.json', '/data1/DATASET/MSRVTT/videos', 'video'], 'test_file': {'test': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_test1k.json', '/data1/DATASET/MSRVTT/videos', 'video']}, 'test_types': ['test'], 'num_workers': 6, 'stop_key': 'test/', 'is_paragraph_retrieval': False, 'num_frames': 12, 'num_frames_test': 12, 'batch_size': 32, 'max_txt_l': 32, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 12, 'sample_type': 'rand', 'num_frames_test': 12, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 32, 'video': 32}, 'batch_size': {'image': 32, 'video': 32}, 'batch_size_test': {'image': 32, 'video': 32}}, 'text_enc': 'bert', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_b16', 'img_size': 224, 'patch_size': 16, 'd_model': 768, 'encoder_embed_dim': 768, 'encoder_depth': 12, 'encoder_num_heads': 12, 'drop_path_rate': 0.2, 'num_frames': 12, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 12, 'clip_decoder_embed_dim': 768, 'clip_output_dim': 512, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_model/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 224, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'multimodal': {'enable': True}, 'embed_dim': 512, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 2e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 10, 'min_lr_multi': 0.01, 'warmup_epochs': 0}, 'evaluate': False, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': True, 'entity': 'user', 'project': 'umt_ret'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': './exp/finetuning/ret_msrvtt/vit_k710pre_d512_im0.5vm0.8_e10lr2dp0.2', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 42, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_model/Unmasked_Teacher/multimodality//b16_5m.pth', 'rank': 0, 'world_size': 1, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2023-09-17T06:22:41 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_train9k.json', '/data1/DATASET/MSRVTT/videos', 'video']
2023-09-17T06:22:41 | INFO | tasks.pretrain : Creating dataset for ret
2023-09-17T06:22:42 | INFO | tasks.shared_utils : Creating model
2023-09-17T06:22:43 | INFO | models.umt : Build vision_encoder: vit_b16
2023-09-17T06:22:43 | INFO | models.backbones.vit.vit : Num of patches: 2352
2023-09-17T06:22:43 | INFO | models.backbones.vit.vit : Use checkpoint: True
2023-09-17T06:22:43 | INFO | models.backbones.vit.vit : Checkpoint number: 12
2023-09-17T06:22:43 | INFO | models.backbones.vit.vit : Student return index: []
2023-09-17T06:22:54 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_model/Unmasked_Teacher/b16_ptk710_f8_res224.pth
2023-09-17T06:22:55 | INFO | models.umt : Build text_encoder bert_base
2023-09-17T06:22:56 | INFO | models.backbones.bert.xbert : build bert with cross_module: ca
2023-09-17T06:22:56 | INFO | models.criterions : Norm type: l2
2023-09-17T06:22:56 | INFO | models.criterions : Loss type: l2
2023-09-17T07:38:05 | INFO | umt : Logging to: ./exp/finetuning/ret_msrvtt/vit_k710pre_d512_im0.5vm0.8_e10lr2dp0.2/train.log
2023-09-17T07:38:05 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  your_msrvtt_path: /data1/DATASET/MSRVTT/videos
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_train9k.json', '/data1/DATASET/MSRVTT/videos', 'video']
  test_file: {
      test: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_test1k.json', '/data1/DATASET/MSRVTT/videos', 'video'] }
  test_types: ['test']
  num_workers: 6
  stop_key: test/
  is_paragraph_retrieval: False
  num_frames: 12
  num_frames_test: 12
  batch_size: 32
  max_txt_l: 32
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 12
          sample_type: rand
          num_frames_test: 12
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 32
          video: 32 }
      batch_size: {
          image: 32
          video: 32 }
      batch_size_test: {
          image: 32
          video: 32 } }
  text_enc: bert
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_b16
          img_size: 224
          patch_size: 16
          d_model: 768
          encoder_embed_dim: 768
          encoder_depth: 12
          encoder_num_heads: 12
          drop_path_rate: 0.2
          num_frames: 12
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 12
          clip_decoder_embed_dim: 768
          clip_output_dim: 512
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_model/Unmasked_Teacher/b16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 224
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      multimodal: {
          enable: True }
      embed_dim: 512
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 2e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 10
      min_lr_multi: 0.01
      warmup_epochs: 0 }
  evaluate: False
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: True
      entity: user
      project: umt_ret }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: ./exp/finetuning/ret_msrvtt/vit_k710pre_d512_im0.5vm0.8_e10lr2dp0.2
  resume: False
  debug: False
  log_freq: 100
  seed: 42
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_model/Unmasked_Teacher/multimodality//b16_5m.pth
  rank: 0
  world_size: 1
  gpu: 0
  distributed: True
  dist_backend: nccl }
2023-09-17T07:39:15 | INFO | umt : Logging to: ./exp/finetuning/ret_msrvtt/vit_k710pre_d512_im0.5vm0.8_e10lr2dp0.2/train.log
2023-09-17T07:39:15 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  your_msrvtt_path: /data1/DATASET/MSRVTT/videos
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_train9k.json', '/data1/DATASET/MSRVTT/videos', 'video']
  test_file: {
      test: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_test1k.json', '/data1/DATASET/MSRVTT/videos', 'video'] }
  test_types: ['test']
  num_workers: 6
  stop_key: test/
  is_paragraph_retrieval: False
  num_frames: 12
  num_frames_test: 12
  batch_size: 32
  max_txt_l: 32
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 12
          sample_type: rand
          num_frames_test: 12
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 32
          video: 32 }
      batch_size: {
          image: 32
          video: 32 }
      batch_size_test: {
          image: 32
          video: 32 } }
  text_enc: bert
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_b16
          img_size: 224
          patch_size: 16
          d_model: 768
          encoder_embed_dim: 768
          encoder_depth: 12
          encoder_num_heads: 12
          drop_path_rate: 0.2
          num_frames: 12
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 12
          clip_decoder_embed_dim: 768
          clip_output_dim: 512
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_model/Unmasked_Teacher/b16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 224
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      multimodal: {
          enable: True }
      embed_dim: 512
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 2e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 10
      min_lr_multi: 0.01
      warmup_epochs: 0 }
  evaluate: False
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: True
      entity: user
      project: umt_ret }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: ./exp/finetuning/ret_msrvtt/vit_k710pre_d512_im0.5vm0.8_e10lr2dp0.2
  resume: False
  debug: False
  log_freq: 100
  seed: 42
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_model/Unmasked_Teacher/multimodality//b16_5m.pth
  rank: 0
  world_size: 1
  gpu: 0
  distributed: True
  dist_backend: nccl }
2023-09-17T07:40:04 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'your_msrvtt_path': '/data1/DATASET/MSRVTT/videos', 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_train9k.json', '/data1/DATASET/MSRVTT/videos', 'video'], 'test_file': {'test': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_test1k.json', '/data1/DATASET/MSRVTT/videos', 'video']}, 'test_types': ['test'], 'num_workers': 6, 'stop_key': 'test/', 'is_paragraph_retrieval': False, 'num_frames': 12, 'num_frames_test': 12, 'batch_size': 32, 'max_txt_l': 32, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 12, 'sample_type': 'rand', 'num_frames_test': 12, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 32, 'video': 32}, 'batch_size': {'image': 32, 'video': 32}, 'batch_size_test': {'image': 32, 'video': 32}}, 'text_enc': 'bert', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_b16', 'img_size': 224, 'patch_size': 16, 'd_model': 768, 'encoder_embed_dim': 768, 'encoder_depth': 12, 'encoder_num_heads': 12, 'drop_path_rate': 0.2, 'num_frames': 12, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 12, 'clip_decoder_embed_dim': 768, 'clip_output_dim': 512, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_model/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 224, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'multimodal': {'enable': True}, 'embed_dim': 512, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 2e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 10, 'min_lr_multi': 0.01, 'warmup_epochs': 0}, 'evaluate': False, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': True, 'entity': 'user', 'project': 'umt_ret'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': './exp/finetuning/ret_msrvtt/vit_k710pre_d512_im0.5vm0.8_e10lr2dp0.2', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 42, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_model/Unmasked_Teacher/multimodality//b16_5m.pth', 'rank': 0, 'world_size': 1, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2023-09-17T07:40:04 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_train9k.json', '/data1/DATASET/MSRVTT/videos', 'video']
2023-09-17T07:40:04 | INFO | tasks.pretrain : Creating dataset for ret
2023-09-17T07:40:04 | INFO | tasks.shared_utils : Creating model
2023-09-17T07:40:05 | INFO | models.umt : Build vision_encoder: vit_b16
2023-09-17T07:40:05 | INFO | models.backbones.vit.vit : Num of patches: 2352
2023-09-17T07:40:05 | INFO | models.backbones.vit.vit : Use checkpoint: True
2023-09-17T07:40:05 | INFO | models.backbones.vit.vit : Checkpoint number: 12
2023-09-17T07:40:05 | INFO | models.backbones.vit.vit : Student return index: []
2023-09-17T07:40:18 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_model/Unmasked_Teacher/b16_ptk710_f8_res224.pth
2023-09-17T07:40:18 | INFO | models.umt : Build text_encoder bert_base
2023-09-17T07:40:20 | INFO | models.backbones.bert.xbert : build bert with cross_module: ca
2023-09-17T07:40:20 | INFO | models.criterions : Norm type: l2
2023-09-17T07:40:20 | INFO | models.criterions : Loss type: l2
2023-09-17T13:10:39 | INFO | umt : Logging to: ./exp/finetuning/ret_msrvtt/vit_k710pre_d512_im0.5vm0.8_e10lr2dp0.2/train.log
2023-09-17T13:10:39 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  your_msrvtt_path: /data1/DATASET/MSRVTT/videos
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_train9k.json', '/data1/DATASET/MSRVTT/videos', 'video']
  test_file: {
      test: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_test1k.json', '/data1/DATASET/MSRVTT/videos', 'video'] }
  test_types: ['test']
  num_workers: 6
  stop_key: test/
  is_paragraph_retrieval: False
  num_frames: 12
  num_frames_test: 12
  batch_size: 32
  max_txt_l: 32
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 12
          sample_type: rand
          num_frames_test: 12
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 32
          video: 32 }
      batch_size: {
          image: 32
          video: 32 }
      batch_size_test: {
          image: 32
          video: 32 } }
  text_enc: bert
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_b16
          img_size: 224
          patch_size: 16
          d_model: 768
          encoder_embed_dim: 768
          encoder_depth: 12
          encoder_num_heads: 12
          drop_path_rate: 0.2
          num_frames: 12
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 12
          clip_decoder_embed_dim: 768
          clip_output_dim: 512
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_model/Unmasked_Teacher/b16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 224
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      multimodal: {
          enable: True }
      embed_dim: 512
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 2e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 10
      min_lr_multi: 0.01
      warmup_epochs: 0 }
  evaluate: False
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: True
      entity: user
      project: umt_ret }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: ./exp/finetuning/ret_msrvtt/vit_k710pre_d512_im0.5vm0.8_e10lr2dp0.2
  resume: False
  debug: False
  log_freq: 100
  seed: 42
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_model/Unmasked_Teacher/multimodality//b16_5m.pth
  rank: 0
  world_size: 2
  gpu: 0
  distributed: True
  dist_backend: nccl }
2023-09-17T13:10:53 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'your_msrvtt_path': '/data1/DATASET/MSRVTT/videos', 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_train9k.json', '/data1/DATASET/MSRVTT/videos', 'video'], 'test_file': {'test': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_test1k.json', '/data1/DATASET/MSRVTT/videos', 'video']}, 'test_types': ['test'], 'num_workers': 6, 'stop_key': 'test/', 'is_paragraph_retrieval': False, 'num_frames': 12, 'num_frames_test': 12, 'batch_size': 32, 'max_txt_l': 32, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 12, 'sample_type': 'rand', 'num_frames_test': 12, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 32, 'video': 32}, 'batch_size': {'image': 32, 'video': 32}, 'batch_size_test': {'image': 32, 'video': 32}}, 'text_enc': 'bert', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_b16', 'img_size': 224, 'patch_size': 16, 'd_model': 768, 'encoder_embed_dim': 768, 'encoder_depth': 12, 'encoder_num_heads': 12, 'drop_path_rate': 0.2, 'num_frames': 12, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 12, 'clip_decoder_embed_dim': 768, 'clip_output_dim': 512, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_model/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 224, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'multimodal': {'enable': True}, 'embed_dim': 512, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 2e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 10, 'min_lr_multi': 0.01, 'warmup_epochs': 0}, 'evaluate': False, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': True, 'entity': 'user', 'project': 'umt_ret'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': './exp/finetuning/ret_msrvtt/vit_k710pre_d512_im0.5vm0.8_e10lr2dp0.2', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 42, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_model/Unmasked_Teacher/multimodality//b16_5m.pth', 'rank': 0, 'world_size': 2, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2023-09-17T13:10:53 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_train9k.json', '/data1/DATASET/MSRVTT/videos', 'video']
2023-09-17T13:10:53 | INFO | tasks.pretrain : Creating dataset for ret
2023-09-17T13:10:54 | INFO | tasks.shared_utils : Creating model
2023-09-17T13:10:55 | INFO | models.umt : Build vision_encoder: vit_b16
2023-09-17T13:10:55 | INFO | models.backbones.vit.vit : Num of patches: 2352
2023-09-17T13:10:55 | INFO | models.backbones.vit.vit : Use checkpoint: True
2023-09-17T13:10:55 | INFO | models.backbones.vit.vit : Checkpoint number: 12
2023-09-17T13:10:55 | INFO | models.backbones.vit.vit : Student return index: []
2023-09-17T13:11:03 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_model/Unmasked_Teacher/b16_ptk710_f8_res224.pth
2023-09-17T13:11:03 | INFO | models.umt : Build text_encoder bert_base
2023-09-17T13:11:05 | INFO | models.backbones.bert.xbert : build bert with cross_module: ca
2023-09-17T13:11:05 | INFO | models.criterions : Norm type: l2
2023-09-17T13:11:05 | INFO | models.criterions : Loss type: l2
2023-09-17T13:11:30 | INFO | umt : Logging to: ./exp/finetuning/ret_msrvtt/vit_k710pre_d512_im0.5vm0.8_e10lr2dp0.2/train.log
2023-09-17T13:11:30 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  your_msrvtt_path: /data1/DATASET/MSRVTT/videos
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_train9k.json', '/data1/DATASET/MSRVTT/videos', 'video']
  test_file: {
      test: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_test1k.json', '/data1/DATASET/MSRVTT/videos', 'video'] }
  test_types: ['test']
  num_workers: 6
  stop_key: test/
  is_paragraph_retrieval: False
  num_frames: 12
  num_frames_test: 12
  batch_size: 32
  max_txt_l: 32
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 12
          sample_type: rand
          num_frames_test: 12
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 32
          video: 32 }
      batch_size: {
          image: 32
          video: 32 }
      batch_size_test: {
          image: 32
          video: 32 } }
  text_enc: bert
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_b16
          img_size: 224
          patch_size: 16
          d_model: 768
          encoder_embed_dim: 768
          encoder_depth: 12
          encoder_num_heads: 12
          drop_path_rate: 0.2
          num_frames: 12
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 12
          clip_decoder_embed_dim: 768
          clip_output_dim: 512
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_model/Unmasked_Teacher/b16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 224
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      multimodal: {
          enable: True }
      embed_dim: 512
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 2e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 10
      min_lr_multi: 0.01
      warmup_epochs: 0 }
  evaluate: False
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: True
      entity: user
      project: umt_ret }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: ./exp/finetuning/ret_msrvtt/vit_k710pre_d512_im0.5vm0.8_e10lr2dp0.2
  resume: False
  debug: False
  log_freq: 100
  seed: 42
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_model/Unmasked_Teacher/multimodality//b16_5m.pth
  rank: 0
  world_size: 2
  gpu: 0
  distributed: True
  dist_backend: nccl }
2023-09-17T13:11:47 | INFO | umt : Logging to: ./exp/finetuning/ret_msrvtt/vit_k710pre_d512_im0.5vm0.8_e10lr2dp0.2/train.log
2023-09-17T13:11:47 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  your_msrvtt_path: /data1/DATASET/MSRVTT/videos
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_train9k.json', '/data1/DATASET/MSRVTT/videos', 'video']
  test_file: {
      test: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_test1k.json', '/data1/DATASET/MSRVTT/videos', 'video'] }
  test_types: ['test']
  num_workers: 6
  stop_key: test/
  is_paragraph_retrieval: False
  num_frames: 12
  num_frames_test: 12
  batch_size: 32
  max_txt_l: 32
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 12
          sample_type: rand
          num_frames_test: 12
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 32
          video: 32 }
      batch_size: {
          image: 32
          video: 32 }
      batch_size_test: {
          image: 32
          video: 32 } }
  text_enc: bert
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_b16
          img_size: 224
          patch_size: 16
          d_model: 768
          encoder_embed_dim: 768
          encoder_depth: 12
          encoder_num_heads: 12
          drop_path_rate: 0.2
          num_frames: 12
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 12
          clip_decoder_embed_dim: 768
          clip_output_dim: 512
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_model/Unmasked_Teacher/b16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 224
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      multimodal: {
          enable: True }
      embed_dim: 512
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 2e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 10
      min_lr_multi: 0.01
      warmup_epochs: 0 }
  evaluate: False
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: True
      entity: user
      project: umt_ret }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: ./exp/finetuning/ret_msrvtt/vit_k710pre_d512_im0.5vm0.8_e10lr2dp0.2
  resume: False
  debug: False
  log_freq: 100
  seed: 42
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_model/Unmasked_Teacher/multimodality//b16_5m.pth
  rank: 0
  world_size: 2
  gpu: 0
  distributed: True
  dist_backend: nccl }
2023-09-17T13:11:56 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'your_msrvtt_path': '/data1/DATASET/MSRVTT/videos', 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_train9k.json', '/data1/DATASET/MSRVTT/videos', 'video'], 'test_file': {'test': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_test1k.json', '/data1/DATASET/MSRVTT/videos', 'video']}, 'test_types': ['test'], 'num_workers': 6, 'stop_key': 'test/', 'is_paragraph_retrieval': False, 'num_frames': 12, 'num_frames_test': 12, 'batch_size': 32, 'max_txt_l': 32, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 12, 'sample_type': 'rand', 'num_frames_test': 12, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 32, 'video': 32}, 'batch_size': {'image': 32, 'video': 32}, 'batch_size_test': {'image': 32, 'video': 32}}, 'text_enc': 'bert', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_b16', 'img_size': 224, 'patch_size': 16, 'd_model': 768, 'encoder_embed_dim': 768, 'encoder_depth': 12, 'encoder_num_heads': 12, 'drop_path_rate': 0.2, 'num_frames': 12, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 12, 'clip_decoder_embed_dim': 768, 'clip_output_dim': 512, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_model/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 224, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'multimodal': {'enable': True}, 'embed_dim': 512, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 2e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 10, 'min_lr_multi': 0.01, 'warmup_epochs': 0}, 'evaluate': False, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': True, 'entity': 'user', 'project': 'umt_ret'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': './exp/finetuning/ret_msrvtt/vit_k710pre_d512_im0.5vm0.8_e10lr2dp0.2', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 42, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_model/Unmasked_Teacher/multimodality//b16_5m.pth', 'rank': 0, 'world_size': 2, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2023-09-17T13:11:56 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_train9k.json', '/data1/DATASET/MSRVTT/videos', 'video']
2023-09-17T13:11:56 | INFO | tasks.pretrain : Creating dataset for ret
2023-09-17T13:11:57 | INFO | tasks.shared_utils : Creating model
2023-09-17T13:11:58 | INFO | models.umt : Build vision_encoder: vit_b16
2023-09-17T13:11:58 | INFO | models.backbones.vit.vit : Num of patches: 2352
2023-09-17T13:11:58 | INFO | models.backbones.vit.vit : Use checkpoint: True
2023-09-17T13:11:58 | INFO | models.backbones.vit.vit : Checkpoint number: 12
2023-09-17T13:11:58 | INFO | models.backbones.vit.vit : Student return index: []
2023-09-17T13:12:07 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_model/Unmasked_Teacher/b16_ptk710_f8_res224.pth
2023-09-17T13:12:07 | INFO | models.umt : Build text_encoder bert_base
2023-09-17T13:12:09 | INFO | models.backbones.bert.xbert : build bert with cross_module: ca
2023-09-17T13:12:09 | INFO | models.criterions : Norm type: l2
2023-09-17T13:12:09 | INFO | models.criterions : Loss type: l2
2023-09-17T13:13:55 | INFO | umt : Logging to: ./exp/finetuning/ret_msrvtt/vit_k710pre_d512_im0.5vm0.8_e10lr2dp0.2/train.log
2023-09-17T13:13:55 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  your_msrvtt_path: /data1/DATASET/MSRVTT/videos
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_train9k.json', '/data1/DATASET/MSRVTT/videos', 'video']
  test_file: {
      test: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_test1k.json', '/data1/DATASET/MSRVTT/videos', 'video'] }
  test_types: ['test']
  num_workers: 6
  stop_key: test/
  is_paragraph_retrieval: False
  num_frames: 12
  num_frames_test: 12
  batch_size: 32
  max_txt_l: 32
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 12
          sample_type: rand
          num_frames_test: 12
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 32
          video: 32 }
      batch_size: {
          image: 32
          video: 32 }
      batch_size_test: {
          image: 32
          video: 32 } }
  text_enc: bert
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_b16
          img_size: 224
          patch_size: 16
          d_model: 768
          encoder_embed_dim: 768
          encoder_depth: 12
          encoder_num_heads: 12
          drop_path_rate: 0.2
          num_frames: 12
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 12
          clip_decoder_embed_dim: 768
          clip_output_dim: 512
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_model/Unmasked_Teacher/b16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 224
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      multimodal: {
          enable: True }
      embed_dim: 512
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 2e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 10
      min_lr_multi: 0.01
      warmup_epochs: 0 }
  evaluate: False
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: True
      entity: user
      project: umt_ret }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: ./exp/finetuning/ret_msrvtt/vit_k710pre_d512_im0.5vm0.8_e10lr2dp0.2
  resume: False
  debug: False
  log_freq: 100
  seed: 42
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_model/Unmasked_Teacher/multimodality//b16_5m.pth
  rank: 0
  world_size: 2
  gpu: 0
  distributed: True
  dist_backend: nccl }
2023-09-17T13:14:03 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'your_msrvtt_path': '/data1/DATASET/MSRVTT/videos', 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_train9k.json', '/data1/DATASET/MSRVTT/videos', 'video'], 'test_file': {'test': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_test1k.json', '/data1/DATASET/MSRVTT/videos', 'video']}, 'test_types': ['test'], 'num_workers': 6, 'stop_key': 'test/', 'is_paragraph_retrieval': False, 'num_frames': 12, 'num_frames_test': 12, 'batch_size': 32, 'max_txt_l': 32, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 12, 'sample_type': 'rand', 'num_frames_test': 12, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 32, 'video': 32}, 'batch_size': {'image': 32, 'video': 32}, 'batch_size_test': {'image': 32, 'video': 32}}, 'text_enc': 'bert', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_b16', 'img_size': 224, 'patch_size': 16, 'd_model': 768, 'encoder_embed_dim': 768, 'encoder_depth': 12, 'encoder_num_heads': 12, 'drop_path_rate': 0.2, 'num_frames': 12, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 12, 'clip_decoder_embed_dim': 768, 'clip_output_dim': 512, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_model/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 224, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'multimodal': {'enable': True}, 'embed_dim': 512, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 2e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 10, 'min_lr_multi': 0.01, 'warmup_epochs': 0}, 'evaluate': False, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': True, 'entity': 'user', 'project': 'umt_ret'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': './exp/finetuning/ret_msrvtt/vit_k710pre_d512_im0.5vm0.8_e10lr2dp0.2', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 42, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_model/Unmasked_Teacher/multimodality//b16_5m.pth', 'rank': 0, 'world_size': 2, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2023-09-17T13:14:03 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_train9k.json', '/data1/DATASET/MSRVTT/videos', 'video']
2023-09-17T13:14:03 | INFO | tasks.pretrain : Creating dataset for ret
2023-09-17T13:14:03 | INFO | tasks.shared_utils : Creating model
2023-09-17T13:14:05 | INFO | models.umt : Build vision_encoder: vit_b16
2023-09-17T13:14:05 | INFO | models.backbones.vit.vit : Num of patches: 2352
2023-09-17T13:14:05 | INFO | models.backbones.vit.vit : Use checkpoint: True
2023-09-17T13:14:05 | INFO | models.backbones.vit.vit : Checkpoint number: 12
2023-09-17T13:14:05 | INFO | models.backbones.vit.vit : Student return index: []
2023-09-17T13:14:14 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_model/Unmasked_Teacher/b16_ptk710_f8_res224.pth
2023-09-17T13:14:14 | INFO | models.umt : Build text_encoder bert_base
2023-09-17T13:14:16 | INFO | models.backbones.bert.xbert : build bert with cross_module: ca
2023-09-17T13:14:16 | INFO | models.criterions : Norm type: l2
2023-09-17T13:14:16 | INFO | models.criterions : Loss type: l2
2023-09-17T13:14:16 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.temp: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.weight: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.q_bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.v_bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.weight: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.weight: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.q_bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.v_bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.weight: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.weight: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.q_bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.v_bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.weight: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.weight: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.q_bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.v_bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.weight: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.weight: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.q_bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.v_bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.weight: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.weight: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.q_bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.v_bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.weight: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.weight: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.q_bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.v_bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.weight: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.weight: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.q_bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.v_bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.weight: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.weight: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.q_bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.v_bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.weight: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.weight: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.q_bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.v_bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.weight: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.weight: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.q_bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.v_bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.weight: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.weight: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.q_bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.v_bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.weight: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.weight: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.weight: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.embeddings.word_embeddings.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.embeddings.position_embeddings.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.embeddings.token_type_embeddings.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_proj.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.vision_proj.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_proj.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.text_proj.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.itm_head.weight: wd: 0.02, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : param module.itm_head.bias: wd: 0, lr: 2e-05
2023-09-17T13:14:16 | INFO | utils.optimizer : optimizer -- lr=2e-05 wd=0.02 len(p)=140
2023-09-17T13:14:16 | INFO | utils.optimizer : optimizer -- lr=2e-05 wd=0 len(p)=256
2023-09-17T13:14:16 | INFO | tasks.shared_utils : Auto resuming
2023-09-17T13:14:16 | INFO | tasks.shared_utils : Not found checkpoint in ./exp/finetuning/ret_msrvtt/vit_k710pre_d512_im0.5vm0.8_e10lr2dp0.2
2023-09-17T13:14:17 | INFO | tasks.shared_utils : _IncompatibleKeys(missing_keys=[], unexpected_keys=['clip_teacher.class_embedding', 'clip_teacher.positional_embedding', 'clip_teacher.proj', 'clip_teacher.conv1.weight', 'clip_teacher.ln_pre.weight', 'clip_teacher.ln_pre.bias', 'clip_teacher.transformer.resblocks.0.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.0.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.0.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.0.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.0.ln_1.weight', 'clip_teacher.transformer.resblocks.0.ln_1.bias', 'clip_teacher.transformer.resblocks.0.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.0.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.0.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.0.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.0.ln_2.weight', 'clip_teacher.transformer.resblocks.0.ln_2.bias', 'clip_teacher.transformer.resblocks.1.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.1.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.1.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.1.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.1.ln_1.weight', 'clip_teacher.transformer.resblocks.1.ln_1.bias', 'clip_teacher.transformer.resblocks.1.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.1.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.1.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.1.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.1.ln_2.weight', 'clip_teacher.transformer.resblocks.1.ln_2.bias', 'clip_teacher.transformer.resblocks.2.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.2.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.2.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.2.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.2.ln_1.weight', 'clip_teacher.transformer.resblocks.2.ln_1.bias', 'clip_teacher.transformer.resblocks.2.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.2.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.2.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.2.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.2.ln_2.weight', 'clip_teacher.transformer.resblocks.2.ln_2.bias', 'clip_teacher.transformer.resblocks.3.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.3.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.3.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.3.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.3.ln_1.weight', 'clip_teacher.transformer.resblocks.3.ln_1.bias', 'clip_teacher.transformer.resblocks.3.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.3.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.3.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.3.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.3.ln_2.weight', 'clip_teacher.transformer.resblocks.3.ln_2.bias', 'clip_teacher.transformer.resblocks.4.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.4.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.4.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.4.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.4.ln_1.weight', 'clip_teacher.transformer.resblocks.4.ln_1.bias', 'clip_teacher.transformer.resblocks.4.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.4.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.4.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.4.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.4.ln_2.weight', 'clip_teacher.transformer.resblocks.4.ln_2.bias', 'clip_teacher.transformer.resblocks.5.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.5.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.5.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.5.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.5.ln_1.weight', 'clip_teacher.transformer.resblocks.5.ln_1.bias', 'clip_teacher.transformer.resblocks.5.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.5.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.5.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.5.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.5.ln_2.weight', 'clip_teacher.transformer.resblocks.5.ln_2.bias', 'clip_teacher.transformer.resblocks.6.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.6.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.6.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.6.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.6.ln_1.weight', 'clip_teacher.transformer.resblocks.6.ln_1.bias', 'clip_teacher.transformer.resblocks.6.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.6.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.6.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.6.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.6.ln_2.weight', 'clip_teacher.transformer.resblocks.6.ln_2.bias', 'clip_teacher.transformer.resblocks.7.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.7.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.7.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.7.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.7.ln_1.weight', 'clip_teacher.transformer.resblocks.7.ln_1.bias', 'clip_teacher.transformer.resblocks.7.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.7.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.7.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.7.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.7.ln_2.weight', 'clip_teacher.transformer.resblocks.7.ln_2.bias', 'clip_teacher.transformer.resblocks.8.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.8.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.8.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.8.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.8.ln_1.weight', 'clip_teacher.transformer.resblocks.8.ln_1.bias', 'clip_teacher.transformer.resblocks.8.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.8.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.8.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.8.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.8.ln_2.weight', 'clip_teacher.transformer.resblocks.8.ln_2.bias', 'clip_teacher.transformer.resblocks.9.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.9.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.9.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.9.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.9.ln_1.weight', 'clip_teacher.transformer.resblocks.9.ln_1.bias', 'clip_teacher.transformer.resblocks.9.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.9.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.9.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.9.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.9.ln_2.weight', 'clip_teacher.transformer.resblocks.9.ln_2.bias', 'clip_teacher.transformer.resblocks.10.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.10.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.10.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.10.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.10.ln_1.weight', 'clip_teacher.transformer.resblocks.10.ln_1.bias', 'clip_teacher.transformer.resblocks.10.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.10.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.10.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.10.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.10.ln_2.weight', 'clip_teacher.transformer.resblocks.10.ln_2.bias', 'clip_teacher.transformer.resblocks.11.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.11.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.11.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.11.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.11.ln_1.weight', 'clip_teacher.transformer.resblocks.11.ln_1.bias', 'clip_teacher.transformer.resblocks.11.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.11.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.11.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.11.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.11.ln_2.weight', 'clip_teacher.transformer.resblocks.11.ln_2.bias', 'clip_teacher.ln_post.weight', 'clip_teacher.ln_post.bias', 'vision_encoder.clip_decoder.0.head.weight', 'vision_encoder.clip_decoder.0.head.bias', 'vision_encoder.clip_decoder.0.norm.weight', 'vision_encoder.clip_decoder.0.norm.bias', 'vision_encoder.clip_decoder.1.head.weight', 'vision_encoder.clip_decoder.1.head.bias', 'vision_encoder.clip_decoder.1.norm.weight', 'vision_encoder.clip_decoder.1.norm.bias', 'vision_encoder.clip_decoder.2.head.weight', 'vision_encoder.clip_decoder.2.head.bias', 'vision_encoder.clip_decoder.2.norm.weight', 'vision_encoder.clip_decoder.2.norm.bias', 'vision_encoder.clip_decoder.3.head.weight', 'vision_encoder.clip_decoder.3.head.bias', 'vision_encoder.clip_decoder.3.norm.weight', 'vision_encoder.clip_decoder.3.norm.bias', 'vision_encoder.clip_decoder.4.head.weight', 'vision_encoder.clip_decoder.4.head.bias', 'vision_encoder.clip_decoder.4.norm.weight', 'vision_encoder.clip_decoder.4.norm.bias', 'vision_encoder.clip_decoder.5.head.weight', 'vision_encoder.clip_decoder.5.head.bias', 'vision_encoder.clip_decoder.5.norm.weight', 'vision_encoder.clip_decoder.5.norm.bias', 'text_encoder.cls.predictions.bias', 'text_encoder.cls.predictions.transform.dense.weight', 'text_encoder.cls.predictions.transform.dense.bias', 'text_encoder.cls.predictions.transform.LayerNorm.weight', 'text_encoder.cls.predictions.transform.LayerNorm.bias', 'text_encoder.cls.predictions.decoder.weight', 'text_encoder.cls.predictions.decoder.bias'])
2023-09-17T13:14:17 | INFO | tasks.shared_utils : Loaded checkpoint from /datassd2/pretrained_model/Unmasked_Teacher/multimodality//b16_5m.pth
2023-09-17T13:14:18 | INFO | __main__ : training
2023-09-17T13:14:18 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 2812 batches in total
dataloader index=0 name=video, batch-size=32 length(#batches)=2812 
2023-09-17T13:14:34 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  builtin_warn(*args, **kwargs)

2023-09-17T13:14:34 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  builtin_warn(*args, **kwargs)

2023-09-17T13:14:34 | INFO | utils.basic_utils : Train Epoch: [0]  [   0/2812]  eta: 12:24:09  lr: 0.000020  temperature: 0.0136  video-loss_vtc: 2.4985  video-loss_vtm: 0.8035  time: 15.8784  data: 7.7789  max mem: 33054 res mem: 39610
2023-09-17T13:14:34 | INFO | torch.nn.parallel.distributed : Reducer buckets have been rebuilt in this iteration.
2023-09-17T13:21:22 | INFO | utils.basic_utils : Train Epoch: [0]  [ 100/2812]  eta: 3:09:55  lr: 0.000020  temperature: 0.0143  video-loss_vtc: 1.0973  video-loss_vtm: 0.3689  time: 4.0944  data: 0.0017  max mem: 34905 res mem: 39722
2023-09-17T13:28:13 | INFO | utils.basic_utils : Train Epoch: [0]  [ 200/2812]  eta: 3:00:49  lr: 0.000020  temperature: 0.0146  video-loss_vtc: 1.1842  video-loss_vtm: 0.4163  time: 4.1055  data: 0.0017  max mem: 34905 res mem: 39722
2023-09-17T13:35:04 | INFO | utils.basic_utils : Train Epoch: [0]  [ 300/2812]  eta: 2:53:20  lr: 0.000020  temperature: 0.0149  video-loss_vtc: 1.3408  video-loss_vtm: 0.5606  time: 4.1127  data: 0.0018  max mem: 34905 res mem: 39722
2023-09-17T13:41:55 | INFO | utils.basic_utils : Train Epoch: [0]  [ 400/2812]  eta: 2:46:08  lr: 0.000020  temperature: 0.0152  video-loss_vtc: 1.1065  video-loss_vtm: 0.4630  time: 4.1121  data: 0.0017  max mem: 34905 res mem: 39722
2023-09-18T05:15:00 | INFO | umt : Logging to: ./exp/finetuning/ret_msrvtt/vit_k710pre_d512_im0.5vm0.8_e10lr2dp0.2/train.log
2023-09-18T05:15:00 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  your_msrvtt_path: /data1/DATASET/MSRVTT/videos
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_train9k.json', '/data1/DATASET/MSRVTT/videos', 'video']
  test_file: {
      test: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_test1k.json', '/data1/DATASET/MSRVTT/videos', 'video'] }
  test_types: ['test']
  num_workers: 6
  stop_key: test/
  is_paragraph_retrieval: False
  num_frames: 12
  num_frames_test: 12
  batch_size: 32
  max_txt_l: 32
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 12
          sample_type: rand
          num_frames_test: 12
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 32
          video: 32 }
      batch_size: {
          image: 32
          video: 32 }
      batch_size_test: {
          image: 32
          video: 32 } }
  text_enc: bert
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_b16
          img_size: 224
          patch_size: 16
          d_model: 768
          encoder_embed_dim: 768
          encoder_depth: 12
          encoder_num_heads: 12
          drop_path_rate: 0.2
          num_frames: 12
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 12
          clip_decoder_embed_dim: 768
          clip_output_dim: 512
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_model/Unmasked_Teacher/b16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 224
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      multimodal: {
          enable: True }
      embed_dim: 512
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 2e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 10
      min_lr_multi: 0.01
      warmup_epochs: 1 }
  evaluate: False
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: True
      entity: user
      project: umt_ret }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: ./exp/finetuning/ret_msrvtt/vit_k710pre_d512_im0.5vm0.8_e10lr2dp0.2
  resume: False
  debug: False
  log_freq: 100
  seed: 42
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_model/Unmasked_Teacher/multimodality/b16_5m.pth
  rank: 0
  world_size: 4
  gpu: 0
  distributed: True
  dist_backend: nccl }
2023-09-18T05:15:10 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'your_msrvtt_path': '/data1/DATASET/MSRVTT/videos', 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_train9k.json', '/data1/DATASET/MSRVTT/videos', 'video'], 'test_file': {'test': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_test1k.json', '/data1/DATASET/MSRVTT/videos', 'video']}, 'test_types': ['test'], 'num_workers': 6, 'stop_key': 'test/', 'is_paragraph_retrieval': False, 'num_frames': 12, 'num_frames_test': 12, 'batch_size': 32, 'max_txt_l': 32, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 12, 'sample_type': 'rand', 'num_frames_test': 12, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 32, 'video': 32}, 'batch_size': {'image': 32, 'video': 32}, 'batch_size_test': {'image': 32, 'video': 32}}, 'text_enc': 'bert', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_b16', 'img_size': 224, 'patch_size': 16, 'd_model': 768, 'encoder_embed_dim': 768, 'encoder_depth': 12, 'encoder_num_heads': 12, 'drop_path_rate': 0.2, 'num_frames': 12, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 12, 'clip_decoder_embed_dim': 768, 'clip_output_dim': 512, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_model/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 224, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'multimodal': {'enable': True}, 'embed_dim': 512, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 2e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 10, 'min_lr_multi': 0.01, 'warmup_epochs': 1}, 'evaluate': False, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': True, 'entity': 'user', 'project': 'umt_ret'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': './exp/finetuning/ret_msrvtt/vit_k710pre_d512_im0.5vm0.8_e10lr2dp0.2', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 42, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_model/Unmasked_Teacher/multimodality/b16_5m.pth', 'rank': 0, 'world_size': 4, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2023-09-18T05:15:10 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_train9k.json', '/data1/DATASET/MSRVTT/videos', 'video']
2023-09-18T05:15:10 | INFO | tasks.pretrain : Creating dataset for ret
2023-09-18T05:15:11 | INFO | tasks.shared_utils : Creating model
2023-09-18T05:15:12 | INFO | models.umt : Build vision_encoder: vit_b16
2023-09-18T05:15:12 | INFO | models.backbones.vit.vit : Num of patches: 2352
2023-09-18T05:15:12 | INFO | models.backbones.vit.vit : Use checkpoint: True
2023-09-18T05:15:12 | INFO | models.backbones.vit.vit : Checkpoint number: 12
2023-09-18T05:15:12 | INFO | models.backbones.vit.vit : Student return index: []
2023-09-18T05:15:19 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_model/Unmasked_Teacher/b16_ptk710_f8_res224.pth
2023-09-18T05:15:20 | INFO | models.umt : Build text_encoder bert_base
2023-09-18T05:15:21 | INFO | models.backbones.bert.xbert : build bert with cross_module: ca
2023-09-18T05:15:21 | INFO | models.criterions : Norm type: l2
2023-09-18T05:15:21 | INFO | models.criterions : Loss type: l2
2023-09-18T05:15:21 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.temp: wd: 0.02, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.weight: wd: 0, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.q_bias: wd: 0, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.v_bias: wd: 0, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.weight: wd: 0, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.weight: wd: 0, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.q_bias: wd: 0, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.v_bias: wd: 0, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.weight: wd: 0, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.weight: wd: 0, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.q_bias: wd: 0, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.v_bias: wd: 0, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.weight: wd: 0, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.weight: wd: 0, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.q_bias: wd: 0, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.v_bias: wd: 0, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.weight: wd: 0, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.weight: wd: 0, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.q_bias: wd: 0, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.v_bias: wd: 0, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.weight: wd: 0, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.weight: wd: 0, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.q_bias: wd: 0, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.v_bias: wd: 0, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.weight: wd: 0, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.weight: wd: 0, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.q_bias: wd: 0, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.v_bias: wd: 0, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.weight: wd: 0, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.weight: wd: 0, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.q_bias: wd: 0, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.v_bias: wd: 0, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.weight: wd: 0, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.weight: wd: 0, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.q_bias: wd: 0, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.v_bias: wd: 0, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.weight: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.weight: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.q_bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.v_bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.weight: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.weight: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.q_bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.v_bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.weight: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.weight: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.q_bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.v_bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.weight: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.weight: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.weight: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.embeddings.word_embeddings.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.embeddings.position_embeddings.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.embeddings.token_type_embeddings.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.vision_proj.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.vision_proj.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_proj.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.text_proj.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.itm_head.weight: wd: 0.02, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : param module.itm_head.bias: wd: 0, lr: 2e-05
2023-09-18T05:15:22 | INFO | utils.optimizer : optimizer -- lr=2e-05 wd=0.02 len(p)=140
2023-09-18T05:15:22 | INFO | utils.optimizer : optimizer -- lr=2e-05 wd=0 len(p)=256
2023-09-18T05:15:22 | INFO | tasks.shared_utils : Auto resuming
2023-09-18T05:15:22 | INFO | tasks.shared_utils : Not found checkpoint in ./exp/finetuning/ret_msrvtt/vit_k710pre_d512_im0.5vm0.8_e10lr2dp0.2
2023-09-18T05:15:22 | INFO | tasks.shared_utils : _IncompatibleKeys(missing_keys=[], unexpected_keys=['clip_teacher.class_embedding', 'clip_teacher.positional_embedding', 'clip_teacher.proj', 'clip_teacher.conv1.weight', 'clip_teacher.ln_pre.weight', 'clip_teacher.ln_pre.bias', 'clip_teacher.transformer.resblocks.0.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.0.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.0.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.0.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.0.ln_1.weight', 'clip_teacher.transformer.resblocks.0.ln_1.bias', 'clip_teacher.transformer.resblocks.0.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.0.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.0.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.0.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.0.ln_2.weight', 'clip_teacher.transformer.resblocks.0.ln_2.bias', 'clip_teacher.transformer.resblocks.1.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.1.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.1.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.1.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.1.ln_1.weight', 'clip_teacher.transformer.resblocks.1.ln_1.bias', 'clip_teacher.transformer.resblocks.1.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.1.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.1.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.1.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.1.ln_2.weight', 'clip_teacher.transformer.resblocks.1.ln_2.bias', 'clip_teacher.transformer.resblocks.2.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.2.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.2.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.2.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.2.ln_1.weight', 'clip_teacher.transformer.resblocks.2.ln_1.bias', 'clip_teacher.transformer.resblocks.2.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.2.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.2.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.2.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.2.ln_2.weight', 'clip_teacher.transformer.resblocks.2.ln_2.bias', 'clip_teacher.transformer.resblocks.3.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.3.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.3.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.3.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.3.ln_1.weight', 'clip_teacher.transformer.resblocks.3.ln_1.bias', 'clip_teacher.transformer.resblocks.3.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.3.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.3.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.3.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.3.ln_2.weight', 'clip_teacher.transformer.resblocks.3.ln_2.bias', 'clip_teacher.transformer.resblocks.4.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.4.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.4.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.4.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.4.ln_1.weight', 'clip_teacher.transformer.resblocks.4.ln_1.bias', 'clip_teacher.transformer.resblocks.4.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.4.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.4.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.4.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.4.ln_2.weight', 'clip_teacher.transformer.resblocks.4.ln_2.bias', 'clip_teacher.transformer.resblocks.5.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.5.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.5.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.5.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.5.ln_1.weight', 'clip_teacher.transformer.resblocks.5.ln_1.bias', 'clip_teacher.transformer.resblocks.5.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.5.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.5.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.5.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.5.ln_2.weight', 'clip_teacher.transformer.resblocks.5.ln_2.bias', 'clip_teacher.transformer.resblocks.6.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.6.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.6.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.6.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.6.ln_1.weight', 'clip_teacher.transformer.resblocks.6.ln_1.bias', 'clip_teacher.transformer.resblocks.6.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.6.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.6.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.6.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.6.ln_2.weight', 'clip_teacher.transformer.resblocks.6.ln_2.bias', 'clip_teacher.transformer.resblocks.7.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.7.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.7.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.7.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.7.ln_1.weight', 'clip_teacher.transformer.resblocks.7.ln_1.bias', 'clip_teacher.transformer.resblocks.7.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.7.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.7.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.7.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.7.ln_2.weight', 'clip_teacher.transformer.resblocks.7.ln_2.bias', 'clip_teacher.transformer.resblocks.8.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.8.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.8.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.8.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.8.ln_1.weight', 'clip_teacher.transformer.resblocks.8.ln_1.bias', 'clip_teacher.transformer.resblocks.8.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.8.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.8.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.8.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.8.ln_2.weight', 'clip_teacher.transformer.resblocks.8.ln_2.bias', 'clip_teacher.transformer.resblocks.9.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.9.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.9.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.9.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.9.ln_1.weight', 'clip_teacher.transformer.resblocks.9.ln_1.bias', 'clip_teacher.transformer.resblocks.9.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.9.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.9.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.9.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.9.ln_2.weight', 'clip_teacher.transformer.resblocks.9.ln_2.bias', 'clip_teacher.transformer.resblocks.10.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.10.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.10.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.10.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.10.ln_1.weight', 'clip_teacher.transformer.resblocks.10.ln_1.bias', 'clip_teacher.transformer.resblocks.10.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.10.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.10.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.10.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.10.ln_2.weight', 'clip_teacher.transformer.resblocks.10.ln_2.bias', 'clip_teacher.transformer.resblocks.11.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.11.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.11.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.11.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.11.ln_1.weight', 'clip_teacher.transformer.resblocks.11.ln_1.bias', 'clip_teacher.transformer.resblocks.11.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.11.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.11.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.11.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.11.ln_2.weight', 'clip_teacher.transformer.resblocks.11.ln_2.bias', 'clip_teacher.ln_post.weight', 'clip_teacher.ln_post.bias', 'vision_encoder.clip_decoder.0.head.weight', 'vision_encoder.clip_decoder.0.head.bias', 'vision_encoder.clip_decoder.0.norm.weight', 'vision_encoder.clip_decoder.0.norm.bias', 'vision_encoder.clip_decoder.1.head.weight', 'vision_encoder.clip_decoder.1.head.bias', 'vision_encoder.clip_decoder.1.norm.weight', 'vision_encoder.clip_decoder.1.norm.bias', 'vision_encoder.clip_decoder.2.head.weight', 'vision_encoder.clip_decoder.2.head.bias', 'vision_encoder.clip_decoder.2.norm.weight', 'vision_encoder.clip_decoder.2.norm.bias', 'vision_encoder.clip_decoder.3.head.weight', 'vision_encoder.clip_decoder.3.head.bias', 'vision_encoder.clip_decoder.3.norm.weight', 'vision_encoder.clip_decoder.3.norm.bias', 'vision_encoder.clip_decoder.4.head.weight', 'vision_encoder.clip_decoder.4.head.bias', 'vision_encoder.clip_decoder.4.norm.weight', 'vision_encoder.clip_decoder.4.norm.bias', 'vision_encoder.clip_decoder.5.head.weight', 'vision_encoder.clip_decoder.5.head.bias', 'vision_encoder.clip_decoder.5.norm.weight', 'vision_encoder.clip_decoder.5.norm.bias', 'text_encoder.cls.predictions.bias', 'text_encoder.cls.predictions.transform.dense.weight', 'text_encoder.cls.predictions.transform.dense.bias', 'text_encoder.cls.predictions.transform.LayerNorm.weight', 'text_encoder.cls.predictions.transform.LayerNorm.bias', 'text_encoder.cls.predictions.decoder.weight', 'text_encoder.cls.predictions.decoder.bias'])
2023-09-18T05:15:22 | INFO | tasks.shared_utils : Loaded checkpoint from /datassd2/pretrained_model/Unmasked_Teacher/multimodality/b16_5m.pth
2023-09-18T05:15:22 | INFO | __main__ : training
2023-09-18T05:15:23 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 1406 batches in total
dataloader index=0 name=video, batch-size=32 length(#batches)=1406 
2023-09-18T05:15:39 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  builtin_warn(*args, **kwargs)

2023-09-18T05:15:39 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  builtin_warn(*args, **kwargs)

2023-09-18T05:15:39 | INFO | utils.basic_utils : Train Epoch: [0]  [   0/1406]  eta: 6:18:01  lr: 0.000000  temperature: 0.0136  video-loss_vtc: 3.2379  video-loss_vtm: 0.7703  time: 16.1319  data: 5.7078  max mem: 33047 res mem: 39610
2023-09-18T05:15:39 | INFO | torch.nn.parallel.distributed : Reducer buckets have been rebuilt in this iteration.
2023-09-18T05:22:33 | INFO | utils.basic_utils : Train Epoch: [0]  [ 100/1406]  eta: 1:32:41  lr: 0.000001  temperature: 0.0137  video-loss_vtc: 2.0666  video-loss_vtm: 0.4601  time: 4.1499  data: 0.0020  max mem: 34900 res mem: 40054
2023-09-18T05:29:27 | INFO | utils.basic_utils : Train Epoch: [0]  [ 200/1406]  eta: 1:24:27  lr: 0.000003  temperature: 0.0138  video-loss_vtc: 2.1150  video-loss_vtm: 0.5286  time: 4.1497  data: 0.0020  max mem: 34900 res mem: 40054
2023-09-18T05:36:22 | INFO | utils.basic_utils : Train Epoch: [0]  [ 300/1406]  eta: 1:17:06  lr: 0.000004  temperature: 0.0138  video-loss_vtc: 1.6826  video-loss_vtm: 0.4495  time: 4.1448  data: 0.0020  max mem: 34900 res mem: 40054
2023-09-18T05:43:16 | INFO | utils.basic_utils : Train Epoch: [0]  [ 400/1406]  eta: 1:09:57  lr: 0.000006  temperature: 0.0139  video-loss_vtc: 1.8414  video-loss_vtm: 0.5538  time: 4.1427  data: 0.0020  max mem: 34900 res mem: 40054
2023-09-18T05:50:10 | INFO | utils.basic_utils : Train Epoch: [0]  [ 500/1406]  eta: 1:02:55  lr: 0.000007  temperature: 0.0140  video-loss_vtc: 1.6258  video-loss_vtm: 0.4350  time: 4.1459  data: 0.0019  max mem: 34900 res mem: 40054
2023-09-18T05:57:05 | INFO | utils.basic_utils : Train Epoch: [0]  [ 600/1406]  eta: 0:55:56  lr: 0.000009  temperature: 0.0140  video-loss_vtc: 1.5746  video-loss_vtm: 0.3955  time: 4.1531  data: 0.0018  max mem: 34900 res mem: 40054
2023-09-18T06:04:01 | INFO | utils.basic_utils : Train Epoch: [0]  [ 700/1406]  eta: 0:48:59  lr: 0.000010  temperature: 0.0141  video-loss_vtc: 1.3548  video-loss_vtm: 0.5197  time: 4.1561  data: 0.0017  max mem: 34900 res mem: 40054
2023-09-18T06:10:57 | INFO | utils.basic_utils : Train Epoch: [0]  [ 800/1406]  eta: 0:42:02  lr: 0.000011  temperature: 0.0142  video-loss_vtc: 1.6675  video-loss_vtm: 0.3928  time: 4.1560  data: 0.0018  max mem: 34900 res mem: 40054
2023-09-18T06:17:53 | INFO | utils.basic_utils : Train Epoch: [0]  [ 900/1406]  eta: 0:35:06  lr: 0.000013  temperature: 0.0143  video-loss_vtc: 1.7887  video-loss_vtm: 0.4451  time: 4.1586  data: 0.0019  max mem: 34900 res mem: 40054
2023-09-18T06:24:49 | INFO | utils.basic_utils : Train Epoch: [0]  [1000/1406]  eta: 0:28:09  lr: 0.000014  temperature: 0.0144  video-loss_vtc: 1.2514  video-loss_vtm: 0.3843  time: 4.1796  data: 0.0017  max mem: 34900 res mem: 40054
2023-09-18T06:31:45 | INFO | utils.basic_utils : Train Epoch: [0]  [1100/1406]  eta: 0:21:13  lr: 0.000016  temperature: 0.0145  video-loss_vtc: 1.2130  video-loss_vtm: 0.3866  time: 4.1574  data: 0.0017  max mem: 34900 res mem: 40054
2023-09-18T06:38:41 | INFO | utils.basic_utils : Train Epoch: [0]  [1200/1406]  eta: 0:14:17  lr: 0.000017  temperature: 0.0146  video-loss_vtc: 1.1661  video-loss_vtm: 0.4042  time: 4.1570  data: 0.0017  max mem: 34900 res mem: 40054
2023-09-18T06:45:36 | INFO | utils.basic_utils : Train Epoch: [0]  [1300/1406]  eta: 0:07:21  lr: 0.000019  temperature: 0.0147  video-loss_vtc: 1.2834  video-loss_vtm: 0.3290  time: 4.1526  data: 0.0022  max mem: 34900 res mem: 40054
2023-09-18T06:52:32 | INFO | utils.basic_utils : Train Epoch: [0]  [1400/1406]  eta: 0:00:24  lr: 0.000020  temperature: 0.0148  video-loss_vtc: 1.2412  video-loss_vtm: 0.3392  time: 4.1518  data: 0.0024  max mem: 34900 res mem: 40054
2023-09-18T06:52:53 | INFO | utils.basic_utils : Train Epoch: [0]  [1405/1406]  eta: 0:00:04  lr: 0.000020  temperature: 0.0148  video-loss_vtc: 1.3842  video-loss_vtm: 0.4159  time: 4.1521  data: 0.0022  max mem: 34900 res mem: 40054
2023-09-18T06:52:53 | INFO | utils.basic_utils : Train Epoch: [0] Total time: 1:37:30 (4.1609 s / it)
2023-09-18T06:52:53 | INFO | __main__ : Averaged train stats: lr: 0.0000  temperature: 0.0142  video-loss_vtc: 1.6742  video-loss_vtm: 0.4370
2023-09-18T06:52:53 | INFO | tasks.retrieval_utils : Start evaluation for media_type=video
2023-09-18T06:52:53 | INFO | tasks.retrieval_utils : Computing dual encoder features...
2023-09-18T06:52:59 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2023-09-18T06:52:59 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2023-09-18T06:53:00 | INFO | utils.basic_utils : extracting image feats  [ 0/32]  eta: 0:03:50    time: 7.2033  data: 6.0968  max mem: 34900 res mem: 40054
2023-09-18T06:53:35 | INFO | utils.basic_utils : extracting image feats  [31/32]  eta: 0:00:01    time: 1.0924  data: 0.0381  max mem: 34900 res mem: 40054
2023-09-18T06:53:35 | INFO | utils.basic_utils : extracting image feats Total time: 0:00:41 (1.3053 s / it)
2023-09-18T06:53:40 | INFO | tasks.retrieval_utils : Finished feature extraction
2023-09-18T06:53:40 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product]
2023-09-18T06:53:40 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product], done!
2023-09-18T06:53:40 | INFO | tasks.retrieval_utils : Rerank dual-encoder results with cross-encoder...
2023-09-18T06:53:40 | INFO | tasks.retrieval_utils : i2t_scores.shape torch.Size([251, 1000])
2023-09-18T06:53:40 | INFO | tasks.retrieval_utils : n_clip_per_video=1, with eval_frame_ensemble=concat
2023-09-18T06:53:40 | INFO | utils.basic_utils : Evaluation:  [  0/251]  eta: 0:00:07    time: 0.0298  data: 0.0007  max mem: 34900 res mem: 40054
2023-09-18T06:53:48 | INFO | utils.basic_utils : Evaluation:  [100/251]  eta: 0:00:11    time: 0.0749  data: 0.0000  max mem: 34900 res mem: 40054
2023-09-18T06:53:55 | INFO | utils.basic_utils : Evaluation:  [200/251]  eta: 0:00:03    time: 0.0748  data: 0.0000  max mem: 34900 res mem: 40054
2023-09-18T06:53:59 | INFO | utils.basic_utils : Evaluation:  [250/251]  eta: 0:00:00    time: 0.0752  data: 0.0000  max mem: 34900 res mem: 40054
2023-09-18T06:53:59 | INFO | utils.basic_utils : Evaluation: Total time: 0:00:18 (0.0747 s / it)
2023-09-18T06:53:59 | INFO | tasks.retrieval_utils : t2i_scores.shape torch.Size([251, 1000])
2023-09-18T06:54:02 | INFO | utils.basic_utils : Evaluation:  [  0/251]  eta: 0:14:31    time: 3.4713  data: 0.0004  max mem: 34900 res mem: 40054
2023-09-18T06:54:10 | INFO | utils.basic_utils : Evaluation:  [100/251]  eta: 0:00:16    time: 0.0747  data: 0.0000  max mem: 34900 res mem: 40054
2023-09-18T06:54:17 | INFO | utils.basic_utils : Evaluation:  [200/251]  eta: 0:00:04    time: 0.0749  data: 0.0000  max mem: 34900 res mem: 40054
2023-09-18T06:54:21 | INFO | utils.basic_utils : Evaluation:  [250/251]  eta: 0:00:00    time: 0.0753  data: 0.0000  max mem: 34900 res mem: 40054
2023-09-18T06:54:21 | INFO | utils.basic_utils : Evaluation: Total time: 0:00:22 (0.0883 s / it)
2023-09-18T06:54:25 | INFO | tasks.retrieval_utils : Evaluation time 0:01:32
2023-09-18T06:54:25 | INFO | __main__ : Epoch 0
2023-09-18T06:54:25 | INFO | __main__ : 
           txt_r1  txt_r5  txt_r10  txt_r_mean  img_r1  img_r5  img_r10  img_r_mean  r_mean
test/        42.6    69.6     80.1       64.10    41.8    69.3     78.6       63.23   63.67
test_emb/    38.6    67.0     77.5       61.03    38.6    66.1     75.6       60.10   60.57
2023-09-18T06:54:28 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 1406 batches in total
dataloader index=0 name=video, batch-size=32 length(#batches)=1406 
2023-09-18T06:54:38 | INFO | utils.basic_utils : Train Epoch: [1]  [   0/1406]  eta: 3:54:17  lr: 0.000020  temperature: 0.0148  video-loss_vtc: 1.2147  video-loss_vtm: 0.4890  time: 9.9980  data: 5.8876  max mem: 34900 res mem: 44920
2023-09-18T07:01:35 | INFO | utils.basic_utils : Train Epoch: [1]  [ 100/1406]  eta: 1:31:55  lr: 0.000020  temperature: 0.0149  video-loss_vtc: 1.2362  video-loss_vtm: 0.3447  time: 4.1586  data: 0.0016  max mem: 34900 res mem: 44920
2023-09-18T07:08:31 | INFO | utils.basic_utils : Train Epoch: [1]  [ 200/1406]  eta: 1:24:12  lr: 0.000020  temperature: 0.0150  video-loss_vtc: 1.4709  video-loss_vtm: 0.3446  time: 4.1525  data: 0.0032  max mem: 34900 res mem: 44920
2023-09-18T07:15:26 | INFO | utils.basic_utils : Train Epoch: [1]  [ 300/1406]  eta: 1:17:00  lr: 0.000020  temperature: 0.0151  video-loss_vtc: 1.3800  video-loss_vtm: 0.1786  time: 4.1556  data: 0.0020  max mem: 34900 res mem: 44920
2023-09-18T07:22:21 | INFO | utils.basic_utils : Train Epoch: [1]  [ 400/1406]  eta: 1:09:56  lr: 0.000020  temperature: 0.0153  video-loss_vtc: 1.3410  video-loss_vtm: 0.4156  time: 4.1498  data: 0.0023  max mem: 34900 res mem: 44920
2023-09-18T07:29:16 | INFO | utils.basic_utils : Train Epoch: [1]  [ 500/1406]  eta: 1:02:55  lr: 0.000020  temperature: 0.0155  video-loss_vtc: 1.0366  video-loss_vtm: 0.3997  time: 4.1509  data: 0.0025  max mem: 34900 res mem: 44920
2023-09-18T07:36:12 | INFO | utils.basic_utils : Train Epoch: [1]  [ 600/1406]  eta: 0:55:57  lr: 0.000020  temperature: 0.0155  video-loss_vtc: 1.0661  video-loss_vtm: 0.4243  time: 4.1712  data: 0.0030  max mem: 34900 res mem: 44920
2023-09-18T07:43:07 | INFO | utils.basic_utils : Train Epoch: [1]  [ 700/1406]  eta: 0:48:59  lr: 0.000020  temperature: 0.0155  video-loss_vtc: 1.2878  video-loss_vtm: 0.5125  time: 4.1522  data: 0.0022  max mem: 34900 res mem: 44920
2023-09-18T07:50:03 | INFO | utils.basic_utils : Train Epoch: [1]  [ 800/1406]  eta: 0:42:02  lr: 0.000020  temperature: 0.0157  video-loss_vtc: 1.2182  video-loss_vtm: 0.4116  time: 4.1540  data: 0.0026  max mem: 34900 res mem: 44920
2023-09-18T07:56:58 | INFO | utils.basic_utils : Train Epoch: [1]  [ 900/1406]  eta: 0:35:05  lr: 0.000020  temperature: 0.0158  video-loss_vtc: 0.9598  video-loss_vtm: 0.2833  time: 4.1581  data: 0.0022  max mem: 34900 res mem: 44920
2023-09-18T08:03:53 | INFO | utils.basic_utils : Train Epoch: [1]  [1000/1406]  eta: 0:28:09  lr: 0.000020  temperature: 0.0158  video-loss_vtc: 0.9171  video-loss_vtm: 0.3211  time: 4.1516  data: 0.0022  max mem: 34900 res mem: 44920
2023-09-18T08:10:49 | INFO | utils.basic_utils : Train Epoch: [1]  [1100/1406]  eta: 0:21:13  lr: 0.000020  temperature: 0.0158  video-loss_vtc: 0.9230  video-loss_vtm: 0.4494  time: 4.1530  data: 0.0022  max mem: 34900 res mem: 44920
2023-09-18T08:17:44 | INFO | utils.basic_utils : Train Epoch: [1]  [1200/1406]  eta: 0:14:16  lr: 0.000020  temperature: 0.0159  video-loss_vtc: 0.9331  video-loss_vtm: 0.2488  time: 4.1552  data: 0.0024  max mem: 34900 res mem: 44920
2023-09-18T08:24:40 | INFO | utils.basic_utils : Train Epoch: [1]  [1300/1406]  eta: 0:07:20  lr: 0.000019  temperature: 0.0160  video-loss_vtc: 1.1321  video-loss_vtm: 0.3798  time: 4.1549  data: 0.0021  max mem: 34900 res mem: 44920
2023-09-18T08:31:35 | INFO | utils.basic_utils : Train Epoch: [1]  [1400/1406]  eta: 0:00:24  lr: 0.000019  temperature: 0.0161  video-loss_vtc: 1.0475  video-loss_vtm: 0.4830  time: 4.1589  data: 0.0022  max mem: 34900 res mem: 44920
2023-09-18T08:31:56 | INFO | utils.basic_utils : Train Epoch: [1]  [1405/1406]  eta: 0:00:04  lr: 0.000019  temperature: 0.0161  video-loss_vtc: 1.0785  video-loss_vtm: 0.2895  time: 4.1584  data: 0.0020  max mem: 34900 res mem: 44920
2023-09-18T08:31:56 | INFO | utils.basic_utils : Train Epoch: [1] Total time: 1:37:27 (4.1591 s / it)
2023-09-18T08:31:56 | INFO | __main__ : Averaged train stats: lr: 0.0000  temperature: 0.0155  video-loss_vtc: 1.1456  video-loss_vtm: 0.3564
2023-09-18T08:31:56 | INFO | tasks.retrieval_utils : Start evaluation for media_type=video
2023-09-18T08:31:56 | INFO | tasks.retrieval_utils : Computing dual encoder features...
2023-09-18T08:32:02 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2023-09-18T08:32:02 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2023-09-18T08:32:03 | INFO | utils.basic_utils : extracting image feats  [ 0/32]  eta: 0:03:25    time: 6.4205  data: 5.2581  max mem: 34900 res mem: 44920
2023-09-18T08:32:38 | INFO | utils.basic_utils : extracting image feats  [31/32]  eta: 0:00:01    time: 1.0965  data: 0.0424  max mem: 34900 res mem: 44920
2023-09-18T08:32:38 | INFO | utils.basic_utils : extracting image feats Total time: 0:00:41 (1.3066 s / it)
2023-09-18T08:32:44 | INFO | tasks.retrieval_utils : Finished feature extraction
2023-09-18T08:32:44 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product]
2023-09-18T08:32:44 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product], done!
2023-09-18T08:32:44 | INFO | tasks.retrieval_utils : Rerank dual-encoder results with cross-encoder...
2023-09-18T08:32:44 | INFO | tasks.retrieval_utils : i2t_scores.shape torch.Size([251, 1000])
2023-09-18T08:32:44 | INFO | tasks.retrieval_utils : n_clip_per_video=1, with eval_frame_ensemble=concat
2023-09-18T08:32:44 | INFO | utils.basic_utils : Evaluation:  [  0/251]  eta: 0:00:06    time: 0.0275  data: 0.0009  max mem: 34900 res mem: 44920
2023-09-18T08:32:51 | INFO | utils.basic_utils : Evaluation:  [100/251]  eta: 0:00:11    time: 0.0738  data: 0.0000  max mem: 34900 res mem: 44920
2023-09-18T08:32:58 | INFO | utils.basic_utils : Evaluation:  [200/251]  eta: 0:00:03    time: 0.0746  data: 0.0000  max mem: 34900 res mem: 44920
2023-09-18T08:33:02 | INFO | utils.basic_utils : Evaluation:  [250/251]  eta: 0:00:00    time: 0.0754  data: 0.0000  max mem: 34900 res mem: 44920
2023-09-18T08:33:02 | INFO | utils.basic_utils : Evaluation: Total time: 0:00:18 (0.0741 s / it)
2023-09-18T08:33:02 | INFO | tasks.retrieval_utils : t2i_scores.shape torch.Size([251, 1000])
2023-09-18T08:33:06 | INFO | utils.basic_utils : Evaluation:  [  0/251]  eta: 0:13:51    time: 3.3117  data: 0.0006  max mem: 34900 res mem: 44920
2023-09-18T08:33:13 | INFO | utils.basic_utils : Evaluation:  [100/251]  eta: 0:00:16    time: 0.0746  data: 0.0000  max mem: 34900 res mem: 44920
2023-09-18T08:33:21 | INFO | utils.basic_utils : Evaluation:  [200/251]  eta: 0:00:04    time: 0.0750  data: 0.0000  max mem: 34900 res mem: 44920
2023-09-18T08:33:24 | INFO | utils.basic_utils : Evaluation:  [250/251]  eta: 0:00:00    time: 0.0754  data: 0.0000  max mem: 34900 res mem: 44920
2023-09-18T08:33:24 | INFO | utils.basic_utils : Evaluation: Total time: 0:00:22 (0.0877 s / it)
2023-09-18T08:33:24 | INFO | tasks.retrieval_utils : Evaluation time 0:01:28
2023-09-18T08:33:25 | INFO | __main__ : Epoch 1
2023-09-18T08:33:25 | INFO | __main__ : 
           txt_r1  txt_r5  txt_r10  txt_r_mean  img_r1  img_r5  img_r10  img_r_mean  r_mean
test/        42.5    70.5     81.1        64.7    42.6    71.6     81.2       65.13   64.92
test_emb/    39.7    68.2     78.4        62.1    39.8    66.8     78.5       61.70   61.90
2023-09-18T08:33:40 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 1406 batches in total
dataloader index=0 name=video, batch-size=32 length(#batches)=1406 
2023-09-18T08:33:50 | INFO | utils.basic_utils : Train Epoch: [2]  [   0/1406]  eta: 4:02:44  lr: 0.000019  temperature: 0.0161  video-loss_vtc: 1.0648  video-loss_vtm: 0.3286  time: 10.3590  data: 5.6349  max mem: 34900 res mem: 44920
2023-09-18T08:40:47 | INFO | utils.basic_utils : Train Epoch: [2]  [ 100/1406]  eta: 1:32:00  lr: 0.000019  temperature: 0.0159  video-loss_vtc: 0.9860  video-loss_vtm: 0.2765  time: 4.1571  data: 0.0016  max mem: 34900 res mem: 44920
2023-09-18T08:47:42 | INFO | utils.basic_utils : Train Epoch: [2]  [ 200/1406]  eta: 1:24:15  lr: 0.000019  temperature: 0.0159  video-loss_vtc: 0.8673  video-loss_vtm: 0.2877  time: 4.1691  data: 0.0016  max mem: 34900 res mem: 44920
2023-09-18T08:54:38 | INFO | utils.basic_utils : Train Epoch: [2]  [ 300/1406]  eta: 1:17:02  lr: 0.000019  temperature: 0.0160  video-loss_vtc: 0.9454  video-loss_vtm: 0.3928  time: 4.1535  data: 0.0016  max mem: 34900 res mem: 44920
2023-09-18T09:01:33 | INFO | utils.basic_utils : Train Epoch: [2]  [ 400/1406]  eta: 1:09:58  lr: 0.000019  temperature: 0.0160  video-loss_vtc: 0.8354  video-loss_vtm: 0.2655  time: 4.1613  data: 0.0015  max mem: 34900 res mem: 44920
2023-09-18T09:08:28 | INFO | utils.basic_utils : Train Epoch: [2]  [ 500/1406]  eta: 1:02:56  lr: 0.000019  temperature: 0.0159  video-loss_vtc: 0.8509  video-loss_vtm: 0.1605  time: 4.1523  data: 0.0017  max mem: 34900 res mem: 44920
2023-09-18T09:15:24 | INFO | utils.basic_utils : Train Epoch: [2]  [ 600/1406]  eta: 0:55:57  lr: 0.000019  temperature: 0.0161  video-loss_vtc: 0.8006  video-loss_vtm: 0.2290  time: 4.1543  data: 0.0016  max mem: 34900 res mem: 44920
2023-09-18T09:22:19 | INFO | utils.basic_utils : Train Epoch: [2]  [ 700/1406]  eta: 0:49:00  lr: 0.000019  temperature: 0.0160  video-loss_vtc: 0.8352  video-loss_vtm: 0.2923  time: 4.1517  data: 0.0016  max mem: 34900 res mem: 44920
2023-09-18T09:29:14 | INFO | utils.basic_utils : Train Epoch: [2]  [ 800/1406]  eta: 0:42:02  lr: 0.000019  temperature: 0.0161  video-loss_vtc: 0.8307  video-loss_vtm: 0.3270  time: 4.1528  data: 0.0015  max mem: 34900 res mem: 44920
2023-09-18T09:36:10 | INFO | utils.basic_utils : Train Epoch: [2]  [ 900/1406]  eta: 0:35:05  lr: 0.000018  temperature: 0.0160  video-loss_vtc: 1.1845  video-loss_vtm: 0.3845  time: 4.1541  data: 0.0016  max mem: 34900 res mem: 44920
2023-09-18T09:43:05 | INFO | utils.basic_utils : Train Epoch: [2]  [1000/1406]  eta: 0:28:09  lr: 0.000018  temperature: 0.0161  video-loss_vtc: 1.0032  video-loss_vtm: 0.3056  time: 4.1527  data: 0.0016  max mem: 34900 res mem: 44920
2023-09-18T09:50:01 | INFO | utils.basic_utils : Train Epoch: [2]  [1100/1406]  eta: 0:21:13  lr: 0.000018  temperature: 0.0161  video-loss_vtc: 0.8401  video-loss_vtm: 0.3152  time: 4.1534  data: 0.0016  max mem: 34900 res mem: 44920
2023-09-18T09:56:56 | INFO | utils.basic_utils : Train Epoch: [2]  [1200/1406]  eta: 0:14:16  lr: 0.000018  temperature: 0.0162  video-loss_vtc: 1.0441  video-loss_vtm: 0.4789  time: 4.1691  data: 0.0016  max mem: 34900 res mem: 44920
2023-09-18T10:03:51 | INFO | utils.basic_utils : Train Epoch: [2]  [1300/1406]  eta: 0:07:20  lr: 0.000018  temperature: 0.0163  video-loss_vtc: 0.8586  video-loss_vtm: 0.3434  time: 4.1575  data: 0.0016  max mem: 34900 res mem: 44920
2023-09-18T10:10:47 | INFO | utils.basic_utils : Train Epoch: [2]  [1400/1406]  eta: 0:00:24  lr: 0.000018  temperature: 0.0164  video-loss_vtc: 1.0567  video-loss_vtm: 0.5069  time: 4.1499  data: 0.0016  max mem: 34900 res mem: 44920
2023-09-18T10:11:07 | INFO | utils.basic_utils : Train Epoch: [2]  [1405/1406]  eta: 0:00:04  lr: 0.000018  temperature: 0.0164  video-loss_vtc: 0.8751  video-loss_vtm: 0.4161  time: 4.1485  data: 0.0015  max mem: 34900 res mem: 44920
2023-09-18T10:11:07 | INFO | utils.basic_utils : Train Epoch: [2] Total time: 1:37:27 (4.1591 s / it)
2023-09-18T10:11:07 | INFO | __main__ : Averaged train stats: lr: 0.0000  temperature: 0.0161  video-loss_vtc: 0.9384  video-loss_vtm: 0.3191
2023-09-18T10:11:07 | INFO | tasks.retrieval_utils : Start evaluation for media_type=video
2023-09-18T10:11:07 | INFO | tasks.retrieval_utils : Computing dual encoder features...
2023-09-18T10:11:13 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2023-09-18T10:11:13 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2023-09-18T10:11:14 | INFO | utils.basic_utils : extracting image feats  [ 0/32]  eta: 0:03:28    time: 6.5141  data: 5.4063  max mem: 34900 res mem: 44920
2023-09-18T10:11:49 | INFO | utils.basic_utils : extracting image feats  [31/32]  eta: 0:00:01    time: 1.0902  data: 0.0421  max mem: 34900 res mem: 44920
2023-09-18T10:11:49 | INFO | utils.basic_utils : extracting image feats Total time: 0:00:41 (1.2906 s / it)
2023-09-18T10:11:54 | INFO | tasks.retrieval_utils : Finished feature extraction
2023-09-18T10:11:54 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product]
2023-09-18T10:11:54 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product], done!
2023-09-18T10:11:54 | INFO | tasks.retrieval_utils : Rerank dual-encoder results with cross-encoder...
2023-09-18T10:11:54 | INFO | tasks.retrieval_utils : i2t_scores.shape torch.Size([251, 1000])
2023-09-18T10:11:54 | INFO | tasks.retrieval_utils : n_clip_per_video=1, with eval_frame_ensemble=concat
2023-09-18T10:11:54 | INFO | utils.basic_utils : Evaluation:  [  0/251]  eta: 0:00:05    time: 0.0232  data: 0.0004  max mem: 34900 res mem: 44920
2023-09-18T10:12:01 | INFO | utils.basic_utils : Evaluation:  [100/251]  eta: 0:00:11    time: 0.0741  data: 0.0000  max mem: 34900 res mem: 44920
2023-09-18T10:12:09 | INFO | utils.basic_utils : Evaluation:  [200/251]  eta: 0:00:03    time: 0.0747  data: 0.0000  max mem: 34900 res mem: 44920
2023-09-18T10:12:12 | INFO | utils.basic_utils : Evaluation:  [250/251]  eta: 0:00:00    time: 0.0749  data: 0.0000  max mem: 34900 res mem: 44920
2023-09-18T10:12:12 | INFO | utils.basic_utils : Evaluation: Total time: 0:00:18 (0.0741 s / it)
2023-09-18T10:12:12 | INFO | tasks.retrieval_utils : t2i_scores.shape torch.Size([251, 1000])
2023-09-18T10:12:16 | INFO | utils.basic_utils : Evaluation:  [  0/251]  eta: 0:13:17    time: 3.1771  data: 0.0004  max mem: 34900 res mem: 44920
2023-09-18T10:12:23 | INFO | utils.basic_utils : Evaluation:  [100/251]  eta: 0:00:15    time: 0.0747  data: 0.0000  max mem: 34900 res mem: 44920
2023-09-18T10:12:30 | INFO | utils.basic_utils : Evaluation:  [200/251]  eta: 0:00:04    time: 0.0751  data: 0.0000  max mem: 34900 res mem: 44920
2023-09-18T10:12:34 | INFO | utils.basic_utils : Evaluation:  [250/251]  eta: 0:00:00    time: 0.0755  data: 0.0000  max mem: 34900 res mem: 44920
2023-09-18T10:12:34 | INFO | utils.basic_utils : Evaluation: Total time: 0:00:21 (0.0873 s / it)
2023-09-18T10:12:36 | INFO | tasks.retrieval_utils : Evaluation time 0:01:28
2023-09-18T10:12:36 | INFO | __main__ : Epoch 2
2023-09-18T10:12:36 | INFO | __main__ : 
           txt_r1  txt_r5  txt_r10  txt_r_mean  img_r1  img_r5  img_r10  img_r_mean  r_mean
test/        43.9    71.6     80.2       65.23    43.2    72.2     81.4       65.60   65.42
test_emb/    40.8    68.5     78.8       62.70    41.1    68.8     77.7       62.53   62.62
2023-09-18T10:12:51 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 1406 batches in total
dataloader index=0 name=video, batch-size=32 length(#batches)=1406 
2023-09-18T10:13:01 | INFO | utils.basic_utils : Train Epoch: [3]  [   0/1406]  eta: 4:02:29  lr: 0.000018  temperature: 0.0164  video-loss_vtc: 0.7149  video-loss_vtm: 0.3124  time: 10.3483  data: 6.2729  max mem: 34900 res mem: 44920
2023-09-18T10:19:57 | INFO | utils.basic_utils : Train Epoch: [3]  [ 100/1406]  eta: 1:31:51  lr: 0.000017  temperature: 0.0162  video-loss_vtc: 0.7849  video-loss_vtm: 0.4276  time: 4.1538  data: 0.0016  max mem: 34900 res mem: 44920
2023-09-18T10:26:52 | INFO | utils.basic_utils : Train Epoch: [3]  [ 200/1406]  eta: 1:24:06  lr: 0.000017  temperature: 0.0162  video-loss_vtc: 0.8988  video-loss_vtm: 0.3340  time: 4.1492  data: 0.0015  max mem: 34900 res mem: 44920
2023-09-18T10:33:47 | INFO | utils.basic_utils : Train Epoch: [3]  [ 300/1406]  eta: 1:16:55  lr: 0.000017  temperature: 0.0161  video-loss_vtc: 0.6724  video-loss_vtm: 0.1991  time: 4.1541  data: 0.0016  max mem: 34900 res mem: 44920
2023-09-18T10:40:42 | INFO | utils.basic_utils : Train Epoch: [3]  [ 400/1406]  eta: 1:09:52  lr: 0.000017  temperature: 0.0160  video-loss_vtc: 0.8214  video-loss_vtm: 0.2524  time: 4.1526  data: 0.0015  max mem: 34900 res mem: 44920
2023-09-18T10:47:38 | INFO | utils.basic_utils : Train Epoch: [3]  [ 500/1406]  eta: 1:02:53  lr: 0.000017  temperature: 0.0162  video-loss_vtc: 0.7870  video-loss_vtm: 0.3212  time: 4.1500  data: 0.0015  max mem: 34900 res mem: 44920
2023-09-18T10:54:33 | INFO | utils.basic_utils : Train Epoch: [3]  [ 600/1406]  eta: 0:55:54  lr: 0.000017  temperature: 0.0162  video-loss_vtc: 0.6826  video-loss_vtm: 0.2919  time: 4.1525  data: 0.0016  max mem: 34900 res mem: 44920
2023-09-18T11:01:28 | INFO | utils.basic_utils : Train Epoch: [3]  [ 700/1406]  eta: 0:48:57  lr: 0.000016  temperature: 0.0162  video-loss_vtc: 0.7792  video-loss_vtm: 0.2318  time: 4.1552  data: 0.0015  max mem: 34900 res mem: 44920
2023-09-18T11:08:24 | INFO | utils.basic_utils : Train Epoch: [3]  [ 800/1406]  eta: 0:42:01  lr: 0.000016  temperature: 0.0161  video-loss_vtc: 0.8665  video-loss_vtm: 0.3076  time: 4.1700  data: 0.0016  max mem: 34900 res mem: 44920
2023-09-18T11:15:19 | INFO | utils.basic_utils : Train Epoch: [3]  [ 900/1406]  eta: 0:35:04  lr: 0.000016  temperature: 0.0161  video-loss_vtc: 0.7112  video-loss_vtm: 0.3249  time: 4.1529  data: 0.0015  max mem: 34900 res mem: 44920
2023-09-18T11:22:14 | INFO | utils.basic_utils : Train Epoch: [3]  [1000/1406]  eta: 0:28:08  lr: 0.000016  temperature: 0.0162  video-loss_vtc: 0.9518  video-loss_vtm: 0.2849  time: 4.1585  data: 0.0017  max mem: 34900 res mem: 44920
2023-09-18T11:29:10 | INFO | utils.basic_utils : Train Epoch: [3]  [1100/1406]  eta: 0:21:12  lr: 0.000016  temperature: 0.0162  video-loss_vtc: 0.6896  video-loss_vtm: 0.2232  time: 4.1521  data: 0.0015  max mem: 34900 res mem: 44920
2023-09-18T11:36:05 | INFO | utils.basic_utils : Train Epoch: [3]  [1200/1406]  eta: 0:14:16  lr: 0.000015  temperature: 0.0161  video-loss_vtc: 0.7554  video-loss_vtm: 0.3242  time: 4.1526  data: 0.0015  max mem: 34900 res mem: 44920
2023-09-18T11:43:01 | INFO | utils.basic_utils : Train Epoch: [3]  [1300/1406]  eta: 0:07:20  lr: 0.000015  temperature: 0.0163  video-loss_vtc: 0.9264  video-loss_vtm: 0.3156  time: 4.1564  data: 0.0016  max mem: 34900 res mem: 44920
2023-09-18T11:49:56 | INFO | utils.basic_utils : Train Epoch: [3]  [1400/1406]  eta: 0:00:24  lr: 0.000015  temperature: 0.0163  video-loss_vtc: 0.9923  video-loss_vtm: 0.2724  time: 4.1526  data: 0.0018  max mem: 34900 res mem: 44920
2023-09-18T11:50:17 | INFO | utils.basic_utils : Train Epoch: [3]  [1405/1406]  eta: 0:00:04  lr: 0.000015  temperature: 0.0163  video-loss_vtc: 0.5632  video-loss_vtm: 0.2759  time: 4.1504  data: 0.0017  max mem: 34900 res mem: 44920
2023-09-18T11:50:17 | INFO | utils.basic_utils : Train Epoch: [3] Total time: 1:37:25 (4.1577 s / it)
2023-09-18T11:50:17 | INFO | __main__ : Averaged train stats: lr: 0.0000  temperature: 0.0162  video-loss_vtc: 0.8096  video-loss_vtm: 0.2920
2023-09-18T11:50:17 | INFO | tasks.retrieval_utils : Start evaluation for media_type=video
2023-09-18T11:50:17 | INFO | tasks.retrieval_utils : Computing dual encoder features...
2023-09-18T11:50:22 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2023-09-18T11:50:22 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2023-09-18T11:50:23 | INFO | utils.basic_utils : extracting image feats  [ 0/32]  eta: 0:03:20    time: 6.2763  data: 5.1429  max mem: 34900 res mem: 44920
2023-09-18T11:50:58 | INFO | utils.basic_utils : extracting image feats  [31/32]  eta: 0:00:01    time: 1.0873  data: 0.0411  max mem: 34900 res mem: 44920
2023-09-18T11:50:58 | INFO | utils.basic_utils : extracting image feats Total time: 0:00:41 (1.2832 s / it)
2023-09-18T11:51:03 | INFO | tasks.retrieval_utils : Finished feature extraction
2023-09-18T11:51:03 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product]
2023-09-18T11:51:03 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product], done!
2023-09-18T11:51:03 | INFO | tasks.retrieval_utils : Rerank dual-encoder results with cross-encoder...
2023-09-18T11:51:03 | INFO | tasks.retrieval_utils : i2t_scores.shape torch.Size([251, 1000])
2023-09-18T11:51:03 | INFO | tasks.retrieval_utils : n_clip_per_video=1, with eval_frame_ensemble=concat
2023-09-18T11:51:03 | INFO | utils.basic_utils : Evaluation:  [  0/251]  eta: 0:00:06    time: 0.0243  data: 0.0005  max mem: 34900 res mem: 44920
2023-09-18T11:51:10 | INFO | utils.basic_utils : Evaluation:  [100/251]  eta: 0:00:10    time: 0.0733  data: 0.0000  max mem: 34900 res mem: 44920
2023-09-18T11:51:18 | INFO | utils.basic_utils : Evaluation:  [200/251]  eta: 0:00:03    time: 0.0747  data: 0.0000  max mem: 34900 res mem: 44920
2023-09-18T11:51:22 | INFO | utils.basic_utils : Evaluation:  [250/251]  eta: 0:00:00    time: 0.0749  data: 0.0000  max mem: 34900 res mem: 44920
2023-09-18T11:51:22 | INFO | utils.basic_utils : Evaluation: Total time: 0:00:18 (0.0739 s / it)
2023-09-18T11:51:22 | INFO | tasks.retrieval_utils : t2i_scores.shape torch.Size([251, 1000])
2023-09-18T11:51:26 | INFO | utils.basic_utils : Evaluation:  [  0/251]  eta: 0:16:18    time: 3.8990  data: 0.0004  max mem: 34900 res mem: 44920
2023-09-18T11:51:33 | INFO | utils.basic_utils : Evaluation:  [100/251]  eta: 0:00:16    time: 0.0746  data: 0.0000  max mem: 34900 res mem: 44920
2023-09-18T11:51:41 | INFO | utils.basic_utils : Evaluation:  [200/251]  eta: 0:00:04    time: 0.0749  data: 0.0000  max mem: 34900 res mem: 44920
2023-09-18T11:51:44 | INFO | utils.basic_utils : Evaluation:  [250/251]  eta: 0:00:00    time: 0.0752  data: 0.0000  max mem: 34900 res mem: 44920
2023-09-18T11:51:44 | INFO | utils.basic_utils : Evaluation: Total time: 0:00:22 (0.0900 s / it)
2023-09-18T11:51:46 | INFO | tasks.retrieval_utils : Evaluation time 0:01:29
2023-09-18T11:51:46 | INFO | __main__ : Epoch 3
2023-09-18T11:51:46 | INFO | __main__ : 
           txt_r1  txt_r5  txt_r10  txt_r_mean  img_r1  img_r5  img_r10  img_r_mean  r_mean
test/        46.1    72.9     80.1       66.37    45.9    72.1     81.2       66.40   66.38
test_emb/    43.0    69.3     78.9       63.73    42.3    69.9     78.5       63.57   63.65
2023-09-18T11:52:02 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 1406 batches in total
dataloader index=0 name=video, batch-size=32 length(#batches)=1406 
2023-09-18T11:52:12 | INFO | utils.basic_utils : Train Epoch: [4]  [   0/1406]  eta: 4:00:02  lr: 0.000015  temperature: 0.0163  video-loss_vtc: 0.7626  video-loss_vtm: 0.2847  time: 10.2438  data: 5.9671  max mem: 34900 res mem: 44920
2023-09-18T11:59:08 | INFO | utils.basic_utils : Train Epoch: [4]  [ 100/1406]  eta: 1:31:56  lr: 0.000015  temperature: 0.0160  video-loss_vtc: 0.6935  video-loss_vtm: 0.3542  time: 4.1561  data: 0.0015  max mem: 34900 res mem: 44920
2023-09-18T12:06:04 | INFO | utils.basic_utils : Train Epoch: [4]  [ 200/1406]  eta: 1:24:12  lr: 0.000015  temperature: 0.0159  video-loss_vtc: 0.5486  video-loss_vtm: 0.1891  time: 4.1534  data: 0.0015  max mem: 34900 res mem: 44920
2023-09-18T12:12:59 | INFO | utils.basic_utils : Train Epoch: [4]  [ 300/1406]  eta: 1:17:00  lr: 0.000014  temperature: 0.0158  video-loss_vtc: 0.7734  video-loss_vtm: 0.2101  time: 4.1564  data: 0.0016  max mem: 34900 res mem: 44920
2023-09-18T12:19:55 | INFO | utils.basic_utils : Train Epoch: [4]  [ 400/1406]  eta: 1:09:58  lr: 0.000014  temperature: 0.0158  video-loss_vtc: 0.5604  video-loss_vtm: 0.1903  time: 4.1539  data: 0.0015  max mem: 34900 res mem: 44920
2023-09-18T12:26:51 | INFO | utils.basic_utils : Train Epoch: [4]  [ 500/1406]  eta: 1:02:57  lr: 0.000014  temperature: 0.0158  video-loss_vtc: 0.7941  video-loss_vtm: 0.2871  time: 4.1604  data: 0.0016  max mem: 34900 res mem: 44920
2023-09-18T12:33:47 | INFO | utils.basic_utils : Train Epoch: [4]  [ 600/1406]  eta: 0:55:59  lr: 0.000014  temperature: 0.0157  video-loss_vtc: 0.5425  video-loss_vtm: 0.1615  time: 4.1563  data: 0.0016  max mem: 34900 res mem: 44920
2023-09-18T12:40:42 | INFO | utils.basic_utils : Train Epoch: [4]  [ 700/1406]  eta: 0:49:01  lr: 0.000013  temperature: 0.0158  video-loss_vtc: 0.6582  video-loss_vtm: 0.2978  time: 4.1574  data: 0.0015  max mem: 34900 res mem: 44920
2023-09-18T12:47:38 | INFO | utils.basic_utils : Train Epoch: [4]  [ 800/1406]  eta: 0:42:03  lr: 0.000013  temperature: 0.0158  video-loss_vtc: 0.7008  video-loss_vtm: 0.3481  time: 4.1550  data: 0.0016  max mem: 34900 res mem: 44920
2023-09-18T12:54:34 | INFO | utils.basic_utils : Train Epoch: [4]  [ 900/1406]  eta: 0:35:06  lr: 0.000013  temperature: 0.0157  video-loss_vtc: 0.7096  video-loss_vtm: 0.2462  time: 4.1558  data: 0.0015  max mem: 34900 res mem: 44920
2023-09-18T13:01:29 | INFO | utils.basic_utils : Train Epoch: [4]  [1000/1406]  eta: 0:28:10  lr: 0.000013  temperature: 0.0158  video-loss_vtc: 0.6389  video-loss_vtm: 0.3216  time: 4.1556  data: 0.0015  max mem: 34900 res mem: 44920
2023-09-18T13:08:25 | INFO | utils.basic_utils : Train Epoch: [4]  [1100/1406]  eta: 0:21:13  lr: 0.000012  temperature: 0.0158  video-loss_vtc: 0.7215  video-loss_vtm: 0.3104  time: 4.1564  data: 0.0015  max mem: 34900 res mem: 44920
2023-09-18T13:15:21 | INFO | utils.basic_utils : Train Epoch: [4]  [1200/1406]  eta: 0:14:17  lr: 0.000012  temperature: 0.0159  video-loss_vtc: 0.4751  video-loss_vtm: 0.2595  time: 4.1561  data: 0.0016  max mem: 34900 res mem: 44920
2023-09-18T13:22:16 | INFO | utils.basic_utils : Train Epoch: [4]  [1300/1406]  eta: 0:07:21  lr: 0.000012  temperature: 0.0159  video-loss_vtc: 0.7728  video-loss_vtm: 0.3604  time: 4.1571  data: 0.0016  max mem: 34900 res mem: 44920
2023-09-18T13:29:12 | INFO | utils.basic_utils : Train Epoch: [4]  [1400/1406]  eta: 0:00:24  lr: 0.000012  temperature: 0.0158  video-loss_vtc: 0.6028  video-loss_vtm: 0.1939  time: 4.1540  data: 0.0016  max mem: 34900 res mem: 44920
2023-09-18T13:29:33 | INFO | utils.basic_utils : Train Epoch: [4]  [1405/1406]  eta: 0:00:04  lr: 0.000012  temperature: 0.0158  video-loss_vtc: 0.6778  video-loss_vtm: 0.3236  time: 4.1532  data: 0.0016  max mem: 34900 res mem: 44920
2023-09-18T13:29:33 | INFO | utils.basic_utils : Train Epoch: [4] Total time: 1:37:31 (4.1616 s / it)
2023-09-18T13:29:33 | INFO | __main__ : Averaged train stats: lr: 0.0000  temperature: 0.0158  video-loss_vtc: 0.7127  video-loss_vtm: 0.2662
2023-09-18T13:29:33 | INFO | tasks.retrieval_utils : Start evaluation for media_type=video
2023-09-18T13:29:33 | INFO | tasks.retrieval_utils : Computing dual encoder features...
2023-09-18T13:29:39 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2023-09-18T13:29:39 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2023-09-18T13:29:40 | INFO | utils.basic_utils : extracting image feats  [ 0/32]  eta: 0:03:17    time: 6.1686  data: 5.0670  max mem: 34900 res mem: 44920
2023-09-18T13:30:14 | INFO | utils.basic_utils : extracting image feats  [31/32]  eta: 0:00:01    time: 1.0853  data: 0.0401  max mem: 34900 res mem: 44920
2023-09-18T13:30:14 | INFO | utils.basic_utils : extracting image feats Total time: 0:00:40 (1.2770 s / it)
2023-09-18T13:30:19 | INFO | tasks.retrieval_utils : Finished feature extraction
2023-09-18T13:30:19 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product]
2023-09-18T13:30:19 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product], done!
2023-09-18T13:30:19 | INFO | tasks.retrieval_utils : Rerank dual-encoder results with cross-encoder...
2023-09-18T13:30:19 | INFO | tasks.retrieval_utils : i2t_scores.shape torch.Size([251, 1000])
2023-09-18T13:30:19 | INFO | tasks.retrieval_utils : n_clip_per_video=1, with eval_frame_ensemble=concat
2023-09-18T13:30:19 | INFO | utils.basic_utils : Evaluation:  [  0/251]  eta: 0:00:05    time: 0.0235  data: 0.0004  max mem: 34900 res mem: 44920
2023-09-18T13:30:27 | INFO | utils.basic_utils : Evaluation:  [100/251]  eta: 0:00:11    time: 0.0747  data: 0.0000  max mem: 34900 res mem: 44920
2023-09-18T13:30:34 | INFO | utils.basic_utils : Evaluation:  [200/251]  eta: 0:00:03    time: 0.0746  data: 0.0000  max mem: 34900 res mem: 44920
2023-09-18T13:30:38 | INFO | utils.basic_utils : Evaluation:  [250/251]  eta: 0:00:00    time: 0.0748  data: 0.0000  max mem: 34900 res mem: 44920
2023-09-18T13:30:38 | INFO | utils.basic_utils : Evaluation: Total time: 0:00:18 (0.0743 s / it)
2023-09-18T13:30:38 | INFO | tasks.retrieval_utils : t2i_scores.shape torch.Size([251, 1000])
2023-09-18T13:30:43 | INFO | utils.basic_utils : Evaluation:  [  0/251]  eta: 0:19:22    time: 4.6308  data: 0.0004  max mem: 34900 res mem: 44920
2023-09-18T13:30:50 | INFO | utils.basic_utils : Evaluation:  [100/251]  eta: 0:00:18    time: 0.0746  data: 0.0000  max mem: 34900 res mem: 44920
2023-09-18T13:30:58 | INFO | utils.basic_utils : Evaluation:  [200/251]  eta: 0:00:04    time: 0.0747  data: 0.0000  max mem: 34900 res mem: 44920
2023-09-18T13:31:01 | INFO | utils.basic_utils : Evaluation:  [250/251]  eta: 0:00:00    time: 0.0751  data: 0.0000  max mem: 34900 res mem: 44920
2023-09-18T13:31:01 | INFO | utils.basic_utils : Evaluation: Total time: 0:00:23 (0.0928 s / it)
2023-09-18T13:31:02 | INFO | tasks.retrieval_utils : Evaluation time 0:01:29
2023-09-18T13:31:03 | INFO | __main__ : Epoch 4
2023-09-18T13:31:03 | INFO | __main__ : 
           txt_r1  txt_r5  txt_r10  txt_r_mean  img_r1  img_r5  img_r10  img_r_mean  r_mean
test/        45.9    72.3     80.3       66.17    45.4    72.7     81.9       66.67   66.42
test_emb/    43.8    70.0     79.9       64.57    41.8    68.6     78.6       63.00   63.78
2023-09-18T13:31:18 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 1406 batches in total
dataloader index=0 name=video, batch-size=32 length(#batches)=1406 
2023-09-18T13:31:28 | INFO | utils.basic_utils : Train Epoch: [5]  [   0/1406]  eta: 3:59:49  lr: 0.000012  temperature: 0.0158  video-loss_vtc: 0.6732  video-loss_vtm: 0.2216  time: 10.2342  data: 5.3845  max mem: 34900 res mem: 44920
2023-09-18T13:38:25 | INFO | utils.basic_utils : Train Epoch: [5]  [ 100/1406]  eta: 1:31:58  lr: 0.000011  temperature: 0.0155  video-loss_vtc: 0.6150  video-loss_vtm: 0.2762  time: 4.1579  data: 0.0016  max mem: 34900 res mem: 44920
2023-09-18T13:45:20 | INFO | utils.basic_utils : Train Epoch: [5]  [ 200/1406]  eta: 1:24:15  lr: 0.000011  temperature: 0.0155  video-loss_vtc: 0.8057  video-loss_vtm: 0.1962  time: 4.1645  data: 0.0016  max mem: 34900 res mem: 44920
2023-09-18T13:52:16 | INFO | utils.basic_utils : Train Epoch: [5]  [ 300/1406]  eta: 1:17:04  lr: 0.000011  temperature: 0.0155  video-loss_vtc: 0.7222  video-loss_vtm: 0.2266  time: 4.1580  data: 0.0017  max mem: 34900 res mem: 44920
2023-09-18T13:59:12 | INFO | utils.basic_utils : Train Epoch: [5]  [ 400/1406]  eta: 1:10:00  lr: 0.000011  temperature: 0.0154  video-loss_vtc: 0.5271  video-loss_vtm: 0.3296  time: 4.1686  data: 0.0017  max mem: 34900 res mem: 44920
2023-09-18T14:06:08 | INFO | utils.basic_utils : Train Epoch: [5]  [ 500/1406]  eta: 1:03:00  lr: 0.000011  temperature: 0.0154  video-loss_vtc: 0.6637  video-loss_vtm: 0.3258  time: 4.1578  data: 0.0017  max mem: 34900 res mem: 44920
2023-09-18T14:13:04 | INFO | utils.basic_utils : Train Epoch: [5]  [ 600/1406]  eta: 0:56:01  lr: 0.000010  temperature: 0.0154  video-loss_vtc: 0.4797  video-loss_vtm: 0.1216  time: 4.1580  data: 0.0016  max mem: 34900 res mem: 44920
2023-09-18T14:20:00 | INFO | utils.basic_utils : Train Epoch: [5]  [ 700/1406]  eta: 0:49:02  lr: 0.000010  temperature: 0.0154  video-loss_vtc: 0.5780  video-loss_vtm: 0.3610  time: 4.1571  data: 0.0016  max mem: 34900 res mem: 44920
2023-09-18T14:26:56 | INFO | utils.basic_utils : Train Epoch: [5]  [ 800/1406]  eta: 0:42:05  lr: 0.000010  temperature: 0.0154  video-loss_vtc: 0.8895  video-loss_vtm: 0.2417  time: 4.1603  data: 0.0016  max mem: 34900 res mem: 44920
2023-09-18T14:33:52 | INFO | utils.basic_utils : Train Epoch: [5]  [ 900/1406]  eta: 0:35:08  lr: 0.000010  temperature: 0.0154  video-loss_vtc: 0.5554  video-loss_vtm: 0.2728  time: 4.1598  data: 0.0016  max mem: 34900 res mem: 44920
2023-09-18T14:40:48 | INFO | utils.basic_utils : Train Epoch: [5]  [1000/1406]  eta: 0:28:11  lr: 0.000009  temperature: 0.0154  video-loss_vtc: 0.6853  video-loss_vtm: 0.2017  time: 4.1620  data: 0.0017  max mem: 34900 res mem: 44920
2023-09-18T14:47:44 | INFO | utils.basic_utils : Train Epoch: [5]  [1100/1406]  eta: 0:21:14  lr: 0.000009  temperature: 0.0154  video-loss_vtc: 0.7334  video-loss_vtm: 0.3387  time: 4.1592  data: 0.0016  max mem: 34900 res mem: 44920
2023-09-18T14:54:40 | INFO | utils.basic_utils : Train Epoch: [5]  [1200/1406]  eta: 0:14:18  lr: 0.000009  temperature: 0.0153  video-loss_vtc: 0.7026  video-loss_vtm: 0.4993  time: 4.1592  data: 0.0016  max mem: 34900 res mem: 44920
2023-09-18T15:01:36 | INFO | utils.basic_utils : Train Epoch: [5]  [1300/1406]  eta: 0:07:21  lr: 0.000009  temperature: 0.0154  video-loss_vtc: 0.8272  video-loss_vtm: 0.2872  time: 4.1597  data: 0.0016  max mem: 34900 res mem: 44920
2023-09-18T15:08:32 | INFO | utils.basic_utils : Train Epoch: [5]  [1400/1406]  eta: 0:00:24  lr: 0.000008  temperature: 0.0153  video-loss_vtc: 0.8213  video-loss_vtm: 0.2288  time: 4.1574  data: 0.0017  max mem: 34900 res mem: 44920
2023-09-18T15:08:53 | INFO | utils.basic_utils : Train Epoch: [5]  [1405/1406]  eta: 0:00:04  lr: 0.000008  temperature: 0.0153  video-loss_vtc: 0.6139  video-loss_vtm: 0.1590  time: 4.1569  data: 0.0016  max mem: 34900 res mem: 44920
2023-09-18T15:08:53 | INFO | utils.basic_utils : Train Epoch: [5] Total time: 1:37:34 (4.1643 s / it)
2023-09-18T15:08:53 | INFO | __main__ : Averaged train stats: lr: 0.0000  temperature: 0.0154  video-loss_vtc: 0.6434  video-loss_vtm: 0.2475
2023-09-18T15:08:53 | INFO | tasks.retrieval_utils : Start evaluation for media_type=video
2023-09-18T15:08:53 | INFO | tasks.retrieval_utils : Computing dual encoder features...
2023-09-18T15:08:58 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2023-09-18T15:08:58 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2023-09-18T15:08:59 | INFO | utils.basic_utils : extracting image feats  [ 0/32]  eta: 0:03:17    time: 6.1590  data: 5.0541  max mem: 34900 res mem: 44920
2023-09-18T15:09:34 | INFO | utils.basic_utils : extracting image feats  [31/32]  eta: 0:00:01    time: 1.0856  data: 0.0390  max mem: 34900 res mem: 44920
2023-09-18T15:09:34 | INFO | utils.basic_utils : extracting image feats Total time: 0:00:40 (1.2793 s / it)
2023-09-18T15:09:39 | INFO | tasks.retrieval_utils : Finished feature extraction
2023-09-18T15:09:39 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product]
2023-09-18T15:09:39 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product], done!
2023-09-18T15:09:39 | INFO | tasks.retrieval_utils : Rerank dual-encoder results with cross-encoder...
2023-09-18T15:09:39 | INFO | tasks.retrieval_utils : i2t_scores.shape torch.Size([251, 1000])
2023-09-18T15:09:39 | INFO | tasks.retrieval_utils : n_clip_per_video=1, with eval_frame_ensemble=concat
2023-09-18T15:09:39 | INFO | utils.basic_utils : Evaluation:  [  0/251]  eta: 0:00:05    time: 0.0232  data: 0.0005  max mem: 34900 res mem: 44920
2023-09-18T15:09:47 | INFO | utils.basic_utils : Evaluation:  [100/251]  eta: 0:00:11    time: 0.0747  data: 0.0000  max mem: 34900 res mem: 44920
2023-09-18T15:09:54 | INFO | utils.basic_utils : Evaluation:  [200/251]  eta: 0:00:03    time: 0.0743  data: 0.0000  max mem: 34900 res mem: 44920
2023-09-18T15:09:58 | INFO | utils.basic_utils : Evaluation:  [250/251]  eta: 0:00:00    time: 0.0744  data: 0.0000  max mem: 34900 res mem: 44920
2023-09-18T15:09:58 | INFO | utils.basic_utils : Evaluation: Total time: 0:00:18 (0.0742 s / it)
2023-09-18T15:09:58 | INFO | tasks.retrieval_utils : t2i_scores.shape torch.Size([251, 1000])
2023-09-18T15:10:03 | INFO | utils.basic_utils : Evaluation:  [  0/251]  eta: 0:22:47    time: 5.4500  data: 0.0004  max mem: 34900 res mem: 44920
2023-09-18T15:10:11 | INFO | utils.basic_utils : Evaluation:  [100/251]  eta: 0:00:19    time: 0.0744  data: 0.0000  max mem: 34900 res mem: 44920
2023-09-18T15:10:18 | INFO | utils.basic_utils : Evaluation:  [200/251]  eta: 0:00:05    time: 0.0747  data: 0.0000  max mem: 34900 res mem: 44920
2023-09-18T15:10:22 | INFO | utils.basic_utils : Evaluation:  [250/251]  eta: 0:00:00    time: 0.0748  data: 0.0000  max mem: 34900 res mem: 44920
2023-09-18T15:10:22 | INFO | utils.basic_utils : Evaluation: Total time: 0:00:24 (0.0960 s / it)
2023-09-18T15:10:22 | INFO | tasks.retrieval_utils : Evaluation time 0:01:29
2023-09-18T15:10:22 | INFO | __main__ : Epoch 5
2023-09-18T15:10:22 | INFO | __main__ : 
           txt_r1  txt_r5  txt_r10  txt_r_mean  img_r1  img_r5  img_r10  img_r_mean  r_mean
test/        45.2    71.8     79.6       65.53    46.2    73.0     80.9       66.70   66.12
test_emb/    44.3    69.8     79.5       64.53    42.5    69.3     78.9       63.57   64.05
2023-09-18T15:10:22 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 1406 batches in total
dataloader index=0 name=video, batch-size=32 length(#batches)=1406 
2023-09-18T15:10:33 | INFO | utils.basic_utils : Train Epoch: [6]  [   0/1406]  eta: 3:55:49  lr: 0.000008  temperature: 0.0153  video-loss_vtc: 0.6763  video-loss_vtm: 0.2317  time: 10.0639  data: 6.0127  max mem: 34900 res mem: 44920
2023-09-18T15:17:29 | INFO | utils.basic_utils : Train Epoch: [6]  [ 100/1406]  eta: 1:31:55  lr: 0.000008  temperature: 0.0152  video-loss_vtc: 0.7085  video-loss_vtm: 0.2019  time: 4.1633  data: 0.0016  max mem: 34900 res mem: 44920
2023-09-18T15:24:25 | INFO | utils.basic_utils : Train Epoch: [6]  [ 200/1406]  eta: 1:24:15  lr: 0.000008  temperature: 0.0152  video-loss_vtc: 0.6434  video-loss_vtm: 0.3005  time: 4.1569  data: 0.0019  max mem: 34900 res mem: 44920
2023-09-18T15:31:21 | INFO | utils.basic_utils : Train Epoch: [6]  [ 300/1406]  eta: 1:17:03  lr: 0.000008  temperature: 0.0151  video-loss_vtc: 0.3539  video-loss_vtm: 0.1361  time: 4.1587  data: 0.0016  max mem: 34900 res mem: 44920
2023-09-18T15:38:17 | INFO | utils.basic_utils : Train Epoch: [6]  [ 400/1406]  eta: 1:10:01  lr: 0.000007  temperature: 0.0151  video-loss_vtc: 0.6480  video-loss_vtm: 0.2746  time: 4.1603  data: 0.0017  max mem: 34900 res mem: 44920
2023-09-18T15:45:13 | INFO | utils.basic_utils : Train Epoch: [6]  [ 500/1406]  eta: 1:03:00  lr: 0.000007  temperature: 0.0151  video-loss_vtc: 0.6324  video-loss_vtm: 0.4341  time: 4.1631  data: 0.0016  max mem: 34900 res mem: 44920
2023-09-18T15:52:10 | INFO | utils.basic_utils : Train Epoch: [6]  [ 600/1406]  eta: 0:56:02  lr: 0.000007  temperature: 0.0151  video-loss_vtc: 0.6582  video-loss_vtm: 0.1812  time: 4.1613  data: 0.0016  max mem: 34900 res mem: 44920
2023-09-18T15:59:06 | INFO | utils.basic_utils : Train Epoch: [6]  [ 700/1406]  eta: 0:49:04  lr: 0.000007  temperature: 0.0150  video-loss_vtc: 0.5835  video-loss_vtm: 0.2473  time: 4.1611  data: 0.0021  max mem: 34900 res mem: 44920
2023-09-18T16:06:02 | INFO | utils.basic_utils : Train Epoch: [6]  [ 800/1406]  eta: 0:42:06  lr: 0.000006  temperature: 0.0150  video-loss_vtc: 0.6594  video-loss_vtm: 0.3675  time: 4.1586  data: 0.0025  max mem: 34900 res mem: 44920
2023-09-18T16:12:59 | INFO | utils.basic_utils : Train Epoch: [6]  [ 900/1406]  eta: 0:35:09  lr: 0.000006  temperature: 0.0149  video-loss_vtc: 0.5582  video-loss_vtm: 0.2070  time: 4.1622  data: 0.0016  max mem: 34900 res mem: 44920
2023-09-18T16:19:55 | INFO | utils.basic_utils : Train Epoch: [6]  [1000/1406]  eta: 0:28:12  lr: 0.000006  temperature: 0.0150  video-loss_vtc: 0.5148  video-loss_vtm: 0.2309  time: 4.1654  data: 0.0017  max mem: 34900 res mem: 44920
2023-09-18T16:26:52 | INFO | utils.basic_utils : Train Epoch: [6]  [1100/1406]  eta: 0:21:15  lr: 0.000006  temperature: 0.0150  video-loss_vtc: 0.5947  video-loss_vtm: 0.2634  time: 4.1611  data: 0.0017  max mem: 34900 res mem: 44920
2023-09-18T16:33:48 | INFO | utils.basic_utils : Train Epoch: [6]  [1200/1406]  eta: 0:14:18  lr: 0.000005  temperature: 0.0150  video-loss_vtc: 0.5124  video-loss_vtm: 0.4671  time: 4.1679  data: 0.0017  max mem: 34900 res mem: 44920
2023-09-18T16:40:45 | INFO | utils.basic_utils : Train Epoch: [6]  [1300/1406]  eta: 0:07:21  lr: 0.000005  temperature: 0.0149  video-loss_vtc: 0.6256  video-loss_vtm: 0.2595  time: 4.1643  data: 0.0021  max mem: 34900 res mem: 44920
2023-09-18T16:47:41 | INFO | utils.basic_utils : Train Epoch: [6]  [1400/1406]  eta: 0:00:25  lr: 0.000005  temperature: 0.0149  video-loss_vtc: 0.5816  video-loss_vtm: 0.2496  time: 4.1559  data: 0.0024  max mem: 34900 res mem: 44920
2023-09-18T16:48:02 | INFO | utils.basic_utils : Train Epoch: [6]  [1405/1406]  eta: 0:00:04  lr: 0.000005  temperature: 0.0149  video-loss_vtc: 0.8397  video-loss_vtm: 0.2594  time: 4.1538  data: 0.0021  max mem: 34900 res mem: 44920
2023-09-18T16:48:02 | INFO | utils.basic_utils : Train Epoch: [6] Total time: 1:37:39 (4.1672 s / it)
2023-09-18T16:48:02 | INFO | __main__ : Averaged train stats: lr: 0.0000  temperature: 0.0151  video-loss_vtc: 0.5915  video-loss_vtm: 0.2328
2023-09-18T16:48:02 | INFO | tasks.retrieval_utils : Start evaluation for media_type=video
2023-09-18T16:48:02 | INFO | tasks.retrieval_utils : Computing dual encoder features...
2023-09-18T16:48:07 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2023-09-18T16:48:07 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2023-09-18T16:48:08 | INFO | utils.basic_utils : extracting image feats  [ 0/32]  eta: 0:03:19    time: 6.2431  data: 5.0789  max mem: 34900 res mem: 44920
2023-09-18T16:48:43 | INFO | utils.basic_utils : extracting image feats  [31/32]  eta: 0:00:01    time: 1.0948  data: 0.0399  max mem: 34900 res mem: 44920
2023-09-18T16:48:43 | INFO | utils.basic_utils : extracting image feats Total time: 0:00:41 (1.2978 s / it)
2023-09-18T16:48:50 | INFO | tasks.retrieval_utils : Finished feature extraction
2023-09-18T16:48:50 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product]
2023-09-18T16:48:50 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product], done!
2023-09-18T16:48:50 | INFO | tasks.retrieval_utils : Rerank dual-encoder results with cross-encoder...
2023-09-18T16:48:50 | INFO | tasks.retrieval_utils : i2t_scores.shape torch.Size([251, 1000])
2023-09-18T16:48:50 | INFO | tasks.retrieval_utils : n_clip_per_video=1, with eval_frame_ensemble=concat
2023-09-18T16:48:50 | INFO | utils.basic_utils : Evaluation:  [  0/251]  eta: 0:00:05    time: 0.0229  data: 0.0006  max mem: 34900 res mem: 44920
2023-09-18T16:48:57 | INFO | utils.basic_utils : Evaluation:  [100/251]  eta: 0:00:11    time: 0.0749  data: 0.0000  max mem: 34900 res mem: 44920
2023-09-18T16:49:05 | INFO | utils.basic_utils : Evaluation:  [200/251]  eta: 0:00:03    time: 0.0743  data: 0.0000  max mem: 34900 res mem: 44920
2023-09-18T16:49:08 | INFO | utils.basic_utils : Evaluation:  [250/251]  eta: 0:00:00    time: 0.0752  data: 0.0000  max mem: 34900 res mem: 44920
2023-09-18T16:49:08 | INFO | utils.basic_utils : Evaluation: Total time: 0:00:18 (0.0742 s / it)
2023-09-18T16:49:08 | INFO | tasks.retrieval_utils : t2i_scores.shape torch.Size([251, 1000])
2023-09-18T16:49:13 | INFO | utils.basic_utils : Evaluation:  [  0/251]  eta: 0:18:14    time: 4.3621  data: 0.0004  max mem: 34900 res mem: 44920
2023-09-18T16:49:20 | INFO | utils.basic_utils : Evaluation:  [100/251]  eta: 0:00:17    time: 0.0744  data: 0.0000  max mem: 34900 res mem: 44920
2023-09-18T16:49:28 | INFO | utils.basic_utils : Evaluation:  [200/251]  eta: 0:00:04    time: 0.0747  data: 0.0000  max mem: 34900 res mem: 44920
2023-09-18T16:49:31 | INFO | utils.basic_utils : Evaluation:  [250/251]  eta: 0:00:00    time: 0.0748  data: 0.0000  max mem: 34900 res mem: 44920
2023-09-18T16:49:31 | INFO | utils.basic_utils : Evaluation: Total time: 0:00:23 (0.0916 s / it)
2023-09-18T16:49:31 | INFO | tasks.retrieval_utils : Evaluation time 0:01:29
2023-09-18T16:49:32 | INFO | __main__ : Epoch 6
2023-09-18T16:49:32 | INFO | __main__ : 
           txt_r1  txt_r5  txt_r10  txt_r_mean  img_r1  img_r5  img_r10  img_r_mean  r_mean
test/        47.2    71.5     79.7       66.13    46.0    72.4     81.9       66.77   66.45
test_emb/    42.9    69.4     78.6       63.63    42.6    69.0     78.9       63.50   63.57
2023-09-18T16:49:48 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 1406 batches in total
dataloader index=0 name=video, batch-size=32 length(#batches)=1406 
2023-09-18T16:49:58 | INFO | utils.basic_utils : Train Epoch: [7]  [   0/1406]  eta: 3:59:54  lr: 0.000005  temperature: 0.0149  video-loss_vtc: 0.4504  video-loss_vtm: 0.3099  time: 10.2378  data: 6.1811  max mem: 34900 res mem: 44920
2023-09-18T16:56:55 | INFO | utils.basic_utils : Train Epoch: [7]  [ 100/1406]  eta: 1:32:08  lr: 0.000005  temperature: 0.0148  video-loss_vtc: 0.6341  video-loss_vtm: 0.1889  time: 4.1652  data: 0.0016  max mem: 34900 res mem: 44920
2023-09-18T17:03:52 | INFO | utils.basic_utils : Train Epoch: [7]  [ 200/1406]  eta: 1:24:26  lr: 0.000005  temperature: 0.0148  video-loss_vtc: 0.5836  video-loss_vtm: 0.2462  time: 4.1600  data: 0.0017  max mem: 34900 res mem: 44920
2023-09-18T17:10:49 | INFO | utils.basic_utils : Train Epoch: [7]  [ 300/1406]  eta: 1:17:13  lr: 0.000004  temperature: 0.0148  video-loss_vtc: 0.7683  video-loss_vtm: 0.2708  time: 4.1678  data: 0.0016  max mem: 34900 res mem: 44920
2023-09-18T17:17:45 | INFO | utils.basic_utils : Train Epoch: [7]  [ 400/1406]  eta: 1:10:08  lr: 0.000004  temperature: 0.0148  video-loss_vtc: 0.5677  video-loss_vtm: 0.1683  time: 4.1655  data: 0.0017  max mem: 34900 res mem: 44920
2023-09-18T17:24:42 | INFO | utils.basic_utils : Train Epoch: [7]  [ 500/1406]  eta: 1:03:06  lr: 0.000004  temperature: 0.0147  video-loss_vtc: 0.4831  video-loss_vtm: 0.2598  time: 4.1621  data: 0.0016  max mem: 34900 res mem: 44920
2023-09-18T17:31:38 | INFO | utils.basic_utils : Train Epoch: [7]  [ 600/1406]  eta: 0:56:06  lr: 0.000004  temperature: 0.0147  video-loss_vtc: 0.5756  video-loss_vtm: 0.3095  time: 4.1651  data: 0.0016  max mem: 34900 res mem: 44920
2023-09-18T17:38:35 | INFO | utils.basic_utils : Train Epoch: [7]  [ 700/1406]  eta: 0:49:07  lr: 0.000004  temperature: 0.0147  video-loss_vtc: 0.4968  video-loss_vtm: 0.2629  time: 4.1660  data: 0.0016  max mem: 34900 res mem: 44920
2023-09-18T17:45:31 | INFO | utils.basic_utils : Train Epoch: [7]  [ 800/1406]  eta: 0:42:09  lr: 0.000003  temperature: 0.0147  video-loss_vtc: 0.4487  video-loss_vtm: 0.2796  time: 4.1637  data: 0.0017  max mem: 34900 res mem: 44920
2023-09-18T17:52:28 | INFO | utils.basic_utils : Train Epoch: [7]  [ 900/1406]  eta: 0:35:11  lr: 0.000003  temperature: 0.0147  video-loss_vtc: 0.4578  video-loss_vtm: 0.1566  time: 4.1647  data: 0.0016  max mem: 34900 res mem: 44920
2023-09-18T17:59:24 | INFO | utils.basic_utils : Train Epoch: [7]  [1000/1406]  eta: 0:28:14  lr: 0.000003  temperature: 0.0148  video-loss_vtc: 0.4666  video-loss_vtm: 0.1784  time: 4.1682  data: 0.0016  max mem: 34900 res mem: 44920
2023-09-18T18:06:21 | INFO | utils.basic_utils : Train Epoch: [7]  [1100/1406]  eta: 0:21:16  lr: 0.000003  temperature: 0.0147  video-loss_vtc: 0.3903  video-loss_vtm: 0.1316  time: 4.1654  data: 0.0016  max mem: 34900 res mem: 44920
2023-09-18T18:13:18 | INFO | utils.basic_utils : Train Epoch: [7]  [1200/1406]  eta: 0:14:19  lr: 0.000003  temperature: 0.0147  video-loss_vtc: 0.5439  video-loss_vtm: 0.2058  time: 4.1656  data: 0.0017  max mem: 34900 res mem: 44920
2023-09-18T18:20:14 | INFO | utils.basic_utils : Train Epoch: [7]  [1300/1406]  eta: 0:07:22  lr: 0.000003  temperature: 0.0146  video-loss_vtc: 0.5656  video-loss_vtm: 0.2481  time: 4.1671  data: 0.0016  max mem: 34900 res mem: 44920
2023-09-18T18:27:11 | INFO | utils.basic_utils : Train Epoch: [7]  [1400/1406]  eta: 0:00:25  lr: 0.000002  temperature: 0.0146  video-loss_vtc: 0.5573  video-loss_vtm: 0.3111  time: 4.1587  data: 0.0018  max mem: 34900 res mem: 44920
2023-09-18T18:27:32 | INFO | utils.basic_utils : Train Epoch: [7]  [1405/1406]  eta: 0:00:04  lr: 0.000002  temperature: 0.0146  video-loss_vtc: 0.5571  video-loss_vtm: 0.2477  time: 4.1550  data: 0.0017  max mem: 34900 res mem: 44920
2023-09-18T18:27:32 | INFO | utils.basic_utils : Train Epoch: [7] Total time: 1:37:43 (4.1706 s / it)
2023-09-18T18:27:32 | INFO | __main__ : Averaged train stats: lr: 0.0000  temperature: 0.0147  video-loss_vtc: 0.5543  video-loss_vtm: 0.2203
2023-09-18T18:27:32 | INFO | tasks.retrieval_utils : Start evaluation for media_type=video
2023-09-18T18:27:32 | INFO | tasks.retrieval_utils : Computing dual encoder features...
2023-09-18T18:27:37 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2023-09-18T18:27:37 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2023-09-18T18:27:38 | INFO | utils.basic_utils : extracting image feats  [ 0/32]  eta: 0:03:21    time: 6.2976  data: 5.1450  max mem: 34900 res mem: 44920
2023-09-18T18:28:13 | INFO | utils.basic_utils : extracting image feats  [31/32]  eta: 0:00:01    time: 1.0822  data: 0.0398  max mem: 34900 res mem: 44920
2023-09-18T18:28:13 | INFO | utils.basic_utils : extracting image feats Total time: 0:00:41 (1.2881 s / it)
2023-09-18T18:28:18 | INFO | tasks.retrieval_utils : Finished feature extraction
2023-09-18T18:28:18 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product]
2023-09-18T18:28:18 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product], done!
2023-09-18T18:28:18 | INFO | tasks.retrieval_utils : Rerank dual-encoder results with cross-encoder...
2023-09-18T18:28:18 | INFO | tasks.retrieval_utils : i2t_scores.shape torch.Size([251, 1000])
2023-09-18T18:28:18 | INFO | tasks.retrieval_utils : n_clip_per_video=1, with eval_frame_ensemble=concat
2023-09-18T18:28:18 | INFO | utils.basic_utils : Evaluation:  [  0/251]  eta: 0:00:05    time: 0.0206  data: 0.0004  max mem: 34900 res mem: 44920
2023-09-18T18:28:25 | INFO | utils.basic_utils : Evaluation:  [100/251]  eta: 0:00:10    time: 0.0732  data: 0.0000  max mem: 34900 res mem: 44920
2023-09-18T18:28:33 | INFO | utils.basic_utils : Evaluation:  [200/251]  eta: 0:00:03    time: 0.0746  data: 0.0000  max mem: 34900 res mem: 44920
2023-09-18T18:28:36 | INFO | utils.basic_utils : Evaluation:  [250/251]  eta: 0:00:00    time: 0.0748  data: 0.0000  max mem: 34900 res mem: 44920
2023-09-18T18:28:36 | INFO | utils.basic_utils : Evaluation: Total time: 0:00:18 (0.0737 s / it)
2023-09-18T18:28:36 | INFO | tasks.retrieval_utils : t2i_scores.shape torch.Size([251, 1000])
2023-09-18T18:28:40 | INFO | utils.basic_utils : Evaluation:  [  0/251]  eta: 0:13:16    time: 3.1718  data: 0.0004  max mem: 34900 res mem: 44920
2023-09-18T18:28:47 | INFO | utils.basic_utils : Evaluation:  [100/251]  eta: 0:00:15    time: 0.0747  data: 0.0000  max mem: 34900 res mem: 44920
2023-09-18T18:28:55 | INFO | utils.basic_utils : Evaluation:  [200/251]  eta: 0:00:04    time: 0.0750  data: 0.0000  max mem: 34900 res mem: 44920
2023-09-18T18:28:58 | INFO | utils.basic_utils : Evaluation:  [250/251]  eta: 0:00:00    time: 0.0753  data: 0.0000  max mem: 34900 res mem: 44920
2023-09-18T18:28:58 | INFO | utils.basic_utils : Evaluation: Total time: 0:00:21 (0.0872 s / it)
2023-09-18T18:29:01 | INFO | tasks.retrieval_utils : Evaluation time 0:01:29
2023-09-18T18:29:01 | INFO | __main__ : Epoch 7
2023-09-18T18:29:01 | INFO | __main__ : 
           txt_r1  txt_r5  txt_r10  txt_r_mean  img_r1  img_r5  img_r10  img_r_mean  r_mean
test/        46.6    71.2     79.4       65.73    45.8    72.3     81.5       66.53   66.13
test_emb/    43.5    69.7     78.8       64.00    42.7    68.6     78.4       63.23   63.62
2023-09-18T18:29:01 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 1406 batches in total
dataloader index=0 name=video, batch-size=32 length(#batches)=1406 
2023-09-18T18:29:11 | INFO | utils.basic_utils : Train Epoch: [8]  [   0/1406]  eta: 3:55:20  lr: 0.000002  temperature: 0.0146  video-loss_vtc: 0.4653  video-loss_vtm: 0.1317  time: 10.0429  data: 5.2307  max mem: 34900 res mem: 44920
2023-09-18T18:36:08 | INFO | utils.basic_utils : Train Epoch: [8]  [ 100/1406]  eta: 1:32:03  lr: 0.000002  temperature: 0.0146  video-loss_vtc: 0.4702  video-loss_vtm: 0.2904  time: 4.1663  data: 0.0016  max mem: 34900 res mem: 44920
2023-09-18T18:43:05 | INFO | utils.basic_utils : Train Epoch: [8]  [ 200/1406]  eta: 1:24:21  lr: 0.000002  temperature: 0.0146  video-loss_vtc: 0.5165  video-loss_vtm: 0.1842  time: 4.1607  data: 0.0016  max mem: 34900 res mem: 44920
2023-09-18T18:50:01 | INFO | utils.basic_utils : Train Epoch: [8]  [ 300/1406]  eta: 1:17:09  lr: 0.000002  temperature: 0.0146  video-loss_vtc: 0.5218  video-loss_vtm: 0.1385  time: 4.1645  data: 0.0017  max mem: 34900 res mem: 44920
2023-09-18T18:56:58 | INFO | utils.basic_utils : Train Epoch: [8]  [ 400/1406]  eta: 1:10:05  lr: 0.000002  temperature: 0.0146  video-loss_vtc: 0.4401  video-loss_vtm: 0.2371  time: 4.1663  data: 0.0017  max mem: 34900 res mem: 44920
2023-09-18T19:03:54 | INFO | utils.basic_utils : Train Epoch: [8]  [ 500/1406]  eta: 1:03:04  lr: 0.000002  temperature: 0.0145  video-loss_vtc: 0.5559  video-loss_vtm: 0.1373  time: 4.1634  data: 0.0016  max mem: 34900 res mem: 44920
2023-09-18T19:10:50 | INFO | utils.basic_utils : Train Epoch: [8]  [ 600/1406]  eta: 0:56:04  lr: 0.000001  temperature: 0.0145  video-loss_vtc: 0.3966  video-loss_vtm: 0.2670  time: 4.1617  data: 0.0016  max mem: 34900 res mem: 44920
2023-09-18T19:17:47 | INFO | utils.basic_utils : Train Epoch: [8]  [ 700/1406]  eta: 0:49:06  lr: 0.000001  temperature: 0.0145  video-loss_vtc: 0.7658  video-loss_vtm: 0.2191  time: 4.1669  data: 0.0016  max mem: 34900 res mem: 44920
2023-09-18T19:24:43 | INFO | utils.basic_utils : Train Epoch: [8]  [ 800/1406]  eta: 0:42:08  lr: 0.000001  temperature: 0.0145  video-loss_vtc: 0.4487  video-loss_vtm: 0.2070  time: 4.1707  data: 0.0017  max mem: 34900 res mem: 44920
2023-09-18T19:31:40 | INFO | utils.basic_utils : Train Epoch: [8]  [ 900/1406]  eta: 0:35:11  lr: 0.000001  temperature: 0.0145  video-loss_vtc: 0.5313  video-loss_vtm: 0.1805  time: 4.1684  data: 0.0016  max mem: 34900 res mem: 44920
2023-09-18T19:38:36 | INFO | utils.basic_utils : Train Epoch: [8]  [1000/1406]  eta: 0:28:13  lr: 0.000001  temperature: 0.0145  video-loss_vtc: 0.5532  video-loss_vtm: 0.3721  time: 4.1663  data: 0.0017  max mem: 34900 res mem: 44920
2023-09-18T19:45:33 | INFO | utils.basic_utils : Train Epoch: [8]  [1100/1406]  eta: 0:21:16  lr: 0.000001  temperature: 0.0145  video-loss_vtc: 0.5655  video-loss_vtm: 0.1651  time: 4.1664  data: 0.0016  max mem: 34900 res mem: 44920
2023-09-18T19:52:29 | INFO | utils.basic_utils : Train Epoch: [8]  [1200/1406]  eta: 0:14:19  lr: 0.000001  temperature: 0.0145  video-loss_vtc: 0.7396  video-loss_vtm: 0.3820  time: 4.1602  data: 0.0016  max mem: 34900 res mem: 44920
2023-09-18T19:59:25 | INFO | utils.basic_utils : Train Epoch: [8]  [1300/1406]  eta: 0:07:21  lr: 0.000001  temperature: 0.0145  video-loss_vtc: 0.6952  video-loss_vtm: 0.4071  time: 4.1583  data: 0.0015  max mem: 34900 res mem: 44920
2023-09-18T20:06:21 | INFO | utils.basic_utils : Train Epoch: [8]  [1400/1406]  eta: 0:00:25  lr: 0.000001  temperature: 0.0145  video-loss_vtc: 0.5500  video-loss_vtm: 0.1777  time: 4.1527  data: 0.0016  max mem: 34900 res mem: 44920
2023-09-18T20:06:42 | INFO | utils.basic_utils : Train Epoch: [8]  [1405/1406]  eta: 0:00:04  lr: 0.000001  temperature: 0.0145  video-loss_vtc: 0.4120  video-loss_vtm: 0.2516  time: 4.1525  data: 0.0016  max mem: 34900 res mem: 44920
2023-09-18T20:06:42 | INFO | utils.basic_utils : Train Epoch: [8] Total time: 1:37:40 (4.1685 s / it)
2023-09-18T20:06:42 | INFO | __main__ : Averaged train stats: lr: 0.0000  temperature: 0.0146  video-loss_vtc: 0.5325  video-loss_vtm: 0.2136
2023-09-18T20:06:42 | INFO | tasks.retrieval_utils : Start evaluation for media_type=video
2023-09-18T20:06:42 | INFO | tasks.retrieval_utils : Computing dual encoder features...
2023-09-18T20:06:48 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2023-09-18T20:06:48 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2023-09-18T20:06:49 | INFO | utils.basic_utils : extracting image feats  [ 0/32]  eta: 0:03:27    time: 6.4861  data: 5.3442  max mem: 34900 res mem: 44920
2023-09-18T20:07:24 | INFO | utils.basic_utils : extracting image feats  [31/32]  eta: 0:00:01    time: 1.1066  data: 0.0451  max mem: 34900 res mem: 44920
2023-09-18T20:07:24 | INFO | utils.basic_utils : extracting image feats Total time: 0:00:42 (1.3138 s / it)
2023-09-18T20:07:29 | INFO | tasks.retrieval_utils : Finished feature extraction
2023-09-18T20:07:29 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product]
2023-09-18T20:07:29 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product], done!
2023-09-18T20:07:29 | INFO | tasks.retrieval_utils : Rerank dual-encoder results with cross-encoder...
2023-09-18T20:07:29 | INFO | tasks.retrieval_utils : i2t_scores.shape torch.Size([251, 1000])
2023-09-18T20:07:29 | INFO | tasks.retrieval_utils : n_clip_per_video=1, with eval_frame_ensemble=concat
2023-09-18T20:07:29 | INFO | utils.basic_utils : Evaluation:  [  0/251]  eta: 0:00:05    time: 0.0213  data: 0.0005  max mem: 34900 res mem: 44920
2023-09-18T20:07:36 | INFO | utils.basic_utils : Evaluation:  [100/251]  eta: 0:00:11    time: 0.0746  data: 0.0000  max mem: 34900 res mem: 44920
2023-09-18T20:07:44 | INFO | utils.basic_utils : Evaluation:  [200/251]  eta: 0:00:03    time: 0.0746  data: 0.0000  max mem: 34900 res mem: 44920
2023-09-18T20:07:48 | INFO | utils.basic_utils : Evaluation:  [250/251]  eta: 0:00:00    time: 0.0747  data: 0.0000  max mem: 34900 res mem: 44920
2023-09-18T20:07:48 | INFO | utils.basic_utils : Evaluation: Total time: 0:00:18 (0.0744 s / it)
2023-09-18T20:07:48 | INFO | tasks.retrieval_utils : t2i_scores.shape torch.Size([251, 1000])
2023-09-18T20:07:51 | INFO | utils.basic_utils : Evaluation:  [  0/251]  eta: 0:12:10    time: 2.9086  data: 0.0003  max mem: 34900 res mem: 44920
2023-09-18T20:07:58 | INFO | utils.basic_utils : Evaluation:  [100/251]  eta: 0:00:15    time: 0.0746  data: 0.0000  max mem: 34900 res mem: 44920
2023-09-18T20:08:06 | INFO | utils.basic_utils : Evaluation:  [200/251]  eta: 0:00:04    time: 0.0749  data: 0.0000  max mem: 34900 res mem: 44920
2023-09-18T20:08:09 | INFO | utils.basic_utils : Evaluation:  [250/251]  eta: 0:00:00    time: 0.0752  data: 0.0000  max mem: 34900 res mem: 44920
2023-09-18T20:08:09 | INFO | utils.basic_utils : Evaluation: Total time: 0:00:21 (0.0861 s / it)
2023-09-18T20:08:10 | INFO | tasks.retrieval_utils : Evaluation time 0:01:28
2023-09-18T20:08:11 | INFO | __main__ : Epoch 8
2023-09-18T20:08:11 | INFO | __main__ : 
           txt_r1  txt_r5  txt_r10  txt_r_mean  img_r1  img_r5  img_r10  img_r_mean  r_mean
test/        46.9    71.0     79.3       65.73    46.3    73.2     81.8        67.1   66.42
test_emb/    43.5    69.8     78.5       63.93    42.3    68.2     79.1        63.2   63.57
2023-09-18T20:08:11 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 1406 batches in total
dataloader index=0 name=video, batch-size=32 length(#batches)=1406 
2023-09-18T20:08:21 | INFO | utils.basic_utils : Train Epoch: [9]  [   0/1406]  eta: 4:02:41  lr: 0.000001  temperature: 0.0145  video-loss_vtc: 0.5116  video-loss_vtm: 0.1287  time: 10.3565  data: 5.5912  max mem: 34900 res mem: 44920
2023-09-18T20:15:18 | INFO | utils.basic_utils : Train Epoch: [9]  [ 100/1406]  eta: 1:32:01  lr: 0.000001  temperature: 0.0145  video-loss_vtc: 0.5230  video-loss_vtm: 0.2291  time: 4.1631  data: 0.0017  max mem: 34900 res mem: 44920
2023-09-18T20:22:14 | INFO | utils.basic_utils : Train Epoch: [9]  [ 200/1406]  eta: 1:24:17  lr: 0.000000  temperature: 0.0145  video-loss_vtc: 0.4663  video-loss_vtm: 0.2879  time: 4.1557  data: 0.0016  max mem: 34900 res mem: 44920
2023-09-18T20:29:09 | INFO | utils.basic_utils : Train Epoch: [9]  [ 300/1406]  eta: 1:17:05  lr: 0.000000  temperature: 0.0145  video-loss_vtc: 0.4989  video-loss_vtm: 0.2364  time: 4.1593  data: 0.0016  max mem: 34900 res mem: 44920
2023-09-18T20:36:06 | INFO | utils.basic_utils : Train Epoch: [9]  [ 400/1406]  eta: 1:10:02  lr: 0.000000  temperature: 0.0145  video-loss_vtc: 0.5661  video-loss_vtm: 0.1216  time: 4.1617  data: 0.0015  max mem: 34900 res mem: 44920
2023-09-18T20:43:02 | INFO | utils.basic_utils : Train Epoch: [9]  [ 500/1406]  eta: 1:03:01  lr: 0.000000  temperature: 0.0145  video-loss_vtc: 0.5165  video-loss_vtm: 0.1231  time: 4.1593  data: 0.0016  max mem: 34900 res mem: 44920
2023-09-18T20:49:58 | INFO | utils.basic_utils : Train Epoch: [9]  [ 600/1406]  eta: 0:56:02  lr: 0.000000  temperature: 0.0145  video-loss_vtc: 0.7273  video-loss_vtm: 0.1784  time: 4.1586  data: 0.0016  max mem: 34900 res mem: 44920
2023-09-18T20:56:54 | INFO | utils.basic_utils : Train Epoch: [9]  [ 700/1406]  eta: 0:49:04  lr: 0.000000  temperature: 0.0145  video-loss_vtc: 0.5537  video-loss_vtm: 0.1407  time: 4.1589  data: 0.0016  max mem: 34900 res mem: 44920
2023-09-18T21:03:50 | INFO | utils.basic_utils : Train Epoch: [9]  [ 800/1406]  eta: 0:42:06  lr: 0.000000  temperature: 0.0145  video-loss_vtc: 0.4805  video-loss_vtm: 0.2268  time: 4.1580  data: 0.0016  max mem: 34900 res mem: 44920
2023-09-18T21:10:46 | INFO | utils.basic_utils : Train Epoch: [9]  [ 900/1406]  eta: 0:35:08  lr: 0.000000  temperature: 0.0145  video-loss_vtc: 0.4338  video-loss_vtm: 0.1770  time: 4.1588  data: 0.0016  max mem: 34900 res mem: 44920
2023-09-18T21:17:42 | INFO | utils.basic_utils : Train Epoch: [9]  [1000/1406]  eta: 0:28:11  lr: 0.000000  temperature: 0.0145  video-loss_vtc: 0.5010  video-loss_vtm: 0.1205  time: 4.1601  data: 0.0016  max mem: 34900 res mem: 44920
2023-09-18T21:24:37 | INFO | utils.basic_utils : Train Epoch: [9]  [1100/1406]  eta: 0:21:14  lr: 0.000000  temperature: 0.0145  video-loss_vtc: 0.5598  video-loss_vtm: 0.2057  time: 4.1618  data: 0.0017  max mem: 34900 res mem: 44920
2023-09-18T21:31:34 | INFO | utils.basic_utils : Train Epoch: [9]  [1200/1406]  eta: 0:14:18  lr: 0.000000  temperature: 0.0145  video-loss_vtc: 0.5376  video-loss_vtm: 0.1956  time: 4.1595  data: 0.0016  max mem: 34900 res mem: 44920
2023-09-18T21:38:29 | INFO | utils.basic_utils : Train Epoch: [9]  [1300/1406]  eta: 0:07:21  lr: 0.000000  temperature: 0.0145  video-loss_vtc: 0.6359  video-loss_vtm: 0.2703  time: 4.1594  data: 0.0016  max mem: 34900 res mem: 44920
2023-09-18T21:45:26 | INFO | utils.basic_utils : Train Epoch: [9]  [1400/1406]  eta: 0:00:24  lr: 0.000000  temperature: 0.0145  video-loss_vtc: 0.4588  video-loss_vtm: 0.1969  time: 4.1550  data: 0.0016  max mem: 34900 res mem: 44920
2023-09-18T21:45:46 | INFO | utils.basic_utils : Train Epoch: [9]  [1405/1406]  eta: 0:00:04  lr: 0.000000  temperature: 0.0145  video-loss_vtc: 0.5547  video-loss_vtm: 0.1133  time: 4.1522  data: 0.0015  max mem: 34900 res mem: 44920
2023-09-18T21:45:46 | INFO | utils.basic_utils : Train Epoch: [9] Total time: 1:37:35 (4.1649 s / it)
2023-09-18T21:45:46 | INFO | __main__ : Averaged train stats: lr: 0.0000  temperature: 0.0145  video-loss_vtc: 0.5257  video-loss_vtm: 0.2086
2023-09-18T21:45:46 | INFO | tasks.retrieval_utils : Start evaluation for media_type=video
2023-09-18T21:45:46 | INFO | tasks.retrieval_utils : Computing dual encoder features...
2023-09-18T21:45:52 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2023-09-18T21:45:52 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2023-09-18T21:45:53 | INFO | utils.basic_utils : extracting image feats  [ 0/32]  eta: 0:03:23    time: 6.3512  data: 5.1931  max mem: 34900 res mem: 44920
2023-09-18T21:46:29 | INFO | utils.basic_utils : extracting image feats  [31/32]  eta: 0:00:01    time: 1.1048  data: 0.0442  max mem: 34900 res mem: 44920
2023-09-18T21:46:29 | INFO | utils.basic_utils : extracting image feats Total time: 0:00:41 (1.3092 s / it)
2023-09-18T21:46:34 | INFO | tasks.retrieval_utils : Finished feature extraction
2023-09-18T21:46:34 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product]
2023-09-18T21:46:34 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product], done!
2023-09-18T21:46:34 | INFO | tasks.retrieval_utils : Rerank dual-encoder results with cross-encoder...
2023-09-18T21:46:34 | INFO | tasks.retrieval_utils : i2t_scores.shape torch.Size([251, 1000])
2023-09-18T21:46:34 | INFO | tasks.retrieval_utils : n_clip_per_video=1, with eval_frame_ensemble=concat
2023-09-18T21:46:34 | INFO | utils.basic_utils : Evaluation:  [  0/251]  eta: 0:00:05    time: 0.0204  data: 0.0004  max mem: 34900 res mem: 44920
2023-09-18T21:46:41 | INFO | utils.basic_utils : Evaluation:  [100/251]  eta: 0:00:11    time: 0.0746  data: 0.0000  max mem: 34900 res mem: 44920
2023-09-18T21:46:49 | INFO | utils.basic_utils : Evaluation:  [200/251]  eta: 0:00:03    time: 0.0734  data: 0.0000  max mem: 34900 res mem: 44920
2023-09-18T21:46:52 | INFO | utils.basic_utils : Evaluation:  [250/251]  eta: 0:00:00    time: 0.0746  data: 0.0000  max mem: 34900 res mem: 44920
2023-09-18T21:46:52 | INFO | utils.basic_utils : Evaluation: Total time: 0:00:18 (0.0737 s / it)
2023-09-18T21:46:52 | INFO | tasks.retrieval_utils : t2i_scores.shape torch.Size([251, 1000])
2023-09-18T21:46:55 | INFO | utils.basic_utils : Evaluation:  [  0/251]  eta: 0:11:14    time: 2.6883  data: 0.0003  max mem: 34900 res mem: 44920
2023-09-18T21:47:03 | INFO | utils.basic_utils : Evaluation:  [100/251]  eta: 0:00:15    time: 0.0747  data: 0.0000  max mem: 34900 res mem: 44920
2023-09-18T21:47:10 | INFO | utils.basic_utils : Evaluation:  [200/251]  eta: 0:00:04    time: 0.0749  data: 0.0000  max mem: 34900 res mem: 44920
2023-09-18T21:47:14 | INFO | utils.basic_utils : Evaluation:  [250/251]  eta: 0:00:00    time: 0.0753  data: 0.0000  max mem: 34900 res mem: 44920
2023-09-18T21:47:14 | INFO | utils.basic_utils : Evaluation: Total time: 0:00:21 (0.0852 s / it)
2023-09-18T21:47:15 | INFO | tasks.retrieval_utils : Evaluation time 0:01:28
2023-09-18T21:47:15 | INFO | __main__ : Epoch 9
2023-09-18T21:47:15 | INFO | __main__ : 
           txt_r1  txt_r5  txt_r10  txt_r_mean  img_r1  img_r5  img_r10  img_r_mean  r_mean
test/        47.2    71.3     79.5       66.00    46.3    72.7     81.9       66.97   66.48
test_emb/    43.3    70.0     78.2       63.83    42.1    68.3     79.2       63.20   63.52
2023-09-18T21:47:30 | INFO | __main__ : Training time 16:32:07
2023-09-18T21:47:30 | INFO | __main__ : best epoch 9 [config.stop_key test/]
2023-09-18T21:47:30 | INFO | __main__ : Checkpoints and Logs saved at ./exp/finetuning/ret_msrvtt/vit_k710pre_d512_im0.5vm0.8_e10lr2dp0.2
2023-09-18T21:47:34 | INFO | __main__ : ===========> START eval_after_training [['test']]
2023-09-18T21:47:34 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'your_msrvtt_path': '/data1/DATASET/MSRVTT/videos', 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_train9k.json', '/data1/DATASET/MSRVTT/videos', 'video'], 'test_file': {'test': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_test1k.json', '/data1/DATASET/MSRVTT/videos', 'video']}, 'test_types': ['test'], 'num_workers': 6, 'stop_key': 'test/', 'is_paragraph_retrieval': False, 'num_frames': 12, 'num_frames_test': 12, 'batch_size': 32, 'max_txt_l': 32, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 12, 'sample_type': 'rand', 'num_frames_test': 12, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 32, 'video': 32}, 'batch_size': {'image': 32, 'video': 32}, 'batch_size_test': {'image': 32, 'video': 32}}, 'text_enc': 'bert', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_b16', 'img_size': 224, 'patch_size': 16, 'd_model': 768, 'encoder_embed_dim': 768, 'encoder_depth': 12, 'encoder_num_heads': 12, 'drop_path_rate': 0.2, 'num_frames': 12, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 12, 'clip_decoder_embed_dim': 768, 'clip_output_dim': 512, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_model/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 224, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'multimodal': {'enable': True}, 'embed_dim': 512, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 2e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 10, 'min_lr_multi': 0.01, 'warmup_epochs': 1, 'num_training_steps': 14060, 'num_warmup_steps': 1406}, 'evaluate': True, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': False, 'entity': 'user', 'project': 'umt_ret'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': './exp/finetuning/ret_msrvtt/vit_k710pre_d512_im0.5vm0.8_e10lr2dp0.2/eval_after_training', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 42, 'save_latest': True, 'auto_resume': True, 'pretrained_path': './exp/finetuning/ret_msrvtt/vit_k710pre_d512_im0.5vm0.8_e10lr2dp0.2/ckpt_best.pth', 'rank': 0, 'world_size': 4, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl', 'result_dir': './exp/finetuning/ret_msrvtt/vit_k710pre_d512_im0.5vm0.8_e10lr2dp0.2/eval_after_training'}
2023-09-18T21:47:34 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_train9k.json', '/data1/DATASET/MSRVTT/videos', 'video']
2023-09-18T21:47:34 | INFO | tasks.pretrain : Creating dataset for ret
2023-09-18T21:47:35 | INFO | tasks.shared_utils : Creating model
2023-09-18T21:47:36 | INFO | models.umt : Build vision_encoder: vit_b16
2023-09-18T21:47:36 | INFO | models.backbones.vit.vit : Num of patches: 2352
2023-09-18T21:47:36 | INFO | models.backbones.vit.vit : Use checkpoint: True
2023-09-18T21:47:36 | INFO | models.backbones.vit.vit : Checkpoint number: 12
2023-09-18T21:47:36 | INFO | models.backbones.vit.vit : Student return index: []
2023-09-18T21:47:43 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_model/Unmasked_Teacher/b16_ptk710_f8_res224.pth
2023-09-18T21:47:44 | INFO | models.umt : Build text_encoder bert_base
2023-09-18T21:47:45 | INFO | models.backbones.bert.xbert : build bert with cross_module: ca
2023-09-18T21:47:45 | INFO | models.criterions : Norm type: l2
2023-09-18T21:47:45 | INFO | models.criterions : Loss type: l2
2023-09-18T21:47:45 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.temp: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.weight: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.q_bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.v_bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.weight: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.weight: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.q_bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.v_bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.weight: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.weight: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.q_bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.v_bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.weight: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.weight: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.q_bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.v_bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.weight: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.weight: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.q_bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.v_bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.weight: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.weight: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.q_bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.v_bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.weight: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.weight: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.q_bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.v_bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.weight: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.weight: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.q_bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.v_bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.weight: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.weight: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.q_bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.v_bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.weight: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.weight: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.q_bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.v_bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.weight: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.weight: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.q_bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.v_bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.weight: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.weight: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.q_bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.v_bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.weight: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.weight: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.weight: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.embeddings.word_embeddings.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.embeddings.position_embeddings.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.embeddings.token_type_embeddings.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_proj.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.vision_proj.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_proj.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.text_proj.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.itm_head.weight: wd: 0.02, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : param module.itm_head.bias: wd: 0, lr: 2e-05
2023-09-18T21:47:45 | INFO | utils.optimizer : optimizer -- lr=2e-05 wd=0.02 len(p)=140
2023-09-18T21:47:45 | INFO | utils.optimizer : optimizer -- lr=2e-05 wd=0 len(p)=256
2023-09-18T21:47:45 | INFO | tasks.shared_utils : Auto resuming
2023-09-18T21:47:45 | INFO | tasks.shared_utils : Not found checkpoint in ./exp/finetuning/ret_msrvtt/vit_k710pre_d512_im0.5vm0.8_e10lr2dp0.2/eval_after_training
2023-09-18T21:47:47 | INFO | tasks.shared_utils : <All keys matched successfully>
2023-09-18T21:47:47 | INFO | tasks.shared_utils : Loaded checkpoint from ./exp/finetuning/ret_msrvtt/vit_k710pre_d512_im0.5vm0.8_e10lr2dp0.2/ckpt_best.pth
2023-09-18T21:47:47 | INFO | __main__ : Start evaluation
2023-09-18T21:47:47 | INFO | tasks.retrieval_utils : Start evaluation for media_type=video
2023-09-18T21:47:47 | INFO | tasks.retrieval_utils : Computing dual encoder features...
2023-09-18T21:47:54 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2023-09-18T21:47:54 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2023-09-18T21:47:55 | INFO | utils.basic_utils : extracting image feats  [ 0/32]  eta: 0:04:19    time: 8.1020  data: 6.9404  max mem: 34900 res mem: 44920
2023-09-18T21:48:30 | INFO | utils.basic_utils : extracting image feats  [31/32]  eta: 0:00:01    time: 1.1004  data: 0.0393  max mem: 34900 res mem: 44920
2023-09-18T21:48:30 | INFO | utils.basic_utils : extracting image feats Total time: 0:00:43 (1.3543 s / it)
2023-09-18T21:48:36 | INFO | tasks.retrieval_utils : Finished feature extraction
2023-09-18T21:48:36 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product]
2023-09-18T21:48:36 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product], done!
2023-09-18T21:48:36 | INFO | tasks.retrieval_utils : Rerank dual-encoder results with cross-encoder...
2023-09-18T21:48:36 | INFO | tasks.retrieval_utils : i2t_scores.shape torch.Size([251, 1000])
2023-09-18T21:48:36 | INFO | tasks.retrieval_utils : n_clip_per_video=1, with eval_frame_ensemble=concat
2023-09-18T21:48:36 | INFO | utils.basic_utils : Evaluation:  [  0/251]  eta: 0:00:05    time: 0.0212  data: 0.0004  max mem: 34900 res mem: 44920
2023-09-18T21:48:43 | INFO | utils.basic_utils : Evaluation:  [100/251]  eta: 0:00:11    time: 0.0744  data: 0.0000  max mem: 34900 res mem: 44920
2023-09-18T21:48:50 | INFO | utils.basic_utils : Evaluation:  [200/251]  eta: 0:00:03    time: 0.0744  data: 0.0000  max mem: 34900 res mem: 44920
2023-09-18T21:48:54 | INFO | utils.basic_utils : Evaluation:  [250/251]  eta: 0:00:00    time: 0.0746  data: 0.0000  max mem: 34900 res mem: 44920
2023-09-18T21:48:54 | INFO | utils.basic_utils : Evaluation: Total time: 0:00:18 (0.0741 s / it)
2023-09-18T21:48:54 | INFO | tasks.retrieval_utils : t2i_scores.shape torch.Size([251, 1000])
2023-09-18T21:48:58 | INFO | utils.basic_utils : Evaluation:  [  0/251]  eta: 0:13:43    time: 3.2801  data: 0.0003  max mem: 34900 res mem: 44920
2023-09-18T21:49:05 | INFO | utils.basic_utils : Evaluation:  [100/251]  eta: 0:00:16    time: 0.0747  data: 0.0000  max mem: 34900 res mem: 44920
2023-09-18T21:49:12 | INFO | utils.basic_utils : Evaluation:  [200/251]  eta: 0:00:04    time: 0.0753  data: 0.0000  max mem: 34900 res mem: 44920
2023-09-18T21:49:16 | INFO | utils.basic_utils : Evaluation:  [250/251]  eta: 0:00:00    time: 0.0756  data: 0.0000  max mem: 34900 res mem: 44920
2023-09-18T21:49:16 | INFO | utils.basic_utils : Evaluation: Total time: 0:00:22 (0.0877 s / it)
2023-09-18T21:49:17 | INFO | tasks.retrieval_utils : Evaluation time 0:01:30
2023-09-18T21:49:17 | INFO | __main__ : Epoch 0
2023-09-18T21:49:17 | INFO | __main__ : 
           txt_r1  txt_r5  txt_r10  txt_r_mean  img_r1  img_r5  img_r10  img_r_mean  r_mean
test/        47.2    71.3     79.5       66.00    46.3    72.7     81.9       66.97   66.48
test_emb/    43.3    70.0     78.2       63.83    42.1    68.3     79.2       63.20   63.52
2023-09-18T21:49:17 | INFO | __main__ : Training time 0:01:30
2023-09-18T21:49:17 | INFO | __main__ : best epoch 0 [config.stop_key test/]
2023-09-18T21:49:17 | INFO | __main__ : Checkpoints and Logs saved at ./exp/finetuning/ret_msrvtt/vit_k710pre_d512_im0.5vm0.8_e10lr2dp0.2/eval_after_training
