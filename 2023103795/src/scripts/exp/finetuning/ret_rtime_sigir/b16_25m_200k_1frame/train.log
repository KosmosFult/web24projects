2024-01-12T04:37:10 | INFO | umt : Logging to: exp/finetuning/ret_rtime/b16_25m_200k_1frame/train.log
2024-01-12T04:37:10 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/training_200k.json', '/data2/dy/temporal_video/dataset', 'video']
  test_file: {
      test: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test2k.json', '/data2/dy/temporal_video/dataset', 'video'] }
  test_types: ['test']
  num_workers: 6
  stop_key: test/
  is_paragraph_retrieval: False
  num_frames: 1
  num_frames_test: 1
  batch_size: 32
  max_txt_l: 32
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 1
          sample_type: rand
          num_frames_test: 1
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 32
          video: 32 }
      batch_size: {
          image: 32
          video: 32 }
      batch_size_test: {
          image: 32
          video: 32 } }
  text_enc: bert
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_b16
          img_size: 224
          patch_size: 16
          d_model: 768
          encoder_embed_dim: 768
          encoder_depth: 12
          encoder_num_heads: 12
          drop_path_rate: 0.2
          num_frames: 1
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 12
          clip_decoder_embed_dim: 768
          clip_output_dim: 512
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 224
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      multimodal: {
          enable: True }
      embed_dim: 512
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 1e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 5
      min_lr_multi: 0.01
      warmup_epochs: 1 }
  evaluate: False
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: True
      entity: user
      project: umt_ret }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/finetuning/ret_rtime/b16_25m_200k_1frame
  resume: False
  debug: False
  log_freq: 100
  seed: 42
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
  rank: 0
  world_size: 4
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-01-15T02:42:05 | INFO | umt : Logging to: exp/finetuning/ret_rtime/b16_25m_200k_1frame/train.log
2024-01-15T02:42:05 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/training_200k.json', '/data2/dy/temporal_video/dataset', 'video']
  test_file: {
      test: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test2k.json', '/data2/dy/temporal_video/dataset', 'video'] }
  test_types: ['test']
  num_workers: 6
  stop_key: test/
  is_paragraph_retrieval: False
  num_frames: 1
  num_frames_test: 1
  batch_size: 32
  max_txt_l: 32
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 1
          sample_type: rand
          num_frames_test: 1
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 32
          video: 32 }
      batch_size: {
          image: 32
          video: 32 }
      batch_size_test: {
          image: 32
          video: 32 } }
  text_enc: bert
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_b16
          img_size: 224
          patch_size: 16
          d_model: 768
          encoder_embed_dim: 768
          encoder_depth: 12
          encoder_num_heads: 12
          drop_path_rate: 0.2
          num_frames: 1
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 12
          clip_decoder_embed_dim: 768
          clip_output_dim: 512
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 224
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      multimodal: {
          enable: True }
      embed_dim: 512
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 1e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 5
      min_lr_multi: 0.01
      warmup_epochs: 1 }
  evaluate: False
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: True
      entity: user
      project: umt_ret }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/finetuning/ret_rtime/b16_25m_200k_1frame
  resume: False
  debug: False
  log_freq: 100
  seed: 42
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
  rank: 0
  world_size: 4
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-01-15T02:42:15 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/training_200k.json', '/data2/dy/temporal_video/dataset', 'video'], 'test_file': {'test': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test2k.json', '/data2/dy/temporal_video/dataset', 'video']}, 'test_types': ['test'], 'num_workers': 6, 'stop_key': 'test/', 'is_paragraph_retrieval': False, 'num_frames': 1, 'num_frames_test': 1, 'batch_size': 32, 'max_txt_l': 32, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 1, 'sample_type': 'rand', 'num_frames_test': 1, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 32, 'video': 32}, 'batch_size': {'image': 32, 'video': 32}, 'batch_size_test': {'image': 32, 'video': 32}}, 'text_enc': 'bert', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_b16', 'img_size': 224, 'patch_size': 16, 'd_model': 768, 'encoder_embed_dim': 768, 'encoder_depth': 12, 'encoder_num_heads': 12, 'drop_path_rate': 0.2, 'num_frames': 1, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 12, 'clip_decoder_embed_dim': 768, 'clip_output_dim': 512, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 224, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'multimodal': {'enable': True}, 'embed_dim': 512, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 1e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 5, 'min_lr_multi': 0.01, 'warmup_epochs': 1}, 'evaluate': False, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': True, 'entity': 'user', 'project': 'umt_ret'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': 'exp/finetuning/ret_rtime/b16_25m_200k_1frame', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 42, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth', 'rank': 0, 'world_size': 4, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2024-01-15T02:42:15 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/training_200k.json', '/data2/dy/temporal_video/dataset', 'video']
2024-01-15T02:42:15 | INFO | tasks.pretrain : Creating dataset for ret
2024-01-15T02:42:15 | INFO | tasks.shared_utils : Creating model
2024-01-15T02:42:27 | INFO | models.umt : Build vision_encoder: vit_b16
2024-01-15T02:42:27 | INFO | models.backbones.vit.vit : Num of patches: 196
2024-01-15T02:42:27 | INFO | models.backbones.vit.vit : Use checkpoint: True
2024-01-15T02:42:27 | INFO | models.backbones.vit.vit : Checkpoint number: 12
2024-01-15T02:42:27 | INFO | models.backbones.vit.vit : Student return index: []
2024-01-15T02:42:29 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
2024-01-15T02:42:30 | INFO | models.umt : Build text_encoder bert_base
2024-01-15T02:42:31 | INFO | models.backbones.bert.xbert : build bert with cross_module: ca
2024-01-15T02:42:32 | INFO | models.criterions : Norm type: l2
2024-01-15T02:42:32 | INFO | models.criterions : Loss type: l2
2024-01-15T02:42:32 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.temp: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.weight: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.weight: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.embeddings.word_embeddings.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.embeddings.position_embeddings.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.embeddings.token_type_embeddings.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.vision_proj.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.text_proj.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.itm_head.weight: wd: 0.02, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : param module.itm_head.bias: wd: 0, lr: 1e-05
2024-01-15T02:42:32 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0.02 len(p)=140
2024-01-15T02:42:32 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0 len(p)=256
2024-01-15T02:42:32 | INFO | tasks.shared_utils : Auto resuming
2024-01-15T02:42:32 | INFO | tasks.shared_utils : Not found checkpoint in exp/finetuning/ret_rtime/b16_25m_200k_1frame
2024-01-15T02:42:33 | INFO | tasks.shared_utils : _IncompatibleKeys(missing_keys=[], unexpected_keys=['clip_teacher.class_embedding', 'clip_teacher.positional_embedding', 'clip_teacher.proj', 'clip_teacher.conv1.weight', 'clip_teacher.ln_pre.weight', 'clip_teacher.ln_pre.bias', 'clip_teacher.transformer.resblocks.0.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.0.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.0.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.0.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.0.ln_1.weight', 'clip_teacher.transformer.resblocks.0.ln_1.bias', 'clip_teacher.transformer.resblocks.0.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.0.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.0.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.0.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.0.ln_2.weight', 'clip_teacher.transformer.resblocks.0.ln_2.bias', 'clip_teacher.transformer.resblocks.1.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.1.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.1.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.1.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.1.ln_1.weight', 'clip_teacher.transformer.resblocks.1.ln_1.bias', 'clip_teacher.transformer.resblocks.1.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.1.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.1.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.1.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.1.ln_2.weight', 'clip_teacher.transformer.resblocks.1.ln_2.bias', 'clip_teacher.transformer.resblocks.2.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.2.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.2.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.2.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.2.ln_1.weight', 'clip_teacher.transformer.resblocks.2.ln_1.bias', 'clip_teacher.transformer.resblocks.2.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.2.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.2.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.2.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.2.ln_2.weight', 'clip_teacher.transformer.resblocks.2.ln_2.bias', 'clip_teacher.transformer.resblocks.3.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.3.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.3.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.3.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.3.ln_1.weight', 'clip_teacher.transformer.resblocks.3.ln_1.bias', 'clip_teacher.transformer.resblocks.3.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.3.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.3.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.3.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.3.ln_2.weight', 'clip_teacher.transformer.resblocks.3.ln_2.bias', 'clip_teacher.transformer.resblocks.4.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.4.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.4.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.4.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.4.ln_1.weight', 'clip_teacher.transformer.resblocks.4.ln_1.bias', 'clip_teacher.transformer.resblocks.4.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.4.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.4.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.4.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.4.ln_2.weight', 'clip_teacher.transformer.resblocks.4.ln_2.bias', 'clip_teacher.transformer.resblocks.5.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.5.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.5.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.5.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.5.ln_1.weight', 'clip_teacher.transformer.resblocks.5.ln_1.bias', 'clip_teacher.transformer.resblocks.5.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.5.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.5.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.5.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.5.ln_2.weight', 'clip_teacher.transformer.resblocks.5.ln_2.bias', 'clip_teacher.transformer.resblocks.6.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.6.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.6.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.6.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.6.ln_1.weight', 'clip_teacher.transformer.resblocks.6.ln_1.bias', 'clip_teacher.transformer.resblocks.6.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.6.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.6.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.6.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.6.ln_2.weight', 'clip_teacher.transformer.resblocks.6.ln_2.bias', 'clip_teacher.transformer.resblocks.7.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.7.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.7.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.7.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.7.ln_1.weight', 'clip_teacher.transformer.resblocks.7.ln_1.bias', 'clip_teacher.transformer.resblocks.7.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.7.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.7.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.7.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.7.ln_2.weight', 'clip_teacher.transformer.resblocks.7.ln_2.bias', 'clip_teacher.transformer.resblocks.8.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.8.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.8.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.8.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.8.ln_1.weight', 'clip_teacher.transformer.resblocks.8.ln_1.bias', 'clip_teacher.transformer.resblocks.8.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.8.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.8.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.8.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.8.ln_2.weight', 'clip_teacher.transformer.resblocks.8.ln_2.bias', 'clip_teacher.transformer.resblocks.9.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.9.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.9.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.9.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.9.ln_1.weight', 'clip_teacher.transformer.resblocks.9.ln_1.bias', 'clip_teacher.transformer.resblocks.9.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.9.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.9.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.9.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.9.ln_2.weight', 'clip_teacher.transformer.resblocks.9.ln_2.bias', 'clip_teacher.transformer.resblocks.10.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.10.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.10.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.10.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.10.ln_1.weight', 'clip_teacher.transformer.resblocks.10.ln_1.bias', 'clip_teacher.transformer.resblocks.10.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.10.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.10.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.10.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.10.ln_2.weight', 'clip_teacher.transformer.resblocks.10.ln_2.bias', 'clip_teacher.transformer.resblocks.11.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.11.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.11.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.11.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.11.ln_1.weight', 'clip_teacher.transformer.resblocks.11.ln_1.bias', 'clip_teacher.transformer.resblocks.11.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.11.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.11.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.11.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.11.ln_2.weight', 'clip_teacher.transformer.resblocks.11.ln_2.bias', 'clip_teacher.ln_post.weight', 'clip_teacher.ln_post.bias', 'vision_encoder.clip_decoder.0.head.weight', 'vision_encoder.clip_decoder.0.head.bias', 'vision_encoder.clip_decoder.0.norm.weight', 'vision_encoder.clip_decoder.0.norm.bias', 'vision_encoder.clip_decoder.1.head.weight', 'vision_encoder.clip_decoder.1.head.bias', 'vision_encoder.clip_decoder.1.norm.weight', 'vision_encoder.clip_decoder.1.norm.bias', 'vision_encoder.clip_decoder.2.head.weight', 'vision_encoder.clip_decoder.2.head.bias', 'vision_encoder.clip_decoder.2.norm.weight', 'vision_encoder.clip_decoder.2.norm.bias', 'vision_encoder.clip_decoder.3.head.weight', 'vision_encoder.clip_decoder.3.head.bias', 'vision_encoder.clip_decoder.3.norm.weight', 'vision_encoder.clip_decoder.3.norm.bias', 'vision_encoder.clip_decoder.4.head.weight', 'vision_encoder.clip_decoder.4.head.bias', 'vision_encoder.clip_decoder.4.norm.weight', 'vision_encoder.clip_decoder.4.norm.bias', 'vision_encoder.clip_decoder.5.head.weight', 'vision_encoder.clip_decoder.5.head.bias', 'vision_encoder.clip_decoder.5.norm.weight', 'vision_encoder.clip_decoder.5.norm.bias', 'text_encoder.cls.predictions.bias', 'text_encoder.cls.predictions.transform.dense.weight', 'text_encoder.cls.predictions.transform.dense.bias', 'text_encoder.cls.predictions.transform.LayerNorm.weight', 'text_encoder.cls.predictions.transform.LayerNorm.bias', 'text_encoder.cls.predictions.decoder.weight', 'text_encoder.cls.predictions.decoder.bias'])
2024-01-15T02:42:33 | INFO | tasks.shared_utils : Loaded checkpoint from /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
2024-01-15T02:42:33 | INFO | __main__ : training
2024-01-15T02:42:33 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 1448 batches in total
dataloader index=0 name=video, batch-size=32 length(#batches)=1448 
2024-01-15T02:42:41 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  builtin_warn(*args, **kwargs)

2024-01-15T02:42:41 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  builtin_warn(*args, **kwargs)

2024-01-15T02:42:41 | INFO | utils.basic_utils : Train Epoch: [0]  [   0/1448]  eta: 3:11:00  lr: 0.000000  temperature: 0.0112  video-loss_vtc: 1.1413  video-loss_vtm: 0.3705  time: 7.9147  data: 2.9569  max mem: 2727 res mem: 2922
2024-01-15T02:42:41 | INFO | torch.nn.parallel.distributed : Reducer buckets have been rebuilt in this iteration.
2024-01-15T02:43:36 | INFO | utils.basic_utils : Train Epoch: [0]  [ 100/1448]  eta: 0:13:56  lr: 0.000001  temperature: 0.0112  video-loss_vtc: 0.9010  video-loss_vtm: 0.3219  time: 0.6046  data: 0.0013  max mem: 4826 res mem: 5178
2024-01-15T02:44:33 | INFO | utils.basic_utils : Train Epoch: [0]  [ 200/1448]  eta: 0:12:24  lr: 0.000001  temperature: 0.0113  video-loss_vtc: 1.0188  video-loss_vtm: 0.3564  time: 0.5643  data: 0.0014  max mem: 4826 res mem: 5178
2024-01-15T02:45:30 | INFO | utils.basic_utils : Train Epoch: [0]  [ 300/1448]  eta: 0:11:13  lr: 0.000002  temperature: 0.0114  video-loss_vtc: 0.7239  video-loss_vtm: 0.2081  time: 0.6401  data: 0.0014  max mem: 4826 res mem: 5178
2024-01-15T02:46:26 | INFO | utils.basic_utils : Train Epoch: [0]  [ 400/1448]  eta: 0:10:08  lr: 0.000003  temperature: 0.0114  video-loss_vtc: 0.6782  video-loss_vtm: 0.2079  time: 0.5384  data: 0.0014  max mem: 4826 res mem: 5178
2024-01-15T02:47:22 | INFO | utils.basic_utils : Train Epoch: [0]  [ 500/1448]  eta: 0:09:07  lr: 0.000003  temperature: 0.0115  video-loss_vtc: 0.5922  video-loss_vtm: 0.2756  time: 0.6149  data: 0.1861  max mem: 4826 res mem: 5178
2024-01-15T02:48:19 | INFO | utils.basic_utils : Train Epoch: [0]  [ 600/1448]  eta: 0:08:08  lr: 0.000004  temperature: 0.0116  video-loss_vtc: 0.6316  video-loss_vtm: 0.1889  time: 0.5768  data: 0.0012  max mem: 4826 res mem: 5178
2024-01-15T02:49:14 | INFO | utils.basic_utils : Train Epoch: [0]  [ 700/1448]  eta: 0:07:08  lr: 0.000005  temperature: 0.0116  video-loss_vtc: 0.6349  video-loss_vtm: 0.1560  time: 0.5739  data: 0.0271  max mem: 4826 res mem: 5178
2024-01-15T02:50:11 | INFO | utils.basic_utils : Train Epoch: [0]  [ 800/1448]  eta: 0:06:10  lr: 0.000006  temperature: 0.0117  video-loss_vtc: 0.5083  video-loss_vtm: 0.3289  time: 0.5278  data: 0.0132  max mem: 4826 res mem: 5178
2024-01-15T02:51:08 | INFO | utils.basic_utils : Train Epoch: [0]  [ 900/1448]  eta: 0:05:12  lr: 0.000006  temperature: 0.0117  video-loss_vtc: 0.6817  video-loss_vtm: 0.2799  time: 0.5948  data: 0.1768  max mem: 4826 res mem: 5178
2024-01-15T02:52:06 | INFO | utils.basic_utils : Train Epoch: [0]  [1000/1448]  eta: 0:04:16  lr: 0.000007  temperature: 0.0117  video-loss_vtc: 0.5926  video-loss_vtm: 0.1644  time: 0.5822  data: 0.0011  max mem: 4826 res mem: 5180
2024-01-15T02:53:02 | INFO | utils.basic_utils : Train Epoch: [0]  [1100/1448]  eta: 0:03:18  lr: 0.000008  temperature: 0.0118  video-loss_vtc: 0.6143  video-loss_vtm: 0.1648  time: 0.6025  data: 0.0016  max mem: 4826 res mem: 5180
2024-01-15T02:53:58 | INFO | utils.basic_utils : Train Epoch: [0]  [1200/1448]  eta: 0:02:21  lr: 0.000008  temperature: 0.0118  video-loss_vtc: 0.4392  video-loss_vtm: 0.2169  time: 0.4922  data: 0.0015  max mem: 4826 res mem: 5180
2024-01-15T02:54:55 | INFO | utils.basic_utils : Train Epoch: [0]  [1300/1448]  eta: 0:01:24  lr: 0.000009  temperature: 0.0118  video-loss_vtc: 0.5900  video-loss_vtm: 0.1439  time: 0.5369  data: 0.0015  max mem: 4826 res mem: 5180
2024-01-15T02:55:50 | INFO | utils.basic_utils : Train Epoch: [0]  [1400/1448]  eta: 0:00:27  lr: 0.000010  temperature: 0.0118  video-loss_vtc: 0.2458  video-loss_vtm: 0.1628  time: 0.5599  data: 0.0015  max mem: 4826 res mem: 5180
2024-01-15T02:56:16 | INFO | utils.basic_utils : Train Epoch: [0]  [1447/1448]  eta: 0:00:00  lr: 0.000010  temperature: 0.0119  video-loss_vtc: 0.6350  video-loss_vtm: 0.2002  time: 0.5119  data: 0.0015  max mem: 4826 res mem: 5180
2024-01-15T02:56:16 | INFO | utils.basic_utils : Train Epoch: [0] Total time: 0:13:42 (0.5679 s / it)
2024-01-15T02:56:16 | INFO | __main__ : Averaged train stats: lr: 0.0000  temperature: 0.0116  video-loss_vtc: 0.6817  video-loss_vtm: 0.2364
2024-01-15T02:56:16 | INFO | tasks.retrieval_utils : Start evaluation for media_type=video
2024-01-15T02:56:16 | INFO | tasks.retrieval_utils : Computing dual encoder features...
2024-01-15T02:56:22 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-01-15T02:56:22 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-01-15T02:56:22 | INFO | utils.basic_utils : extracting image feats  [ 0/63]  eta: 0:05:35    time: 5.3242  data: 5.2721  max mem: 4826 res mem: 5368
2024-01-15T02:57:01 | INFO | utils.basic_utils : extracting image feats  [62/63]  eta: 0:00:00    time: 0.6319  data: 0.5854  max mem: 4826 res mem: 5368
2024-01-15T02:57:01 | INFO | utils.basic_utils : extracting image feats Total time: 0:00:44 (0.7035 s / it)
2024-01-15T02:57:02 | INFO | tasks.retrieval_utils : Finished feature extraction
2024-01-15T02:57:02 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product]
2024-01-15T02:57:02 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product], done!
2024-01-15T02:57:02 | INFO | tasks.retrieval_utils : Rerank dual-encoder results with cross-encoder...
2024-01-15T02:57:02 | INFO | tasks.retrieval_utils : i2t_scores.shape torch.Size([501, 2000])
2024-01-15T02:57:02 | INFO | tasks.retrieval_utils : n_clip_per_video=1, with eval_frame_ensemble=concat
2024-01-15T02:57:02 | INFO | utils.basic_utils : Evaluation:  [  0/501]  eta: 0:00:11    time: 0.0228  data: 0.0009  max mem: 4826 res mem: 5368
2024-01-15T02:57:03 | INFO | utils.basic_utils : Evaluation:  [100/501]  eta: 0:00:06    time: 0.0170  data: 0.0000  max mem: 4826 res mem: 5368
2024-01-15T02:57:05 | INFO | utils.basic_utils : Evaluation:  [200/501]  eta: 0:00:05    time: 0.0176  data: 0.0000  max mem: 4826 res mem: 5368
2024-01-15T02:57:07 | INFO | utils.basic_utils : Evaluation:  [300/501]  eta: 0:00:03    time: 0.0178  data: 0.0000  max mem: 4826 res mem: 5368
2024-01-15T02:57:09 | INFO | utils.basic_utils : Evaluation:  [400/501]  eta: 0:00:01    time: 0.0173  data: 0.0000  max mem: 4826 res mem: 5368
2024-01-15T02:57:10 | INFO | utils.basic_utils : Evaluation:  [500/501]  eta: 0:00:00    time: 0.0175  data: 0.0000  max mem: 4826 res mem: 5368
2024-01-15T02:57:10 | INFO | utils.basic_utils : Evaluation: Total time: 0:00:08 (0.0175 s / it)
2024-01-15T02:57:10 | INFO | tasks.retrieval_utils : t2i_scores.shape torch.Size([501, 2000])
2024-01-15T02:57:10 | INFO | utils.basic_utils : Evaluation:  [  0/501]  eta: 0:00:30    time: 0.0613  data: 0.0006  max mem: 4826 res mem: 5368
2024-01-15T02:57:16 | INFO | utils.basic_utils : Evaluation:  [100/501]  eta: 0:00:20    time: 0.0517  data: 0.0000  max mem: 4826 res mem: 5368
2024-01-15T02:57:21 | INFO | utils.basic_utils : Evaluation:  [200/501]  eta: 0:00:15    time: 0.0513  data: 0.0000  max mem: 4826 res mem: 5368
2024-01-15T02:57:26 | INFO | utils.basic_utils : Evaluation:  [300/501]  eta: 0:00:10    time: 0.0537  data: 0.0000  max mem: 4826 res mem: 5368
2024-01-15T02:57:31 | INFO | utils.basic_utils : Evaluation:  [400/501]  eta: 0:00:05    time: 0.0494  data: 0.0000  max mem: 4826 res mem: 5368
2024-01-15T02:57:36 | INFO | utils.basic_utils : Evaluation:  [500/501]  eta: 0:00:00    time: 0.0505  data: 0.0000  max mem: 4826 res mem: 5368
2024-01-15T02:57:36 | INFO | utils.basic_utils : Evaluation: Total time: 0:00:25 (0.0510 s / it)
2024-01-15T02:57:40 | INFO | tasks.retrieval_utils : Evaluation time 0:01:24
2024-01-15T02:57:41 | INFO | __main__ : Epoch 0
2024-01-15T02:57:41 | INFO | __main__ : 
           txt_r1  txt_r5  txt_r10  txt_r_mean  img_r1  img_r5  img_r10  img_r_mean  r_mean  txt_acc  img_acc
test/       37.95   86.85    92.50       72.43   37.85    86.0     92.8       72.22   72.32     49.3     49.9
test_emb/   34.50   81.90    89.65       68.68   34.20    81.9     89.9       68.67   68.68     49.2     48.5
2024-01-15T02:57:43 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 1448 batches in total
dataloader index=0 name=video, batch-size=32 length(#batches)=1448 
2024-01-15T02:57:48 | INFO | utils.basic_utils : Train Epoch: [1]  [   0/1448]  eta: 1:40:34  lr: 0.000010  temperature: 0.0119  video-loss_vtc: 0.4289  video-loss_vtm: 0.1251  time: 4.1673  data: 2.8908  max mem: 4826 res mem: 5368
2024-01-15T02:58:44 | INFO | utils.basic_utils : Train Epoch: [1]  [ 100/1448]  eta: 0:13:23  lr: 0.000010  temperature: 0.0119  video-loss_vtc: 0.3932  video-loss_vtm: 0.1783  time: 0.5225  data: 0.0014  max mem: 4826 res mem: 5368
2024-01-15T02:59:40 | INFO | utils.basic_utils : Train Epoch: [1]  [ 200/1448]  eta: 0:12:01  lr: 0.000010  temperature: 0.0119  video-loss_vtc: 0.4640  video-loss_vtm: 0.1542  time: 0.5518  data: 0.0015  max mem: 4826 res mem: 5368
2024-01-15T03:00:36 | INFO | utils.basic_utils : Train Epoch: [1]  [ 300/1448]  eta: 0:10:59  lr: 0.000010  temperature: 0.0118  video-loss_vtc: 0.4677  video-loss_vtm: 0.1875  time: 0.6172  data: 0.0015  max mem: 4826 res mem: 5368
2024-01-15T03:01:32 | INFO | utils.basic_utils : Train Epoch: [1]  [ 400/1448]  eta: 0:09:57  lr: 0.000010  temperature: 0.0118  video-loss_vtc: 0.3657  video-loss_vtm: 0.1813  time: 0.5203  data: 0.0014  max mem: 4826 res mem: 5368
2024-01-15T03:02:29 | INFO | utils.basic_utils : Train Epoch: [1]  [ 500/1448]  eta: 0:08:59  lr: 0.000010  temperature: 0.0118  video-loss_vtc: 0.3910  video-loss_vtm: 0.4446  time: 0.5857  data: 0.0014  max mem: 4826 res mem: 5368
2024-01-15T03:03:24 | INFO | utils.basic_utils : Train Epoch: [1]  [ 600/1448]  eta: 0:08:01  lr: 0.000010  temperature: 0.0119  video-loss_vtc: 0.3867  video-loss_vtm: 0.0621  time: 0.5454  data: 0.0018  max mem: 4826 res mem: 5368
2024-01-15T03:04:21 | INFO | utils.basic_utils : Train Epoch: [1]  [ 700/1448]  eta: 0:07:03  lr: 0.000010  temperature: 0.0118  video-loss_vtc: 0.3526  video-loss_vtm: 0.1740  time: 0.5613  data: 0.1763  max mem: 4826 res mem: 5368
2024-01-15T03:05:18 | INFO | utils.basic_utils : Train Epoch: [1]  [ 800/1448]  eta: 0:06:07  lr: 0.000010  temperature: 0.0118  video-loss_vtc: 0.3317  video-loss_vtm: 0.1504  time: 0.5566  data: 0.1248  max mem: 4826 res mem: 5368
2024-01-15T03:06:15 | INFO | utils.basic_utils : Train Epoch: [1]  [ 900/1448]  eta: 0:05:11  lr: 0.000009  temperature: 0.0118  video-loss_vtc: 0.2507  video-loss_vtm: 0.1349  time: 0.5398  data: 0.0015  max mem: 4826 res mem: 5368
2024-01-15T03:07:11 | INFO | utils.basic_utils : Train Epoch: [1]  [1000/1448]  eta: 0:04:13  lr: 0.000009  temperature: 0.0119  video-loss_vtc: 0.3526  video-loss_vtm: 0.1971  time: 0.5571  data: 0.0239  max mem: 4826 res mem: 5368
2024-01-15T03:08:09 | INFO | utils.basic_utils : Train Epoch: [1]  [1100/1448]  eta: 0:03:17  lr: 0.000009  temperature: 0.0119  video-loss_vtc: 0.4514  video-loss_vtm: 0.1019  time: 0.6369  data: 0.0012  max mem: 4826 res mem: 5368
2024-01-15T03:09:04 | INFO | utils.basic_utils : Train Epoch: [1]  [1200/1448]  eta: 0:02:20  lr: 0.000009  temperature: 0.0118  video-loss_vtc: 0.4335  video-loss_vtm: 0.2825  time: 0.5930  data: 0.0015  max mem: 4826 res mem: 5368
2024-01-15T03:10:01 | INFO | utils.basic_utils : Train Epoch: [1]  [1300/1448]  eta: 0:01:23  lr: 0.000009  temperature: 0.0118  video-loss_vtc: 0.4227  video-loss_vtm: 0.3163  time: 0.5645  data: 0.0013  max mem: 4826 res mem: 5368
2024-01-15T03:10:58 | INFO | utils.basic_utils : Train Epoch: [1]  [1400/1448]  eta: 0:00:27  lr: 0.000009  temperature: 0.0118  video-loss_vtc: 0.1862  video-loss_vtm: 0.1662  time: 0.5559  data: 0.0020  max mem: 4826 res mem: 5368
2024-01-15T03:11:24 | INFO | utils.basic_utils : Train Epoch: [1]  [1447/1448]  eta: 0:00:00  lr: 0.000009  temperature: 0.0117  video-loss_vtc: 0.1776  video-loss_vtm: 0.0759  time: 0.5862  data: 0.0015  max mem: 4826 res mem: 5368
2024-01-15T03:11:24 | INFO | utils.basic_utils : Train Epoch: [1] Total time: 0:13:41 (0.5670 s / it)
2024-01-15T03:11:24 | INFO | __main__ : Averaged train stats: lr: 0.0000  temperature: 0.0118  video-loss_vtc: 0.3864  video-loss_vtm: 0.1710
2024-01-15T03:11:24 | INFO | tasks.retrieval_utils : Start evaluation for media_type=video
2024-01-15T03:11:24 | INFO | tasks.retrieval_utils : Computing dual encoder features...
2024-01-15T03:11:30 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-01-15T03:11:30 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-01-15T03:11:30 | INFO | utils.basic_utils : extracting image feats  [ 0/63]  eta: 0:04:56    time: 4.6995  data: 4.6527  max mem: 4826 res mem: 5368
2024-01-15T03:12:04 | INFO | utils.basic_utils : extracting image feats  [62/63]  eta: 0:00:00    time: 0.5102  data: 0.4675  max mem: 4826 res mem: 5368
2024-01-15T03:12:04 | INFO | utils.basic_utils : extracting image feats Total time: 0:00:39 (0.6196 s / it)
2024-01-15T03:12:05 | INFO | tasks.retrieval_utils : Finished feature extraction
2024-01-15T03:12:05 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product]
2024-01-15T03:12:05 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product], done!
2024-01-15T03:12:05 | INFO | tasks.retrieval_utils : Rerank dual-encoder results with cross-encoder...
2024-01-15T03:12:05 | INFO | tasks.retrieval_utils : i2t_scores.shape torch.Size([501, 2000])
2024-01-15T03:12:05 | INFO | tasks.retrieval_utils : n_clip_per_video=1, with eval_frame_ensemble=concat
2024-01-15T03:12:05 | INFO | utils.basic_utils : Evaluation:  [  0/501]  eta: 0:00:10    time: 0.0208  data: 0.0007  max mem: 4826 res mem: 5368
2024-01-15T03:12:07 | INFO | utils.basic_utils : Evaluation:  [100/501]  eta: 0:00:06    time: 0.0181  data: 0.0000  max mem: 4826 res mem: 5368
2024-01-15T03:12:09 | INFO | utils.basic_utils : Evaluation:  [200/501]  eta: 0:00:05    time: 0.0173  data: 0.0000  max mem: 4826 res mem: 5368
2024-01-15T03:12:10 | INFO | utils.basic_utils : Evaluation:  [300/501]  eta: 0:00:03    time: 0.0172  data: 0.0000  max mem: 4826 res mem: 5368
2024-01-15T03:12:12 | INFO | utils.basic_utils : Evaluation:  [400/501]  eta: 0:00:01    time: 0.0175  data: 0.0000  max mem: 4826 res mem: 5368
2024-01-15T03:12:14 | INFO | utils.basic_utils : Evaluation:  [500/501]  eta: 0:00:00    time: 0.0174  data: 0.0000  max mem: 4826 res mem: 5368
2024-01-15T03:12:14 | INFO | utils.basic_utils : Evaluation: Total time: 0:00:08 (0.0174 s / it)
2024-01-15T03:12:14 | INFO | tasks.retrieval_utils : t2i_scores.shape torch.Size([501, 2000])
2024-01-15T03:12:14 | INFO | utils.basic_utils : Evaluation:  [  0/501]  eta: 0:00:30    time: 0.0611  data: 0.0006  max mem: 4826 res mem: 5368
2024-01-15T03:12:19 | INFO | utils.basic_utils : Evaluation:  [100/501]  eta: 0:00:20    time: 0.0525  data: 0.0000  max mem: 4826 res mem: 5368
2024-01-15T03:12:24 | INFO | utils.basic_utils : Evaluation:  [200/501]  eta: 0:00:15    time: 0.0502  data: 0.0000  max mem: 4826 res mem: 5368
2024-01-15T03:12:29 | INFO | utils.basic_utils : Evaluation:  [300/501]  eta: 0:00:10    time: 0.0486  data: 0.0000  max mem: 4826 res mem: 5368
2024-01-15T03:12:34 | INFO | utils.basic_utils : Evaluation:  [400/501]  eta: 0:00:05    time: 0.0489  data: 0.0000  max mem: 4826 res mem: 5368
2024-01-15T03:12:39 | INFO | utils.basic_utils : Evaluation:  [500/501]  eta: 0:00:00    time: 0.0520  data: 0.0000  max mem: 4826 res mem: 5368
2024-01-15T03:12:39 | INFO | utils.basic_utils : Evaluation: Total time: 0:00:25 (0.0505 s / it)
2024-01-15T03:12:42 | INFO | tasks.retrieval_utils : Evaluation time 0:01:17
2024-01-15T03:12:42 | INFO | __main__ : Epoch 1
2024-01-15T03:12:42 | INFO | __main__ : 
           txt_r1  txt_r5  txt_r10  txt_r_mean  img_r1  img_r5  img_r10  img_r_mean  r_mean  txt_acc  img_acc
test/       38.00    86.8     93.0       72.60   38.05   86.45    92.45       72.32   72.46    49.70    49.75
test_emb/   34.55    82.5     90.1       69.05   34.55   82.40    90.55       69.17   69.11    49.65    48.70
2024-01-15T03:13:02 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 1448 batches in total
dataloader index=0 name=video, batch-size=32 length(#batches)=1448 
2024-01-15T03:13:05 | INFO | utils.basic_utils : Train Epoch: [2]  [   0/1448]  eta: 1:27:35  lr: 0.000009  temperature: 0.0117  video-loss_vtc: 0.3471  video-loss_vtm: 0.1841  time: 3.6296  data: 3.2684  max mem: 4826 res mem: 5368
2024-01-15T03:14:02 | INFO | utils.basic_utils : Train Epoch: [2]  [ 100/1448]  eta: 0:13:22  lr: 0.000008  temperature: 0.0116  video-loss_vtc: 0.2781  video-loss_vtm: 0.0707  time: 0.5217  data: 0.0014  max mem: 4826 res mem: 5368
2024-01-15T03:14:58 | INFO | utils.basic_utils : Train Epoch: [2]  [ 200/1448]  eta: 0:12:05  lr: 0.000008  temperature: 0.0117  video-loss_vtc: 0.3079  video-loss_vtm: 0.0994  time: 0.5486  data: 0.0014  max mem: 4826 res mem: 5368
2024-01-15T03:15:55 | INFO | utils.basic_utils : Train Epoch: [2]  [ 300/1448]  eta: 0:11:01  lr: 0.000008  temperature: 0.0116  video-loss_vtc: 0.3203  video-loss_vtm: 0.1315  time: 0.5799  data: 0.0017  max mem: 4826 res mem: 5368
2024-01-15T03:16:51 | INFO | utils.basic_utils : Train Epoch: [2]  [ 400/1448]  eta: 0:10:00  lr: 0.000008  temperature: 0.0116  video-loss_vtc: 0.1590  video-loss_vtm: 0.0820  time: 0.5381  data: 0.0018  max mem: 4826 res mem: 5368
2024-01-15T03:17:45 | INFO | utils.basic_utils : Train Epoch: [2]  [ 500/1448]  eta: 0:08:56  lr: 0.000007  temperature: 0.0116  video-loss_vtc: 0.4258  video-loss_vtm: 0.1792  time: 0.5568  data: 0.0266  max mem: 4826 res mem: 5368
2024-01-15T03:18:43 | INFO | utils.basic_utils : Train Epoch: [2]  [ 600/1448]  eta: 0:08:01  lr: 0.000007  temperature: 0.0116  video-loss_vtc: 0.2269  video-loss_vtm: 0.0696  time: 0.5444  data: 0.1700  max mem: 4826 res mem: 5368
2024-01-15T03:19:41 | INFO | utils.basic_utils : Train Epoch: [2]  [ 700/1448]  eta: 0:07:05  lr: 0.000007  temperature: 0.0116  video-loss_vtc: 0.2688  video-loss_vtm: 0.1605  time: 0.5269  data: 0.1176  max mem: 4826 res mem: 5368
2024-01-15T03:20:38 | INFO | utils.basic_utils : Train Epoch: [2]  [ 800/1448]  eta: 0:06:09  lr: 0.000007  temperature: 0.0116  video-loss_vtc: 0.4261  video-loss_vtm: 0.1048  time: 0.6116  data: 0.2407  max mem: 4826 res mem: 5368
2024-01-15T03:21:34 | INFO | utils.basic_utils : Train Epoch: [2]  [ 900/1448]  eta: 0:05:11  lr: 0.000006  temperature: 0.0116  video-loss_vtc: 0.2754  video-loss_vtm: 0.1162  time: 0.5567  data: 0.1774  max mem: 4826 res mem: 5368
2024-01-15T03:22:30 | INFO | utils.basic_utils : Train Epoch: [2]  [1000/1448]  eta: 0:04:14  lr: 0.000006  temperature: 0.0115  video-loss_vtc: 0.2475  video-loss_vtm: 0.2932  time: 0.5484  data: 0.0262  max mem: 4826 res mem: 5368
2024-01-15T03:23:25 | INFO | utils.basic_utils : Train Epoch: [2]  [1100/1448]  eta: 0:03:17  lr: 0.000006  temperature: 0.0115  video-loss_vtc: 0.1872  video-loss_vtm: 0.0604  time: 0.4933  data: 0.0016  max mem: 4826 res mem: 5368
2024-01-15T03:24:22 | INFO | utils.basic_utils : Train Epoch: [2]  [1200/1448]  eta: 0:02:20  lr: 0.000006  temperature: 0.0115  video-loss_vtc: 0.2969  video-loss_vtm: 0.0863  time: 0.5935  data: 0.0017  max mem: 4826 res mem: 5368
2024-01-15T03:25:18 | INFO | utils.basic_utils : Train Epoch: [2]  [1300/1448]  eta: 0:01:23  lr: 0.000005  temperature: 0.0115  video-loss_vtc: 0.1879  video-loss_vtm: 0.0583  time: 0.6000  data: 0.0017  max mem: 4826 res mem: 5368
2024-01-15T03:26:13 | INFO | utils.basic_utils : Train Epoch: [2]  [1400/1448]  eta: 0:00:27  lr: 0.000005  temperature: 0.0115  video-loss_vtc: 0.3928  video-loss_vtm: 0.1120  time: 0.4923  data: 0.0047  max mem: 4826 res mem: 5368
2024-01-15T03:26:40 | INFO | utils.basic_utils : Train Epoch: [2]  [1447/1448]  eta: 0:00:00  lr: 0.000005  temperature: 0.0115  video-loss_vtc: 0.3111  video-loss_vtm: 0.0838  time: 0.5854  data: 0.0276  max mem: 4826 res mem: 5368
2024-01-15T03:26:40 | INFO | utils.basic_utils : Train Epoch: [2] Total time: 0:13:38 (0.5651 s / it)
2024-01-15T03:26:40 | INFO | __main__ : Averaged train stats: lr: 0.0000  temperature: 0.0116  video-loss_vtc: 0.2851  video-loss_vtm: 0.1398
2024-01-15T03:26:40 | INFO | tasks.retrieval_utils : Start evaluation for media_type=video
2024-01-15T03:26:40 | INFO | tasks.retrieval_utils : Computing dual encoder features...
2024-01-15T03:26:45 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-01-15T03:26:45 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-01-15T03:26:45 | INFO | utils.basic_utils : extracting image feats  [ 0/63]  eta: 0:04:47    time: 4.5699  data: 4.5217  max mem: 4826 res mem: 5368
2024-01-15T03:27:20 | INFO | utils.basic_utils : extracting image feats  [62/63]  eta: 0:00:00    time: 0.5176  data: 0.4746  max mem: 4826 res mem: 5368
2024-01-15T03:27:20 | INFO | utils.basic_utils : extracting image feats Total time: 0:00:39 (0.6233 s / it)
2024-01-15T03:27:21 | INFO | tasks.retrieval_utils : Finished feature extraction
2024-01-15T03:27:21 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product]
2024-01-15T03:27:21 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product], done!
2024-01-15T03:27:21 | INFO | tasks.retrieval_utils : Rerank dual-encoder results with cross-encoder...
2024-01-15T03:27:21 | INFO | tasks.retrieval_utils : i2t_scores.shape torch.Size([501, 2000])
2024-01-15T03:27:21 | INFO | tasks.retrieval_utils : n_clip_per_video=1, with eval_frame_ensemble=concat
2024-01-15T03:27:21 | INFO | utils.basic_utils : Evaluation:  [  0/501]  eta: 0:00:10    time: 0.0206  data: 0.0010  max mem: 4826 res mem: 5368
2024-01-15T03:27:23 | INFO | utils.basic_utils : Evaluation:  [100/501]  eta: 0:00:06    time: 0.0169  data: 0.0000  max mem: 4826 res mem: 5368
2024-01-15T03:27:24 | INFO | utils.basic_utils : Evaluation:  [200/501]  eta: 0:00:05    time: 0.0166  data: 0.0000  max mem: 4826 res mem: 5368
2024-01-15T03:27:26 | INFO | utils.basic_utils : Evaluation:  [300/501]  eta: 0:00:03    time: 0.0165  data: 0.0000  max mem: 4826 res mem: 5368
2024-01-15T03:27:28 | INFO | utils.basic_utils : Evaluation:  [400/501]  eta: 0:00:01    time: 0.0168  data: 0.0000  max mem: 4826 res mem: 5368
2024-01-15T03:27:29 | INFO | utils.basic_utils : Evaluation:  [500/501]  eta: 0:00:00    time: 0.0166  data: 0.0000  max mem: 4826 res mem: 5368
2024-01-15T03:27:29 | INFO | utils.basic_utils : Evaluation: Total time: 0:00:08 (0.0168 s / it)
2024-01-15T03:27:29 | INFO | tasks.retrieval_utils : t2i_scores.shape torch.Size([501, 2000])
2024-01-15T03:27:29 | INFO | utils.basic_utils : Evaluation:  [  0/501]  eta: 0:00:30    time: 0.0606  data: 0.0006  max mem: 4826 res mem: 5368
2024-01-15T03:27:35 | INFO | utils.basic_utils : Evaluation:  [100/501]  eta: 0:00:21    time: 0.0516  data: 0.0000  max mem: 4826 res mem: 5368
2024-01-15T03:27:40 | INFO | utils.basic_utils : Evaluation:  [200/501]  eta: 0:00:15    time: 0.0516  data: 0.0000  max mem: 4826 res mem: 5368
2024-01-15T03:27:45 | INFO | utils.basic_utils : Evaluation:  [300/501]  eta: 0:00:10    time: 0.0534  data: 0.0000  max mem: 4826 res mem: 5368
2024-01-15T03:27:50 | INFO | utils.basic_utils : Evaluation:  [400/501]  eta: 0:00:05    time: 0.0525  data: 0.0000  max mem: 4826 res mem: 5368
2024-01-15T03:27:55 | INFO | utils.basic_utils : Evaluation:  [500/501]  eta: 0:00:00    time: 0.0479  data: 0.0000  max mem: 4826 res mem: 5368
2024-01-15T03:27:55 | INFO | utils.basic_utils : Evaluation: Total time: 0:00:26 (0.0519 s / it)
2024-01-15T03:27:56 | INFO | tasks.retrieval_utils : Evaluation time 0:01:16
2024-01-15T03:27:57 | INFO | __main__ : Epoch 2
2024-01-15T03:27:57 | INFO | __main__ : 
           txt_r1  txt_r5  txt_r10  txt_r_mean  img_r1  img_r5  img_r10  img_r_mean  r_mean  txt_acc  img_acc
test/       37.90   87.55    92.35       72.60   38.15    86.4    92.00       72.18   72.39    48.95    49.25
test_emb/   35.55   83.10    89.60       69.42   34.65    82.6    90.55       69.27   69.34    50.10    48.55
2024-01-15T03:27:57 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 1448 batches in total
dataloader index=0 name=video, batch-size=32 length(#batches)=1448 
2024-01-15T03:28:01 | INFO | utils.basic_utils : Train Epoch: [3]  [   0/1448]  eta: 1:36:47  lr: 0.000005  temperature: 0.0115  video-loss_vtc: 0.2458  video-loss_vtm: 0.1813  time: 4.0104  data: 2.9176  max mem: 4826 res mem: 5368
2024-01-15T03:29:27 | INFO | utils.basic_utils : Train Epoch: [3]  [ 100/1448]  eta: 0:20:00  lr: 0.000005  temperature: 0.0115  video-loss_vtc: 0.2902  video-loss_vtm: 0.2249  time: 0.9216  data: 0.1730  max mem: 4826 res mem: 5368
2024-01-15T03:31:03 | INFO | utils.basic_utils : Train Epoch: [3]  [ 200/1448]  eta: 0:19:13  lr: 0.000004  temperature: 0.0114  video-loss_vtc: 0.2249  video-loss_vtm: 0.0598  time: 0.9507  data: 0.3451  max mem: 4826 res mem: 5368
2024-01-15T03:32:33 | INFO | utils.basic_utils : Train Epoch: [3]  [ 300/1448]  eta: 0:17:30  lr: 0.000004  temperature: 0.0114  video-loss_vtc: 0.2790  video-loss_vtm: 0.2059  time: 0.8368  data: 0.4293  max mem: 4826 res mem: 5368
2024-01-15T03:33:35 | INFO | utils.basic_utils : Train Epoch: [3]  [ 400/1448]  eta: 0:14:43  lr: 0.000004  temperature: 0.0113  video-loss_vtc: 0.3057  video-loss_vtm: 0.0950  time: 0.6350  data: 0.0860  max mem: 4826 res mem: 5368
2024-01-15T03:34:34 | INFO | utils.basic_utils : Train Epoch: [3]  [ 500/1448]  eta: 0:12:30  lr: 0.000004  temperature: 0.0113  video-loss_vtc: 0.1824  video-loss_vtm: 0.0927  time: 0.5561  data: 0.0015  max mem: 4826 res mem: 5368
2024-01-15T03:35:32 | INFO | utils.basic_utils : Train Epoch: [3]  [ 600/1448]  eta: 0:10:41  lr: 0.000003  temperature: 0.0113  video-loss_vtc: 0.2257  video-loss_vtm: 0.1955  time: 0.5279  data: 0.0016  max mem: 4826 res mem: 5368
2024-01-15T03:36:30 | INFO | utils.basic_utils : Train Epoch: [3]  [ 700/1448]  eta: 0:09:06  lr: 0.000003  temperature: 0.0113  video-loss_vtc: 0.3586  video-loss_vtm: 0.1911  time: 0.5862  data: 0.0018  max mem: 4826 res mem: 5368
2024-01-15T03:37:27 | INFO | utils.basic_utils : Train Epoch: [3]  [ 800/1448]  eta: 0:07:40  lr: 0.000003  temperature: 0.0113  video-loss_vtc: 0.2207  video-loss_vtm: 0.0576  time: 0.5822  data: 0.0015  max mem: 4826 res mem: 5368
2024-01-15T03:38:26 | INFO | utils.basic_utils : Train Epoch: [3]  [ 900/1448]  eta: 0:06:22  lr: 0.000003  temperature: 0.0113  video-loss_vtc: 0.2430  video-loss_vtm: 0.0966  time: 0.5804  data: 0.0015  max mem: 4826 res mem: 5368
2024-01-15T03:39:25 | INFO | utils.basic_utils : Train Epoch: [3]  [1000/1448]  eta: 0:05:07  lr: 0.000002  temperature: 0.0113  video-loss_vtc: 0.1622  video-loss_vtm: 0.0440  time: 0.6512  data: 0.0014  max mem: 4826 res mem: 5368
2024-01-15T03:40:22 | INFO | utils.basic_utils : Train Epoch: [3]  [1100/1448]  eta: 0:03:55  lr: 0.000002  temperature: 0.0113  video-loss_vtc: 0.2753  video-loss_vtm: 0.1437  time: 0.5806  data: 0.0016  max mem: 4826 res mem: 5368
2024-01-15T03:41:19 | INFO | utils.basic_utils : Train Epoch: [3]  [1200/1448]  eta: 0:02:45  lr: 0.000002  temperature: 0.0113  video-loss_vtc: 0.1546  video-loss_vtm: 0.0853  time: 0.6300  data: 0.0016  max mem: 4826 res mem: 5368
2024-01-15T03:42:15 | INFO | utils.basic_utils : Train Epoch: [3]  [1300/1448]  eta: 0:01:37  lr: 0.000002  temperature: 0.0113  video-loss_vtc: 0.2552  video-loss_vtm: 0.1331  time: 0.5482  data: 0.0016  max mem: 4826 res mem: 5368
2024-01-15T03:43:09 | INFO | utils.basic_utils : Train Epoch: [3]  [1400/1448]  eta: 0:00:31  lr: 0.000002  temperature: 0.0113  video-loss_vtc: 0.2483  video-loss_vtm: 0.2128  time: 0.5476  data: 0.0017  max mem: 4826 res mem: 5368
2024-01-15T03:43:35 | INFO | utils.basic_utils : Train Epoch: [3]  [1447/1448]  eta: 0:00:00  lr: 0.000001  temperature: 0.0113  video-loss_vtc: 0.1537  video-loss_vtm: 0.0891  time: 0.5179  data: 0.0019  max mem: 4826 res mem: 5368
2024-01-15T03:43:35 | INFO | utils.basic_utils : Train Epoch: [3] Total time: 0:15:37 (0.6472 s / it)
2024-01-15T03:43:35 | INFO | __main__ : Averaged train stats: lr: 0.0000  temperature: 0.0113  video-loss_vtc: 0.2337  video-loss_vtm: 0.1214
2024-01-15T03:43:35 | INFO | tasks.retrieval_utils : Start evaluation for media_type=video
2024-01-15T03:43:35 | INFO | tasks.retrieval_utils : Computing dual encoder features...
2024-01-15T03:43:40 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-01-15T03:43:40 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-01-15T03:43:40 | INFO | utils.basic_utils : extracting image feats  [ 0/63]  eta: 0:04:37    time: 4.4104  data: 4.3636  max mem: 4826 res mem: 5368
2024-01-15T03:44:14 | INFO | utils.basic_utils : extracting image feats  [62/63]  eta: 0:00:00    time: 0.4910  data: 0.4437  max mem: 4826 res mem: 5368
2024-01-15T03:44:14 | INFO | utils.basic_utils : extracting image feats Total time: 0:00:38 (0.6137 s / it)
2024-01-15T03:44:15 | INFO | tasks.retrieval_utils : Finished feature extraction
2024-01-15T03:44:15 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product]
2024-01-15T03:44:15 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product], done!
2024-01-15T03:44:15 | INFO | tasks.retrieval_utils : Rerank dual-encoder results with cross-encoder...
2024-01-15T03:44:15 | INFO | tasks.retrieval_utils : i2t_scores.shape torch.Size([501, 2000])
2024-01-15T03:44:15 | INFO | tasks.retrieval_utils : n_clip_per_video=1, with eval_frame_ensemble=concat
2024-01-15T03:44:15 | INFO | utils.basic_utils : Evaluation:  [  0/501]  eta: 0:00:09    time: 0.0186  data: 0.0007  max mem: 4826 res mem: 5368
2024-01-15T03:44:17 | INFO | utils.basic_utils : Evaluation:  [100/501]  eta: 0:00:07    time: 0.0177  data: 0.0000  max mem: 4826 res mem: 5368
2024-01-15T03:44:19 | INFO | utils.basic_utils : Evaluation:  [200/501]  eta: 0:00:05    time: 0.0165  data: 0.0000  max mem: 4826 res mem: 5368
2024-01-15T03:44:20 | INFO | utils.basic_utils : Evaluation:  [300/501]  eta: 0:00:03    time: 0.0167  data: 0.0000  max mem: 4826 res mem: 5368
2024-01-15T03:44:22 | INFO | utils.basic_utils : Evaluation:  [400/501]  eta: 0:00:01    time: 0.0164  data: 0.0000  max mem: 4826 res mem: 5368
2024-01-15T03:44:24 | INFO | utils.basic_utils : Evaluation:  [500/501]  eta: 0:00:00    time: 0.0168  data: 0.0000  max mem: 4826 res mem: 5368
2024-01-15T03:44:24 | INFO | utils.basic_utils : Evaluation: Total time: 0:00:08 (0.0169 s / it)
2024-01-15T03:44:24 | INFO | tasks.retrieval_utils : t2i_scores.shape torch.Size([501, 2000])
2024-01-15T03:44:24 | INFO | utils.basic_utils : Evaluation:  [  0/501]  eta: 0:00:28    time: 0.0562  data: 0.0005  max mem: 4826 res mem: 5368
2024-01-15T03:44:29 | INFO | utils.basic_utils : Evaluation:  [100/501]  eta: 0:00:21    time: 0.0543  data: 0.0000  max mem: 4826 res mem: 5368
2024-01-15T03:44:34 | INFO | utils.basic_utils : Evaluation:  [200/501]  eta: 0:00:16    time: 0.0535  data: 0.0000  max mem: 4826 res mem: 5368
2024-01-15T03:44:40 | INFO | utils.basic_utils : Evaluation:  [300/501]  eta: 0:00:10    time: 0.0578  data: 0.0000  max mem: 4826 res mem: 5368
2024-01-15T03:44:45 | INFO | utils.basic_utils : Evaluation:  [400/501]  eta: 0:00:05    time: 0.0551  data: 0.0000  max mem: 4826 res mem: 5368
2024-01-15T03:44:51 | INFO | utils.basic_utils : Evaluation:  [500/501]  eta: 0:00:00    time: 0.0487  data: 0.0000  max mem: 4826 res mem: 5368
2024-01-15T03:44:51 | INFO | utils.basic_utils : Evaluation: Total time: 0:00:27 (0.0543 s / it)
2024-01-15T03:44:51 | INFO | tasks.retrieval_utils : Evaluation time 0:01:16
2024-01-15T03:44:52 | INFO | __main__ : Epoch 3
2024-01-15T03:44:52 | INFO | __main__ : 
           txt_r1  txt_r5  txt_r10  txt_r_mean  img_r1  img_r5  img_r10  img_r_mean  r_mean  txt_acc  img_acc
test/       38.10   87.30    92.95       72.78    37.9    86.5    92.30       72.23   72.51    49.25    49.65
test_emb/   35.25   83.15    90.40       69.60    34.3    83.0    90.65       69.32   69.46    49.80    48.35
2024-01-15T03:45:11 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 1448 batches in total
dataloader index=0 name=video, batch-size=32 length(#batches)=1448 
2024-01-15T03:45:15 | INFO | utils.basic_utils : Train Epoch: [4]  [   0/1448]  eta: 1:29:49  lr: 0.000001  temperature: 0.0113  video-loss_vtc: 0.1217  video-loss_vtm: 0.0676  time: 3.7218  data: 2.7218  max mem: 4826 res mem: 5368
2024-01-15T03:46:10 | INFO | utils.basic_utils : Train Epoch: [4]  [ 100/1448]  eta: 0:13:13  lr: 0.000001  temperature: 0.0113  video-loss_vtc: 0.2479  video-loss_vtm: 0.0457  time: 0.5565  data: 0.0018  max mem: 4826 res mem: 5368
2024-01-15T03:47:07 | INFO | utils.basic_utils : Train Epoch: [4]  [ 200/1448]  eta: 0:12:00  lr: 0.000001  temperature: 0.0112  video-loss_vtc: 0.2440  video-loss_vtm: 0.1171  time: 0.6020  data: 0.2181  max mem: 4826 res mem: 5368
2024-01-15T03:48:05 | INFO | utils.basic_utils : Train Epoch: [4]  [ 300/1448]  eta: 0:11:04  lr: 0.000001  temperature: 0.0112  video-loss_vtc: 0.2326  video-loss_vtm: 0.1535  time: 0.5709  data: 0.2041  max mem: 4826 res mem: 5368
2024-01-15T03:49:02 | INFO | utils.basic_utils : Train Epoch: [4]  [ 400/1448]  eta: 0:10:05  lr: 0.000001  temperature: 0.0112  video-loss_vtc: 0.2003  video-loss_vtm: 0.0291  time: 0.5692  data: 0.2077  max mem: 4826 res mem: 5368
2024-01-15T03:49:58 | INFO | utils.basic_utils : Train Epoch: [4]  [ 500/1448]  eta: 0:09:04  lr: 0.000001  temperature: 0.0112  video-loss_vtc: 0.2468  video-loss_vtm: 0.0730  time: 0.5521  data: 0.1810  max mem: 4826 res mem: 5368
2024-01-15T03:50:55 | INFO | utils.basic_utils : Train Epoch: [4]  [ 600/1448]  eta: 0:08:05  lr: 0.000001  temperature: 0.0112  video-loss_vtc: 0.4658  video-loss_vtm: 0.2210  time: 0.5134  data: 0.1425  max mem: 4826 res mem: 5368
2024-01-15T03:51:52 | INFO | utils.basic_utils : Train Epoch: [4]  [ 700/1448]  eta: 0:07:07  lr: 0.000000  temperature: 0.0112  video-loss_vtc: 0.2153  video-loss_vtm: 0.1259  time: 0.6023  data: 0.1422  max mem: 4826 res mem: 5368
2024-01-15T03:52:48 | INFO | utils.basic_utils : Train Epoch: [4]  [ 800/1448]  eta: 0:06:09  lr: 0.000000  temperature: 0.0112  video-loss_vtc: 0.1178  video-loss_vtm: 0.1504  time: 0.5719  data: 0.1935  max mem: 4826 res mem: 5368
2024-01-15T03:53:43 | INFO | utils.basic_utils : Train Epoch: [4]  [ 900/1448]  eta: 0:05:11  lr: 0.000000  temperature: 0.0112  video-loss_vtc: 0.1908  video-loss_vtm: 0.0517  time: 0.5293  data: 0.0015  max mem: 4826 res mem: 5368
2024-01-15T03:54:41 | INFO | utils.basic_utils : Train Epoch: [4]  [1000/1448]  eta: 0:04:15  lr: 0.000000  temperature: 0.0112  video-loss_vtc: 0.2367  video-loss_vtm: 0.1319  time: 0.5863  data: 0.2229  max mem: 4826 res mem: 5368
2024-01-15T03:55:38 | INFO | utils.basic_utils : Train Epoch: [4]  [1100/1448]  eta: 0:03:18  lr: 0.000000  temperature: 0.0112  video-loss_vtc: 0.2050  video-loss_vtm: 0.0283  time: 0.4998  data: 0.0016  max mem: 4826 res mem: 5368
2024-01-15T03:56:35 | INFO | utils.basic_utils : Train Epoch: [4]  [1200/1448]  eta: 0:02:21  lr: 0.000000  temperature: 0.0112  video-loss_vtc: 0.2188  video-loss_vtm: 0.1030  time: 0.5789  data: 0.1014  max mem: 4826 res mem: 5368
2024-01-15T03:57:30 | INFO | utils.basic_utils : Train Epoch: [4]  [1300/1448]  eta: 0:01:24  lr: 0.000000  temperature: 0.0112  video-loss_vtc: 0.1902  video-loss_vtm: 0.0573  time: 0.5367  data: 0.1618  max mem: 4826 res mem: 5368
2024-01-15T03:58:26 | INFO | utils.basic_utils : Train Epoch: [4]  [1400/1448]  eta: 0:00:27  lr: 0.000000  temperature: 0.0112  video-loss_vtc: 0.3281  video-loss_vtm: 0.0986  time: 0.5713  data: 0.0232  max mem: 4826 res mem: 5368
2024-01-15T03:58:53 | INFO | utils.basic_utils : Train Epoch: [4]  [1447/1448]  eta: 0:00:00  lr: 0.000000  temperature: 0.0112  video-loss_vtc: 0.1975  video-loss_vtm: 0.0719  time: 0.5656  data: 0.1607  max mem: 4826 res mem: 5368
2024-01-15T03:58:53 | INFO | utils.basic_utils : Train Epoch: [4] Total time: 0:13:42 (0.5681 s / it)
2024-01-15T03:58:53 | INFO | __main__ : Averaged train stats: lr: 0.0000  temperature: 0.0112  video-loss_vtc: 0.2171  video-loss_vtm: 0.1142
2024-01-15T03:58:53 | INFO | tasks.retrieval_utils : Start evaluation for media_type=video
2024-01-15T03:58:53 | INFO | tasks.retrieval_utils : Computing dual encoder features...
2024-01-15T03:58:59 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-01-15T03:58:59 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-01-15T03:58:59 | INFO | utils.basic_utils : extracting image feats  [ 0/63]  eta: 0:04:40    time: 4.4524  data: 4.4081  max mem: 4826 res mem: 5368
2024-01-15T03:59:33 | INFO | utils.basic_utils : extracting image feats  [62/63]  eta: 0:00:00    time: 0.5040  data: 0.4581  max mem: 4826 res mem: 5368
2024-01-15T03:59:33 | INFO | utils.basic_utils : extracting image feats Total time: 0:00:38 (0.6156 s / it)
2024-01-15T03:59:34 | INFO | tasks.retrieval_utils : Finished feature extraction
2024-01-15T03:59:34 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product]
2024-01-15T03:59:34 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product], done!
2024-01-15T03:59:34 | INFO | tasks.retrieval_utils : Rerank dual-encoder results with cross-encoder...
2024-01-15T03:59:34 | INFO | tasks.retrieval_utils : i2t_scores.shape torch.Size([501, 2000])
2024-01-15T03:59:34 | INFO | tasks.retrieval_utils : n_clip_per_video=1, with eval_frame_ensemble=concat
2024-01-15T03:59:34 | INFO | utils.basic_utils : Evaluation:  [  0/501]  eta: 0:00:09    time: 0.0185  data: 0.0008  max mem: 4826 res mem: 5368
2024-01-15T03:59:36 | INFO | utils.basic_utils : Evaluation:  [100/501]  eta: 0:00:06    time: 0.0174  data: 0.0000  max mem: 4826 res mem: 5368
2024-01-15T03:59:37 | INFO | utils.basic_utils : Evaluation:  [200/501]  eta: 0:00:05    time: 0.0169  data: 0.0000  max mem: 4826 res mem: 5368
2024-01-15T03:59:39 | INFO | utils.basic_utils : Evaluation:  [300/501]  eta: 0:00:03    time: 0.0167  data: 0.0000  max mem: 4826 res mem: 5368
2024-01-15T03:59:41 | INFO | utils.basic_utils : Evaluation:  [400/501]  eta: 0:00:01    time: 0.0168  data: 0.0000  max mem: 4826 res mem: 5368
2024-01-15T03:59:42 | INFO | utils.basic_utils : Evaluation:  [500/501]  eta: 0:00:00    time: 0.0169  data: 0.0000  max mem: 4826 res mem: 5368
2024-01-15T03:59:42 | INFO | utils.basic_utils : Evaluation: Total time: 0:00:08 (0.0168 s / it)
2024-01-15T03:59:42 | INFO | tasks.retrieval_utils : t2i_scores.shape torch.Size([501, 2000])
2024-01-15T03:59:42 | INFO | utils.basic_utils : Evaluation:  [  0/501]  eta: 0:00:28    time: 0.0571  data: 0.0006  max mem: 4826 res mem: 5368
2024-01-15T03:59:48 | INFO | utils.basic_utils : Evaluation:  [100/501]  eta: 0:00:21    time: 0.0527  data: 0.0000  max mem: 4826 res mem: 5368
2024-01-15T03:59:53 | INFO | utils.basic_utils : Evaluation:  [200/501]  eta: 0:00:15    time: 0.0523  data: 0.0000  max mem: 4826 res mem: 5368
2024-01-15T03:59:58 | INFO | utils.basic_utils : Evaluation:  [300/501]  eta: 0:00:10    time: 0.0539  data: 0.0000  max mem: 4826 res mem: 5368
2024-01-15T04:00:04 | INFO | utils.basic_utils : Evaluation:  [400/501]  eta: 0:00:05    time: 0.0523  data: 0.0000  max mem: 4826 res mem: 5368
2024-01-15T04:00:09 | INFO | utils.basic_utils : Evaluation:  [500/501]  eta: 0:00:00    time: 0.0445  data: 0.0000  max mem: 4826 res mem: 5368
2024-01-15T04:00:09 | INFO | utils.basic_utils : Evaluation: Total time: 0:00:26 (0.0524 s / it)
2024-01-15T04:00:09 | INFO | tasks.retrieval_utils : Evaluation time 0:01:15
2024-01-15T04:00:10 | INFO | __main__ : Epoch 4
2024-01-15T04:00:10 | INFO | __main__ : 
           txt_r1  txt_r5  txt_r10  txt_r_mean  img_r1  img_r5  img_r10  img_r_mean  r_mean  txt_acc  img_acc
test/       38.15   87.25    92.80       72.73    38.6   86.45     92.2       72.42   72.58    49.25    49.90
test_emb/   35.60   82.90    90.05       69.52    34.3   82.90     90.7       69.30   69.41    50.05    48.35
2024-01-15T04:00:29 | INFO | __main__ : Training time 1:17:55
2024-01-15T04:00:29 | INFO | __main__ : best epoch 4 [config.stop_key test/]
2024-01-15T04:00:29 | INFO | __main__ : Checkpoints and Logs saved at exp/finetuning/ret_rtime/b16_25m_200k_1frame
2024-01-15T04:00:33 | INFO | __main__ : ===========> START eval_after_training [['test']]
2024-01-15T04:00:33 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/training_200k.json', '/data2/dy/temporal_video/dataset', 'video'], 'test_file': {'test': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test2k.json', '/data2/dy/temporal_video/dataset', 'video']}, 'test_types': ['test'], 'num_workers': 6, 'stop_key': 'test/', 'is_paragraph_retrieval': False, 'num_frames': 1, 'num_frames_test': 1, 'batch_size': 32, 'max_txt_l': 32, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 1, 'sample_type': 'rand', 'num_frames_test': 1, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 32, 'video': 32}, 'batch_size': {'image': 32, 'video': 32}, 'batch_size_test': {'image': 32, 'video': 32}}, 'text_enc': 'bert', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_b16', 'img_size': 224, 'patch_size': 16, 'd_model': 768, 'encoder_embed_dim': 768, 'encoder_depth': 12, 'encoder_num_heads': 12, 'drop_path_rate': 0.2, 'num_frames': 1, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 12, 'clip_decoder_embed_dim': 768, 'clip_output_dim': 512, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 224, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'multimodal': {'enable': True}, 'embed_dim': 512, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 1e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 5, 'min_lr_multi': 0.01, 'warmup_epochs': 1, 'num_training_steps': 7240, 'num_warmup_steps': 1448}, 'evaluate': True, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': False, 'entity': 'user', 'project': 'umt_ret'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': 'exp/finetuning/ret_rtime/b16_25m_200k_1frame/eval_after_training', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 42, 'save_latest': True, 'auto_resume': True, 'pretrained_path': 'exp/finetuning/ret_rtime/b16_25m_200k_1frame/ckpt_best.pth', 'rank': 0, 'world_size': 4, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl', 'result_dir': 'exp/finetuning/ret_rtime/b16_25m_200k_1frame/eval_after_training'}
2024-01-15T04:00:33 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/training_200k.json', '/data2/dy/temporal_video/dataset', 'video']
2024-01-15T04:00:33 | INFO | tasks.pretrain : Creating dataset for ret
2024-01-15T04:00:33 | INFO | tasks.shared_utils : Creating model
2024-01-15T04:00:35 | INFO | models.umt : Build vision_encoder: vit_b16
2024-01-15T04:00:35 | INFO | models.backbones.vit.vit : Num of patches: 196
2024-01-15T04:00:35 | INFO | models.backbones.vit.vit : Use checkpoint: True
2024-01-15T04:00:35 | INFO | models.backbones.vit.vit : Checkpoint number: 12
2024-01-15T04:00:35 | INFO | models.backbones.vit.vit : Student return index: []
2024-01-15T04:00:38 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
2024-01-15T04:00:38 | INFO | models.umt : Build text_encoder bert_base
2024-01-15T04:00:39 | INFO | models.backbones.bert.xbert : build bert with cross_module: ca
2024-01-15T04:00:40 | INFO | models.criterions : Norm type: l2
2024-01-15T04:00:40 | INFO | models.criterions : Loss type: l2
2024-01-15T04:00:40 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.temp: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.weight: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.weight: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.embeddings.word_embeddings.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.embeddings.position_embeddings.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.embeddings.token_type_embeddings.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.vision_proj.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.text_proj.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.itm_head.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : param module.itm_head.bias: wd: 0, lr: 1e-05
2024-01-15T04:00:40 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0.02 len(p)=140
2024-01-15T04:00:40 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0 len(p)=256
2024-01-15T04:00:40 | INFO | tasks.shared_utils : Auto resuming
2024-01-15T04:00:40 | INFO | tasks.shared_utils : Not found checkpoint in exp/finetuning/ret_rtime/b16_25m_200k_1frame/eval_after_training
2024-01-15T04:00:41 | WARNING | urllib3.connectionpool : Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:997)'))': /api/4504800232407040/envelope/
2024-01-15T04:00:41 | INFO | tasks.shared_utils : <All keys matched successfully>
2024-01-15T04:00:41 | INFO | tasks.shared_utils : Loaded checkpoint from exp/finetuning/ret_rtime/b16_25m_200k_1frame/ckpt_best.pth
2024-01-15T04:00:41 | INFO | __main__ : Start evaluation
2024-01-15T04:00:41 | INFO | tasks.retrieval_utils : Start evaluation for media_type=video
2024-01-15T04:00:41 | INFO | tasks.retrieval_utils : Computing dual encoder features...
2024-01-15T04:00:48 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-01-15T04:00:48 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-01-15T04:00:48 | INFO | utils.basic_utils : extracting image feats  [ 0/63]  eta: 0:06:10    time: 5.8747  data: 5.8116  max mem: 4826 res mem: 5892
2024-01-15T04:00:51 | WARNING | urllib3.connectionpool : Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:997)'))': /api/4504800232407040/envelope/
2024-01-15T04:01:01 | WARNING | urllib3.connectionpool : Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:997)'))': /api/4504800232407040/envelope/
2024-01-15T04:01:25 | INFO | utils.basic_utils : extracting image feats  [62/63]  eta: 0:00:00    time: 0.5179  data: 0.4696  max mem: 4826 res mem: 5892
2024-01-15T04:01:25 | INFO | utils.basic_utils : extracting image feats Total time: 0:00:42 (0.6813 s / it)
2024-01-15T04:01:26 | INFO | tasks.retrieval_utils : Finished feature extraction
2024-01-15T04:01:26 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product]
2024-01-15T04:01:26 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product], done!
2024-01-15T04:01:26 | INFO | tasks.retrieval_utils : Rerank dual-encoder results with cross-encoder...
2024-01-15T04:01:26 | INFO | tasks.retrieval_utils : i2t_scores.shape torch.Size([501, 2000])
2024-01-15T04:01:26 | INFO | tasks.retrieval_utils : n_clip_per_video=1, with eval_frame_ensemble=concat
2024-01-15T04:01:26 | INFO | utils.basic_utils : Evaluation:  [  0/501]  eta: 0:00:10    time: 0.0213  data: 0.0007  max mem: 4826 res mem: 5892
2024-01-15T04:01:28 | INFO | utils.basic_utils : Evaluation:  [100/501]  eta: 0:00:06    time: 0.0164  data: 0.0000  max mem: 4826 res mem: 5892
2024-01-15T04:01:30 | INFO | utils.basic_utils : Evaluation:  [200/501]  eta: 0:00:05    time: 0.0165  data: 0.0000  max mem: 4826 res mem: 5892
2024-01-15T04:01:31 | INFO | utils.basic_utils : Evaluation:  [300/501]  eta: 0:00:03    time: 0.0167  data: 0.0000  max mem: 4826 res mem: 5892
2024-01-15T04:01:33 | INFO | utils.basic_utils : Evaluation:  [400/501]  eta: 0:00:01    time: 0.0169  data: 0.0000  max mem: 4826 res mem: 5892
2024-01-15T04:01:35 | INFO | utils.basic_utils : Evaluation:  [500/501]  eta: 0:00:00    time: 0.0171  data: 0.0000  max mem: 4826 res mem: 5892
2024-01-15T04:01:35 | INFO | utils.basic_utils : Evaluation: Total time: 0:00:08 (0.0168 s / it)
2024-01-15T04:01:35 | INFO | tasks.retrieval_utils : t2i_scores.shape torch.Size([501, 2000])
2024-01-15T04:01:35 | INFO | utils.basic_utils : Evaluation:  [  0/501]  eta: 0:00:33    time: 0.0678  data: 0.0006  max mem: 4826 res mem: 5892
2024-01-15T04:01:41 | INFO | utils.basic_utils : Evaluation:  [100/501]  eta: 0:00:23    time: 0.0575  data: 0.0000  max mem: 4826 res mem: 5892
2024-01-15T04:01:46 | INFO | utils.basic_utils : Evaluation:  [200/501]  eta: 0:00:17    time: 0.0555  data: 0.0000  max mem: 4826 res mem: 5892
2024-01-15T04:01:52 | INFO | utils.basic_utils : Evaluation:  [300/501]  eta: 0:00:11    time: 0.0573  data: 0.0000  max mem: 4826 res mem: 5892
2024-01-15T04:01:57 | INFO | utils.basic_utils : Evaluation:  [400/501]  eta: 0:00:05    time: 0.0501  data: 0.0000  max mem: 4826 res mem: 5892
2024-01-15T04:02:02 | INFO | utils.basic_utils : Evaluation:  [500/501]  eta: 0:00:00    time: 0.0449  data: 0.0000  max mem: 4826 res mem: 5892
2024-01-15T04:02:02 | INFO | utils.basic_utils : Evaluation: Total time: 0:00:27 (0.0542 s / it)
2024-01-15T04:02:02 | INFO | tasks.retrieval_utils : Evaluation time 0:01:20
2024-01-15T04:02:03 | INFO | __main__ : Epoch 0
2024-01-15T04:02:03 | INFO | __main__ : 
           txt_r1  txt_r5  txt_r10  txt_r_mean  img_r1  img_r5  img_r10  img_r_mean  r_mean  txt_acc  img_acc
test/       38.15   87.25    92.80       72.73    38.6   86.45     92.2       72.42   72.58    49.25    49.90
test_emb/   35.60   82.90    90.05       69.52    34.3   82.90     90.7       69.30   69.41    50.05    48.35
2024-01-15T04:02:03 | INFO | __main__ : Training time 0:01:21
2024-01-15T04:02:03 | INFO | __main__ : best epoch 0 [config.stop_key test/]
2024-01-15T04:02:03 | INFO | __main__ : Checkpoints and Logs saved at exp/finetuning/ret_rtime/b16_25m_200k_1frame/eval_after_training
2024-01-15T04:09:11 | INFO | umt : Logging to: exp/finetuning/ret_rtime/b16_25m_200k_1frame/train.log
2024-01-15T04:09:11 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/training_200k.json', '/data2/dy/temporal_video/dataset', 'video']
  test_file: {
      test: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test2k.json', '/data2/dy/temporal_video/dataset', 'video'] }
  test_types: ['test']
  num_workers: 6
  stop_key: test/
  is_paragraph_retrieval: False
  num_frames: 4
  num_frames_test: 4
  batch_size: 32
  max_txt_l: 32
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 4
          sample_type: rand
          num_frames_test: 4
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 32
          video: 32 }
      batch_size: {
          image: 32
          video: 32 }
      batch_size_test: {
          image: 32
          video: 32 } }
  text_enc: bert
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_b16
          img_size: 224
          patch_size: 16
          d_model: 768
          encoder_embed_dim: 768
          encoder_depth: 12
          encoder_num_heads: 12
          drop_path_rate: 0.2
          num_frames: 4
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 12
          clip_decoder_embed_dim: 768
          clip_output_dim: 512
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 224
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      multimodal: {
          enable: True }
      embed_dim: 512
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 1e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 5
      min_lr_multi: 0.01
      warmup_epochs: 1 }
  evaluate: True
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: user
      project: umt_ret }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/finetuning/ret_rtime/b16_25m_200k_1frame
  resume: False
  debug: False
  log_freq: 100
  seed: 42
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
  rank: 0
  world_size: 4
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-01-15T04:09:11 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/training_200k.json', '/data2/dy/temporal_video/dataset', 'video'], 'test_file': {'test': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test2k.json', '/data2/dy/temporal_video/dataset', 'video']}, 'test_types': ['test'], 'num_workers': 6, 'stop_key': 'test/', 'is_paragraph_retrieval': False, 'num_frames': 4, 'num_frames_test': 4, 'batch_size': 32, 'max_txt_l': 32, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 4, 'sample_type': 'rand', 'num_frames_test': 4, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 32, 'video': 32}, 'batch_size': {'image': 32, 'video': 32}, 'batch_size_test': {'image': 32, 'video': 32}}, 'text_enc': 'bert', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_b16', 'img_size': 224, 'patch_size': 16, 'd_model': 768, 'encoder_embed_dim': 768, 'encoder_depth': 12, 'encoder_num_heads': 12, 'drop_path_rate': 0.2, 'num_frames': 4, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 12, 'clip_decoder_embed_dim': 768, 'clip_output_dim': 512, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 224, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'multimodal': {'enable': True}, 'embed_dim': 512, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 1e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 5, 'min_lr_multi': 0.01, 'warmup_epochs': 1}, 'evaluate': True, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': False, 'entity': 'user', 'project': 'umt_ret'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': 'exp/finetuning/ret_rtime/b16_25m_200k_1frame', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 42, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth', 'rank': 0, 'world_size': 4, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2024-01-15T04:09:11 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/training_200k.json', '/data2/dy/temporal_video/dataset', 'video']
2024-01-15T04:09:11 | INFO | tasks.pretrain : Creating dataset for ret
2024-01-15T04:09:11 | INFO | tasks.shared_utils : Creating model
2024-01-15T04:09:23 | INFO | models.umt : Build vision_encoder: vit_b16
2024-01-15T04:09:23 | INFO | models.backbones.vit.vit : Num of patches: 784
2024-01-15T04:09:23 | INFO | models.backbones.vit.vit : Use checkpoint: True
2024-01-15T04:09:23 | INFO | models.backbones.vit.vit : Checkpoint number: 12
2024-01-15T04:09:23 | INFO | models.backbones.vit.vit : Student return index: []
2024-01-15T04:09:27 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
2024-01-15T04:09:28 | INFO | models.umt : Build text_encoder bert_base
2024-01-15T04:09:29 | INFO | models.backbones.bert.xbert : build bert with cross_module: ca
2024-01-15T04:09:29 | INFO | models.criterions : Norm type: l2
2024-01-15T04:09:29 | INFO | models.criterions : Loss type: l2
2024-01-15T04:09:31 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.temp: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.weight: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.weight: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.embeddings.word_embeddings.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.embeddings.position_embeddings.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.embeddings.token_type_embeddings.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.vision_proj.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.text_proj.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.itm_head.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : param module.itm_head.bias: wd: 0, lr: 1e-05
2024-01-15T04:09:31 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0.02 len(p)=140
2024-01-15T04:09:31 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0 len(p)=256
2024-01-15T04:09:31 | INFO | tasks.shared_utils : Auto resuming
2024-01-15T04:09:34 | INFO | tasks.shared_utils : <All keys matched successfully>
2024-01-15T04:09:34 | INFO | tasks.shared_utils : Loaded checkpoint from exp/finetuning/ret_rtime/b16_25m_200k_1frame/ckpt_best.pth
2024-01-15T04:09:34 | INFO | __main__ : Start evaluation
2024-01-15T04:09:34 | INFO | __main__ : Training time 0:00:00
2024-01-15T04:09:34 | INFO | __main__ : best epoch 0 [config.stop_key test/]
2024-01-15T04:09:34 | INFO | __main__ : Checkpoints and Logs saved at exp/finetuning/ret_rtime/b16_25m_200k_1frame
2024-01-15T04:20:18 | INFO | umt : Logging to: exp/finetuning/ret_rtime/b16_25m_200k_1frame/train.log
2024-01-15T04:20:18 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/training_200k.json', '/data2/dy/temporal_video/dataset', 'video']
  test_file: {
      test: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test2k.json', '/data2/dy/temporal_video/dataset', 'video'] }
  test_types: ['test']
  num_workers: 6
  stop_key: test/
  is_paragraph_retrieval: False
  num_frames: 4
  num_frames_test: 4
  batch_size: 32
  max_txt_l: 32
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 4
          sample_type: rand
          num_frames_test: 4
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 32
          video: 32 }
      batch_size: {
          image: 32
          video: 32 }
      batch_size_test: {
          image: 32
          video: 32 } }
  text_enc: bert
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_b16
          img_size: 224
          patch_size: 16
          d_model: 768
          encoder_embed_dim: 768
          encoder_depth: 12
          encoder_num_heads: 12
          drop_path_rate: 0.2
          num_frames: 4
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 12
          clip_decoder_embed_dim: 768
          clip_output_dim: 512
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 224
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      multimodal: {
          enable: True }
      embed_dim: 512
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 1e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 5
      min_lr_multi: 0.01
      warmup_epochs: 1 }
  zero_shot: False
  evaluate: True
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: user
      project: umt_ret }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/finetuning/ret_rtime/b16_25m_200k_1frame
  resume: False
  debug: False
  log_freq: 100
  seed: 42
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
  rank: 0
  world_size: 4
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-01-15T04:20:18 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/training_200k.json', '/data2/dy/temporal_video/dataset', 'video'], 'test_file': {'test': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test2k.json', '/data2/dy/temporal_video/dataset', 'video']}, 'test_types': ['test'], 'num_workers': 6, 'stop_key': 'test/', 'is_paragraph_retrieval': False, 'num_frames': 4, 'num_frames_test': 4, 'batch_size': 32, 'max_txt_l': 32, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 4, 'sample_type': 'rand', 'num_frames_test': 4, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 32, 'video': 32}, 'batch_size': {'image': 32, 'video': 32}, 'batch_size_test': {'image': 32, 'video': 32}}, 'text_enc': 'bert', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_b16', 'img_size': 224, 'patch_size': 16, 'd_model': 768, 'encoder_embed_dim': 768, 'encoder_depth': 12, 'encoder_num_heads': 12, 'drop_path_rate': 0.2, 'num_frames': 4, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 12, 'clip_decoder_embed_dim': 768, 'clip_output_dim': 512, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 224, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'multimodal': {'enable': True}, 'embed_dim': 512, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 1e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 5, 'min_lr_multi': 0.01, 'warmup_epochs': 1}, 'zero_shot': False, 'evaluate': True, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': False, 'entity': 'user', 'project': 'umt_ret'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': 'exp/finetuning/ret_rtime/b16_25m_200k_1frame', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 42, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth', 'rank': 0, 'world_size': 4, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2024-01-15T04:20:18 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/training_200k.json', '/data2/dy/temporal_video/dataset', 'video']
2024-01-15T04:20:18 | INFO | tasks.pretrain : Creating dataset for ret
2024-01-15T04:20:19 | INFO | tasks.shared_utils : Creating model
2024-01-15T04:20:31 | INFO | models.umt : Build vision_encoder: vit_b16
2024-01-15T04:20:31 | INFO | models.backbones.vit.vit : Num of patches: 784
2024-01-15T04:20:31 | INFO | models.backbones.vit.vit : Use checkpoint: True
2024-01-15T04:20:31 | INFO | models.backbones.vit.vit : Checkpoint number: 12
2024-01-15T04:20:31 | INFO | models.backbones.vit.vit : Student return index: []
2024-01-15T04:20:38 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
2024-01-15T04:20:38 | INFO | models.umt : Build text_encoder bert_base
2024-01-15T04:20:40 | INFO | models.backbones.bert.xbert : build bert with cross_module: ca
2024-01-15T04:20:41 | INFO | models.criterions : Norm type: l2
2024-01-15T04:20:41 | INFO | models.criterions : Loss type: l2
2024-01-15T04:20:42 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.temp: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.weight: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.weight: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.embeddings.word_embeddings.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.embeddings.position_embeddings.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.embeddings.token_type_embeddings.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.vision_proj.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.text_proj.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.itm_head.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : param module.itm_head.bias: wd: 0, lr: 1e-05
2024-01-15T04:20:42 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0.02 len(p)=140
2024-01-15T04:20:42 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0 len(p)=256
2024-01-15T04:20:42 | INFO | tasks.shared_utils : Auto resuming
2024-01-15T04:20:47 | INFO | tasks.shared_utils : <All keys matched successfully>
2024-01-15T04:20:47 | INFO | tasks.shared_utils : Loaded checkpoint from exp/finetuning/ret_rtime/b16_25m_200k_1frame/ckpt_best.pth
2024-01-15T04:20:47 | INFO | __main__ : Start evaluation
2024-01-15T04:20:47 | INFO | tasks.retrieval_utils : Start evaluation for media_type=video
2024-01-15T04:20:47 | INFO | tasks.retrieval_utils : Computing dual encoder features...
2024-01-15T04:21:13 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-01-15T04:21:13 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-01-15T04:21:13 | INFO | utils.basic_utils : extracting image feats  [ 0/63]  eta: 0:24:02    time: 22.9034  data: 16.8316  max mem: 5393 res mem: 6346
2024-01-15T04:22:42 | INFO | utils.basic_utils : extracting image feats  [62/63]  eta: 0:00:01    time: 1.3599  data: 1.1296  max mem: 5478 res mem: 6348
2024-01-15T04:22:42 | INFO | utils.basic_utils : extracting image feats Total time: 0:01:51 (1.7766 s / it)
2024-01-15T04:22:46 | INFO | tasks.retrieval_utils : Finished feature extraction
2024-01-15T04:22:46 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product]
2024-01-15T04:22:46 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product], done!
2024-01-15T04:22:46 | INFO | tasks.retrieval_utils : Rerank dual-encoder results with cross-encoder...
2024-01-15T04:22:46 | INFO | tasks.retrieval_utils : i2t_scores.shape torch.Size([501, 2000])
2024-01-15T04:22:46 | INFO | tasks.retrieval_utils : n_clip_per_video=1, with eval_frame_ensemble=concat
2024-01-15T04:22:46 | INFO | utils.basic_utils : Evaluation:  [  0/501]  eta: 0:00:11    time: 0.0232  data: 0.0004  max mem: 5478 res mem: 6348
2024-01-15T04:22:49 | INFO | utils.basic_utils : Evaluation:  [100/501]  eta: 0:00:11    time: 0.0283  data: 0.0000  max mem: 5478 res mem: 6348
2024-01-15T04:22:52 | INFO | utils.basic_utils : Evaluation:  [200/501]  eta: 0:00:08    time: 0.0283  data: 0.0000  max mem: 5478 res mem: 6348
2024-01-15T04:22:55 | INFO | utils.basic_utils : Evaluation:  [300/501]  eta: 0:00:05    time: 0.0283  data: 0.0000  max mem: 5478 res mem: 6348
2024-01-15T04:22:58 | INFO | utils.basic_utils : Evaluation:  [400/501]  eta: 0:00:02    time: 0.0284  data: 0.0000  max mem: 5478 res mem: 6348
2024-01-15T04:23:01 | INFO | utils.basic_utils : Evaluation:  [500/501]  eta: 0:00:00    time: 0.0285  data: 0.0000  max mem: 5478 res mem: 6348
2024-01-15T04:23:01 | INFO | utils.basic_utils : Evaluation: Total time: 0:00:14 (0.0284 s / it)
2024-01-15T04:23:01 | INFO | tasks.retrieval_utils : t2i_scores.shape torch.Size([501, 2000])
2024-01-15T04:23:01 | INFO | utils.basic_utils : Evaluation:  [  0/501]  eta: 0:02:23    time: 0.2859  data: 0.0003  max mem: 5478 res mem: 6348
2024-01-15T04:23:39 | INFO | utils.basic_utils : Evaluation:  [100/501]  eta: 0:02:30    time: 0.4100  data: 0.0000  max mem: 5478 res mem: 6348
2024-01-15T04:24:12 | INFO | utils.basic_utils : Evaluation:  [200/501]  eta: 0:01:47    time: 0.2620  data: 0.0000  max mem: 5478 res mem: 6348
2024-01-15T04:24:38 | INFO | utils.basic_utils : Evaluation:  [300/501]  eta: 0:01:05    time: 0.2543  data: 0.0000  max mem: 5478 res mem: 6348
2024-01-15T04:25:04 | INFO | utils.basic_utils : Evaluation:  [400/501]  eta: 0:00:30    time: 0.2512  data: 0.0000  max mem: 5478 res mem: 6348
2024-01-15T04:25:29 | INFO | utils.basic_utils : Evaluation:  [500/501]  eta: 0:00:00    time: 0.2461  data: 0.0000  max mem: 5478 res mem: 6348
2024-01-15T04:25:29 | INFO | utils.basic_utils : Evaluation: Total time: 0:02:28 (0.2956 s / it)
2024-01-15T04:25:43 | INFO | tasks.retrieval_utils : Evaluation time 0:04:56
2024-01-15T04:25:44 | INFO | __main__ : Epoch 0
2024-01-15T04:25:44 | INFO | __main__ : 
           txt_r1  txt_r5  txt_r10  txt_r_mean  img_r1  img_r5  img_r10  img_r_mean  r_mean  txt_acc  img_acc
test/        41.3    92.9    97.00       77.07   42.85    92.9    97.45       77.73   77.40    49.25    51.45
test_emb/    38.1    88.8    94.75       73.88   37.65    88.5    94.75       73.63   73.76    49.80    47.80
2024-01-15T04:25:44 | INFO | __main__ : Training time 0:04:57
2024-01-15T04:25:44 | INFO | __main__ : best epoch 0 [config.stop_key test/]
2024-01-15T04:25:44 | INFO | __main__ : Checkpoints and Logs saved at exp/finetuning/ret_rtime/b16_25m_200k_1frame
2024-01-15T04:29:42 | INFO | umt : Logging to: exp/finetuning/ret_rtime/b16_25m_200k_1frame/train.log
2024-01-15T04:29:42 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/training_200k.json', '/data2/dy/temporal_video/dataset', 'video']
  test_file: {
      test: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test2k.json', '/data2/dy/temporal_video/dataset', 'video'] }
  test_types: ['test']
  num_workers: 6
  stop_key: test/
  is_paragraph_retrieval: False
  num_frames: 1
  num_frames_test: 4
  batch_size: 32
  max_txt_l: 32
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 1
          sample_type: rand
          num_frames_test: 4
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 32
          video: 32 }
      batch_size: {
          image: 32
          video: 32 }
      batch_size_test: {
          image: 32
          video: 32 } }
  text_enc: bert
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_b16
          img_size: 224
          patch_size: 16
          d_model: 768
          encoder_embed_dim: 768
          encoder_depth: 12
          encoder_num_heads: 12
          drop_path_rate: 0.2
          num_frames: 1
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 12
          clip_decoder_embed_dim: 768
          clip_output_dim: 512
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 224
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      multimodal: {
          enable: True }
      embed_dim: 512
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 1e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 5
      min_lr_multi: 0.01
      warmup_epochs: 1 }
  zero_shot: False
  evaluate: True
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: user
      project: umt_ret }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/finetuning/ret_rtime/b16_25m_200k_1frame
  resume: False
  debug: False
  log_freq: 100
  seed: 42
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
  rank: 0
  world_size: 4
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-01-15T04:29:42 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/training_200k.json', '/data2/dy/temporal_video/dataset', 'video'], 'test_file': {'test': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test2k.json', '/data2/dy/temporal_video/dataset', 'video']}, 'test_types': ['test'], 'num_workers': 6, 'stop_key': 'test/', 'is_paragraph_retrieval': False, 'num_frames': 1, 'num_frames_test': 4, 'batch_size': 32, 'max_txt_l': 32, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 1, 'sample_type': 'rand', 'num_frames_test': 4, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 32, 'video': 32}, 'batch_size': {'image': 32, 'video': 32}, 'batch_size_test': {'image': 32, 'video': 32}}, 'text_enc': 'bert', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_b16', 'img_size': 224, 'patch_size': 16, 'd_model': 768, 'encoder_embed_dim': 768, 'encoder_depth': 12, 'encoder_num_heads': 12, 'drop_path_rate': 0.2, 'num_frames': 1, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 12, 'clip_decoder_embed_dim': 768, 'clip_output_dim': 512, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 224, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'multimodal': {'enable': True}, 'embed_dim': 512, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 1e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 5, 'min_lr_multi': 0.01, 'warmup_epochs': 1}, 'zero_shot': False, 'evaluate': True, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': False, 'entity': 'user', 'project': 'umt_ret'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': 'exp/finetuning/ret_rtime/b16_25m_200k_1frame', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 42, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth', 'rank': 0, 'world_size': 4, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2024-01-15T04:29:42 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/training_200k.json', '/data2/dy/temporal_video/dataset', 'video']
2024-01-15T04:29:42 | INFO | tasks.pretrain : Creating dataset for ret
2024-01-15T04:29:42 | INFO | tasks.shared_utils : Creating model
2024-01-15T04:29:54 | INFO | models.umt : Build vision_encoder: vit_b16
2024-01-15T04:29:54 | INFO | models.backbones.vit.vit : Num of patches: 196
2024-01-15T04:29:54 | INFO | models.backbones.vit.vit : Use checkpoint: True
2024-01-15T04:29:54 | INFO | models.backbones.vit.vit : Checkpoint number: 12
2024-01-15T04:29:54 | INFO | models.backbones.vit.vit : Student return index: []
2024-01-15T04:29:58 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
2024-01-15T04:29:58 | INFO | models.umt : Build text_encoder bert_base
2024-01-15T04:30:01 | INFO | models.backbones.bert.xbert : build bert with cross_module: ca
2024-01-15T04:30:02 | INFO | models.criterions : Norm type: l2
2024-01-15T04:30:02 | INFO | models.criterions : Loss type: l2
2024-01-15T04:30:03 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.temp: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.weight: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.weight: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.embeddings.word_embeddings.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.embeddings.position_embeddings.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.embeddings.token_type_embeddings.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.vision_proj.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.text_proj.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.itm_head.weight: wd: 0.02, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : param module.itm_head.bias: wd: 0, lr: 1e-05
2024-01-15T04:30:03 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0.02 len(p)=140
2024-01-15T04:30:03 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0 len(p)=256
2024-01-15T04:30:03 | INFO | tasks.shared_utils : Auto resuming
2024-01-15T04:30:09 | INFO | tasks.shared_utils : <All keys matched successfully>
2024-01-15T04:30:09 | INFO | tasks.shared_utils : Loaded checkpoint from exp/finetuning/ret_rtime/b16_25m_200k_1frame/ckpt_best.pth
2024-01-15T04:30:09 | INFO | __main__ : Start evaluation
2024-01-15T04:30:09 | INFO | tasks.retrieval_utils : Start evaluation for media_type=video
2024-01-15T04:30:09 | INFO | tasks.retrieval_utils : Computing dual encoder features...
2024-01-15T06:55:54 | INFO | umt : Logging to: exp/finetuning/ret_rtime/b16_25m_200k_1frame/train.log
2024-01-15T06:55:54 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/training_200k.json', '/data2/dy/temporal_video/dataset', 'video']
  test_file: {
      test: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test2k.json', '/data2/dy/temporal_video/dataset', 'video'] }
  test_types: ['test']
  num_workers: 6
  stop_key: test/
  is_paragraph_retrieval: False
  num_frames: 4
  num_frames_test: 4
  batch_size: 32
  max_txt_l: 32
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 4
          sample_type: rand
          num_frames_test: 4
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 32
          video: 32 }
      batch_size: {
          image: 32
          video: 32 }
      batch_size_test: {
          image: 32
          video: 32 } }
  text_enc: bert
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_b16
          img_size: 224
          patch_size: 16
          d_model: 768
          encoder_embed_dim: 768
          encoder_depth: 12
          encoder_num_heads: 12
          drop_path_rate: 0.2
          num_frames: 4
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 12
          clip_decoder_embed_dim: 768
          clip_output_dim: 512
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 224
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      multimodal: {
          enable: True }
      embed_dim: 512
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 1e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 5
      min_lr_multi: 0.01
      warmup_epochs: 1 }
  zero_shot: False
  evaluate: True
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: user
      project: umt_ret }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/finetuning/ret_rtime/b16_25m_200k_1frame
  resume: False
  debug: False
  log_freq: 100
  seed: 42
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
  rank: 0
  world_size: 4
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-01-15T06:55:54 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/training_200k.json', '/data2/dy/temporal_video/dataset', 'video'], 'test_file': {'test': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test2k.json', '/data2/dy/temporal_video/dataset', 'video']}, 'test_types': ['test'], 'num_workers': 6, 'stop_key': 'test/', 'is_paragraph_retrieval': False, 'num_frames': 4, 'num_frames_test': 4, 'batch_size': 32, 'max_txt_l': 32, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 4, 'sample_type': 'rand', 'num_frames_test': 4, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 32, 'video': 32}, 'batch_size': {'image': 32, 'video': 32}, 'batch_size_test': {'image': 32, 'video': 32}}, 'text_enc': 'bert', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_b16', 'img_size': 224, 'patch_size': 16, 'd_model': 768, 'encoder_embed_dim': 768, 'encoder_depth': 12, 'encoder_num_heads': 12, 'drop_path_rate': 0.2, 'num_frames': 4, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 12, 'clip_decoder_embed_dim': 768, 'clip_output_dim': 512, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 224, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'multimodal': {'enable': True}, 'embed_dim': 512, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 1e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 5, 'min_lr_multi': 0.01, 'warmup_epochs': 1}, 'zero_shot': False, 'evaluate': True, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': False, 'entity': 'user', 'project': 'umt_ret'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': 'exp/finetuning/ret_rtime/b16_25m_200k_1frame', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 42, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth', 'rank': 0, 'world_size': 4, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2024-01-15T06:55:54 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/training_200k.json', '/data2/dy/temporal_video/dataset', 'video']
2024-01-15T06:55:54 | INFO | tasks.pretrain : Creating dataset for ret
2024-01-15T06:55:55 | INFO | tasks.shared_utils : Creating model
2024-01-15T06:56:07 | INFO | models.umt : Build vision_encoder: vit_b16
2024-01-15T06:56:07 | INFO | models.backbones.vit.vit : Num of patches: 784
2024-01-15T06:56:07 | INFO | models.backbones.vit.vit : Use checkpoint: True
2024-01-15T06:56:07 | INFO | models.backbones.vit.vit : Checkpoint number: 12
2024-01-15T06:56:07 | INFO | models.backbones.vit.vit : Student return index: []
2024-01-15T08:01:46 | INFO | umt : Logging to: exp/finetuning/ret_rtime/b16_25m_200k_1frame/train.log
2024-01-15T08:01:46 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/training_200k.json', '/data2/dy/temporal_video/dataset', 'video']
  test_file: {
      test: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test2k.json', '/data2/dy/temporal_video/dataset', 'video'] }
  test_types: ['test']
  num_workers: 6
  stop_key: test/
  is_paragraph_retrieval: False
  num_frames: 12
  num_frames_test: 12
  batch_size: 32
  max_txt_l: 32
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 12
          sample_type: rand
          num_frames_test: 12
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 32
          video: 32 }
      batch_size: {
          image: 32
          video: 32 }
      batch_size_test: {
          image: 32
          video: 32 } }
  text_enc: bert
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_b16
          img_size: 224
          patch_size: 16
          d_model: 768
          encoder_embed_dim: 768
          encoder_depth: 12
          encoder_num_heads: 12
          drop_path_rate: 0.2
          num_frames: 12
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 12
          clip_decoder_embed_dim: 768
          clip_output_dim: 512
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 224
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      multimodal: {
          enable: True }
      embed_dim: 512
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 1e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 5
      min_lr_multi: 0.01
      warmup_epochs: 1 }
  zero_shot: False
  evaluate: True
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: user
      project: umt_ret }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/finetuning/ret_rtime/b16_25m_200k_1frame
  resume: False
  debug: False
  log_freq: 100
  seed: 42
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
  rank: 0
  world_size: 4
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-01-15T08:01:46 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/training_200k.json', '/data2/dy/temporal_video/dataset', 'video'], 'test_file': {'test': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test2k.json', '/data2/dy/temporal_video/dataset', 'video']}, 'test_types': ['test'], 'num_workers': 6, 'stop_key': 'test/', 'is_paragraph_retrieval': False, 'num_frames': 12, 'num_frames_test': 12, 'batch_size': 32, 'max_txt_l': 32, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 12, 'sample_type': 'rand', 'num_frames_test': 12, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 32, 'video': 32}, 'batch_size': {'image': 32, 'video': 32}, 'batch_size_test': {'image': 32, 'video': 32}}, 'text_enc': 'bert', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_b16', 'img_size': 224, 'patch_size': 16, 'd_model': 768, 'encoder_embed_dim': 768, 'encoder_depth': 12, 'encoder_num_heads': 12, 'drop_path_rate': 0.2, 'num_frames': 12, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 12, 'clip_decoder_embed_dim': 768, 'clip_output_dim': 512, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 224, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'multimodal': {'enable': True}, 'embed_dim': 512, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 1e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 5, 'min_lr_multi': 0.01, 'warmup_epochs': 1}, 'zero_shot': False, 'evaluate': True, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': False, 'entity': 'user', 'project': 'umt_ret'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': 'exp/finetuning/ret_rtime/b16_25m_200k_1frame', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 42, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth', 'rank': 0, 'world_size': 4, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2024-01-15T08:01:46 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/training_200k.json', '/data2/dy/temporal_video/dataset', 'video']
2024-01-15T08:01:46 | INFO | tasks.pretrain : Creating dataset for ret
2024-01-15T08:01:46 | INFO | tasks.shared_utils : Creating model
2024-01-15T08:01:58 | INFO | models.umt : Build vision_encoder: vit_b16
2024-01-15T08:01:58 | INFO | models.backbones.vit.vit : Num of patches: 2352
2024-01-15T08:01:58 | INFO | models.backbones.vit.vit : Use checkpoint: True
2024-01-15T08:01:58 | INFO | models.backbones.vit.vit : Checkpoint number: 12
2024-01-15T08:01:58 | INFO | models.backbones.vit.vit : Student return index: []
2024-01-15T08:02:06 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
2024-01-15T08:02:06 | INFO | models.umt : Build text_encoder bert_base
2024-01-15T08:02:08 | INFO | models.backbones.bert.xbert : build bert with cross_module: ca
2024-01-15T08:02:08 | INFO | models.criterions : Norm type: l2
2024-01-15T08:02:08 | INFO | models.criterions : Loss type: l2
2024-01-15T08:02:10 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.temp: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.weight: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.weight: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.embeddings.word_embeddings.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.embeddings.position_embeddings.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.embeddings.token_type_embeddings.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.vision_proj.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.text_proj.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.itm_head.weight: wd: 0.02, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : param module.itm_head.bias: wd: 0, lr: 1e-05
2024-01-15T08:02:10 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0.02 len(p)=140
2024-01-15T08:02:10 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0 len(p)=256
2024-01-15T08:02:10 | INFO | tasks.shared_utils : Auto resuming
2024-01-15T08:02:13 | INFO | tasks.shared_utils : <All keys matched successfully>
2024-01-15T08:02:13 | INFO | tasks.shared_utils : Loaded checkpoint from exp/finetuning/ret_rtime/b16_25m_200k_1frame/ckpt_best.pth
2024-01-15T08:02:13 | INFO | __main__ : Start evaluation
2024-01-15T08:02:13 | INFO | tasks.retrieval_utils : Start evaluation for media_type=video
2024-01-15T08:02:13 | INFO | tasks.retrieval_utils : Computing dual encoder features...
2024-01-15T08:02:32 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-01-15T08:02:32 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-01-15T08:02:33 | INFO | utils.basic_utils : extracting image feats  [ 0/63]  eta: 0:19:29    time: 18.5613  data: 14.8665  max mem: 17077 res mem: 25264
2024-01-15T08:04:46 | INFO | utils.basic_utils : extracting image feats  [62/63]  eta: 0:00:02    time: 2.0334  data: 0.9585  max mem: 17311 res mem: 25264
2024-01-15T08:04:46 | INFO | utils.basic_utils : extracting image feats Total time: 0:02:30 (2.3915 s / it)
2024-01-15T08:04:57 | INFO | tasks.retrieval_utils : Finished feature extraction
2024-01-15T08:04:57 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product]
2024-01-15T08:04:57 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product], done!
2024-01-15T08:04:57 | INFO | tasks.retrieval_utils : Rerank dual-encoder results with cross-encoder...
2024-01-15T08:04:57 | INFO | tasks.retrieval_utils : i2t_scores.shape torch.Size([501, 2000])
2024-01-15T08:04:57 | INFO | tasks.retrieval_utils : n_clip_per_video=1, with eval_frame_ensemble=concat
2024-01-15T08:04:57 | INFO | utils.basic_utils : Evaluation:  [  0/501]  eta: 0:00:11    time: 0.0231  data: 0.0004  max mem: 17311 res mem: 25264
2024-01-15T08:05:04 | INFO | utils.basic_utils : Evaluation:  [100/501]  eta: 0:00:29    time: 0.0734  data: 0.0000  max mem: 17311 res mem: 25264
2024-01-15T08:05:11 | INFO | utils.basic_utils : Evaluation:  [200/501]  eta: 0:00:22    time: 0.0737  data: 0.0000  max mem: 17311 res mem: 25264
2024-01-15T08:05:19 | INFO | utils.basic_utils : Evaluation:  [300/501]  eta: 0:00:14    time: 0.0739  data: 0.0000  max mem: 17311 res mem: 25264
2024-01-15T08:05:26 | INFO | utils.basic_utils : Evaluation:  [400/501]  eta: 0:00:07    time: 0.0741  data: 0.0000  max mem: 17311 res mem: 25264
2024-01-15T08:05:34 | INFO | utils.basic_utils : Evaluation:  [500/501]  eta: 0:00:00    time: 0.0746  data: 0.0000  max mem: 17311 res mem: 25264
2024-01-15T08:05:34 | INFO | utils.basic_utils : Evaluation: Total time: 0:00:36 (0.0737 s / it)
2024-01-15T08:05:34 | INFO | tasks.retrieval_utils : t2i_scores.shape torch.Size([501, 2000])
2024-01-15T08:05:35 | INFO | utils.basic_utils : Evaluation:  [  0/501]  eta: 0:07:42    time: 0.9234  data: 0.0004  max mem: 17311 res mem: 25264
2024-01-15T08:06:57 | INFO | utils.basic_utils : Evaluation:  [100/501]  eta: 0:05:30    time: 0.8081  data: 0.0000  max mem: 17311 res mem: 25264
2024-01-15T08:08:19 | INFO | utils.basic_utils : Evaluation:  [200/501]  eta: 0:04:07    time: 0.8151  data: 0.0000  max mem: 17311 res mem: 25264
2024-01-15T08:09:39 | INFO | utils.basic_utils : Evaluation:  [300/501]  eta: 0:02:44    time: 0.8022  data: 0.0000  max mem: 17311 res mem: 25264
2024-01-15T08:11:00 | INFO | utils.basic_utils : Evaluation:  [400/501]  eta: 0:01:22    time: 0.8057  data: 0.0000  max mem: 17311 res mem: 25264
2024-01-15T08:12:21 | INFO | utils.basic_utils : Evaluation:  [500/501]  eta: 0:00:00    time: 0.7967  data: 0.0000  max mem: 17311 res mem: 25264
2024-01-15T08:12:21 | INFO | utils.basic_utils : Evaluation: Total time: 0:06:46 (0.8122 s / it)
2024-01-15T08:12:23 | INFO | tasks.retrieval_utils : Evaluation time 0:10:09
2024-01-15T08:12:25 | INFO | __main__ : Epoch 0
2024-01-15T08:12:25 | INFO | __main__ : 
           txt_r1  txt_r5  txt_r10  txt_r_mean  img_r1  img_r5  img_r10  img_r_mean  r_mean  txt_acc  img_acc
test/       36.85    83.9    90.95       70.57   38.75   86.10    91.65       72.17   71.37    50.55    50.95
test_emb/   28.85    72.5    84.65       62.00   33.45   79.45    88.80       67.23   64.62    49.90    50.30
2024-01-15T08:12:25 | INFO | __main__ : Training time 0:10:11
2024-01-15T08:12:25 | INFO | __main__ : best epoch 0 [config.stop_key test/]
2024-01-15T08:12:25 | INFO | __main__ : Checkpoints and Logs saved at exp/finetuning/ret_rtime/b16_25m_200k_1frame
2024-01-21T16:47:43 | INFO | umt : Logging to: exp/finetuning/ret_rtime/b16_25m_200k_1frame/train.log
2024-01-21T16:47:43 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/training_200k.json', '/data2/dy/temporal_video/dataset', 'video']
  test_file: {
      test: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test2k.json', '/data2/dy/temporal_video/dataset', 'video'] }
  test_types: ['test']
  num_workers: 6
  stop_key: test/
  is_paragraph_retrieval: False
  num_frames: 12
  num_frames_test: 12
  batch_size: 32
  max_txt_l: 32
  train_shuffle: True
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 12
          sample_type: rand
          num_frames_test: 12
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 32
          video: 32 }
      batch_size: {
          image: 32
          video: 32 }
      batch_size_test: {
          image: 32
          video: 32 } }
  text_enc: bert
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_b16
          img_size: 224
          patch_size: 16
          d_model: 768
          encoder_embed_dim: 768
          encoder_depth: 12
          encoder_num_heads: 12
          drop_path_rate: 0.2
          num_frames: 12
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 12
          clip_decoder_embed_dim: 768
          clip_output_dim: 512
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 224
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      multimodal: {
          enable: True }
      embed_dim: 512
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 1e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 5
      min_lr_multi: 0.01
      warmup_epochs: 1 }
  zero_shot: False
  evaluate: True
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: user
      project: umt_ret }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/finetuning/ret_rtime/b16_25m_200k_1frame
  resume: False
  debug: False
  log_freq: 100
  seed: 42
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
  rank: 0
  world_size: 3
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-01-21T16:47:43 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/training_200k.json', '/data2/dy/temporal_video/dataset', 'video'], 'test_file': {'test': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test2k.json', '/data2/dy/temporal_video/dataset', 'video']}, 'test_types': ['test'], 'num_workers': 6, 'stop_key': 'test/', 'is_paragraph_retrieval': False, 'num_frames': 12, 'num_frames_test': 12, 'batch_size': 32, 'max_txt_l': 32, 'train_shuffle': True, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 12, 'sample_type': 'rand', 'num_frames_test': 12, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 32, 'video': 32}, 'batch_size': {'image': 32, 'video': 32}, 'batch_size_test': {'image': 32, 'video': 32}}, 'text_enc': 'bert', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_b16', 'img_size': 224, 'patch_size': 16, 'd_model': 768, 'encoder_embed_dim': 768, 'encoder_depth': 12, 'encoder_num_heads': 12, 'drop_path_rate': 0.2, 'num_frames': 12, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 12, 'clip_decoder_embed_dim': 768, 'clip_output_dim': 512, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 224, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'multimodal': {'enable': True}, 'embed_dim': 512, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 1e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 5, 'min_lr_multi': 0.01, 'warmup_epochs': 1}, 'zero_shot': False, 'evaluate': True, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': False, 'entity': 'user', 'project': 'umt_ret'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': 'exp/finetuning/ret_rtime/b16_25m_200k_1frame', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 42, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth', 'rank': 0, 'world_size': 3, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2024-01-21T16:47:43 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/training_200k.json', '/data2/dy/temporal_video/dataset', 'video']
2024-01-21T16:47:43 | INFO | tasks.pretrain : Creating dataset for ret
2024-01-21T16:47:44 | INFO | tasks.shared_utils : Creating model
2024-01-21T16:47:55 | INFO | models.umt : Build vision_encoder: vit_b16
2024-01-21T16:47:55 | INFO | models.backbones.vit.vit : Num of patches: 2352
2024-01-21T16:47:55 | INFO | models.backbones.vit.vit : Use checkpoint: True
2024-01-21T16:47:55 | INFO | models.backbones.vit.vit : Checkpoint number: 12
2024-01-21T16:47:55 | INFO | models.backbones.vit.vit : Student return index: []
2024-01-21T16:48:03 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
2024-01-21T16:48:03 | INFO | models.umt : Build text_encoder bert_base
2024-01-21T16:48:05 | INFO | models.backbones.bert.xbert : build bert with cross_module: ca
2024-01-21T16:48:05 | INFO | models.criterions : Norm type: l2
2024-01-21T16:48:05 | INFO | models.criterions : Loss type: l2
2024-01-21T16:48:06 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.temp: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.weight: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.q_bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.v_bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.weight: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.weight: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.q_bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.v_bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.weight: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.weight: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.q_bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.v_bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.weight: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.weight: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.q_bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.v_bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.weight: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.weight: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.q_bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.v_bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.weight: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.weight: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.q_bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.v_bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.weight: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.weight: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.q_bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.v_bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.weight: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.weight: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.q_bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.v_bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.weight: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.weight: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.q_bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.v_bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.weight: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.weight: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.q_bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.v_bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.weight: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.weight: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.q_bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.v_bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.weight: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.weight: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.q_bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.v_bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.weight: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.weight: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.weight: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.embeddings.word_embeddings.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.embeddings.position_embeddings.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.embeddings.token_type_embeddings.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_proj.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.vision_proj.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_proj.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.text_proj.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.itm_head.weight: wd: 0.02, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : param module.itm_head.bias: wd: 0, lr: 1e-05
2024-01-21T16:48:06 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0.02 len(p)=140
2024-01-21T16:48:06 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0 len(p)=256
2024-01-21T16:48:06 | INFO | tasks.shared_utils : Auto resuming
2024-01-21T16:48:09 | INFO | tasks.shared_utils : <All keys matched successfully>
2024-01-21T16:48:09 | INFO | tasks.shared_utils : Loaded checkpoint from exp/finetuning/ret_rtime/b16_25m_200k_1frame/ckpt_best.pth
2024-01-21T16:48:09 | INFO | __main__ : Start evaluation
2024-01-21T16:48:09 | INFO | tasks.retrieval_utils : Start evaluation for media_type=video
2024-01-21T16:48:09 | INFO | tasks.retrieval_utils : Computing dual encoder features...
2024-01-21T16:48:27 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-01-21T16:48:27 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-01-21T16:48:28 | INFO | utils.basic_utils : extracting image feats  [ 0/63]  eta: 0:18:21    time: 17.4775  data: 14.3370  max mem: 17077 res mem: 25264
2024-01-21T16:50:39 | INFO | utils.basic_utils : extracting image feats  [62/63]  eta: 0:00:02    time: 1.9623  data: 0.9403  max mem: 17311 res mem: 25264
2024-01-21T16:50:39 | INFO | utils.basic_utils : extracting image feats Total time: 0:02:28 (2.3537 s / it)
2024-01-21T16:50:47 | INFO | tasks.retrieval_utils : Finished feature extraction
2024-01-21T16:50:47 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product]
2024-01-21T16:50:47 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product], done!
2024-01-21T16:50:47 | INFO | tasks.retrieval_utils : Rerank dual-encoder results with cross-encoder...
2024-01-21T16:50:47 | INFO | tasks.retrieval_utils : i2t_scores.shape torch.Size([667, 2000])
2024-01-21T16:50:47 | INFO | tasks.retrieval_utils : n_clip_per_video=1, with eval_frame_ensemble=concat
2024-01-21T16:50:47 | INFO | utils.basic_utils : Evaluation:  [  0/667]  eta: 0:00:14    time: 0.0214  data: 0.0004  max mem: 17311 res mem: 25264
2024-01-21T16:50:54 | INFO | utils.basic_utils : Evaluation:  [100/667]  eta: 0:00:40    time: 0.0721  data: 0.0000  max mem: 17311 res mem: 25264
2024-01-21T16:51:02 | INFO | utils.basic_utils : Evaluation:  [200/667]  eta: 0:00:33    time: 0.0729  data: 0.0000  max mem: 17311 res mem: 25264
2024-01-21T16:51:09 | INFO | utils.basic_utils : Evaluation:  [300/667]  eta: 0:00:26    time: 0.0733  data: 0.0000  max mem: 17311 res mem: 25264
2024-01-21T16:51:16 | INFO | utils.basic_utils : Evaluation:  [400/667]  eta: 0:00:19    time: 0.0733  data: 0.0000  max mem: 17311 res mem: 25264
2024-01-21T16:51:24 | INFO | utils.basic_utils : Evaluation:  [500/667]  eta: 0:00:12    time: 0.0735  data: 0.0000  max mem: 17311 res mem: 25264
2024-01-21T16:51:31 | INFO | utils.basic_utils : Evaluation:  [600/667]  eta: 0:00:04    time: 0.0737  data: 0.0000  max mem: 17311 res mem: 25264
2024-01-21T16:51:36 | INFO | utils.basic_utils : Evaluation:  [666/667]  eta: 0:00:00    time: 0.0738  data: 0.0000  max mem: 17311 res mem: 25264
2024-01-21T16:51:36 | INFO | utils.basic_utils : Evaluation: Total time: 0:00:48 (0.0730 s / it)
2024-01-21T16:51:36 | INFO | tasks.retrieval_utils : t2i_scores.shape torch.Size([667, 2000])
2024-01-21T16:51:37 | INFO | utils.basic_utils : Evaluation:  [  0/667]  eta: 0:07:41    time: 0.6921  data: 0.0004  max mem: 17311 res mem: 25264
2024-01-21T16:52:45 | INFO | utils.basic_utils : Evaluation:  [100/667]  eta: 0:06:27    time: 0.6912  data: 0.0000  max mem: 17311 res mem: 25264
2024-01-21T16:53:55 | INFO | utils.basic_utils : Evaluation:  [200/667]  eta: 0:05:22    time: 0.6951  data: 0.0000  max mem: 17311 res mem: 25264
2024-01-21T16:55:06 | INFO | utils.basic_utils : Evaluation:  [300/667]  eta: 0:04:16    time: 0.7215  data: 0.0000  max mem: 17311 res mem: 25264
2024-01-21T16:56:18 | INFO | utils.basic_utils : Evaluation:  [400/667]  eta: 0:03:07    time: 0.7137  data: 0.0000  max mem: 17311 res mem: 25264
2024-01-21T16:57:29 | INFO | utils.basic_utils : Evaluation:  [500/667]  eta: 0:01:57    time: 0.7126  data: 0.0000  max mem: 17311 res mem: 25264
2024-01-21T16:58:40 | INFO | utils.basic_utils : Evaluation:  [600/667]  eta: 0:00:47    time: 0.7018  data: 0.0000  max mem: 17311 res mem: 25264
2024-01-21T16:59:28 | INFO | utils.basic_utils : Evaluation:  [666/667]  eta: 0:00:00    time: 0.7108  data: 0.0000  max mem: 17311 res mem: 25264
2024-01-21T16:59:28 | INFO | utils.basic_utils : Evaluation: Total time: 0:07:51 (0.7069 s / it)
2024-01-21T17:00:54 | INFO | tasks.retrieval_utils : Evaluation time 0:12:45
2024-01-21T17:00:56 | INFO | __main__ : Epoch 0
2024-01-21T17:00:56 | INFO | __main__ : 
           txt_r1  txt_r5  txt_r10  txt_r_mean  img_r1  img_r5  img_r10  img_r_mean  r_mean  txt_acc  img_acc
test/       36.85    83.9    90.95       70.57   38.75   86.10    91.65       72.17   71.37    50.55    50.95
test_emb/   28.85    72.5    84.65       62.00   33.45   79.45    88.80       67.23   64.62    49.90    50.30
2024-01-21T17:00:56 | INFO | __main__ : Training time 0:12:46
2024-01-21T17:00:56 | INFO | __main__ : best epoch 0 [config.stop_key test/]
2024-01-21T17:00:56 | INFO | __main__ : Checkpoints and Logs saved at exp/finetuning/ret_rtime/b16_25m_200k_1frame
