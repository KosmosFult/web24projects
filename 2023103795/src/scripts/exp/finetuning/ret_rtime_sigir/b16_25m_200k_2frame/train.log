2024-01-11T13:32:11 | INFO | umt : Logging to: exp/finetuning/ret_rtime/b16_25m_200k_2frame/train.log
2024-01-11T13:32:11 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/training_200k.json', '/data2/dy/temporal_video/dataset', 'video']
  test_file: {
      test: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test2k.json', '/data2/dy/temporal_video/dataset', 'video'] }
  test_types: ['test']
  num_workers: 6
  stop_key: test/
  is_paragraph_retrieval: False
  num_frames: 2
  num_frames_test: 2
  batch_size: 32
  max_txt_l: 32
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 2
          sample_type: rand
          num_frames_test: 2
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 32
          video: 32 }
      batch_size: {
          image: 32
          video: 32 }
      batch_size_test: {
          image: 32
          video: 32 } }
  text_enc: bert
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_b16
          img_size: 224
          patch_size: 16
          d_model: 768
          encoder_embed_dim: 768
          encoder_depth: 12
          encoder_num_heads: 12
          drop_path_rate: 0.2
          num_frames: 2
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 12
          clip_decoder_embed_dim: 768
          clip_output_dim: 512
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 224
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      multimodal: {
          enable: True }
      embed_dim: 512
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 1e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 5
      min_lr_multi: 0.01
      warmup_epochs: 1 }
  evaluate: False
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: True
      entity: user
      project: umt_ret }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/finetuning/ret_rtime/b16_25m_200k_2frame
  resume: False
  debug: False
  log_freq: 100
  seed: 42
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
  rank: 0
  world_size: 4
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-01-11T13:36:05 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/training_200k.json', '/data2/dy/temporal_video/dataset', 'video'], 'test_file': {'test': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test2k.json', '/data2/dy/temporal_video/dataset', 'video']}, 'test_types': ['test'], 'num_workers': 6, 'stop_key': 'test/', 'is_paragraph_retrieval': False, 'num_frames': 2, 'num_frames_test': 2, 'batch_size': 32, 'max_txt_l': 32, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 2, 'sample_type': 'rand', 'num_frames_test': 2, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 32, 'video': 32}, 'batch_size': {'image': 32, 'video': 32}, 'batch_size_test': {'image': 32, 'video': 32}}, 'text_enc': 'bert', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_b16', 'img_size': 224, 'patch_size': 16, 'd_model': 768, 'encoder_embed_dim': 768, 'encoder_depth': 12, 'encoder_num_heads': 12, 'drop_path_rate': 0.2, 'num_frames': 2, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 12, 'clip_decoder_embed_dim': 768, 'clip_output_dim': 512, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 224, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'multimodal': {'enable': True}, 'embed_dim': 512, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 1e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 5, 'min_lr_multi': 0.01, 'warmup_epochs': 1}, 'evaluate': False, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': True, 'entity': 'user', 'project': 'umt_ret'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': 'exp/finetuning/ret_rtime/b16_25m_200k_2frame', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 42, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth', 'rank': 0, 'world_size': 4, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2024-01-11T13:36:05 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/training_200k.json', '/data2/dy/temporal_video/dataset', 'video']
2024-01-11T13:36:05 | INFO | tasks.pretrain : Creating dataset for ret
2024-01-11T13:36:06 | INFO | tasks.shared_utils : Creating model
2024-01-11T13:36:18 | INFO | models.umt : Build vision_encoder: vit_b16
2024-01-11T13:36:18 | INFO | models.backbones.vit.vit : Num of patches: 392
2024-01-11T13:36:18 | INFO | models.backbones.vit.vit : Use checkpoint: True
2024-01-11T13:36:18 | INFO | models.backbones.vit.vit : Checkpoint number: 12
2024-01-11T13:36:18 | INFO | models.backbones.vit.vit : Student return index: []
2024-01-11T13:36:20 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
2024-01-11T13:36:21 | INFO | models.umt : Build text_encoder bert_base
2024-01-11T13:36:22 | INFO | models.backbones.bert.xbert : build bert with cross_module: ca
2024-01-11T13:36:23 | INFO | models.criterions : Norm type: l2
2024-01-11T13:36:23 | INFO | models.criterions : Loss type: l2
2024-01-11T13:36:23 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.temp: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.weight: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.q_bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.v_bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.weight: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.weight: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.q_bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.v_bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.weight: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.weight: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.q_bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.v_bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.weight: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.weight: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.q_bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.v_bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.weight: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.weight: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.q_bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.v_bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.weight: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.weight: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.q_bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.v_bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.weight: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.weight: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.q_bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.v_bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.weight: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.weight: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.q_bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.v_bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.weight: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.weight: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.q_bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.v_bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.weight: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.weight: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.q_bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.v_bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.weight: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.weight: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.q_bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.v_bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.weight: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.weight: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.q_bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.v_bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.weight: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.weight: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.weight: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.embeddings.word_embeddings.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.embeddings.position_embeddings.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.embeddings.token_type_embeddings.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_proj.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.vision_proj.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_proj.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.text_proj.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.itm_head.weight: wd: 0.02, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : param module.itm_head.bias: wd: 0, lr: 1e-05
2024-01-11T13:36:23 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0.02 len(p)=140
2024-01-11T13:36:23 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0 len(p)=256
2024-01-11T13:36:23 | INFO | tasks.shared_utils : Auto resuming
2024-01-11T13:36:23 | INFO | tasks.shared_utils : Not found checkpoint in exp/finetuning/ret_rtime/b16_25m_200k_2frame
2024-01-11T13:36:24 | INFO | tasks.shared_utils : _IncompatibleKeys(missing_keys=[], unexpected_keys=['clip_teacher.class_embedding', 'clip_teacher.positional_embedding', 'clip_teacher.proj', 'clip_teacher.conv1.weight', 'clip_teacher.ln_pre.weight', 'clip_teacher.ln_pre.bias', 'clip_teacher.transformer.resblocks.0.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.0.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.0.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.0.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.0.ln_1.weight', 'clip_teacher.transformer.resblocks.0.ln_1.bias', 'clip_teacher.transformer.resblocks.0.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.0.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.0.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.0.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.0.ln_2.weight', 'clip_teacher.transformer.resblocks.0.ln_2.bias', 'clip_teacher.transformer.resblocks.1.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.1.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.1.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.1.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.1.ln_1.weight', 'clip_teacher.transformer.resblocks.1.ln_1.bias', 'clip_teacher.transformer.resblocks.1.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.1.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.1.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.1.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.1.ln_2.weight', 'clip_teacher.transformer.resblocks.1.ln_2.bias', 'clip_teacher.transformer.resblocks.2.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.2.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.2.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.2.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.2.ln_1.weight', 'clip_teacher.transformer.resblocks.2.ln_1.bias', 'clip_teacher.transformer.resblocks.2.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.2.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.2.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.2.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.2.ln_2.weight', 'clip_teacher.transformer.resblocks.2.ln_2.bias', 'clip_teacher.transformer.resblocks.3.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.3.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.3.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.3.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.3.ln_1.weight', 'clip_teacher.transformer.resblocks.3.ln_1.bias', 'clip_teacher.transformer.resblocks.3.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.3.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.3.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.3.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.3.ln_2.weight', 'clip_teacher.transformer.resblocks.3.ln_2.bias', 'clip_teacher.transformer.resblocks.4.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.4.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.4.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.4.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.4.ln_1.weight', 'clip_teacher.transformer.resblocks.4.ln_1.bias', 'clip_teacher.transformer.resblocks.4.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.4.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.4.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.4.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.4.ln_2.weight', 'clip_teacher.transformer.resblocks.4.ln_2.bias', 'clip_teacher.transformer.resblocks.5.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.5.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.5.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.5.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.5.ln_1.weight', 'clip_teacher.transformer.resblocks.5.ln_1.bias', 'clip_teacher.transformer.resblocks.5.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.5.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.5.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.5.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.5.ln_2.weight', 'clip_teacher.transformer.resblocks.5.ln_2.bias', 'clip_teacher.transformer.resblocks.6.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.6.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.6.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.6.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.6.ln_1.weight', 'clip_teacher.transformer.resblocks.6.ln_1.bias', 'clip_teacher.transformer.resblocks.6.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.6.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.6.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.6.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.6.ln_2.weight', 'clip_teacher.transformer.resblocks.6.ln_2.bias', 'clip_teacher.transformer.resblocks.7.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.7.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.7.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.7.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.7.ln_1.weight', 'clip_teacher.transformer.resblocks.7.ln_1.bias', 'clip_teacher.transformer.resblocks.7.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.7.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.7.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.7.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.7.ln_2.weight', 'clip_teacher.transformer.resblocks.7.ln_2.bias', 'clip_teacher.transformer.resblocks.8.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.8.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.8.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.8.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.8.ln_1.weight', 'clip_teacher.transformer.resblocks.8.ln_1.bias', 'clip_teacher.transformer.resblocks.8.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.8.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.8.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.8.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.8.ln_2.weight', 'clip_teacher.transformer.resblocks.8.ln_2.bias', 'clip_teacher.transformer.resblocks.9.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.9.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.9.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.9.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.9.ln_1.weight', 'clip_teacher.transformer.resblocks.9.ln_1.bias', 'clip_teacher.transformer.resblocks.9.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.9.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.9.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.9.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.9.ln_2.weight', 'clip_teacher.transformer.resblocks.9.ln_2.bias', 'clip_teacher.transformer.resblocks.10.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.10.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.10.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.10.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.10.ln_1.weight', 'clip_teacher.transformer.resblocks.10.ln_1.bias', 'clip_teacher.transformer.resblocks.10.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.10.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.10.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.10.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.10.ln_2.weight', 'clip_teacher.transformer.resblocks.10.ln_2.bias', 'clip_teacher.transformer.resblocks.11.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.11.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.11.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.11.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.11.ln_1.weight', 'clip_teacher.transformer.resblocks.11.ln_1.bias', 'clip_teacher.transformer.resblocks.11.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.11.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.11.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.11.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.11.ln_2.weight', 'clip_teacher.transformer.resblocks.11.ln_2.bias', 'clip_teacher.ln_post.weight', 'clip_teacher.ln_post.bias', 'vision_encoder.clip_decoder.0.head.weight', 'vision_encoder.clip_decoder.0.head.bias', 'vision_encoder.clip_decoder.0.norm.weight', 'vision_encoder.clip_decoder.0.norm.bias', 'vision_encoder.clip_decoder.1.head.weight', 'vision_encoder.clip_decoder.1.head.bias', 'vision_encoder.clip_decoder.1.norm.weight', 'vision_encoder.clip_decoder.1.norm.bias', 'vision_encoder.clip_decoder.2.head.weight', 'vision_encoder.clip_decoder.2.head.bias', 'vision_encoder.clip_decoder.2.norm.weight', 'vision_encoder.clip_decoder.2.norm.bias', 'vision_encoder.clip_decoder.3.head.weight', 'vision_encoder.clip_decoder.3.head.bias', 'vision_encoder.clip_decoder.3.norm.weight', 'vision_encoder.clip_decoder.3.norm.bias', 'vision_encoder.clip_decoder.4.head.weight', 'vision_encoder.clip_decoder.4.head.bias', 'vision_encoder.clip_decoder.4.norm.weight', 'vision_encoder.clip_decoder.4.norm.bias', 'vision_encoder.clip_decoder.5.head.weight', 'vision_encoder.clip_decoder.5.head.bias', 'vision_encoder.clip_decoder.5.norm.weight', 'vision_encoder.clip_decoder.5.norm.bias', 'text_encoder.cls.predictions.bias', 'text_encoder.cls.predictions.transform.dense.weight', 'text_encoder.cls.predictions.transform.dense.bias', 'text_encoder.cls.predictions.transform.LayerNorm.weight', 'text_encoder.cls.predictions.transform.LayerNorm.bias', 'text_encoder.cls.predictions.decoder.weight', 'text_encoder.cls.predictions.decoder.bias'])
2024-01-11T13:36:24 | INFO | tasks.shared_utils : Loaded checkpoint from /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
2024-01-11T13:36:24 | INFO | __main__ : training
2024-01-11T13:36:24 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 1448 batches in total
dataloader index=0 name=video, batch-size=32 length(#batches)=1448 
2024-01-11T13:36:35 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  builtin_warn(*args, **kwargs)

2024-01-11T13:36:35 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  builtin_warn(*args, **kwargs)

2024-01-11T13:36:35 | INFO | utils.basic_utils : Train Epoch: [0]  [   0/1448]  eta: 4:13:22  lr: 0.000000  temperature: 0.0112  video-loss_vtc: 0.6821  video-loss_vtm: 0.1954  time: 10.4989  data: 5.5170  max mem: 3372 res mem: 4070
2024-01-11T13:36:35 | INFO | torch.nn.parallel.distributed : Reducer buckets have been rebuilt in this iteration.
2024-01-11T13:38:17 | INFO | utils.basic_utils : Train Epoch: [0]  [ 100/1448]  eta: 0:25:00  lr: 0.000001  temperature: 0.0112  video-loss_vtc: 0.5577  video-loss_vtm: 0.3231  time: 1.1204  data: 0.0015  max mem: 5234 res mem: 5850
2024-01-11T13:40:17 | INFO | utils.basic_utils : Train Epoch: [0]  [ 200/1448]  eta: 0:24:05  lr: 0.000001  temperature: 0.0113  video-loss_vtc: 0.6058  video-loss_vtm: 0.1671  time: 1.6390  data: 0.0036  max mem: 5234 res mem: 5850
2024-01-11T13:43:09 | INFO | utils.basic_utils : Train Epoch: [0]  [ 300/1448]  eta: 0:25:45  lr: 0.000002  temperature: 0.0113  video-loss_vtc: 0.5172  video-loss_vtm: 0.1751  time: 1.6786  data: 0.4777  max mem: 5234 res mem: 5850
2024-01-11T13:46:04 | INFO | utils.basic_utils : Train Epoch: [0]  [ 400/1448]  eta: 0:25:16  lr: 0.000003  temperature: 0.0114  video-loss_vtc: 0.4248  video-loss_vtm: 0.1155  time: 1.5186  data: 0.3992  max mem: 5234 res mem: 5850
2024-01-11T13:48:57 | INFO | utils.basic_utils : Train Epoch: [0]  [ 500/1448]  eta: 0:23:44  lr: 0.000003  temperature: 0.0115  video-loss_vtc: 0.3671  video-loss_vtm: 0.2183  time: 1.8317  data: 0.6859  max mem: 5234 res mem: 5850
2024-01-11T13:51:46 | INFO | utils.basic_utils : Train Epoch: [0]  [ 600/1448]  eta: 0:21:40  lr: 0.000004  temperature: 0.0115  video-loss_vtc: 0.4011  video-loss_vtm: 0.0902  time: 1.7547  data: 0.0206  max mem: 5234 res mem: 5850
2024-01-11T13:54:46 | INFO | utils.basic_utils : Train Epoch: [0]  [ 700/1448]  eta: 0:19:36  lr: 0.000005  temperature: 0.0116  video-loss_vtc: 0.2648  video-loss_vtm: 0.0771  time: 1.9774  data: 0.0038  max mem: 5234 res mem: 5850
2024-01-11T13:57:35 | INFO | utils.basic_utils : Train Epoch: [0]  [ 800/1448]  eta: 0:17:08  lr: 0.000006  temperature: 0.0116  video-loss_vtc: 0.3125  video-loss_vtm: 0.2449  time: 1.7497  data: 0.0035  max mem: 5234 res mem: 5850
2024-01-11T14:00:24 | INFO | utils.basic_utils : Train Epoch: [0]  [ 900/1448]  eta: 0:14:35  lr: 0.000006  temperature: 0.0116  video-loss_vtc: 0.4482  video-loss_vtm: 0.1614  time: 1.6906  data: 0.0538  max mem: 5234 res mem: 5850
2024-01-11T14:03:20 | INFO | utils.basic_utils : Train Epoch: [0]  [1000/1448]  eta: 0:12:03  lr: 0.000007  temperature: 0.0115  video-loss_vtc: 0.3189  video-loss_vtm: 0.0971  time: 1.8526  data: 0.0031  max mem: 5234 res mem: 5850
2024-01-11T14:06:10 | INFO | utils.basic_utils : Train Epoch: [0]  [1100/1448]  eta: 0:09:24  lr: 0.000008  temperature: 0.0115  video-loss_vtc: 0.3212  video-loss_vtm: 0.0984  time: 1.6926  data: 0.0042  max mem: 5234 res mem: 5850
2024-01-11T14:08:58 | INFO | utils.basic_utils : Train Epoch: [0]  [1200/1448]  eta: 0:06:43  lr: 0.000008  temperature: 0.0115  video-loss_vtc: 0.3200  video-loss_vtm: 0.1425  time: 1.8046  data: 0.0039  max mem: 5234 res mem: 5850
2024-01-11T14:11:50 | INFO | utils.basic_utils : Train Epoch: [0]  [1300/1448]  eta: 0:04:01  lr: 0.000009  temperature: 0.0115  video-loss_vtc: 0.4079  video-loss_vtm: 0.1547  time: 1.8312  data: 0.2261  max mem: 5234 res mem: 5850
2024-01-11T14:14:41 | INFO | utils.basic_utils : Train Epoch: [0]  [1400/1448]  eta: 0:01:18  lr: 0.000010  temperature: 0.0115  video-loss_vtc: 0.2866  video-loss_vtm: 0.1023  time: 1.5849  data: 0.2540  max mem: 5234 res mem: 5850
2024-01-11T14:15:58 | INFO | utils.basic_utils : Train Epoch: [0]  [1447/1448]  eta: 0:00:01  lr: 0.000010  temperature: 0.0115  video-loss_vtc: 0.3732  video-loss_vtm: 0.1107  time: 1.6555  data: 0.5388  max mem: 5234 res mem: 5850
2024-01-11T14:15:58 | INFO | utils.basic_utils : Train Epoch: [0] Total time: 0:39:33 (1.6393 s / it)
2024-01-11T14:15:58 | INFO | __main__ : Averaged train stats: lr: 0.0000  temperature: 0.0115  video-loss_vtc: 0.4460  video-loss_vtm: 0.1715
2024-01-11T14:15:58 | INFO | tasks.retrieval_utils : Start evaluation for media_type=video
2024-01-11T14:15:58 | INFO | tasks.retrieval_utils : Computing dual encoder features...
2024-01-11T14:16:11 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-01-11T14:16:11 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-01-11T14:16:11 | INFO | utils.basic_utils : extracting image feats  [ 0/63]  eta: 0:12:03    time: 11.4805  data: 11.3528  max mem: 5234 res mem: 5850
2024-01-11T14:17:56 | INFO | utils.basic_utils : extracting image feats  [62/63]  eta: 0:00:01    time: 1.7387  data: 1.5834  max mem: 5234 res mem: 5850
2024-01-11T14:17:56 | INFO | utils.basic_utils : extracting image feats Total time: 0:01:57 (1.8629 s / it)
2024-01-11T14:17:58 | INFO | tasks.retrieval_utils : Finished feature extraction
2024-01-11T14:17:58 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product]
2024-01-11T14:17:58 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product], done!
2024-01-11T14:17:58 | INFO | tasks.retrieval_utils : Rerank dual-encoder results with cross-encoder...
2024-01-11T14:17:58 | INFO | tasks.retrieval_utils : i2t_scores.shape torch.Size([501, 2000])
2024-01-11T14:17:58 | INFO | tasks.retrieval_utils : n_clip_per_video=1, with eval_frame_ensemble=concat
2024-01-11T14:17:58 | INFO | utils.basic_utils : Evaluation:  [  0/501]  eta: 0:00:15    time: 0.0301  data: 0.0010  max mem: 5234 res mem: 5850
2024-01-11T14:18:01 | INFO | utils.basic_utils : Evaluation:  [100/501]  eta: 0:00:10    time: 0.0270  data: 0.0000  max mem: 5234 res mem: 5850
2024-01-11T14:18:05 | INFO | utils.basic_utils : Evaluation:  [200/501]  eta: 0:00:09    time: 0.0386  data: 0.0000  max mem: 5234 res mem: 5850
2024-01-11T14:18:09 | INFO | utils.basic_utils : Evaluation:  [300/501]  eta: 0:00:06    time: 0.0372  data: 0.0000  max mem: 5234 res mem: 5850
2024-01-11T14:18:13 | INFO | utils.basic_utils : Evaluation:  [400/501]  eta: 0:00:03    time: 0.0387  data: 0.0000  max mem: 5234 res mem: 5850
2024-01-11T14:18:17 | INFO | utils.basic_utils : Evaluation:  [500/501]  eta: 0:00:00    time: 0.0415  data: 0.0000  max mem: 5234 res mem: 5850
2024-01-11T14:18:17 | INFO | utils.basic_utils : Evaluation: Total time: 0:00:18 (0.0369 s / it)
2024-01-11T14:18:17 | INFO | tasks.retrieval_utils : t2i_scores.shape torch.Size([501, 2000])
2024-01-11T14:18:17 | INFO | utils.basic_utils : Evaluation:  [  0/501]  eta: 0:01:55    time: 0.2314  data: 0.0017  max mem: 5234 res mem: 5850
2024-01-11T14:18:37 | INFO | utils.basic_utils : Evaluation:  [100/501]  eta: 0:01:19    time: 0.1984  data: 0.0000  max mem: 5234 res mem: 5850
2024-01-11T14:18:56 | INFO | utils.basic_utils : Evaluation:  [200/501]  eta: 0:00:58    time: 0.1982  data: 0.0000  max mem: 5234 res mem: 5850
2024-01-11T14:19:15 | INFO | utils.basic_utils : Evaluation:  [300/501]  eta: 0:00:38    time: 0.1791  data: 0.0000  max mem: 5234 res mem: 5850
2024-01-11T14:19:34 | INFO | utils.basic_utils : Evaluation:  [400/501]  eta: 0:00:19    time: 0.1872  data: 0.0000  max mem: 5234 res mem: 5850
2024-01-11T14:19:53 | INFO | utils.basic_utils : Evaluation:  [500/501]  eta: 0:00:00    time: 0.1889  data: 0.0000  max mem: 5234 res mem: 5850
2024-01-11T14:19:53 | INFO | utils.basic_utils : Evaluation: Total time: 0:01:36 (0.1918 s / it)
2024-01-11T14:19:55 | INFO | tasks.retrieval_utils : Evaluation time 0:03:56
2024-01-11T14:19:56 | INFO | __main__ : Epoch 0
2024-01-11T14:19:56 | INFO | __main__ : 
           txt_r1  txt_r5  txt_r10  txt_r_mean  img_r1  img_r5  img_r10  img_r_mean  r_mean  txt_acc  img_acc
test/        42.0    93.0    97.15       77.38    43.3   92.15     96.9       77.45   77.42     49.7    51.50
test_emb/    38.1    88.5    94.55       73.72    39.1   87.65     94.6       73.78   73.75     49.3    49.85
2024-01-11T14:20:00 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 1448 batches in total
dataloader index=0 name=video, batch-size=32 length(#batches)=1448 
2024-01-11T14:20:11 | INFO | utils.basic_utils : Train Epoch: [1]  [   0/1448]  eta: 4:33:54  lr: 0.000010  temperature: 0.0115  video-loss_vtc: 0.1902  video-loss_vtm: 0.0617  time: 11.3498  data: 10.2619  max mem: 5235 res mem: 6024
2024-01-11T14:23:06 | INFO | utils.basic_utils : Train Epoch: [1]  [ 100/1448]  eta: 0:41:28  lr: 0.000010  temperature: 0.0114  video-loss_vtc: 0.2279  video-loss_vtm: 0.1469  time: 1.5748  data: 0.0034  max mem: 5235 res mem: 6024
2024-01-11T14:26:03 | INFO | utils.basic_utils : Train Epoch: [1]  [ 200/1448]  eta: 0:37:36  lr: 0.000010  temperature: 0.0114  video-loss_vtc: 0.1712  video-loss_vtm: 0.0975  time: 1.8518  data: 0.0032  max mem: 5235 res mem: 6024
2024-01-11T14:28:50 | INFO | utils.basic_utils : Train Epoch: [1]  [ 300/1448]  eta: 0:33:43  lr: 0.000010  temperature: 0.0114  video-loss_vtc: 0.2331  video-loss_vtm: 0.0666  time: 1.5571  data: 0.0043  max mem: 5235 res mem: 6024
2024-01-11T14:31:45 | INFO | utils.basic_utils : Train Epoch: [1]  [ 400/1448]  eta: 0:30:43  lr: 0.000010  temperature: 0.0113  video-loss_vtc: 0.2689  video-loss_vtm: 0.1255  time: 1.8396  data: 0.0029  max mem: 5235 res mem: 6024
2024-01-11T14:34:34 | INFO | utils.basic_utils : Train Epoch: [1]  [ 500/1448]  eta: 0:27:34  lr: 0.000010  temperature: 0.0113  video-loss_vtc: 0.2334  video-loss_vtm: 0.4173  time: 1.6794  data: 0.0040  max mem: 5235 res mem: 6024
2024-01-11T14:37:30 | INFO | utils.basic_utils : Train Epoch: [1]  [ 600/1448]  eta: 0:24:42  lr: 0.000010  temperature: 0.0112  video-loss_vtc: 0.1667  video-loss_vtm: 0.0975  time: 1.7952  data: 0.0046  max mem: 5235 res mem: 6024
2024-01-11T14:40:28 | INFO | utils.basic_utils : Train Epoch: [1]  [ 700/1448]  eta: 0:21:50  lr: 0.000010  temperature: 0.0111  video-loss_vtc: 0.2603  video-loss_vtm: 0.1334  time: 1.9678  data: 0.0039  max mem: 5235 res mem: 6024
2024-01-11T14:43:14 | INFO | utils.basic_utils : Train Epoch: [1]  [ 800/1448]  eta: 0:18:48  lr: 0.000010  temperature: 0.0112  video-loss_vtc: 0.1421  video-loss_vtm: 0.1483  time: 1.6963  data: 0.0040  max mem: 5235 res mem: 6024
2024-01-11T14:45:53 | INFO | utils.basic_utils : Train Epoch: [1]  [ 900/1448]  eta: 0:15:44  lr: 0.000009  temperature: 0.0111  video-loss_vtc: 0.2146  video-loss_vtm: 0.1221  time: 1.5636  data: 0.1459  max mem: 5235 res mem: 6024
2024-01-11T14:48:15 | INFO | utils.basic_utils : Train Epoch: [1]  [1000/1448]  eta: 0:12:38  lr: 0.000009  temperature: 0.0112  video-loss_vtc: 0.1541  video-loss_vtm: 0.1514  time: 1.1441  data: 0.0019  max mem: 5235 res mem: 6024
2024-01-11T14:50:06 | INFO | utils.basic_utils : Train Epoch: [1]  [1100/1448]  eta: 0:09:31  lr: 0.000009  temperature: 0.0112  video-loss_vtc: 0.4108  video-loss_vtm: 0.0791  time: 1.0953  data: 0.0018  max mem: 5235 res mem: 6024
2024-01-11T14:52:28 | INFO | utils.basic_utils : Train Epoch: [1]  [1200/1448]  eta: 0:06:42  lr: 0.000009  temperature: 0.0111  video-loss_vtc: 0.1938  video-loss_vtm: 0.1989  time: 1.6541  data: 0.0040  max mem: 5235 res mem: 6024
2024-01-11T14:55:18 | INFO | utils.basic_utils : Train Epoch: [1]  [1300/1448]  eta: 0:04:00  lr: 0.000009  temperature: 0.0111  video-loss_vtc: 0.2659  video-loss_vtm: 0.1389  time: 1.6110  data: 0.0029  max mem: 5235 res mem: 6024
2024-01-11T14:58:13 | INFO | utils.basic_utils : Train Epoch: [1]  [1400/1448]  eta: 0:01:18  lr: 0.000009  temperature: 0.0111  video-loss_vtc: 0.1032  video-loss_vtm: 0.1200  time: 1.8274  data: 0.6575  max mem: 5235 res mem: 6024
2024-01-11T14:59:30 | INFO | utils.basic_utils : Train Epoch: [1]  [1447/1448]  eta: 0:00:01  lr: 0.000009  temperature: 0.0110  video-loss_vtc: 0.1421  video-loss_vtm: 0.0192  time: 1.5966  data: 0.4321  max mem: 5235 res mem: 6024
2024-01-11T14:59:30 | INFO | utils.basic_utils : Train Epoch: [1] Total time: 0:39:29 (1.6366 s / it)
2024-01-11T14:59:30 | INFO | __main__ : Averaged train stats: lr: 0.0000  temperature: 0.0112  video-loss_vtc: 0.2307  video-loss_vtm: 0.1158
2024-01-11T14:59:30 | INFO | tasks.retrieval_utils : Start evaluation for media_type=video
2024-01-11T14:59:30 | INFO | tasks.retrieval_utils : Computing dual encoder features...
2024-01-11T14:59:40 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-01-11T14:59:40 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-01-11T14:59:41 | INFO | utils.basic_utils : extracting image feats  [ 0/63]  eta: 0:10:26    time: 9.9498  data: 9.7734  max mem: 5235 res mem: 6024
2024-01-11T15:01:29 | INFO | utils.basic_utils : extracting image feats  [62/63]  eta: 0:00:01    time: 1.9071  data: 1.7291  max mem: 5235 res mem: 6024
2024-01-11T15:01:29 | INFO | utils.basic_utils : extracting image feats Total time: 0:01:58 (1.8766 s / it)
2024-01-11T15:01:31 | INFO | tasks.retrieval_utils : Finished feature extraction
2024-01-11T15:01:31 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product]
2024-01-11T15:01:31 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product], done!
2024-01-11T15:01:31 | INFO | tasks.retrieval_utils : Rerank dual-encoder results with cross-encoder...
2024-01-11T15:01:31 | INFO | tasks.retrieval_utils : i2t_scores.shape torch.Size([501, 2000])
2024-01-11T15:01:31 | INFO | tasks.retrieval_utils : n_clip_per_video=1, with eval_frame_ensemble=concat
2024-01-11T15:01:31 | INFO | utils.basic_utils : Evaluation:  [  0/501]  eta: 0:00:14    time: 0.0291  data: 0.0009  max mem: 5235 res mem: 6024
2024-01-11T15:01:35 | INFO | utils.basic_utils : Evaluation:  [100/501]  eta: 0:00:15    time: 0.0373  data: 0.0000  max mem: 5235 res mem: 6024
2024-01-11T15:01:39 | INFO | utils.basic_utils : Evaluation:  [200/501]  eta: 0:00:11    time: 0.0414  data: 0.0000  max mem: 5235 res mem: 6024
2024-01-11T15:01:43 | INFO | utils.basic_utils : Evaluation:  [300/501]  eta: 0:00:07    time: 0.0394  data: 0.0000  max mem: 5235 res mem: 6024
2024-01-11T15:01:47 | INFO | utils.basic_utils : Evaluation:  [400/501]  eta: 0:00:03    time: 0.0383  data: 0.0000  max mem: 5235 res mem: 6024
2024-01-11T15:01:51 | INFO | utils.basic_utils : Evaluation:  [500/501]  eta: 0:00:00    time: 0.0385  data: 0.0000  max mem: 5235 res mem: 6024
2024-01-11T15:01:51 | INFO | utils.basic_utils : Evaluation: Total time: 0:00:19 (0.0391 s / it)
2024-01-11T15:01:51 | INFO | tasks.retrieval_utils : t2i_scores.shape torch.Size([501, 2000])
2024-01-11T15:01:51 | INFO | utils.basic_utils : Evaluation:  [  0/501]  eta: 0:01:43    time: 0.2076  data: 0.0010  max mem: 5235 res mem: 6024
2024-01-11T15:02:09 | INFO | utils.basic_utils : Evaluation:  [100/501]  eta: 0:01:15    time: 0.1848  data: 0.0000  max mem: 5235 res mem: 6024
2024-01-11T15:02:28 | INFO | utils.basic_utils : Evaluation:  [200/501]  eta: 0:00:56    time: 0.1767  data: 0.0000  max mem: 5235 res mem: 6024
2024-01-11T15:02:46 | INFO | utils.basic_utils : Evaluation:  [300/501]  eta: 0:00:37    time: 0.1865  data: 0.0000  max mem: 5235 res mem: 6024
2024-01-11T15:03:04 | INFO | utils.basic_utils : Evaluation:  [400/501]  eta: 0:00:18    time: 0.1753  data: 0.0000  max mem: 5235 res mem: 6024
2024-01-11T15:03:23 | INFO | utils.basic_utils : Evaluation:  [500/501]  eta: 0:00:00    time: 0.1729  data: 0.0000  max mem: 5235 res mem: 6024
2024-01-11T15:03:23 | INFO | utils.basic_utils : Evaluation: Total time: 0:01:32 (0.1847 s / it)
2024-01-11T15:03:24 | INFO | tasks.retrieval_utils : Evaluation time 0:03:54
2024-01-11T15:03:25 | INFO | __main__ : Epoch 1
2024-01-11T15:03:25 | INFO | __main__ : 
           txt_r1  txt_r5  txt_r10  txt_r_mean  img_r1  img_r5  img_r10  img_r_mean  r_mean  txt_acc  img_acc
test/       41.60    92.8    97.25       77.22   41.40   92.45    97.10       76.98   77.10    49.95     49.9
test_emb/   37.85    89.3    95.30       74.15   38.65   88.90    95.55       74.37   74.26    49.45     49.4
2024-01-11T15:03:26 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 1448 batches in total
dataloader index=0 name=video, batch-size=32 length(#batches)=1448 
2024-01-11T15:03:36 | INFO | utils.basic_utils : Train Epoch: [2]  [   0/1448]  eta: 4:19:15  lr: 0.000009  temperature: 0.0110  video-loss_vtc: 0.2156  video-loss_vtm: 0.0486  time: 10.7431  data: 8.9828  max mem: 5235 res mem: 6024
2024-01-11T15:06:24 | INFO | utils.basic_utils : Train Epoch: [2]  [ 100/1448]  eta: 0:39:47  lr: 0.000008  temperature: 0.0110  video-loss_vtc: 0.2038  video-loss_vtm: 0.0364  time: 1.6148  data: 0.5005  max mem: 5235 res mem: 6024
2024-01-11T15:09:19 | INFO | utils.basic_utils : Train Epoch: [2]  [ 200/1448]  eta: 0:36:36  lr: 0.000008  temperature: 0.0110  video-loss_vtc: 0.1575  video-loss_vtm: 0.0490  time: 1.8232  data: 0.0023  max mem: 5235 res mem: 6024
2024-01-11T15:12:08 | INFO | utils.basic_utils : Train Epoch: [2]  [ 300/1448]  eta: 0:33:12  lr: 0.000008  temperature: 0.0109  video-loss_vtc: 0.1535  video-loss_vtm: 0.1230  time: 1.7187  data: 0.0042  max mem: 5235 res mem: 6024
2024-01-11T15:14:57 | INFO | utils.basic_utils : Train Epoch: [2]  [ 400/1448]  eta: 0:30:07  lr: 0.000008  temperature: 0.0108  video-loss_vtc: 0.1313  video-loss_vtm: 0.1017  time: 1.6026  data: 0.0029  max mem: 5235 res mem: 6024
2024-01-11T15:17:48 | INFO | utils.basic_utils : Train Epoch: [2]  [ 500/1448]  eta: 0:27:11  lr: 0.000007  temperature: 0.0109  video-loss_vtc: 0.2375  video-loss_vtm: 0.2003  time: 1.7625  data: 0.0036  max mem: 5235 res mem: 6024
2024-01-11T15:20:37 | INFO | utils.basic_utils : Train Epoch: [2]  [ 600/1448]  eta: 0:24:15  lr: 0.000007  temperature: 0.0108  video-loss_vtc: 0.0894  video-loss_vtm: 0.0278  time: 1.6575  data: 0.0032  max mem: 5235 res mem: 6024
2024-01-11T15:23:26 | INFO | utils.basic_utils : Train Epoch: [2]  [ 700/1448]  eta: 0:21:20  lr: 0.000007  temperature: 0.0109  video-loss_vtc: 0.2350  video-loss_vtm: 0.0855  time: 1.6383  data: 0.5259  max mem: 5235 res mem: 6024
2024-01-11T15:26:16 | INFO | utils.basic_utils : Train Epoch: [2]  [ 800/1448]  eta: 0:18:28  lr: 0.000007  temperature: 0.0109  video-loss_vtc: 0.1749  video-loss_vtm: 0.0948  time: 1.5945  data: 0.0026  max mem: 5235 res mem: 6024
2024-01-11T15:29:04 | INFO | utils.basic_utils : Train Epoch: [2]  [ 900/1448]  eta: 0:15:35  lr: 0.000006  temperature: 0.0109  video-loss_vtc: 0.1513  video-loss_vtm: 0.0589  time: 1.7070  data: 0.0034  max mem: 5235 res mem: 6024
2024-01-11T15:31:55 | INFO | utils.basic_utils : Train Epoch: [2]  [1000/1448]  eta: 0:12:45  lr: 0.000006  temperature: 0.0109  video-loss_vtc: 0.2112  video-loss_vtm: 0.1967  time: 1.7066  data: 0.0022  max mem: 5235 res mem: 6024
2024-01-11T15:34:43 | INFO | utils.basic_utils : Train Epoch: [2]  [1100/1448]  eta: 0:09:53  lr: 0.000006  temperature: 0.0109  video-loss_vtc: 0.0673  video-loss_vtm: 0.0233  time: 1.6883  data: 0.0037  max mem: 5235 res mem: 6024
2024-01-11T15:37:30 | INFO | utils.basic_utils : Train Epoch: [2]  [1200/1448]  eta: 0:07:02  lr: 0.000006  temperature: 0.0109  video-loss_vtc: 0.1334  video-loss_vtm: 0.1015  time: 1.5088  data: 0.0033  max mem: 5235 res mem: 6024
2024-01-11T15:40:21 | INFO | utils.basic_utils : Train Epoch: [2]  [1300/1448]  eta: 0:04:11  lr: 0.000005  temperature: 0.0109  video-loss_vtc: 0.0777  video-loss_vtm: 0.0483  time: 1.7788  data: 0.0031  max mem: 5235 res mem: 6024
2024-01-11T15:43:08 | INFO | utils.basic_utils : Train Epoch: [2]  [1400/1448]  eta: 0:01:21  lr: 0.000005  temperature: 0.0109  video-loss_vtc: 0.1656  video-loss_vtm: 0.0457  time: 1.6020  data: 0.0034  max mem: 5235 res mem: 6024
2024-01-11T15:44:26 | INFO | utils.basic_utils : Train Epoch: [2]  [1447/1448]  eta: 0:00:01  lr: 0.000005  temperature: 0.0109  video-loss_vtc: 0.2882  video-loss_vtm: 0.1294  time: 1.5820  data: 0.0026  max mem: 5235 res mem: 6024
2024-01-11T15:44:26 | INFO | utils.basic_utils : Train Epoch: [2] Total time: 0:41:00 (1.6989 s / it)
2024-01-11T15:44:26 | INFO | __main__ : Averaged train stats: lr: 0.0000  temperature: 0.0109  video-loss_vtc: 0.1645  video-loss_vtm: 0.0917
2024-01-11T15:44:26 | INFO | tasks.retrieval_utils : Start evaluation for media_type=video
2024-01-11T15:44:26 | INFO | tasks.retrieval_utils : Computing dual encoder features...
2024-01-11T15:44:37 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-01-11T15:44:37 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-01-11T15:44:37 | INFO | utils.basic_utils : extracting image feats  [ 0/63]  eta: 0:10:35    time: 10.0906  data: 9.9134  max mem: 5235 res mem: 6024
2024-01-11T15:46:21 | INFO | utils.basic_utils : extracting image feats  [62/63]  eta: 0:00:01    time: 1.6875  data: 1.5088  max mem: 5235 res mem: 6024
2024-01-11T15:46:21 | INFO | utils.basic_utils : extracting image feats Total time: 0:01:54 (1.8148 s / it)
2024-01-11T15:46:23 | INFO | tasks.retrieval_utils : Finished feature extraction
2024-01-11T15:46:23 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product]
2024-01-11T15:46:23 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product], done!
2024-01-11T15:46:23 | INFO | tasks.retrieval_utils : Rerank dual-encoder results with cross-encoder...
2024-01-11T15:46:23 | INFO | tasks.retrieval_utils : i2t_scores.shape torch.Size([501, 2000])
2024-01-11T15:46:23 | INFO | tasks.retrieval_utils : n_clip_per_video=1, with eval_frame_ensemble=concat
2024-01-11T15:46:23 | INFO | utils.basic_utils : Evaluation:  [  0/501]  eta: 0:00:14    time: 0.0283  data: 0.0008  max mem: 5235 res mem: 6024
2024-01-11T15:46:27 | INFO | utils.basic_utils : Evaluation:  [100/501]  eta: 0:00:15    time: 0.0397  data: 0.0000  max mem: 5235 res mem: 6024
2024-01-11T15:46:31 | INFO | utils.basic_utils : Evaluation:  [200/501]  eta: 0:00:11    time: 0.0407  data: 0.0000  max mem: 5235 res mem: 6024
2024-01-11T15:46:35 | INFO | utils.basic_utils : Evaluation:  [300/501]  eta: 0:00:07    time: 0.0412  data: 0.0000  max mem: 5235 res mem: 6024
2024-01-11T15:46:39 | INFO | utils.basic_utils : Evaluation:  [400/501]  eta: 0:00:04    time: 0.0407  data: 0.0000  max mem: 5235 res mem: 6024
2024-01-11T15:46:43 | INFO | utils.basic_utils : Evaluation:  [500/501]  eta: 0:00:00    time: 0.0386  data: 0.0000  max mem: 5235 res mem: 6024
2024-01-11T15:46:43 | INFO | utils.basic_utils : Evaluation: Total time: 0:00:19 (0.0396 s / it)
2024-01-11T15:46:43 | INFO | tasks.retrieval_utils : t2i_scores.shape torch.Size([501, 2000])
2024-01-11T15:46:43 | INFO | utils.basic_utils : Evaluation:  [  0/501]  eta: 0:01:37    time: 0.1954  data: 0.0007  max mem: 5235 res mem: 6024
2024-01-11T15:47:02 | INFO | utils.basic_utils : Evaluation:  [100/501]  eta: 0:01:16    time: 0.2067  data: 0.0000  max mem: 5235 res mem: 6024
2024-01-11T15:47:21 | INFO | utils.basic_utils : Evaluation:  [200/501]  eta: 0:00:56    time: 0.1726  data: 0.0000  max mem: 5235 res mem: 6024
2024-01-11T15:47:39 | INFO | utils.basic_utils : Evaluation:  [300/501]  eta: 0:00:37    time: 0.1787  data: 0.0000  max mem: 5235 res mem: 6024
2024-01-11T15:47:57 | INFO | utils.basic_utils : Evaluation:  [400/501]  eta: 0:00:18    time: 0.1820  data: 0.0000  max mem: 5235 res mem: 6024
2024-01-11T15:48:15 | INFO | utils.basic_utils : Evaluation:  [500/501]  eta: 0:00:00    time: 0.1691  data: 0.0000  max mem: 5235 res mem: 6024
2024-01-11T15:48:15 | INFO | utils.basic_utils : Evaluation: Total time: 0:01:31 (0.1832 s / it)
2024-01-11T15:48:18 | INFO | tasks.retrieval_utils : Evaluation time 0:03:52
2024-01-11T15:48:19 | INFO | __main__ : Epoch 2
2024-01-11T15:48:19 | INFO | __main__ : 
           txt_r1  txt_r5  txt_r10  txt_r_mean  img_r1  img_r5  img_r10  img_r_mean  r_mean  txt_acc  img_acc
test/       41.65   93.20     97.4       77.42   40.25   92.70    97.15        76.7   77.06     49.6    48.65
test_emb/   38.60   90.35     95.5       74.82   37.80   89.05    95.15        74.0   74.41     49.3    48.10
2024-01-11T15:48:19 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 1448 batches in total
dataloader index=0 name=video, batch-size=32 length(#batches)=1448 
2024-01-11T15:48:30 | INFO | utils.basic_utils : Train Epoch: [3]  [   0/1448]  eta: 4:18:38  lr: 0.000005  temperature: 0.0109  video-loss_vtc: 0.1379  video-loss_vtm: 0.1137  time: 10.7171  data: 9.3886  max mem: 5235 res mem: 6024
2024-01-11T15:51:15 | INFO | utils.basic_utils : Train Epoch: [3]  [ 100/1448]  eta: 0:39:08  lr: 0.000005  temperature: 0.0108  video-loss_vtc: 0.1729  video-loss_vtm: 0.1953  time: 1.5515  data: 0.4564  max mem: 5235 res mem: 6024
2024-01-11T15:54:00 | INFO | utils.basic_utils : Train Epoch: [3]  [ 200/1448]  eta: 0:35:15  lr: 0.000004  temperature: 0.0108  video-loss_vtc: 0.1277  video-loss_vtm: 0.0519  time: 1.2621  data: 0.3944  max mem: 5235 res mem: 6024
2024-01-11T15:56:36 | INFO | utils.basic_utils : Train Epoch: [3]  [ 300/1448]  eta: 0:31:34  lr: 0.000004  temperature: 0.0108  video-loss_vtc: 0.1082  video-loss_vtm: 0.0821  time: 1.5299  data: 0.8347  max mem: 5235 res mem: 6024
2024-01-11T15:58:31 | INFO | utils.basic_utils : Train Epoch: [3]  [ 400/1448]  eta: 0:26:38  lr: 0.000004  temperature: 0.0107  video-loss_vtc: 0.2110  video-loss_vtm: 0.0759  time: 1.1010  data: 0.0022  max mem: 5235 res mem: 6024
2024-01-11T16:00:31 | INFO | utils.basic_utils : Train Epoch: [3]  [ 500/1448]  eta: 0:23:04  lr: 0.000004  temperature: 0.0107  video-loss_vtc: 0.1163  video-loss_vtm: 0.1010  time: 1.2860  data: 0.0020  max mem: 5235 res mem: 6024
2024-01-11T16:03:09 | INFO | utils.basic_utils : Train Epoch: [3]  [ 600/1448]  eta: 0:20:54  lr: 0.000003  temperature: 0.0107  video-loss_vtc: 0.1474  video-loss_vtm: 0.1316  time: 1.6469  data: 0.1810  max mem: 5235 res mem: 6024
2024-01-11T16:05:57 | INFO | utils.basic_utils : Train Epoch: [3]  [ 700/1448]  eta: 0:18:48  lr: 0.000003  temperature: 0.0107  video-loss_vtc: 0.1386  video-loss_vtm: 0.1294  time: 1.7060  data: 0.0021  max mem: 5235 res mem: 6024
2024-01-11T16:08:42 | INFO | utils.basic_utils : Train Epoch: [3]  [ 800/1448]  eta: 0:16:29  lr: 0.000003  temperature: 0.0107  video-loss_vtc: 0.0878  video-loss_vtm: 0.0191  time: 1.5185  data: 0.0070  max mem: 5235 res mem: 6024
2024-01-11T16:11:34 | INFO | utils.basic_utils : Train Epoch: [3]  [ 900/1448]  eta: 0:14:08  lr: 0.000003  temperature: 0.0107  video-loss_vtc: 0.0781  video-loss_vtm: 0.1013  time: 1.7040  data: 0.0042  max mem: 5235 res mem: 6024
2024-01-11T16:14:23 | INFO | utils.basic_utils : Train Epoch: [3]  [1000/1448]  eta: 0:11:39  lr: 0.000002  temperature: 0.0106  video-loss_vtc: 0.0958  video-loss_vtm: 0.0539  time: 1.8350  data: 0.0032  max mem: 5235 res mem: 6024
2024-01-11T16:17:06 | INFO | utils.basic_utils : Train Epoch: [3]  [1100/1448]  eta: 0:09:05  lr: 0.000002  temperature: 0.0106  video-loss_vtc: 0.1032  video-loss_vtm: 0.0259  time: 1.6925  data: 0.0041  max mem: 5235 res mem: 6024
2024-01-11T16:19:56 | INFO | utils.basic_utils : Train Epoch: [3]  [1200/1448]  eta: 0:06:31  lr: 0.000002  temperature: 0.0107  video-loss_vtc: 0.0473  video-loss_vtm: 0.0325  time: 1.7157  data: 0.0038  max mem: 5235 res mem: 6024
2024-01-11T16:22:41 | INFO | utils.basic_utils : Train Epoch: [3]  [1300/1448]  eta: 0:03:54  lr: 0.000002  temperature: 0.0106  video-loss_vtc: 0.1738  video-loss_vtm: 0.0646  time: 1.8241  data: 0.0026  max mem: 5235 res mem: 6024
2024-01-11T16:25:28 | INFO | utils.basic_utils : Train Epoch: [3]  [1400/1448]  eta: 0:01:16  lr: 0.000002  temperature: 0.0106  video-loss_vtc: 0.1306  video-loss_vtm: 0.1561  time: 1.5186  data: 0.0025  max mem: 5235 res mem: 6024
2024-01-11T16:26:45 | INFO | utils.basic_utils : Train Epoch: [3]  [1447/1448]  eta: 0:00:01  lr: 0.000001  temperature: 0.0106  video-loss_vtc: 0.0716  video-loss_vtm: 0.0340  time: 1.5306  data: 0.2843  max mem: 5235 res mem: 6024
2024-01-11T16:26:45 | INFO | utils.basic_utils : Train Epoch: [3] Total time: 0:38:25 (1.5922 s / it)
2024-01-11T16:26:45 | INFO | __main__ : Averaged train stats: lr: 0.0000  temperature: 0.0107  video-loss_vtc: 0.1336  video-loss_vtm: 0.0778
2024-01-11T16:26:45 | INFO | tasks.retrieval_utils : Start evaluation for media_type=video
2024-01-11T16:26:45 | INFO | tasks.retrieval_utils : Computing dual encoder features...
2024-01-11T16:26:56 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-01-11T16:26:56 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-01-11T16:26:56 | INFO | utils.basic_utils : extracting image feats  [ 0/63]  eta: 0:10:35    time: 10.0814  data: 9.9790  max mem: 5235 res mem: 6024
2024-01-11T16:28:40 | INFO | utils.basic_utils : extracting image feats  [62/63]  eta: 0:00:01    time: 1.6949  data: 1.5281  max mem: 5235 res mem: 6024
2024-01-11T16:28:40 | INFO | utils.basic_utils : extracting image feats Total time: 0:01:53 (1.8075 s / it)
2024-01-11T16:28:41 | INFO | tasks.retrieval_utils : Finished feature extraction
2024-01-11T16:28:41 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product]
2024-01-11T16:28:41 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product], done!
2024-01-11T16:28:41 | INFO | tasks.retrieval_utils : Rerank dual-encoder results with cross-encoder...
2024-01-11T16:28:41 | INFO | tasks.retrieval_utils : i2t_scores.shape torch.Size([501, 2000])
2024-01-11T16:28:41 | INFO | tasks.retrieval_utils : n_clip_per_video=1, with eval_frame_ensemble=concat
2024-01-11T16:28:42 | INFO | utils.basic_utils : Evaluation:  [  0/501]  eta: 0:00:14    time: 0.0291  data: 0.0011  max mem: 5235 res mem: 6024
2024-01-11T16:28:45 | INFO | utils.basic_utils : Evaluation:  [100/501]  eta: 0:00:13    time: 0.0406  data: 0.0000  max mem: 5235 res mem: 6024
2024-01-11T16:28:49 | INFO | utils.basic_utils : Evaluation:  [200/501]  eta: 0:00:10    time: 0.0389  data: 0.0000  max mem: 5235 res mem: 6024
2024-01-11T16:28:53 | INFO | utils.basic_utils : Evaluation:  [300/501]  eta: 0:00:07    time: 0.0374  data: 0.0000  max mem: 5235 res mem: 6024
2024-01-11T16:28:57 | INFO | utils.basic_utils : Evaluation:  [400/501]  eta: 0:00:03    time: 0.0395  data: 0.0000  max mem: 5235 res mem: 6024
2024-01-11T16:29:01 | INFO | utils.basic_utils : Evaluation:  [500/501]  eta: 0:00:00    time: 0.0412  data: 0.0000  max mem: 5235 res mem: 6024
2024-01-11T16:29:01 | INFO | utils.basic_utils : Evaluation: Total time: 0:00:19 (0.0382 s / it)
2024-01-11T16:29:01 | INFO | tasks.retrieval_utils : t2i_scores.shape torch.Size([501, 2000])
2024-01-11T16:29:01 | INFO | utils.basic_utils : Evaluation:  [  0/501]  eta: 0:01:41    time: 0.2019  data: 0.0008  max mem: 5235 res mem: 6024
2024-01-11T16:29:20 | INFO | utils.basic_utils : Evaluation:  [100/501]  eta: 0:01:16    time: 0.1893  data: 0.0000  max mem: 5235 res mem: 6024
2024-01-11T16:29:38 | INFO | utils.basic_utils : Evaluation:  [200/501]  eta: 0:00:56    time: 0.1757  data: 0.0000  max mem: 5235 res mem: 6024
2024-01-11T16:29:57 | INFO | utils.basic_utils : Evaluation:  [300/501]  eta: 0:00:37    time: 0.1918  data: 0.0000  max mem: 5235 res mem: 6024
2024-01-11T16:30:16 | INFO | utils.basic_utils : Evaluation:  [400/501]  eta: 0:00:19    time: 0.1879  data: 0.0000  max mem: 5235 res mem: 6024
2024-01-11T16:30:35 | INFO | utils.basic_utils : Evaluation:  [500/501]  eta: 0:00:00    time: 0.1799  data: 0.0000  max mem: 5235 res mem: 6024
2024-01-11T16:30:35 | INFO | utils.basic_utils : Evaluation: Total time: 0:01:34 (0.1888 s / it)
2024-01-11T16:30:36 | INFO | tasks.retrieval_utils : Evaluation time 0:03:51
2024-01-11T16:30:37 | INFO | __main__ : Epoch 3
2024-01-11T16:30:37 | INFO | __main__ : 
           txt_r1  txt_r5  txt_r10  txt_r_mean  img_r1  img_r5  img_r10  img_r_mean  r_mean  txt_acc  img_acc
test/       42.15   93.35     97.5       77.67    42.6   93.00     97.4       77.67   77.67    49.65     50.2
test_emb/   39.25   89.90     95.6       74.92    38.1   89.55     95.9       74.52   74.72    49.35     48.2
2024-01-11T16:30:58 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 1448 batches in total
dataloader index=0 name=video, batch-size=32 length(#batches)=1448 
2024-01-11T16:31:09 | INFO | utils.basic_utils : Train Epoch: [4]  [   0/1448]  eta: 4:36:44  lr: 0.000001  temperature: 0.0106  video-loss_vtc: 0.0499  video-loss_vtm: 0.0762  time: 11.4674  data: 9.3382  max mem: 5235 res mem: 6024
2024-01-11T16:34:03 | INFO | utils.basic_utils : Train Epoch: [4]  [ 100/1448]  eta: 0:41:12  lr: 0.000001  temperature: 0.0106  video-loss_vtc: 0.1073  video-loss_vtm: 0.0326  time: 1.7104  data: 0.6278  max mem: 5235 res mem: 6024
2024-01-11T16:36:54 | INFO | utils.basic_utils : Train Epoch: [4]  [ 200/1448]  eta: 0:36:55  lr: 0.000001  temperature: 0.0106  video-loss_vtc: 0.1364  video-loss_vtm: 0.0764  time: 1.5531  data: 0.4897  max mem: 5235 res mem: 6024
2024-01-11T16:39:42 | INFO | utils.basic_utils : Train Epoch: [4]  [ 300/1448]  eta: 0:33:18  lr: 0.000001  temperature: 0.0106  video-loss_vtc: 0.1490  video-loss_vtm: 0.1783  time: 1.8271  data: 0.7580  max mem: 5235 res mem: 6024
2024-01-11T16:42:30 | INFO | utils.basic_utils : Train Epoch: [4]  [ 400/1448]  eta: 0:30:08  lr: 0.000001  temperature: 0.0106  video-loss_vtc: 0.1162  video-loss_vtm: 0.0099  time: 1.7503  data: 0.3969  max mem: 5235 res mem: 6024
2024-01-11T16:45:22 | INFO | utils.basic_utils : Train Epoch: [4]  [ 500/1448]  eta: 0:27:16  lr: 0.000001  temperature: 0.0106  video-loss_vtc: 0.1118  video-loss_vtm: 0.0657  time: 1.7374  data: 0.6604  max mem: 5235 res mem: 6024
2024-01-11T16:48:09 | INFO | utils.basic_utils : Train Epoch: [4]  [ 600/1448]  eta: 0:24:14  lr: 0.000001  temperature: 0.0106  video-loss_vtc: 0.1679  video-loss_vtm: 0.1107  time: 1.8770  data: 0.7653  max mem: 5235 res mem: 6024
2024-01-11T16:50:51 | INFO | utils.basic_utils : Train Epoch: [4]  [ 700/1448]  eta: 0:21:13  lr: 0.000000  temperature: 0.0106  video-loss_vtc: 0.1079  video-loss_vtm: 0.0260  time: 1.6094  data: 0.2303  max mem: 5235 res mem: 6024
2024-01-11T16:53:39 | INFO | utils.basic_utils : Train Epoch: [4]  [ 800/1448]  eta: 0:18:21  lr: 0.000000  temperature: 0.0106  video-loss_vtc: 0.0442  video-loss_vtm: 0.1742  time: 1.6871  data: 0.0273  max mem: 5235 res mem: 6024
2024-01-11T16:56:35 | INFO | utils.basic_utils : Train Epoch: [4]  [ 900/1448]  eta: 0:15:35  lr: 0.000000  temperature: 0.0106  video-loss_vtc: 0.1087  video-loss_vtm: 0.0341  time: 1.7561  data: 0.0041  max mem: 5235 res mem: 6024
2024-01-11T16:59:18 | INFO | utils.basic_utils : Train Epoch: [4]  [1000/1448]  eta: 0:12:40  lr: 0.000000  temperature: 0.0106  video-loss_vtc: 0.1077  video-loss_vtm: 0.1321  time: 1.6132  data: 0.0024  max mem: 5235 res mem: 6024
2024-01-11T17:02:10 | INFO | utils.basic_utils : Train Epoch: [4]  [1100/1448]  eta: 0:09:51  lr: 0.000000  temperature: 0.0106  video-loss_vtc: 0.1573  video-loss_vtm: 0.0327  time: 1.7514  data: 0.1099  max mem: 5235 res mem: 6024
2024-01-11T17:04:44 | INFO | utils.basic_utils : Train Epoch: [4]  [1200/1448]  eta: 0:06:58  lr: 0.000000  temperature: 0.0106  video-loss_vtc: 0.0996  video-loss_vtm: 0.0834  time: 1.7551  data: 0.0034  max mem: 5235 res mem: 6024
2024-01-11T17:07:04 | INFO | utils.basic_utils : Train Epoch: [4]  [1300/1448]  eta: 0:04:06  lr: 0.000000  temperature: 0.0106  video-loss_vtc: 0.1228  video-loss_vtm: 0.0287  time: 1.0891  data: 0.0509  max mem: 5235 res mem: 6024
2024-01-11T17:09:02 | INFO | utils.basic_utils : Train Epoch: [4]  [1400/1448]  eta: 0:01:18  lr: 0.000000  temperature: 0.0106  video-loss_vtc: 0.1219  video-loss_vtm: 0.0356  time: 1.0963  data: 0.0022  max mem: 5235 res mem: 6024
2024-01-11T17:09:55 | INFO | utils.basic_utils : Train Epoch: [4]  [1447/1448]  eta: 0:00:01  lr: 0.000000  temperature: 0.0106  video-loss_vtc: 0.1542  video-loss_vtm: 0.0184  time: 1.2146  data: 0.0019  max mem: 5235 res mem: 6024
2024-01-11T17:09:55 | INFO | utils.basic_utils : Train Epoch: [4] Total time: 0:38:57 (1.6143 s / it)
2024-01-11T17:09:55 | INFO | __main__ : Averaged train stats: lr: 0.0000  temperature: 0.0106  video-loss_vtc: 0.1218  video-loss_vtm: 0.0715
2024-01-11T17:09:55 | INFO | tasks.retrieval_utils : Start evaluation for media_type=video
2024-01-11T17:09:55 | INFO | tasks.retrieval_utils : Computing dual encoder features...
2024-01-11T17:10:06 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-01-11T17:10:06 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-01-11T17:10:06 | INFO | utils.basic_utils : extracting image feats  [ 0/63]  eta: 0:10:18    time: 9.8115  data: 9.7067  max mem: 5235 res mem: 6024
2024-01-11T17:11:49 | INFO | utils.basic_utils : extracting image feats  [62/63]  eta: 0:00:01    time: 1.6515  data: 1.4805  max mem: 5235 res mem: 6024
2024-01-11T17:11:49 | INFO | utils.basic_utils : extracting image feats Total time: 0:01:52 (1.7879 s / it)
2024-01-11T17:11:51 | INFO | tasks.retrieval_utils : Finished feature extraction
2024-01-11T17:11:51 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product]
2024-01-11T17:11:51 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product], done!
2024-01-11T17:11:51 | INFO | tasks.retrieval_utils : Rerank dual-encoder results with cross-encoder...
2024-01-11T17:11:51 | INFO | tasks.retrieval_utils : i2t_scores.shape torch.Size([501, 2000])
2024-01-11T17:11:51 | INFO | tasks.retrieval_utils : n_clip_per_video=1, with eval_frame_ensemble=concat
2024-01-11T17:11:51 | INFO | utils.basic_utils : Evaluation:  [  0/501]  eta: 0:00:13    time: 0.0271  data: 0.0007  max mem: 5235 res mem: 6024
2024-01-11T17:11:55 | INFO | utils.basic_utils : Evaluation:  [100/501]  eta: 0:00:15    time: 0.0374  data: 0.0000  max mem: 5235 res mem: 6024
2024-01-11T17:11:58 | INFO | utils.basic_utils : Evaluation:  [200/501]  eta: 0:00:11    time: 0.0403  data: 0.0000  max mem: 5235 res mem: 6024
2024-01-11T17:12:02 | INFO | utils.basic_utils : Evaluation:  [300/501]  eta: 0:00:07    time: 0.0405  data: 0.0000  max mem: 5235 res mem: 6024
2024-01-11T17:12:06 | INFO | utils.basic_utils : Evaluation:  [400/501]  eta: 0:00:03    time: 0.0404  data: 0.0000  max mem: 5235 res mem: 6024
2024-01-11T17:12:10 | INFO | utils.basic_utils : Evaluation:  [500/501]  eta: 0:00:00    time: 0.0412  data: 0.0000  max mem: 5235 res mem: 6024
2024-01-11T17:12:10 | INFO | utils.basic_utils : Evaluation: Total time: 0:00:19 (0.0392 s / it)
2024-01-11T17:12:10 | INFO | tasks.retrieval_utils : t2i_scores.shape torch.Size([501, 2000])
2024-01-11T17:12:11 | INFO | utils.basic_utils : Evaluation:  [  0/501]  eta: 0:01:40    time: 0.2005  data: 0.0007  max mem: 5235 res mem: 6024
2024-01-11T17:12:30 | INFO | utils.basic_utils : Evaluation:  [100/501]  eta: 0:01:15    time: 0.1760  data: 0.0000  max mem: 5235 res mem: 6024
2024-01-11T17:12:48 | INFO | utils.basic_utils : Evaluation:  [200/501]  eta: 0:00:56    time: 0.1781  data: 0.0000  max mem: 5235 res mem: 6024
2024-01-11T17:13:07 | INFO | utils.basic_utils : Evaluation:  [300/501]  eta: 0:00:38    time: 0.1805  data: 0.0000  max mem: 5235 res mem: 6024
2024-01-11T17:13:26 | INFO | utils.basic_utils : Evaluation:  [400/501]  eta: 0:00:19    time: 0.1828  data: 0.0000  max mem: 5235 res mem: 6024
2024-01-11T17:13:45 | INFO | utils.basic_utils : Evaluation:  [500/501]  eta: 0:00:00    time: 0.1882  data: 0.0000  max mem: 5235 res mem: 6024
2024-01-11T17:13:45 | INFO | utils.basic_utils : Evaluation: Total time: 0:01:34 (0.1885 s / it)
2024-01-11T17:13:45 | INFO | tasks.retrieval_utils : Evaluation time 0:03:49
2024-01-11T17:13:46 | INFO | __main__ : Epoch 4
2024-01-11T17:13:46 | INFO | __main__ : 
           txt_r1  txt_r5  txt_r10  txt_r_mean  img_r1  img_r5  img_r10  img_r_mean  r_mean  txt_acc  img_acc
test/       42.05   93.60    97.65       77.77   42.05   92.65     97.5       77.40   77.58    49.65    50.05
test_emb/   39.30   90.05    95.55       74.97   38.15   89.50     95.6       74.42   74.69    49.25    47.70
2024-01-11T17:13:46 | INFO | __main__ : Training time 3:37:22
2024-01-11T17:13:46 | INFO | __main__ : best epoch 3 [config.stop_key test/]
2024-01-11T17:13:46 | INFO | __main__ : Checkpoints and Logs saved at exp/finetuning/ret_rtime/b16_25m_200k_2frame
2024-01-11T17:13:51 | INFO | __main__ : ===========> START eval_after_training [['test']]
2024-01-11T17:13:51 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/training_200k.json', '/data2/dy/temporal_video/dataset', 'video'], 'test_file': {'test': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test2k.json', '/data2/dy/temporal_video/dataset', 'video']}, 'test_types': ['test'], 'num_workers': 6, 'stop_key': 'test/', 'is_paragraph_retrieval': False, 'num_frames': 2, 'num_frames_test': 2, 'batch_size': 32, 'max_txt_l': 32, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 2, 'sample_type': 'rand', 'num_frames_test': 2, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 32, 'video': 32}, 'batch_size': {'image': 32, 'video': 32}, 'batch_size_test': {'image': 32, 'video': 32}}, 'text_enc': 'bert', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_b16', 'img_size': 224, 'patch_size': 16, 'd_model': 768, 'encoder_embed_dim': 768, 'encoder_depth': 12, 'encoder_num_heads': 12, 'drop_path_rate': 0.2, 'num_frames': 2, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 12, 'clip_decoder_embed_dim': 768, 'clip_output_dim': 512, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 224, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'multimodal': {'enable': True}, 'embed_dim': 512, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 1e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 5, 'min_lr_multi': 0.01, 'warmup_epochs': 1, 'num_training_steps': 7240, 'num_warmup_steps': 1448}, 'evaluate': True, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': False, 'entity': 'user', 'project': 'umt_ret'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': 'exp/finetuning/ret_rtime/b16_25m_200k_2frame/eval_after_training', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 42, 'save_latest': True, 'auto_resume': True, 'pretrained_path': 'exp/finetuning/ret_rtime/b16_25m_200k_2frame/ckpt_best.pth', 'rank': 0, 'world_size': 4, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl', 'result_dir': 'exp/finetuning/ret_rtime/b16_25m_200k_2frame/eval_after_training'}
2024-01-11T17:13:51 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/training_200k.json', '/data2/dy/temporal_video/dataset', 'video']
2024-01-11T17:13:51 | INFO | tasks.pretrain : Creating dataset for ret
2024-01-11T17:13:52 | INFO | tasks.shared_utils : Creating model
2024-01-11T17:13:59 | WARNING | urllib3.connectionpool : Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:997)'))': /api/4504800232407040/envelope/
2024-01-11T17:14:04 | INFO | models.umt : Build vision_encoder: vit_b16
2024-01-11T17:14:04 | INFO | models.backbones.vit.vit : Num of patches: 392
2024-01-11T17:14:04 | INFO | models.backbones.vit.vit : Use checkpoint: True
2024-01-11T17:14:04 | INFO | models.backbones.vit.vit : Checkpoint number: 12
2024-01-11T17:14:04 | INFO | models.backbones.vit.vit : Student return index: []
2024-01-11T17:14:07 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
2024-01-11T17:14:07 | INFO | models.umt : Build text_encoder bert_base
2024-01-11T17:14:09 | WARNING | urllib3.connectionpool : Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:997)'))': /api/4504800232407040/envelope/
2024-01-11T17:14:09 | INFO | models.backbones.bert.xbert : build bert with cross_module: ca
2024-01-11T17:14:10 | INFO | models.criterions : Norm type: l2
2024-01-11T17:14:10 | INFO | models.criterions : Loss type: l2
2024-01-11T17:14:11 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.temp: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.weight: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.q_bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.v_bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.weight: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.weight: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.q_bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.v_bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.weight: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.weight: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.q_bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.v_bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.weight: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.weight: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.q_bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.v_bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.weight: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.weight: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.q_bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.v_bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.weight: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.weight: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.q_bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.v_bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.weight: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.weight: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.q_bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.v_bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.weight: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.weight: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.q_bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.v_bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.weight: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.weight: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.q_bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.v_bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.weight: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.weight: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.q_bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.v_bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.weight: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.weight: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.q_bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.v_bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.weight: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.weight: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.q_bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.v_bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.weight: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.weight: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.weight: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.embeddings.word_embeddings.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.embeddings.position_embeddings.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.embeddings.token_type_embeddings.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_proj.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.vision_proj.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_proj.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.text_proj.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.itm_head.weight: wd: 0.02, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : param module.itm_head.bias: wd: 0, lr: 1e-05
2024-01-11T17:14:11 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0.02 len(p)=140
2024-01-11T17:14:11 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0 len(p)=256
2024-01-11T17:14:11 | INFO | tasks.shared_utils : Auto resuming
2024-01-11T17:14:11 | INFO | tasks.shared_utils : Not found checkpoint in exp/finetuning/ret_rtime/b16_25m_200k_2frame/eval_after_training
2024-01-11T17:14:13 | INFO | tasks.shared_utils : <All keys matched successfully>
2024-01-11T17:14:13 | INFO | tasks.shared_utils : Loaded checkpoint from exp/finetuning/ret_rtime/b16_25m_200k_2frame/ckpt_best.pth
2024-01-11T17:14:13 | INFO | __main__ : Start evaluation
2024-01-11T17:14:13 | INFO | tasks.retrieval_utils : Start evaluation for media_type=video
2024-01-11T17:14:13 | INFO | tasks.retrieval_utils : Computing dual encoder features...
2024-01-11T17:14:19 | WARNING | urllib3.connectionpool : Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:997)'))': /api/4504800232407040/envelope/
2024-01-11T17:14:27 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-01-11T17:14:27 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-01-11T17:14:27 | INFO | utils.basic_utils : extracting image feats  [ 0/63]  eta: 0:12:55    time: 12.3102  data: 12.0950  max mem: 5235 res mem: 6798
2024-01-11T17:14:40 | WARNING | urllib3.connectionpool : Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:997)'))': /api/4504800232407040/envelope/
2024-01-11T17:14:50 | WARNING | urllib3.connectionpool : Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:997)'))': /api/4504800232407040/envelope/
2024-01-11T17:15:01 | WARNING | urllib3.connectionpool : Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:997)'))': /api/4504800232407040/envelope/
2024-01-11T17:16:12 | INFO | utils.basic_utils : extracting image feats  [62/63]  eta: 0:00:01    time: 1.4400  data: 1.2615  max mem: 5235 res mem: 6798
2024-01-11T17:16:12 | INFO | utils.basic_utils : extracting image feats Total time: 0:01:57 (1.8594 s / it)
2024-01-11T17:16:14 | INFO | tasks.retrieval_utils : Finished feature extraction
2024-01-11T17:16:14 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product]
2024-01-11T17:16:14 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product], done!
2024-01-11T17:16:14 | INFO | tasks.retrieval_utils : Rerank dual-encoder results with cross-encoder...
2024-01-11T17:16:14 | INFO | tasks.retrieval_utils : i2t_scores.shape torch.Size([501, 2000])
2024-01-11T17:16:14 | INFO | tasks.retrieval_utils : n_clip_per_video=1, with eval_frame_ensemble=concat
2024-01-11T17:16:14 | INFO | utils.basic_utils : Evaluation:  [  0/501]  eta: 0:00:21    time: 0.0435  data: 0.0067  max mem: 5235 res mem: 6798
2024-01-11T17:16:18 | INFO | utils.basic_utils : Evaluation:  [100/501]  eta: 0:00:15    time: 0.0411  data: 0.0000  max mem: 5235 res mem: 6798
2024-01-11T17:16:22 | INFO | utils.basic_utils : Evaluation:  [200/501]  eta: 0:00:11    time: 0.0406  data: 0.0000  max mem: 5235 res mem: 6798
2024-01-11T17:16:26 | INFO | utils.basic_utils : Evaluation:  [300/501]  eta: 0:00:07    time: 0.0387  data: 0.0000  max mem: 5235 res mem: 6798
2024-01-11T17:16:30 | INFO | utils.basic_utils : Evaluation:  [400/501]  eta: 0:00:04    time: 0.0383  data: 0.0000  max mem: 5235 res mem: 6798
2024-01-11T17:16:34 | INFO | utils.basic_utils : Evaluation:  [500/501]  eta: 0:00:00    time: 0.0380  data: 0.0000  max mem: 5235 res mem: 6798
2024-01-11T17:16:34 | INFO | utils.basic_utils : Evaluation: Total time: 0:00:19 (0.0397 s / it)
2024-01-11T17:16:34 | INFO | tasks.retrieval_utils : t2i_scores.shape torch.Size([501, 2000])
2024-01-11T17:16:34 | INFO | utils.basic_utils : Evaluation:  [  0/501]  eta: 0:01:10    time: 0.1401  data: 0.0010  max mem: 5235 res mem: 6798
2024-01-11T17:16:46 | INFO | utils.basic_utils : Evaluation:  [100/501]  eta: 0:00:46    time: 0.1165  data: 0.0000  max mem: 5235 res mem: 6798
2024-01-11T17:16:57 | INFO | utils.basic_utils : Evaluation:  [200/501]  eta: 0:00:35    time: 0.1145  data: 0.0000  max mem: 5235 res mem: 6798
2024-01-11T17:17:09 | INFO | utils.basic_utils : Evaluation:  [300/501]  eta: 0:00:23    time: 0.1141  data: 0.0000  max mem: 5235 res mem: 6798
2024-01-11T17:17:20 | INFO | utils.basic_utils : Evaluation:  [400/501]  eta: 0:00:11    time: 0.1145  data: 0.0000  max mem: 5235 res mem: 6798
2024-01-11T17:17:31 | INFO | utils.basic_utils : Evaluation:  [500/501]  eta: 0:00:00    time: 0.1120  data: 0.0000  max mem: 5235 res mem: 6798
2024-01-11T17:17:31 | INFO | utils.basic_utils : Evaluation: Total time: 0:00:57 (0.1142 s / it)
2024-01-11T17:17:35 | INFO | tasks.retrieval_utils : Evaluation time 0:03:21
2024-01-11T17:17:36 | INFO | __main__ : Epoch 0
2024-01-11T17:17:36 | INFO | __main__ : 
           txt_r1  txt_r5  txt_r10  txt_r_mean  img_r1  img_r5  img_r10  img_r_mean  r_mean  txt_acc  img_acc
test/       42.15   93.35     97.5       77.67    42.6   93.00     97.4       77.67   77.67    49.65     50.2
test_emb/   39.25   89.90     95.6       74.92    38.1   89.55     95.9       74.52   74.72    49.35     48.2
2024-01-11T17:17:36 | INFO | __main__ : Training time 0:03:22
2024-01-11T17:17:36 | INFO | __main__ : best epoch 0 [config.stop_key test/]
2024-01-11T17:17:36 | INFO | __main__ : Checkpoints and Logs saved at exp/finetuning/ret_rtime/b16_25m_200k_2frame/eval_after_training
2024-01-15T06:59:26 | INFO | umt : Logging to: exp/finetuning/ret_rtime/b16_25m_200k_2frame/train.log
2024-01-15T06:59:26 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/training_200k.json', '/data2/dy/temporal_video/dataset', 'video']
  test_file: {
      test: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test2k.json', '/data2/dy/temporal_video/dataset', 'video'] }
  test_types: ['test']
  num_workers: 6
  stop_key: test/
  is_paragraph_retrieval: False
  num_frames: 4
  num_frames_test: 4
  batch_size: 32
  max_txt_l: 32
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 4
          sample_type: rand
          num_frames_test: 4
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 32
          video: 32 }
      batch_size: {
          image: 32
          video: 32 }
      batch_size_test: {
          image: 32
          video: 32 } }
  text_enc: bert
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_b16
          img_size: 224
          patch_size: 16
          d_model: 768
          encoder_embed_dim: 768
          encoder_depth: 12
          encoder_num_heads: 12
          drop_path_rate: 0.2
          num_frames: 4
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 12
          clip_decoder_embed_dim: 768
          clip_output_dim: 512
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 224
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      multimodal: {
          enable: True }
      embed_dim: 512
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 1e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 5
      min_lr_multi: 0.01
      warmup_epochs: 1 }
  zero_shot: False
  evaluate: True
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: user
      project: umt_ret }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/finetuning/ret_rtime/b16_25m_200k_2frame
  resume: False
  debug: False
  log_freq: 100
  seed: 42
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
  rank: 0
  world_size: 4
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-01-15T06:59:26 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/training_200k.json', '/data2/dy/temporal_video/dataset', 'video'], 'test_file': {'test': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test2k.json', '/data2/dy/temporal_video/dataset', 'video']}, 'test_types': ['test'], 'num_workers': 6, 'stop_key': 'test/', 'is_paragraph_retrieval': False, 'num_frames': 4, 'num_frames_test': 4, 'batch_size': 32, 'max_txt_l': 32, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 4, 'sample_type': 'rand', 'num_frames_test': 4, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 32, 'video': 32}, 'batch_size': {'image': 32, 'video': 32}, 'batch_size_test': {'image': 32, 'video': 32}}, 'text_enc': 'bert', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_b16', 'img_size': 224, 'patch_size': 16, 'd_model': 768, 'encoder_embed_dim': 768, 'encoder_depth': 12, 'encoder_num_heads': 12, 'drop_path_rate': 0.2, 'num_frames': 4, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 12, 'clip_decoder_embed_dim': 768, 'clip_output_dim': 512, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 224, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'multimodal': {'enable': True}, 'embed_dim': 512, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 1e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 5, 'min_lr_multi': 0.01, 'warmup_epochs': 1}, 'zero_shot': False, 'evaluate': True, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': False, 'entity': 'user', 'project': 'umt_ret'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': 'exp/finetuning/ret_rtime/b16_25m_200k_2frame', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 42, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth', 'rank': 0, 'world_size': 4, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2024-01-15T06:59:26 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/training_200k.json', '/data2/dy/temporal_video/dataset', 'video']
2024-01-15T06:59:26 | INFO | tasks.pretrain : Creating dataset for ret
2024-01-15T06:59:27 | INFO | tasks.shared_utils : Creating model
2024-01-15T06:59:39 | INFO | models.umt : Build vision_encoder: vit_b16
2024-01-15T06:59:39 | INFO | models.backbones.vit.vit : Num of patches: 784
2024-01-15T06:59:39 | INFO | models.backbones.vit.vit : Use checkpoint: True
2024-01-15T06:59:39 | INFO | models.backbones.vit.vit : Checkpoint number: 12
2024-01-15T06:59:39 | INFO | models.backbones.vit.vit : Student return index: []
2024-01-15T06:59:43 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
2024-01-15T06:59:43 | INFO | models.umt : Build text_encoder bert_base
2024-01-15T06:59:44 | INFO | models.backbones.bert.xbert : build bert with cross_module: ca
2024-01-15T06:59:45 | INFO | models.criterions : Norm type: l2
2024-01-15T06:59:45 | INFO | models.criterions : Loss type: l2
2024-01-15T06:59:45 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.temp: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.weight: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.q_bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.v_bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.weight: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.weight: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.weight: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.embeddings.word_embeddings.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.embeddings.position_embeddings.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.embeddings.token_type_embeddings.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.vision_proj.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_proj.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.text_proj.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.itm_head.weight: wd: 0.02, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : param module.itm_head.bias: wd: 0, lr: 1e-05
2024-01-15T06:59:45 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0.02 len(p)=140
2024-01-15T06:59:45 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0 len(p)=256
2024-01-15T06:59:45 | INFO | tasks.shared_utils : Auto resuming
2024-01-15T06:59:49 | INFO | tasks.shared_utils : <All keys matched successfully>
2024-01-15T06:59:49 | INFO | tasks.shared_utils : Loaded checkpoint from exp/finetuning/ret_rtime/b16_25m_200k_2frame/ckpt_best.pth
2024-01-15T06:59:49 | INFO | __main__ : Start evaluation
2024-01-15T06:59:49 | INFO | tasks.retrieval_utils : Start evaluation for media_type=video
2024-01-15T06:59:49 | INFO | tasks.retrieval_utils : Computing dual encoder features...
2024-01-15T07:00:03 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-01-15T07:00:03 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-01-15T07:00:04 | INFO | utils.basic_utils : extracting image feats  [ 0/63]  eta: 0:14:04    time: 13.4000  data: 10.5624  max mem: 5393 res mem: 6346
2024-01-15T07:01:37 | INFO | utils.basic_utils : extracting image feats  [62/63]  eta: 0:00:01    time: 1.5400  data: 1.3082  max mem: 5478 res mem: 6348
2024-01-15T07:01:37 | INFO | utils.basic_utils : extracting image feats Total time: 0:01:46 (1.6968 s / it)
2024-01-15T07:01:41 | INFO | tasks.retrieval_utils : Finished feature extraction
2024-01-15T07:01:41 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product]
2024-01-15T07:01:41 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product], done!
2024-01-15T07:01:41 | INFO | tasks.retrieval_utils : Rerank dual-encoder results with cross-encoder...
2024-01-15T07:01:41 | INFO | tasks.retrieval_utils : i2t_scores.shape torch.Size([501, 2000])
2024-01-15T07:01:41 | INFO | tasks.retrieval_utils : n_clip_per_video=1, with eval_frame_ensemble=concat
2024-01-15T07:01:41 | INFO | utils.basic_utils : Evaluation:  [  0/501]  eta: 0:00:13    time: 0.0272  data: 0.0004  max mem: 5478 res mem: 6348
2024-01-15T07:01:44 | INFO | utils.basic_utils : Evaluation:  [100/501]  eta: 0:00:11    time: 0.0280  data: 0.0000  max mem: 5478 res mem: 6348
2024-01-15T07:01:47 | INFO | utils.basic_utils : Evaluation:  [200/501]  eta: 0:00:08    time: 0.0279  data: 0.0000  max mem: 5478 res mem: 6348
2024-01-15T07:01:50 | INFO | utils.basic_utils : Evaluation:  [300/501]  eta: 0:00:05    time: 0.0282  data: 0.0000  max mem: 5478 res mem: 6348
2024-01-15T07:01:52 | INFO | utils.basic_utils : Evaluation:  [400/501]  eta: 0:00:02    time: 0.0283  data: 0.0000  max mem: 5478 res mem: 6348
2024-01-15T07:01:55 | INFO | utils.basic_utils : Evaluation:  [500/501]  eta: 0:00:00    time: 0.0284  data: 0.0000  max mem: 5478 res mem: 6348
2024-01-15T07:01:55 | INFO | utils.basic_utils : Evaluation: Total time: 0:00:14 (0.0282 s / it)
2024-01-15T07:01:55 | INFO | tasks.retrieval_utils : t2i_scores.shape torch.Size([501, 2000])
2024-01-15T07:01:56 | INFO | utils.basic_utils : Evaluation:  [  0/501]  eta: 0:02:45    time: 0.3308  data: 0.0004  max mem: 5478 res mem: 6348
2024-01-15T07:02:25 | INFO | utils.basic_utils : Evaluation:  [100/501]  eta: 0:01:59    time: 0.2983  data: 0.0000  max mem: 5478 res mem: 6348
2024-01-15T07:02:54 | INFO | utils.basic_utils : Evaluation:  [200/501]  eta: 0:01:28    time: 0.2905  data: 0.0000  max mem: 5478 res mem: 6348
2024-01-15T07:03:23 | INFO | utils.basic_utils : Evaluation:  [300/501]  eta: 0:00:58    time: 0.2881  data: 0.0000  max mem: 5478 res mem: 6348
2024-01-15T07:03:51 | INFO | utils.basic_utils : Evaluation:  [400/501]  eta: 0:00:29    time: 0.2787  data: 0.0000  max mem: 5478 res mem: 6348
2024-01-15T07:04:19 | INFO | utils.basic_utils : Evaluation:  [500/501]  eta: 0:00:00    time: 0.2682  data: 0.0000  max mem: 5478 res mem: 6348
2024-01-15T07:04:19 | INFO | utils.basic_utils : Evaluation: Total time: 0:02:23 (0.2869 s / it)
2024-01-15T07:04:19 | INFO | tasks.retrieval_utils : Evaluation time 0:04:30
2024-01-15T07:04:20 | INFO | __main__ : Epoch 0
2024-01-15T07:04:20 | INFO | __main__ : 
           txt_r1  txt_r5  txt_r10  txt_r_mean  img_r1  img_r5  img_r10  img_r_mean  r_mean  txt_acc  img_acc
test/       43.20   94.20    97.45       78.28   42.25   94.10     97.6       77.98   78.13    50.05     49.4
test_emb/   39.75   90.95    95.80       75.50   38.90   90.55     96.2       75.22   75.36    49.85     48.1
2024-01-15T07:04:20 | INFO | __main__ : Training time 0:04:31
2024-01-15T07:04:20 | INFO | __main__ : best epoch 0 [config.stop_key test/]
2024-01-15T07:04:20 | INFO | __main__ : Checkpoints and Logs saved at exp/finetuning/ret_rtime/b16_25m_200k_2frame
2024-01-21T17:08:44 | INFO | umt : Logging to: exp/finetuning/ret_rtime/b16_25m_200k_2frame/train.log
2024-01-21T17:08:44 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/training_200k.json', '/data2/dy/temporal_video/dataset', 'video']
  test_file: {
      test: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test2k.json', '/data2/dy/temporal_video/dataset', 'video'] }
  test_types: ['test']
  num_workers: 6
  stop_key: test/
  is_paragraph_retrieval: False
  num_frames: 12
  num_frames_test: 12
  batch_size: 32
  max_txt_l: 32
  train_shuffle: True
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 12
          sample_type: rand
          num_frames_test: 12
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 32
          video: 32 }
      batch_size: {
          image: 32
          video: 32 }
      batch_size_test: {
          image: 32
          video: 32 } }
  text_enc: bert
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_b16
          img_size: 224
          patch_size: 16
          d_model: 768
          encoder_embed_dim: 768
          encoder_depth: 12
          encoder_num_heads: 12
          drop_path_rate: 0.2
          num_frames: 12
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 12
          clip_decoder_embed_dim: 768
          clip_output_dim: 512
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 224
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      multimodal: {
          enable: True }
      embed_dim: 512
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 1e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 5
      min_lr_multi: 0.01
      warmup_epochs: 1 }
  zero_shot: False
  evaluate: True
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: user
      project: umt_ret }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/finetuning/ret_rtime/b16_25m_200k_2frame
  resume: False
  debug: False
  log_freq: 100
  seed: 42
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
  rank: 0
  world_size: 3
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-01-21T17:08:44 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/training_200k.json', '/data2/dy/temporal_video/dataset', 'video'], 'test_file': {'test': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test2k.json', '/data2/dy/temporal_video/dataset', 'video']}, 'test_types': ['test'], 'num_workers': 6, 'stop_key': 'test/', 'is_paragraph_retrieval': False, 'num_frames': 12, 'num_frames_test': 12, 'batch_size': 32, 'max_txt_l': 32, 'train_shuffle': True, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 12, 'sample_type': 'rand', 'num_frames_test': 12, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 32, 'video': 32}, 'batch_size': {'image': 32, 'video': 32}, 'batch_size_test': {'image': 32, 'video': 32}}, 'text_enc': 'bert', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_b16', 'img_size': 224, 'patch_size': 16, 'd_model': 768, 'encoder_embed_dim': 768, 'encoder_depth': 12, 'encoder_num_heads': 12, 'drop_path_rate': 0.2, 'num_frames': 12, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 12, 'clip_decoder_embed_dim': 768, 'clip_output_dim': 512, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 224, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'multimodal': {'enable': True}, 'embed_dim': 512, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 1e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 5, 'min_lr_multi': 0.01, 'warmup_epochs': 1}, 'zero_shot': False, 'evaluate': True, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': False, 'entity': 'user', 'project': 'umt_ret'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': 'exp/finetuning/ret_rtime/b16_25m_200k_2frame', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 42, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth', 'rank': 0, 'world_size': 3, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2024-01-21T17:08:44 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/training_200k.json', '/data2/dy/temporal_video/dataset', 'video']
2024-01-21T17:08:44 | INFO | tasks.pretrain : Creating dataset for ret
2024-01-21T17:08:44 | INFO | tasks.shared_utils : Creating model
2024-01-21T17:08:56 | INFO | models.umt : Build vision_encoder: vit_b16
2024-01-21T17:08:56 | INFO | models.backbones.vit.vit : Num of patches: 2352
2024-01-21T17:08:56 | INFO | models.backbones.vit.vit : Use checkpoint: True
2024-01-21T17:08:56 | INFO | models.backbones.vit.vit : Checkpoint number: 12
2024-01-21T17:08:56 | INFO | models.backbones.vit.vit : Student return index: []
2024-01-21T17:09:04 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
2024-01-21T17:09:04 | INFO | models.umt : Build text_encoder bert_base
2024-01-21T17:09:06 | INFO | models.backbones.bert.xbert : build bert with cross_module: ca
2024-01-21T17:09:06 | INFO | models.criterions : Norm type: l2
2024-01-21T17:09:06 | INFO | models.criterions : Loss type: l2
2024-01-21T17:09:09 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.temp: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.weight: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.q_bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.v_bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.weight: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.weight: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.q_bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.v_bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.weight: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.weight: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.q_bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.v_bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.weight: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.weight: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.q_bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.v_bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.weight: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.weight: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.q_bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.v_bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.weight: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.weight: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.q_bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.v_bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.weight: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.weight: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.q_bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.v_bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.weight: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.weight: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.q_bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.v_bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.weight: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.weight: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.q_bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.v_bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.weight: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.weight: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.q_bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.v_bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.weight: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.weight: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.q_bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.v_bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.weight: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.weight: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.q_bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.v_bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.weight: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.weight: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.weight: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.embeddings.word_embeddings.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.embeddings.position_embeddings.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.embeddings.token_type_embeddings.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_proj.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.vision_proj.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_proj.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.text_proj.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.itm_head.weight: wd: 0.02, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : param module.itm_head.bias: wd: 0, lr: 1e-05
2024-01-21T17:09:09 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0.02 len(p)=140
2024-01-21T17:09:09 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0 len(p)=256
2024-01-21T17:09:09 | INFO | tasks.shared_utils : Auto resuming
2024-01-21T17:09:11 | INFO | tasks.shared_utils : <All keys matched successfully>
2024-01-21T17:09:11 | INFO | tasks.shared_utils : Loaded checkpoint from exp/finetuning/ret_rtime/b16_25m_200k_2frame/ckpt_best.pth
2024-01-21T17:09:11 | INFO | __main__ : Start evaluation
2024-01-21T17:09:11 | INFO | tasks.retrieval_utils : Start evaluation for media_type=video
2024-01-21T17:09:11 | INFO | tasks.retrieval_utils : Computing dual encoder features...
2024-01-21T17:09:29 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-01-21T17:09:29 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-01-21T17:09:30 | INFO | utils.basic_utils : extracting image feats  [ 0/63]  eta: 0:17:54    time: 17.0574  data: 13.8652  max mem: 17077 res mem: 25264
2024-01-21T17:11:41 | INFO | utils.basic_utils : extracting image feats  [62/63]  eta: 0:00:02    time: 1.9776  data: 0.9505  max mem: 17311 res mem: 25264
2024-01-21T17:11:41 | INFO | utils.basic_utils : extracting image feats Total time: 0:02:28 (2.3530 s / it)
2024-01-21T17:11:50 | INFO | tasks.retrieval_utils : Finished feature extraction
2024-01-21T17:11:50 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product]
2024-01-21T17:11:50 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product], done!
2024-01-21T17:11:50 | INFO | tasks.retrieval_utils : Rerank dual-encoder results with cross-encoder...
2024-01-21T17:11:50 | INFO | tasks.retrieval_utils : i2t_scores.shape torch.Size([667, 2000])
2024-01-21T17:11:50 | INFO | tasks.retrieval_utils : n_clip_per_video=1, with eval_frame_ensemble=concat
2024-01-21T17:11:51 | INFO | utils.basic_utils : Evaluation:  [  0/667]  eta: 0:00:16    time: 0.0250  data: 0.0005  max mem: 17311 res mem: 25264
2024-01-21T17:11:58 | INFO | utils.basic_utils : Evaluation:  [100/667]  eta: 0:00:41    time: 0.0732  data: 0.0000  max mem: 17311 res mem: 25264
2024-01-21T17:12:05 | INFO | utils.basic_utils : Evaluation:  [200/667]  eta: 0:00:33    time: 0.0729  data: 0.0000  max mem: 17311 res mem: 25264
2024-01-21T17:12:12 | INFO | utils.basic_utils : Evaluation:  [300/667]  eta: 0:00:26    time: 0.0732  data: 0.0000  max mem: 17311 res mem: 25264
2024-01-21T17:12:20 | INFO | utils.basic_utils : Evaluation:  [400/667]  eta: 0:00:19    time: 0.0735  data: 0.0000  max mem: 17311 res mem: 25264
2024-01-21T17:12:27 | INFO | utils.basic_utils : Evaluation:  [500/667]  eta: 0:00:12    time: 0.0736  data: 0.0000  max mem: 17311 res mem: 25264
2024-01-21T17:12:35 | INFO | utils.basic_utils : Evaluation:  [600/667]  eta: 0:00:04    time: 0.0737  data: 0.0000  max mem: 17311 res mem: 25264
2024-01-21T17:12:39 | INFO | utils.basic_utils : Evaluation:  [666/667]  eta: 0:00:00    time: 0.0739  data: 0.0000  max mem: 17311 res mem: 25264
2024-01-21T17:12:39 | INFO | utils.basic_utils : Evaluation: Total time: 0:00:48 (0.0733 s / it)
2024-01-21T17:12:39 | INFO | tasks.retrieval_utils : t2i_scores.shape torch.Size([667, 2000])
2024-01-21T17:12:40 | INFO | utils.basic_utils : Evaluation:  [  0/667]  eta: 0:08:11    time: 0.7376  data: 0.0004  max mem: 17311 res mem: 25264
2024-01-21T17:13:50 | INFO | utils.basic_utils : Evaluation:  [100/667]  eta: 0:06:37    time: 0.7024  data: 0.0000  max mem: 17311 res mem: 25264
2024-01-21T17:15:00 | INFO | utils.basic_utils : Evaluation:  [200/667]  eta: 0:05:26    time: 0.7023  data: 0.0000  max mem: 17311 res mem: 25264
2024-01-21T17:16:10 | INFO | utils.basic_utils : Evaluation:  [300/667]  eta: 0:04:17    time: 0.7042  data: 0.0000  max mem: 17311 res mem: 25264
2024-01-21T17:17:21 | INFO | utils.basic_utils : Evaluation:  [400/667]  eta: 0:03:07    time: 0.6866  data: 0.0000  max mem: 17311 res mem: 25264
2024-01-21T17:18:31 | INFO | utils.basic_utils : Evaluation:  [500/667]  eta: 0:01:57    time: 0.6927  data: 0.0000  max mem: 17311 res mem: 25264
2024-01-21T17:19:42 | INFO | utils.basic_utils : Evaluation:  [600/667]  eta: 0:00:47    time: 0.7022  data: 0.0000  max mem: 17311 res mem: 25264
2024-01-21T17:20:28 | INFO | utils.basic_utils : Evaluation:  [666/667]  eta: 0:00:00    time: 0.7001  data: 0.0000  max mem: 17311 res mem: 25264
2024-01-21T17:20:28 | INFO | utils.basic_utils : Evaluation: Total time: 0:07:48 (0.7026 s / it)
2024-01-21T17:22:23 | INFO | tasks.retrieval_utils : Evaluation time 0:13:12
2024-01-21T17:22:25 | INFO | __main__ : Epoch 0
2024-01-21T17:22:25 | INFO | __main__ : 
           txt_r1  txt_r5  txt_r10  txt_r_mean  img_r1  img_r5  img_r10  img_r_mean  r_mean  txt_acc  img_acc
test/       39.15   88.55    94.45       74.05   39.35   89.15    94.55       74.35   74.20     50.3    50.70
test_emb/   33.15   80.75    89.40       67.77   34.95   82.95    91.35       69.75   68.76     49.5    48.85
2024-01-21T17:22:25 | INFO | __main__ : Training time 0:13:13
2024-01-21T17:22:25 | INFO | __main__ : best epoch 0 [config.stop_key test/]
2024-01-21T17:22:25 | INFO | __main__ : Checkpoints and Logs saved at exp/finetuning/ret_rtime/b16_25m_200k_2frame
