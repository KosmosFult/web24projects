2024-05-27T18:16:35 | INFO | umt : Logging to: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2/train.log
2024-05-27T18:16:35 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
  test_file: {
      test: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test1k.json', '/data2/dy/temporal_video/dataset', 'video'] }
  test_types: ['test']
  num_workers: 6
  rtime: False
  pos_num: 1
  neg_num: 10
  stop_key: test/
  is_paragraph_retrieval: False
  is_pretrain: False
  num_frames: 12
  num_frames_test: 12
  batch_size: 32
  max_txt_l: 50
  evaluate: False
  train_shuffle: False
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 12
          sample_type: rand
          num_frames_test: 12
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 50
          video: 50 }
      batch_size: {
          image: 32
          video: 32 }
      batch_size_test: {
          image: 32
          video: 32 } }
  text_enc: bert
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_b16
          img_size: 224
          patch_size: 16
          d_model: 768
          encoder_embed_dim: 768
          encoder_depth: 12
          encoder_num_heads: 12
          drop_path_rate: 0.2
          num_frames: 12
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 12
          clip_decoder_embed_dim: 768
          clip_output_dim: 512
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 224
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      multimodal: {
          enable: True }
      embed_dim: 512
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 1e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 5
      min_lr_multi: 0.01
      warmup_epochs: 1 }
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: user
      project: umt_ret }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
  resume: False
  debug: False
  log_freq: 100
  seed: 3407
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
  rank: 0
  world_size: 1
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-05-27T18:16:35 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video'], 'test_file': {'test': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test1k.json', '/data2/dy/temporal_video/dataset', 'video']}, 'test_types': ['test'], 'num_workers': 6, 'rtime': False, 'pos_num': 1, 'neg_num': 10, 'stop_key': 'test/', 'is_paragraph_retrieval': False, 'is_pretrain': False, 'num_frames': 12, 'num_frames_test': 12, 'batch_size': 32, 'max_txt_l': 50, 'evaluate': False, 'train_shuffle': False, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 12, 'sample_type': 'rand', 'num_frames_test': 12, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 50, 'video': 50}, 'batch_size': {'image': 32, 'video': 32}, 'batch_size_test': {'image': 32, 'video': 32}}, 'text_enc': 'bert', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_b16', 'img_size': 224, 'patch_size': 16, 'd_model': 768, 'encoder_embed_dim': 768, 'encoder_depth': 12, 'encoder_num_heads': 12, 'drop_path_rate': 0.2, 'num_frames': 12, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 12, 'clip_decoder_embed_dim': 768, 'clip_output_dim': 512, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 224, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'multimodal': {'enable': True}, 'embed_dim': 512, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 1e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 5, 'min_lr_multi': 0.01, 'warmup_epochs': 1}, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': False, 'entity': 'user', 'project': 'umt_ret'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': 'exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 3407, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth', 'rank': 0, 'world_size': 1, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2024-05-27T18:16:35 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
2024-05-27T18:16:35 | INFO | tasks.pretrain : Creating dataset for ret
2024-05-27T18:16:36 | INFO | tasks.shared_utils : Creating model
2024-05-27T18:16:46 | INFO | models.umt : Build vision_encoder: vit_b16
2024-05-27T18:16:46 | INFO | models.backbones.vit.vit : Num of patches: 2352
2024-05-27T18:16:46 | INFO | models.backbones.vit.vit : Use checkpoint: True
2024-05-27T18:16:46 | INFO | models.backbones.vit.vit : Checkpoint number: 12
2024-05-27T18:16:46 | INFO | models.backbones.vit.vit : Student return index: []
2024-05-27T18:16:54 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
2024-05-27T18:16:54 | INFO | models.umt : Build text_encoder bert_base
2024-05-27T18:16:55 | INFO | models.backbones.bert.xbert : build bert with cross_module: ca
2024-05-27T18:16:56 | INFO | models.criterions : Norm type: l2
2024-05-27T18:16:56 | INFO | models.criterions : Loss type: l2
2024-05-27T18:16:56 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.temp: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.weight: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.weight: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.embeddings.word_embeddings.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.embeddings.position_embeddings.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.embeddings.token_type_embeddings.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.vision_proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.text_proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.itm_head.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : param module.itm_head.bias: wd: 0, lr: 1e-05
2024-05-27T18:16:56 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0.02 len(p)=164
2024-05-27T18:16:56 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0 len(p)=304
2024-05-27T18:16:56 | INFO | tasks.shared_utils : Auto resuming
2024-05-27T18:16:56 | INFO | tasks.shared_utils : Not found checkpoint in exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
2024-05-27T18:17:45 | INFO | umt : Logging to: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2/train.log
2024-05-27T18:17:45 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
  test_file: {
      test: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test1k.json', '/data2/dy/temporal_video/dataset', 'video'] }
  test_types: ['test']
  num_workers: 6
  rtime: False
  pos_num: 1
  neg_num: 10
  stop_key: test/
  is_paragraph_retrieval: False
  is_pretrain: False
  num_frames: 12
  num_frames_test: 12
  batch_size: 32
  max_txt_l: 50
  evaluate: False
  train_shuffle: False
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 12
          sample_type: rand
          num_frames_test: 12
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 50
          video: 50 }
      batch_size: {
          image: 32
          video: 32 }
      batch_size_test: {
          image: 32
          video: 32 } }
  text_enc: bert
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_b16
          img_size: 224
          patch_size: 16
          d_model: 768
          encoder_embed_dim: 768
          encoder_depth: 12
          encoder_num_heads: 12
          drop_path_rate: 0.2
          num_frames: 12
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 12
          clip_decoder_embed_dim: 768
          clip_output_dim: 512
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 224
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      multimodal: {
          enable: True }
      embed_dim: 512
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 1e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 5
      min_lr_multi: 0.01
      warmup_epochs: 1 }
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: user
      project: umt_ret }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
  resume: False
  debug: False
  log_freq: 100
  seed: 3407
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
  rank: 0
  world_size: 1
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-05-27T18:17:45 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video'], 'test_file': {'test': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test1k.json', '/data2/dy/temporal_video/dataset', 'video']}, 'test_types': ['test'], 'num_workers': 6, 'rtime': False, 'pos_num': 1, 'neg_num': 10, 'stop_key': 'test/', 'is_paragraph_retrieval': False, 'is_pretrain': False, 'num_frames': 12, 'num_frames_test': 12, 'batch_size': 32, 'max_txt_l': 50, 'evaluate': False, 'train_shuffle': False, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 12, 'sample_type': 'rand', 'num_frames_test': 12, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 50, 'video': 50}, 'batch_size': {'image': 32, 'video': 32}, 'batch_size_test': {'image': 32, 'video': 32}}, 'text_enc': 'bert', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_b16', 'img_size': 224, 'patch_size': 16, 'd_model': 768, 'encoder_embed_dim': 768, 'encoder_depth': 12, 'encoder_num_heads': 12, 'drop_path_rate': 0.2, 'num_frames': 12, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 12, 'clip_decoder_embed_dim': 768, 'clip_output_dim': 512, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 224, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'multimodal': {'enable': True}, 'embed_dim': 512, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 1e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 5, 'min_lr_multi': 0.01, 'warmup_epochs': 1}, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': False, 'entity': 'user', 'project': 'umt_ret'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': 'exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 3407, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth', 'rank': 0, 'world_size': 1, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2024-05-27T18:17:45 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
2024-05-27T18:17:45 | INFO | tasks.pretrain : Creating dataset for ret
2024-05-27T18:17:45 | INFO | tasks.shared_utils : Creating model
2024-05-27T18:17:55 | INFO | models.umt : Build vision_encoder: vit_b16
2024-05-27T18:17:55 | INFO | models.backbones.vit.vit : Num of patches: 2352
2024-05-27T18:17:55 | INFO | models.backbones.vit.vit : Use checkpoint: True
2024-05-27T18:17:55 | INFO | models.backbones.vit.vit : Checkpoint number: 12
2024-05-27T18:17:55 | INFO | models.backbones.vit.vit : Student return index: []
2024-05-27T18:18:03 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
2024-05-27T18:18:03 | INFO | models.umt : Build text_encoder bert_base
2024-05-27T18:18:04 | INFO | models.backbones.bert.xbert : build bert with cross_module: ca
2024-05-27T18:18:05 | INFO | models.criterions : Norm type: l2
2024-05-27T18:18:05 | INFO | models.criterions : Loss type: l2
2024-05-27T18:18:05 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.temp: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.weight: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.weight: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.embeddings.word_embeddings.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.embeddings.position_embeddings.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.embeddings.token_type_embeddings.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.vision_proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.text_proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.itm_head.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : param module.itm_head.bias: wd: 0, lr: 1e-05
2024-05-27T18:18:05 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0.02 len(p)=164
2024-05-27T18:18:05 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0 len(p)=304
2024-05-27T18:18:05 | INFO | tasks.shared_utils : Auto resuming
2024-05-27T18:18:05 | INFO | tasks.shared_utils : Not found checkpoint in exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
2024-05-27T18:20:19 | INFO | umt : Logging to: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2/train.log
2024-05-27T18:20:19 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
  test_file: {
      test: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test1k.json', '/data2/dy/temporal_video/dataset', 'video'] }
  test_types: ['test']
  num_workers: 6
  rtime: False
  pos_num: 1
  neg_num: 10
  stop_key: test/
  is_paragraph_retrieval: False
  is_pretrain: False
  num_frames: 12
  num_frames_test: 12
  batch_size: 32
  max_txt_l: 50
  evaluate: False
  train_shuffle: False
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 12
          sample_type: rand
          num_frames_test: 12
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 50
          video: 50 }
      batch_size: {
          image: 32
          video: 32 }
      batch_size_test: {
          image: 32
          video: 32 } }
  text_enc: bert
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_b16
          img_size: 224
          patch_size: 16
          d_model: 768
          encoder_embed_dim: 768
          encoder_depth: 12
          encoder_num_heads: 12
          drop_path_rate: 0.2
          num_frames: 12
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 12
          clip_decoder_embed_dim: 768
          clip_output_dim: 512
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 224
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      multimodal: {
          enable: True }
      embed_dim: 512
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 1e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 5
      min_lr_multi: 0.01
      warmup_epochs: 1 }
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: user
      project: umt_ret }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
  resume: False
  debug: False
  log_freq: 100
  seed: 3407
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
  rank: 0
  world_size: 1
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-05-27T18:20:19 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video'], 'test_file': {'test': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test1k.json', '/data2/dy/temporal_video/dataset', 'video']}, 'test_types': ['test'], 'num_workers': 6, 'rtime': False, 'pos_num': 1, 'neg_num': 10, 'stop_key': 'test/', 'is_paragraph_retrieval': False, 'is_pretrain': False, 'num_frames': 12, 'num_frames_test': 12, 'batch_size': 32, 'max_txt_l': 50, 'evaluate': False, 'train_shuffle': False, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 12, 'sample_type': 'rand', 'num_frames_test': 12, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 50, 'video': 50}, 'batch_size': {'image': 32, 'video': 32}, 'batch_size_test': {'image': 32, 'video': 32}}, 'text_enc': 'bert', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_b16', 'img_size': 224, 'patch_size': 16, 'd_model': 768, 'encoder_embed_dim': 768, 'encoder_depth': 12, 'encoder_num_heads': 12, 'drop_path_rate': 0.2, 'num_frames': 12, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 12, 'clip_decoder_embed_dim': 768, 'clip_output_dim': 512, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 224, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'multimodal': {'enable': True}, 'embed_dim': 512, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 1e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 5, 'min_lr_multi': 0.01, 'warmup_epochs': 1}, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': False, 'entity': 'user', 'project': 'umt_ret'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': 'exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 3407, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth', 'rank': 0, 'world_size': 1, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2024-05-27T18:20:19 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
2024-05-27T18:20:19 | INFO | tasks.pretrain : Creating dataset for ret
2024-05-27T18:20:19 | INFO | tasks.shared_utils : Creating model
2024-05-27T18:20:29 | INFO | models.umt : Build vision_encoder: vit_b16
2024-05-27T18:20:29 | INFO | models.backbones.vit.vit : Num of patches: 2352
2024-05-27T18:20:29 | INFO | models.backbones.vit.vit : Use checkpoint: True
2024-05-27T18:20:29 | INFO | models.backbones.vit.vit : Checkpoint number: 12
2024-05-27T18:20:29 | INFO | models.backbones.vit.vit : Student return index: []
2024-05-27T18:20:37 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
2024-05-27T18:20:37 | INFO | models.umt : Build text_encoder bert_base
2024-05-27T18:20:38 | INFO | models.backbones.bert.xbert : build bert with cross_module: ca
2024-05-27T18:20:38 | INFO | models.criterions : Norm type: l2
2024-05-27T18:20:38 | INFO | models.criterions : Loss type: l2
2024-05-27T18:20:39 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.temp: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.weight: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.weight: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.embeddings.word_embeddings.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.embeddings.position_embeddings.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.embeddings.token_type_embeddings.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.vision_proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.text_proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.itm_head.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : param module.itm_head.bias: wd: 0, lr: 1e-05
2024-05-27T18:20:39 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0.02 len(p)=164
2024-05-27T18:20:39 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0 len(p)=304
2024-05-27T18:20:39 | INFO | tasks.shared_utils : Auto resuming
2024-05-27T18:20:39 | INFO | tasks.shared_utils : Not found checkpoint in exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
2024-05-27T18:22:24 | INFO | umt : Logging to: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2/train.log
2024-05-27T18:22:24 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
  test_file: {
      test: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test1k.json', '/data2/dy/temporal_video/dataset', 'video'] }
  test_types: ['test']
  num_workers: 6
  rtime: False
  pos_num: 1
  neg_num: 10
  stop_key: test/
  is_paragraph_retrieval: False
  is_pretrain: False
  num_frames: 12
  num_frames_test: 12
  batch_size: 32
  max_txt_l: 50
  evaluate: False
  train_shuffle: False
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 12
          sample_type: rand
          num_frames_test: 12
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 50
          video: 50 }
      batch_size: {
          image: 32
          video: 32 }
      batch_size_test: {
          image: 32
          video: 32 } }
  text_enc: bert
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_b16
          img_size: 224
          patch_size: 16
          d_model: 768
          encoder_embed_dim: 768
          encoder_depth: 12
          encoder_num_heads: 12
          drop_path_rate: 0.2
          num_frames: 12
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 12
          clip_decoder_embed_dim: 768
          clip_output_dim: 512
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 224
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      multimodal: {
          enable: True }
      embed_dim: 512
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 1e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 5
      min_lr_multi: 0.01
      warmup_epochs: 1 }
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: user
      project: umt_ret }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
  resume: False
  debug: False
  log_freq: 100
  seed: 3407
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
  rank: 0
  world_size: 1
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-05-27T18:22:24 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video'], 'test_file': {'test': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test1k.json', '/data2/dy/temporal_video/dataset', 'video']}, 'test_types': ['test'], 'num_workers': 6, 'rtime': False, 'pos_num': 1, 'neg_num': 10, 'stop_key': 'test/', 'is_paragraph_retrieval': False, 'is_pretrain': False, 'num_frames': 12, 'num_frames_test': 12, 'batch_size': 32, 'max_txt_l': 50, 'evaluate': False, 'train_shuffle': False, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 12, 'sample_type': 'rand', 'num_frames_test': 12, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 50, 'video': 50}, 'batch_size': {'image': 32, 'video': 32}, 'batch_size_test': {'image': 32, 'video': 32}}, 'text_enc': 'bert', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_b16', 'img_size': 224, 'patch_size': 16, 'd_model': 768, 'encoder_embed_dim': 768, 'encoder_depth': 12, 'encoder_num_heads': 12, 'drop_path_rate': 0.2, 'num_frames': 12, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 12, 'clip_decoder_embed_dim': 768, 'clip_output_dim': 512, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 224, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'multimodal': {'enable': True}, 'embed_dim': 512, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 1e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 5, 'min_lr_multi': 0.01, 'warmup_epochs': 1}, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': False, 'entity': 'user', 'project': 'umt_ret'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': 'exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 3407, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth', 'rank': 0, 'world_size': 1, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2024-05-27T18:22:24 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
2024-05-27T18:22:24 | INFO | tasks.pretrain : Creating dataset for ret
2024-05-27T18:22:24 | INFO | tasks.shared_utils : Creating model
2024-05-27T18:22:34 | INFO | models.umt : Build vision_encoder: vit_b16
2024-05-27T18:22:34 | INFO | models.backbones.vit.vit : Num of patches: 2352
2024-05-27T18:22:34 | INFO | models.backbones.vit.vit : Use checkpoint: True
2024-05-27T18:22:34 | INFO | models.backbones.vit.vit : Checkpoint number: 12
2024-05-27T18:22:34 | INFO | models.backbones.vit.vit : Student return index: []
2024-05-27T18:22:42 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
2024-05-27T18:22:42 | INFO | models.umt : Build text_encoder bert_base
2024-05-27T18:22:43 | INFO | models.backbones.bert.xbert : build bert with cross_module: ca
2024-05-27T18:22:44 | INFO | models.criterions : Norm type: l2
2024-05-27T18:22:44 | INFO | models.criterions : Loss type: l2
2024-05-27T18:22:44 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.temp: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.weight: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.weight: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.embeddings.word_embeddings.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.embeddings.position_embeddings.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.embeddings.token_type_embeddings.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.vision_proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.text_proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.itm_head.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : param module.itm_head.bias: wd: 0, lr: 1e-05
2024-05-27T18:22:44 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0.02 len(p)=164
2024-05-27T18:22:44 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0 len(p)=304
2024-05-27T18:22:44 | INFO | tasks.shared_utils : Auto resuming
2024-05-27T18:22:44 | INFO | tasks.shared_utils : Not found checkpoint in exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
2024-05-27T18:27:47 | INFO | umt : Logging to: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2/train.log
2024-05-27T18:27:47 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
  test_file: {
      test: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test1k.json', '/data2/dy/temporal_video/dataset', 'video'] }
  test_types: ['test']
  num_workers: 6
  rtime: False
  pos_num: 1
  neg_num: 10
  stop_key: test/
  is_paragraph_retrieval: False
  is_pretrain: False
  num_frames: 12
  num_frames_test: 12
  batch_size: 32
  max_txt_l: 50
  evaluate: False
  train_shuffle: False
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 12
          sample_type: rand
          num_frames_test: 12
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 50
          video: 50 }
      batch_size: {
          image: 32
          video: 32 }
      batch_size_test: {
          image: 32
          video: 32 } }
  text_enc: bert
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_b16
          img_size: 224
          patch_size: 16
          d_model: 768
          encoder_embed_dim: 768
          encoder_depth: 12
          encoder_num_heads: 12
          drop_path_rate: 0.2
          num_frames: 12
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 12
          clip_decoder_embed_dim: 768
          clip_output_dim: 512
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 224
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      multimodal: {
          enable: True }
      embed_dim: 512
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 1e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 5
      min_lr_multi: 0.01
      warmup_epochs: 1 }
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: user
      project: umt_ret }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
  resume: False
  debug: False
  log_freq: 100
  seed: 3407
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
  rank: 0
  world_size: 1
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-05-27T18:27:47 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video'], 'test_file': {'test': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test1k.json', '/data2/dy/temporal_video/dataset', 'video']}, 'test_types': ['test'], 'num_workers': 6, 'rtime': False, 'pos_num': 1, 'neg_num': 10, 'stop_key': 'test/', 'is_paragraph_retrieval': False, 'is_pretrain': False, 'num_frames': 12, 'num_frames_test': 12, 'batch_size': 32, 'max_txt_l': 50, 'evaluate': False, 'train_shuffle': False, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 12, 'sample_type': 'rand', 'num_frames_test': 12, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 50, 'video': 50}, 'batch_size': {'image': 32, 'video': 32}, 'batch_size_test': {'image': 32, 'video': 32}}, 'text_enc': 'bert', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_b16', 'img_size': 224, 'patch_size': 16, 'd_model': 768, 'encoder_embed_dim': 768, 'encoder_depth': 12, 'encoder_num_heads': 12, 'drop_path_rate': 0.2, 'num_frames': 12, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 12, 'clip_decoder_embed_dim': 768, 'clip_output_dim': 512, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 224, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'multimodal': {'enable': True}, 'embed_dim': 512, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 1e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 5, 'min_lr_multi': 0.01, 'warmup_epochs': 1}, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': False, 'entity': 'user', 'project': 'umt_ret'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': 'exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 3407, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth', 'rank': 0, 'world_size': 1, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2024-05-27T18:27:47 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
2024-05-27T18:27:47 | INFO | tasks.pretrain : Creating dataset for ret
2024-05-27T18:27:48 | INFO | tasks.shared_utils : Creating model
2024-05-27T18:27:58 | INFO | models.umt : Build vision_encoder: vit_b16
2024-05-27T18:27:58 | INFO | models.backbones.vit.vit : Num of patches: 2352
2024-05-27T18:27:58 | INFO | models.backbones.vit.vit : Use checkpoint: True
2024-05-27T18:27:58 | INFO | models.backbones.vit.vit : Checkpoint number: 12
2024-05-27T18:27:58 | INFO | models.backbones.vit.vit : Student return index: []
2024-05-27T18:28:06 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
2024-05-27T18:28:06 | INFO | models.umt : Build text_encoder bert_base
2024-05-27T18:28:07 | INFO | models.backbones.bert.xbert : build bert with cross_module: ca
2024-05-27T18:28:07 | INFO | models.criterions : Norm type: l2
2024-05-27T18:28:07 | INFO | models.criterions : Loss type: l2
2024-05-27T18:28:08 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.temp: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.weight: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.weight: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.embeddings.word_embeddings.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.embeddings.position_embeddings.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.embeddings.token_type_embeddings.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.vision_proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.text_proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.itm_head.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : param module.itm_head.bias: wd: 0, lr: 1e-05
2024-05-27T18:28:08 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0.02 len(p)=164
2024-05-27T18:28:08 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0 len(p)=304
2024-05-27T18:28:08 | INFO | tasks.shared_utils : Auto resuming
2024-05-27T18:28:08 | INFO | tasks.shared_utils : Not found checkpoint in exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
2024-05-27T18:30:07 | INFO | umt : Logging to: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2/train.log
2024-05-27T18:30:07 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
  test_file: {
      test: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test1k.json', '/data2/dy/temporal_video/dataset', 'video'] }
  test_types: ['test']
  num_workers: 6
  rtime: False
  pos_num: 1
  neg_num: 10
  stop_key: test/
  is_paragraph_retrieval: False
  is_pretrain: False
  num_frames: 12
  num_frames_test: 12
  batch_size: 32
  max_txt_l: 50
  evaluate: False
  train_shuffle: False
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 12
          sample_type: rand
          num_frames_test: 12
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 50
          video: 50 }
      batch_size: {
          image: 32
          video: 32 }
      batch_size_test: {
          image: 32
          video: 32 } }
  text_enc: bert
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_b16
          img_size: 224
          patch_size: 16
          d_model: 768
          encoder_embed_dim: 768
          encoder_depth: 12
          encoder_num_heads: 12
          drop_path_rate: 0.2
          num_frames: 12
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 12
          clip_decoder_embed_dim: 768
          clip_output_dim: 512
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 224
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      multimodal: {
          enable: True }
      embed_dim: 512
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 1e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 5
      min_lr_multi: 0.01
      warmup_epochs: 1 }
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: user
      project: umt_ret }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
  resume: False
  debug: False
  log_freq: 100
  seed: 3407
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
  rank: 0
  world_size: 4
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-05-27T18:30:07 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video'], 'test_file': {'test': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test1k.json', '/data2/dy/temporal_video/dataset', 'video']}, 'test_types': ['test'], 'num_workers': 6, 'rtime': False, 'pos_num': 1, 'neg_num': 10, 'stop_key': 'test/', 'is_paragraph_retrieval': False, 'is_pretrain': False, 'num_frames': 12, 'num_frames_test': 12, 'batch_size': 32, 'max_txt_l': 50, 'evaluate': False, 'train_shuffle': False, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 12, 'sample_type': 'rand', 'num_frames_test': 12, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 50, 'video': 50}, 'batch_size': {'image': 32, 'video': 32}, 'batch_size_test': {'image': 32, 'video': 32}}, 'text_enc': 'bert', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_b16', 'img_size': 224, 'patch_size': 16, 'd_model': 768, 'encoder_embed_dim': 768, 'encoder_depth': 12, 'encoder_num_heads': 12, 'drop_path_rate': 0.2, 'num_frames': 12, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 12, 'clip_decoder_embed_dim': 768, 'clip_output_dim': 512, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 224, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'multimodal': {'enable': True}, 'embed_dim': 512, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 1e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 5, 'min_lr_multi': 0.01, 'warmup_epochs': 1}, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': False, 'entity': 'user', 'project': 'umt_ret'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': 'exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 3407, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth', 'rank': 0, 'world_size': 4, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2024-05-27T18:30:07 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
2024-05-27T18:30:07 | INFO | tasks.pretrain : Creating dataset for ret
2024-05-27T18:30:08 | INFO | tasks.shared_utils : Creating model
2024-05-27T18:30:18 | INFO | models.umt : Build vision_encoder: vit_b16
2024-05-27T18:30:18 | INFO | models.backbones.vit.vit : Num of patches: 2352
2024-05-27T18:30:18 | INFO | models.backbones.vit.vit : Use checkpoint: True
2024-05-27T18:30:18 | INFO | models.backbones.vit.vit : Checkpoint number: 12
2024-05-27T18:30:18 | INFO | models.backbones.vit.vit : Student return index: []
2024-05-27T18:30:25 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
2024-05-27T18:30:26 | INFO | models.umt : Build text_encoder bert_base
2024-05-27T18:30:27 | INFO | models.backbones.bert.xbert : build bert with cross_module: ca
2024-05-27T18:30:27 | INFO | models.criterions : Norm type: l2
2024-05-27T18:30:27 | INFO | models.criterions : Loss type: l2
2024-05-27T18:30:28 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.temp: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.weight: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.weight: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.embeddings.word_embeddings.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.embeddings.position_embeddings.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.embeddings.token_type_embeddings.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.vision_proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.text_proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.itm_head.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : param module.itm_head.bias: wd: 0, lr: 1e-05
2024-05-27T18:30:28 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0.02 len(p)=164
2024-05-27T18:30:28 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0 len(p)=304
2024-05-27T18:30:28 | INFO | tasks.shared_utils : Auto resuming
2024-05-27T18:30:28 | INFO | tasks.shared_utils : Not found checkpoint in exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
2024-05-27T18:30:29 | INFO | tasks.shared_utils : _IncompatibleKeys(missing_keys=['vision_encoder.encoder.blocks.0.lora_r', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.1.lora_r', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.2.lora_r', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.3.lora_r', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.4.lora_r', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.5.lora_r', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.6.lora_r', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.7.lora_r', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.8.lora_r', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.9.lora_r', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.10.lora_r', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.11.lora_r', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.bias'], unexpected_keys=['clip_teacher.class_embedding', 'clip_teacher.positional_embedding', 'clip_teacher.proj', 'clip_teacher.conv1.weight', 'clip_teacher.ln_pre.weight', 'clip_teacher.ln_pre.bias', 'clip_teacher.transformer.resblocks.0.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.0.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.0.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.0.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.0.ln_1.weight', 'clip_teacher.transformer.resblocks.0.ln_1.bias', 'clip_teacher.transformer.resblocks.0.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.0.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.0.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.0.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.0.ln_2.weight', 'clip_teacher.transformer.resblocks.0.ln_2.bias', 'clip_teacher.transformer.resblocks.1.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.1.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.1.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.1.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.1.ln_1.weight', 'clip_teacher.transformer.resblocks.1.ln_1.bias', 'clip_teacher.transformer.resblocks.1.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.1.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.1.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.1.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.1.ln_2.weight', 'clip_teacher.transformer.resblocks.1.ln_2.bias', 'clip_teacher.transformer.resblocks.2.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.2.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.2.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.2.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.2.ln_1.weight', 'clip_teacher.transformer.resblocks.2.ln_1.bias', 'clip_teacher.transformer.resblocks.2.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.2.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.2.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.2.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.2.ln_2.weight', 'clip_teacher.transformer.resblocks.2.ln_2.bias', 'clip_teacher.transformer.resblocks.3.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.3.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.3.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.3.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.3.ln_1.weight', 'clip_teacher.transformer.resblocks.3.ln_1.bias', 'clip_teacher.transformer.resblocks.3.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.3.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.3.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.3.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.3.ln_2.weight', 'clip_teacher.transformer.resblocks.3.ln_2.bias', 'clip_teacher.transformer.resblocks.4.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.4.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.4.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.4.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.4.ln_1.weight', 'clip_teacher.transformer.resblocks.4.ln_1.bias', 'clip_teacher.transformer.resblocks.4.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.4.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.4.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.4.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.4.ln_2.weight', 'clip_teacher.transformer.resblocks.4.ln_2.bias', 'clip_teacher.transformer.resblocks.5.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.5.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.5.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.5.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.5.ln_1.weight', 'clip_teacher.transformer.resblocks.5.ln_1.bias', 'clip_teacher.transformer.resblocks.5.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.5.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.5.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.5.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.5.ln_2.weight', 'clip_teacher.transformer.resblocks.5.ln_2.bias', 'clip_teacher.transformer.resblocks.6.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.6.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.6.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.6.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.6.ln_1.weight', 'clip_teacher.transformer.resblocks.6.ln_1.bias', 'clip_teacher.transformer.resblocks.6.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.6.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.6.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.6.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.6.ln_2.weight', 'clip_teacher.transformer.resblocks.6.ln_2.bias', 'clip_teacher.transformer.resblocks.7.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.7.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.7.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.7.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.7.ln_1.weight', 'clip_teacher.transformer.resblocks.7.ln_1.bias', 'clip_teacher.transformer.resblocks.7.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.7.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.7.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.7.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.7.ln_2.weight', 'clip_teacher.transformer.resblocks.7.ln_2.bias', 'clip_teacher.transformer.resblocks.8.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.8.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.8.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.8.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.8.ln_1.weight', 'clip_teacher.transformer.resblocks.8.ln_1.bias', 'clip_teacher.transformer.resblocks.8.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.8.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.8.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.8.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.8.ln_2.weight', 'clip_teacher.transformer.resblocks.8.ln_2.bias', 'clip_teacher.transformer.resblocks.9.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.9.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.9.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.9.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.9.ln_1.weight', 'clip_teacher.transformer.resblocks.9.ln_1.bias', 'clip_teacher.transformer.resblocks.9.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.9.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.9.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.9.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.9.ln_2.weight', 'clip_teacher.transformer.resblocks.9.ln_2.bias', 'clip_teacher.transformer.resblocks.10.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.10.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.10.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.10.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.10.ln_1.weight', 'clip_teacher.transformer.resblocks.10.ln_1.bias', 'clip_teacher.transformer.resblocks.10.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.10.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.10.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.10.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.10.ln_2.weight', 'clip_teacher.transformer.resblocks.10.ln_2.bias', 'clip_teacher.transformer.resblocks.11.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.11.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.11.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.11.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.11.ln_1.weight', 'clip_teacher.transformer.resblocks.11.ln_1.bias', 'clip_teacher.transformer.resblocks.11.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.11.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.11.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.11.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.11.ln_2.weight', 'clip_teacher.transformer.resblocks.11.ln_2.bias', 'clip_teacher.ln_post.weight', 'clip_teacher.ln_post.bias', 'vision_encoder.clip_decoder.0.head.weight', 'vision_encoder.clip_decoder.0.head.bias', 'vision_encoder.clip_decoder.0.norm.weight', 'vision_encoder.clip_decoder.0.norm.bias', 'vision_encoder.clip_decoder.1.head.weight', 'vision_encoder.clip_decoder.1.head.bias', 'vision_encoder.clip_decoder.1.norm.weight', 'vision_encoder.clip_decoder.1.norm.bias', 'vision_encoder.clip_decoder.2.head.weight', 'vision_encoder.clip_decoder.2.head.bias', 'vision_encoder.clip_decoder.2.norm.weight', 'vision_encoder.clip_decoder.2.norm.bias', 'vision_encoder.clip_decoder.3.head.weight', 'vision_encoder.clip_decoder.3.head.bias', 'vision_encoder.clip_decoder.3.norm.weight', 'vision_encoder.clip_decoder.3.norm.bias', 'vision_encoder.clip_decoder.4.head.weight', 'vision_encoder.clip_decoder.4.head.bias', 'vision_encoder.clip_decoder.4.norm.weight', 'vision_encoder.clip_decoder.4.norm.bias', 'vision_encoder.clip_decoder.5.head.weight', 'vision_encoder.clip_decoder.5.head.bias', 'vision_encoder.clip_decoder.5.norm.weight', 'vision_encoder.clip_decoder.5.norm.bias', 'text_encoder.cls.predictions.bias', 'text_encoder.cls.predictions.transform.dense.weight', 'text_encoder.cls.predictions.transform.dense.bias', 'text_encoder.cls.predictions.transform.LayerNorm.weight', 'text_encoder.cls.predictions.transform.LayerNorm.bias', 'text_encoder.cls.predictions.decoder.weight', 'text_encoder.cls.predictions.decoder.bias'])
2024-05-27T18:30:29 | INFO | tasks.shared_utils : Loaded checkpoint from /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
2024-05-27T18:30:29 | INFO | __main__ : training
2024-05-27T18:30:29 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T18:30:29 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T18:30:29 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T18:30:29 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T18:30:29 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 1448 batches in total
dataloader index=0 name=video, batch-size=32 length(#batches)=1448 
2024-05-27T18:30:29 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T18:30:29 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T18:30:29 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T18:30:29 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T18:30:29 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T18:30:29 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T18:30:30 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T18:30:30 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T18:30:47 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  builtin_warn(*args, **kwargs)

2024-05-27T18:30:47 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  builtin_warn(*args, **kwargs)

2024-05-27T18:30:47 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-05-27T18:30:47 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-05-27T18:32:17 | INFO | umt : Logging to: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2/train.log
2024-05-27T18:32:17 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
  test_file: {
      test: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test1k.json', '/data2/dy/temporal_video/dataset', 'video'] }
  test_types: ['test']
  num_workers: 6
  rtime: False
  pos_num: 1
  neg_num: 10
  stop_key: test/
  is_paragraph_retrieval: False
  is_pretrain: False
  num_frames: 12
  num_frames_test: 12
  batch_size: 32
  max_txt_l: 50
  evaluate: False
  train_shuffle: False
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 12
          sample_type: rand
          num_frames_test: 12
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 50
          video: 50 }
      batch_size: {
          image: 32
          video: 32 }
      batch_size_test: {
          image: 32
          video: 32 } }
  text_enc: bert
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_b16
          img_size: 224
          patch_size: 16
          d_model: 768
          encoder_embed_dim: 768
          encoder_depth: 12
          encoder_num_heads: 12
          drop_path_rate: 0.2
          num_frames: 12
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 12
          clip_decoder_embed_dim: 768
          clip_output_dim: 512
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 224
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      multimodal: {
          enable: True }
      embed_dim: 512
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 1e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 5
      min_lr_multi: 0.01
      warmup_epochs: 1 }
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: user
      project: umt_ret }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
  resume: False
  debug: False
  log_freq: 100
  seed: 3407
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
  rank: 0
  world_size: 1
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-05-27T18:32:17 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video'], 'test_file': {'test': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test1k.json', '/data2/dy/temporal_video/dataset', 'video']}, 'test_types': ['test'], 'num_workers': 6, 'rtime': False, 'pos_num': 1, 'neg_num': 10, 'stop_key': 'test/', 'is_paragraph_retrieval': False, 'is_pretrain': False, 'num_frames': 12, 'num_frames_test': 12, 'batch_size': 32, 'max_txt_l': 50, 'evaluate': False, 'train_shuffle': False, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 12, 'sample_type': 'rand', 'num_frames_test': 12, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 50, 'video': 50}, 'batch_size': {'image': 32, 'video': 32}, 'batch_size_test': {'image': 32, 'video': 32}}, 'text_enc': 'bert', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_b16', 'img_size': 224, 'patch_size': 16, 'd_model': 768, 'encoder_embed_dim': 768, 'encoder_depth': 12, 'encoder_num_heads': 12, 'drop_path_rate': 0.2, 'num_frames': 12, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 12, 'clip_decoder_embed_dim': 768, 'clip_output_dim': 512, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 224, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'multimodal': {'enable': True}, 'embed_dim': 512, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 1e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 5, 'min_lr_multi': 0.01, 'warmup_epochs': 1}, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': False, 'entity': 'user', 'project': 'umt_ret'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': 'exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 3407, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth', 'rank': 0, 'world_size': 1, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2024-05-27T18:32:17 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
2024-05-27T18:32:17 | INFO | tasks.pretrain : Creating dataset for ret
2024-05-27T18:32:18 | INFO | tasks.shared_utils : Creating model
2024-05-27T18:32:28 | INFO | models.umt : Build vision_encoder: vit_b16
2024-05-27T18:32:28 | INFO | models.backbones.vit.vit : Num of patches: 2352
2024-05-27T18:32:28 | INFO | models.backbones.vit.vit : Use checkpoint: True
2024-05-27T18:32:28 | INFO | models.backbones.vit.vit : Checkpoint number: 12
2024-05-27T18:32:28 | INFO | models.backbones.vit.vit : Student return index: []
2024-05-27T18:32:36 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
2024-05-27T18:32:36 | INFO | models.umt : Build text_encoder bert_base
2024-05-27T18:32:37 | INFO | models.backbones.bert.xbert : build bert with cross_module: ca
2024-05-27T18:32:37 | INFO | models.criterions : Norm type: l2
2024-05-27T18:32:37 | INFO | models.criterions : Loss type: l2
2024-05-27T18:32:37 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.temp: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.weight: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.weight: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.embeddings.word_embeddings.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.embeddings.position_embeddings.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.embeddings.token_type_embeddings.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.vision_proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.text_proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.itm_head.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : param module.itm_head.bias: wd: 0, lr: 1e-05
2024-05-27T18:32:37 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0.02 len(p)=164
2024-05-27T18:32:37 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0 len(p)=304
2024-05-27T18:32:37 | INFO | tasks.shared_utils : Auto resuming
2024-05-27T18:32:37 | INFO | tasks.shared_utils : Not found checkpoint in exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
2024-05-27T18:32:38 | INFO | tasks.shared_utils : _IncompatibleKeys(missing_keys=['vision_encoder.encoder.blocks.0.lora_r', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.1.lora_r', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.2.lora_r', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.3.lora_r', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.4.lora_r', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.5.lora_r', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.6.lora_r', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.7.lora_r', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.8.lora_r', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.9.lora_r', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.10.lora_r', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.11.lora_r', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.bias'], unexpected_keys=['clip_teacher.class_embedding', 'clip_teacher.positional_embedding', 'clip_teacher.proj', 'clip_teacher.conv1.weight', 'clip_teacher.ln_pre.weight', 'clip_teacher.ln_pre.bias', 'clip_teacher.transformer.resblocks.0.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.0.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.0.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.0.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.0.ln_1.weight', 'clip_teacher.transformer.resblocks.0.ln_1.bias', 'clip_teacher.transformer.resblocks.0.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.0.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.0.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.0.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.0.ln_2.weight', 'clip_teacher.transformer.resblocks.0.ln_2.bias', 'clip_teacher.transformer.resblocks.1.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.1.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.1.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.1.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.1.ln_1.weight', 'clip_teacher.transformer.resblocks.1.ln_1.bias', 'clip_teacher.transformer.resblocks.1.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.1.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.1.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.1.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.1.ln_2.weight', 'clip_teacher.transformer.resblocks.1.ln_2.bias', 'clip_teacher.transformer.resblocks.2.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.2.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.2.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.2.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.2.ln_1.weight', 'clip_teacher.transformer.resblocks.2.ln_1.bias', 'clip_teacher.transformer.resblocks.2.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.2.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.2.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.2.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.2.ln_2.weight', 'clip_teacher.transformer.resblocks.2.ln_2.bias', 'clip_teacher.transformer.resblocks.3.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.3.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.3.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.3.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.3.ln_1.weight', 'clip_teacher.transformer.resblocks.3.ln_1.bias', 'clip_teacher.transformer.resblocks.3.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.3.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.3.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.3.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.3.ln_2.weight', 'clip_teacher.transformer.resblocks.3.ln_2.bias', 'clip_teacher.transformer.resblocks.4.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.4.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.4.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.4.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.4.ln_1.weight', 'clip_teacher.transformer.resblocks.4.ln_1.bias', 'clip_teacher.transformer.resblocks.4.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.4.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.4.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.4.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.4.ln_2.weight', 'clip_teacher.transformer.resblocks.4.ln_2.bias', 'clip_teacher.transformer.resblocks.5.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.5.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.5.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.5.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.5.ln_1.weight', 'clip_teacher.transformer.resblocks.5.ln_1.bias', 'clip_teacher.transformer.resblocks.5.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.5.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.5.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.5.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.5.ln_2.weight', 'clip_teacher.transformer.resblocks.5.ln_2.bias', 'clip_teacher.transformer.resblocks.6.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.6.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.6.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.6.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.6.ln_1.weight', 'clip_teacher.transformer.resblocks.6.ln_1.bias', 'clip_teacher.transformer.resblocks.6.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.6.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.6.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.6.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.6.ln_2.weight', 'clip_teacher.transformer.resblocks.6.ln_2.bias', 'clip_teacher.transformer.resblocks.7.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.7.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.7.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.7.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.7.ln_1.weight', 'clip_teacher.transformer.resblocks.7.ln_1.bias', 'clip_teacher.transformer.resblocks.7.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.7.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.7.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.7.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.7.ln_2.weight', 'clip_teacher.transformer.resblocks.7.ln_2.bias', 'clip_teacher.transformer.resblocks.8.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.8.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.8.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.8.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.8.ln_1.weight', 'clip_teacher.transformer.resblocks.8.ln_1.bias', 'clip_teacher.transformer.resblocks.8.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.8.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.8.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.8.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.8.ln_2.weight', 'clip_teacher.transformer.resblocks.8.ln_2.bias', 'clip_teacher.transformer.resblocks.9.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.9.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.9.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.9.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.9.ln_1.weight', 'clip_teacher.transformer.resblocks.9.ln_1.bias', 'clip_teacher.transformer.resblocks.9.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.9.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.9.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.9.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.9.ln_2.weight', 'clip_teacher.transformer.resblocks.9.ln_2.bias', 'clip_teacher.transformer.resblocks.10.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.10.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.10.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.10.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.10.ln_1.weight', 'clip_teacher.transformer.resblocks.10.ln_1.bias', 'clip_teacher.transformer.resblocks.10.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.10.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.10.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.10.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.10.ln_2.weight', 'clip_teacher.transformer.resblocks.10.ln_2.bias', 'clip_teacher.transformer.resblocks.11.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.11.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.11.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.11.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.11.ln_1.weight', 'clip_teacher.transformer.resblocks.11.ln_1.bias', 'clip_teacher.transformer.resblocks.11.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.11.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.11.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.11.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.11.ln_2.weight', 'clip_teacher.transformer.resblocks.11.ln_2.bias', 'clip_teacher.ln_post.weight', 'clip_teacher.ln_post.bias', 'vision_encoder.clip_decoder.0.head.weight', 'vision_encoder.clip_decoder.0.head.bias', 'vision_encoder.clip_decoder.0.norm.weight', 'vision_encoder.clip_decoder.0.norm.bias', 'vision_encoder.clip_decoder.1.head.weight', 'vision_encoder.clip_decoder.1.head.bias', 'vision_encoder.clip_decoder.1.norm.weight', 'vision_encoder.clip_decoder.1.norm.bias', 'vision_encoder.clip_decoder.2.head.weight', 'vision_encoder.clip_decoder.2.head.bias', 'vision_encoder.clip_decoder.2.norm.weight', 'vision_encoder.clip_decoder.2.norm.bias', 'vision_encoder.clip_decoder.3.head.weight', 'vision_encoder.clip_decoder.3.head.bias', 'vision_encoder.clip_decoder.3.norm.weight', 'vision_encoder.clip_decoder.3.norm.bias', 'vision_encoder.clip_decoder.4.head.weight', 'vision_encoder.clip_decoder.4.head.bias', 'vision_encoder.clip_decoder.4.norm.weight', 'vision_encoder.clip_decoder.4.norm.bias', 'vision_encoder.clip_decoder.5.head.weight', 'vision_encoder.clip_decoder.5.head.bias', 'vision_encoder.clip_decoder.5.norm.weight', 'vision_encoder.clip_decoder.5.norm.bias', 'text_encoder.cls.predictions.bias', 'text_encoder.cls.predictions.transform.dense.weight', 'text_encoder.cls.predictions.transform.dense.bias', 'text_encoder.cls.predictions.transform.LayerNorm.weight', 'text_encoder.cls.predictions.transform.LayerNorm.bias', 'text_encoder.cls.predictions.decoder.weight', 'text_encoder.cls.predictions.decoder.bias'])
2024-05-27T18:32:38 | INFO | tasks.shared_utils : Loaded checkpoint from /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
2024-05-27T18:32:38 | INFO | __main__ : training
2024-05-27T18:32:39 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T18:32:39 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T18:32:39 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T18:32:39 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T18:32:39 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 5792 batches in total
dataloader index=0 name=video, batch-size=32 length(#batches)=5792 
2024-05-27T18:32:39 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T18:32:39 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T18:32:39 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T18:32:39 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T18:32:39 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T18:32:39 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T18:32:39 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T18:32:39 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T18:32:53 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  builtin_warn(*args, **kwargs)

2024-05-27T18:32:53 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  builtin_warn(*args, **kwargs)

2024-05-27T18:32:53 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-05-27T18:32:53 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-05-27T18:35:44 | INFO | umt : Logging to: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2/train.log
2024-05-27T18:35:44 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
  test_file: {
      test: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test1k.json', '/data2/dy/temporal_video/dataset', 'video'] }
  test_types: ['test']
  num_workers: 6
  rtime: False
  pos_num: 1
  neg_num: 10
  stop_key: test/
  is_paragraph_retrieval: False
  is_pretrain: False
  num_frames: 12
  num_frames_test: 12
  batch_size: 32
  max_txt_l: 50
  evaluate: False
  train_shuffle: False
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 12
          sample_type: rand
          num_frames_test: 12
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 50
          video: 50 }
      batch_size: {
          image: 32
          video: 32 }
      batch_size_test: {
          image: 32
          video: 32 } }
  text_enc: bert
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_b16
          img_size: 224
          patch_size: 16
          d_model: 768
          encoder_embed_dim: 768
          encoder_depth: 12
          encoder_num_heads: 12
          drop_path_rate: 0.2
          num_frames: 12
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 12
          clip_decoder_embed_dim: 768
          clip_output_dim: 512
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 224
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      multimodal: {
          enable: True }
      embed_dim: 512
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 1e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 5
      min_lr_multi: 0.01
      warmup_epochs: 1 }
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: user
      project: umt_ret }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
  resume: False
  debug: False
  log_freq: 100
  seed: 3407
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
  rank: 0
  world_size: 1
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-05-27T18:35:44 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video'], 'test_file': {'test': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test1k.json', '/data2/dy/temporal_video/dataset', 'video']}, 'test_types': ['test'], 'num_workers': 6, 'rtime': False, 'pos_num': 1, 'neg_num': 10, 'stop_key': 'test/', 'is_paragraph_retrieval': False, 'is_pretrain': False, 'num_frames': 12, 'num_frames_test': 12, 'batch_size': 32, 'max_txt_l': 50, 'evaluate': False, 'train_shuffle': False, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 12, 'sample_type': 'rand', 'num_frames_test': 12, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 50, 'video': 50}, 'batch_size': {'image': 32, 'video': 32}, 'batch_size_test': {'image': 32, 'video': 32}}, 'text_enc': 'bert', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_b16', 'img_size': 224, 'patch_size': 16, 'd_model': 768, 'encoder_embed_dim': 768, 'encoder_depth': 12, 'encoder_num_heads': 12, 'drop_path_rate': 0.2, 'num_frames': 12, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 12, 'clip_decoder_embed_dim': 768, 'clip_output_dim': 512, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 224, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'multimodal': {'enable': True}, 'embed_dim': 512, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 1e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 5, 'min_lr_multi': 0.01, 'warmup_epochs': 1}, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': False, 'entity': 'user', 'project': 'umt_ret'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': 'exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 3407, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth', 'rank': 0, 'world_size': 1, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2024-05-27T18:35:44 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
2024-05-27T18:35:44 | INFO | tasks.pretrain : Creating dataset for ret
2024-05-27T18:35:44 | INFO | tasks.shared_utils : Creating model
2024-05-27T18:35:54 | INFO | models.umt : Build vision_encoder: vit_b16
2024-05-27T18:35:54 | INFO | models.backbones.vit.vit : Num of patches: 2352
2024-05-27T18:35:54 | INFO | models.backbones.vit.vit : Use checkpoint: True
2024-05-27T18:35:54 | INFO | models.backbones.vit.vit : Checkpoint number: 12
2024-05-27T18:35:54 | INFO | models.backbones.vit.vit : Student return index: []
2024-05-27T18:36:03 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
2024-05-27T18:36:04 | INFO | models.umt : Build text_encoder bert_base
2024-05-27T18:36:05 | INFO | models.backbones.bert.xbert : build bert with cross_module: ca
2024-05-27T18:36:05 | INFO | models.criterions : Norm type: l2
2024-05-27T18:36:05 | INFO | models.criterions : Loss type: l2
2024-05-27T18:36:05 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.temp: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.weight: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.weight: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.embeddings.word_embeddings.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.embeddings.position_embeddings.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.embeddings.token_type_embeddings.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.vision_proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.text_proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.itm_head.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : param module.itm_head.bias: wd: 0, lr: 1e-05
2024-05-27T18:36:05 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0.02 len(p)=164
2024-05-27T18:36:05 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0 len(p)=304
2024-05-27T18:36:05 | INFO | tasks.shared_utils : Auto resuming
2024-05-27T18:36:05 | INFO | tasks.shared_utils : Not found checkpoint in exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
2024-05-27T18:36:06 | INFO | tasks.shared_utils : _IncompatibleKeys(missing_keys=['vision_encoder.encoder.blocks.0.lora_r', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.1.lora_r', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.2.lora_r', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.3.lora_r', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.4.lora_r', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.5.lora_r', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.6.lora_r', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.7.lora_r', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.8.lora_r', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.9.lora_r', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.10.lora_r', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.11.lora_r', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.bias'], unexpected_keys=['clip_teacher.class_embedding', 'clip_teacher.positional_embedding', 'clip_teacher.proj', 'clip_teacher.conv1.weight', 'clip_teacher.ln_pre.weight', 'clip_teacher.ln_pre.bias', 'clip_teacher.transformer.resblocks.0.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.0.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.0.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.0.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.0.ln_1.weight', 'clip_teacher.transformer.resblocks.0.ln_1.bias', 'clip_teacher.transformer.resblocks.0.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.0.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.0.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.0.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.0.ln_2.weight', 'clip_teacher.transformer.resblocks.0.ln_2.bias', 'clip_teacher.transformer.resblocks.1.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.1.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.1.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.1.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.1.ln_1.weight', 'clip_teacher.transformer.resblocks.1.ln_1.bias', 'clip_teacher.transformer.resblocks.1.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.1.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.1.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.1.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.1.ln_2.weight', 'clip_teacher.transformer.resblocks.1.ln_2.bias', 'clip_teacher.transformer.resblocks.2.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.2.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.2.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.2.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.2.ln_1.weight', 'clip_teacher.transformer.resblocks.2.ln_1.bias', 'clip_teacher.transformer.resblocks.2.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.2.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.2.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.2.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.2.ln_2.weight', 'clip_teacher.transformer.resblocks.2.ln_2.bias', 'clip_teacher.transformer.resblocks.3.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.3.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.3.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.3.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.3.ln_1.weight', 'clip_teacher.transformer.resblocks.3.ln_1.bias', 'clip_teacher.transformer.resblocks.3.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.3.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.3.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.3.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.3.ln_2.weight', 'clip_teacher.transformer.resblocks.3.ln_2.bias', 'clip_teacher.transformer.resblocks.4.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.4.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.4.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.4.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.4.ln_1.weight', 'clip_teacher.transformer.resblocks.4.ln_1.bias', 'clip_teacher.transformer.resblocks.4.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.4.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.4.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.4.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.4.ln_2.weight', 'clip_teacher.transformer.resblocks.4.ln_2.bias', 'clip_teacher.transformer.resblocks.5.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.5.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.5.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.5.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.5.ln_1.weight', 'clip_teacher.transformer.resblocks.5.ln_1.bias', 'clip_teacher.transformer.resblocks.5.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.5.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.5.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.5.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.5.ln_2.weight', 'clip_teacher.transformer.resblocks.5.ln_2.bias', 'clip_teacher.transformer.resblocks.6.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.6.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.6.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.6.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.6.ln_1.weight', 'clip_teacher.transformer.resblocks.6.ln_1.bias', 'clip_teacher.transformer.resblocks.6.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.6.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.6.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.6.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.6.ln_2.weight', 'clip_teacher.transformer.resblocks.6.ln_2.bias', 'clip_teacher.transformer.resblocks.7.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.7.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.7.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.7.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.7.ln_1.weight', 'clip_teacher.transformer.resblocks.7.ln_1.bias', 'clip_teacher.transformer.resblocks.7.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.7.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.7.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.7.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.7.ln_2.weight', 'clip_teacher.transformer.resblocks.7.ln_2.bias', 'clip_teacher.transformer.resblocks.8.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.8.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.8.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.8.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.8.ln_1.weight', 'clip_teacher.transformer.resblocks.8.ln_1.bias', 'clip_teacher.transformer.resblocks.8.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.8.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.8.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.8.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.8.ln_2.weight', 'clip_teacher.transformer.resblocks.8.ln_2.bias', 'clip_teacher.transformer.resblocks.9.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.9.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.9.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.9.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.9.ln_1.weight', 'clip_teacher.transformer.resblocks.9.ln_1.bias', 'clip_teacher.transformer.resblocks.9.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.9.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.9.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.9.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.9.ln_2.weight', 'clip_teacher.transformer.resblocks.9.ln_2.bias', 'clip_teacher.transformer.resblocks.10.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.10.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.10.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.10.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.10.ln_1.weight', 'clip_teacher.transformer.resblocks.10.ln_1.bias', 'clip_teacher.transformer.resblocks.10.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.10.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.10.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.10.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.10.ln_2.weight', 'clip_teacher.transformer.resblocks.10.ln_2.bias', 'clip_teacher.transformer.resblocks.11.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.11.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.11.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.11.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.11.ln_1.weight', 'clip_teacher.transformer.resblocks.11.ln_1.bias', 'clip_teacher.transformer.resblocks.11.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.11.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.11.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.11.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.11.ln_2.weight', 'clip_teacher.transformer.resblocks.11.ln_2.bias', 'clip_teacher.ln_post.weight', 'clip_teacher.ln_post.bias', 'vision_encoder.clip_decoder.0.head.weight', 'vision_encoder.clip_decoder.0.head.bias', 'vision_encoder.clip_decoder.0.norm.weight', 'vision_encoder.clip_decoder.0.norm.bias', 'vision_encoder.clip_decoder.1.head.weight', 'vision_encoder.clip_decoder.1.head.bias', 'vision_encoder.clip_decoder.1.norm.weight', 'vision_encoder.clip_decoder.1.norm.bias', 'vision_encoder.clip_decoder.2.head.weight', 'vision_encoder.clip_decoder.2.head.bias', 'vision_encoder.clip_decoder.2.norm.weight', 'vision_encoder.clip_decoder.2.norm.bias', 'vision_encoder.clip_decoder.3.head.weight', 'vision_encoder.clip_decoder.3.head.bias', 'vision_encoder.clip_decoder.3.norm.weight', 'vision_encoder.clip_decoder.3.norm.bias', 'vision_encoder.clip_decoder.4.head.weight', 'vision_encoder.clip_decoder.4.head.bias', 'vision_encoder.clip_decoder.4.norm.weight', 'vision_encoder.clip_decoder.4.norm.bias', 'vision_encoder.clip_decoder.5.head.weight', 'vision_encoder.clip_decoder.5.head.bias', 'vision_encoder.clip_decoder.5.norm.weight', 'vision_encoder.clip_decoder.5.norm.bias', 'text_encoder.cls.predictions.bias', 'text_encoder.cls.predictions.transform.dense.weight', 'text_encoder.cls.predictions.transform.dense.bias', 'text_encoder.cls.predictions.transform.LayerNorm.weight', 'text_encoder.cls.predictions.transform.LayerNorm.bias', 'text_encoder.cls.predictions.decoder.weight', 'text_encoder.cls.predictions.decoder.bias'])
2024-05-27T18:36:06 | INFO | tasks.shared_utils : Loaded checkpoint from /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
2024-05-27T18:36:06 | INFO | __main__ : training
2024-05-27T18:36:07 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T18:36:07 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T18:36:07 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T18:36:07 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T18:36:07 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 5792 batches in total
dataloader index=0 name=video, batch-size=32 length(#batches)=5792 
2024-05-27T18:36:07 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T18:36:07 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T18:36:07 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T18:36:07 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T18:36:07 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T18:36:07 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T18:36:07 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T18:36:07 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T18:36:21 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  builtin_warn(*args, **kwargs)

2024-05-27T18:36:21 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  builtin_warn(*args, **kwargs)

2024-05-27T18:36:21 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-05-27T18:36:21 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-05-27T18:40:21 | INFO | umt : Logging to: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2/train.log
2024-05-27T18:40:21 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
  test_file: {
      test: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test1k.json', '/data2/dy/temporal_video/dataset', 'video'] }
  test_types: ['test']
  num_workers: 6
  rtime: False
  pos_num: 1
  neg_num: 10
  stop_key: test/
  is_paragraph_retrieval: False
  is_pretrain: False
  num_frames: 12
  num_frames_test: 12
  batch_size: 32
  max_txt_l: 50
  evaluate: False
  train_shuffle: False
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 12
          sample_type: rand
          num_frames_test: 12
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 50
          video: 50 }
      batch_size: {
          image: 32
          video: 32 }
      batch_size_test: {
          image: 32
          video: 32 } }
  text_enc: bert
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_b16
          img_size: 224
          patch_size: 16
          d_model: 768
          encoder_embed_dim: 768
          encoder_depth: 12
          encoder_num_heads: 12
          drop_path_rate: 0.2
          num_frames: 12
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 12
          clip_decoder_embed_dim: 768
          clip_output_dim: 512
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 224
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      multimodal: {
          enable: True }
      embed_dim: 512
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 1e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 5
      min_lr_multi: 0.01
      warmup_epochs: 1 }
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: user
      project: umt_ret }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
  resume: False
  debug: False
  log_freq: 100
  seed: 3407
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
  rank: 0
  world_size: 1
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-05-27T18:40:21 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video'], 'test_file': {'test': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test1k.json', '/data2/dy/temporal_video/dataset', 'video']}, 'test_types': ['test'], 'num_workers': 6, 'rtime': False, 'pos_num': 1, 'neg_num': 10, 'stop_key': 'test/', 'is_paragraph_retrieval': False, 'is_pretrain': False, 'num_frames': 12, 'num_frames_test': 12, 'batch_size': 32, 'max_txt_l': 50, 'evaluate': False, 'train_shuffle': False, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 12, 'sample_type': 'rand', 'num_frames_test': 12, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 50, 'video': 50}, 'batch_size': {'image': 32, 'video': 32}, 'batch_size_test': {'image': 32, 'video': 32}}, 'text_enc': 'bert', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_b16', 'img_size': 224, 'patch_size': 16, 'd_model': 768, 'encoder_embed_dim': 768, 'encoder_depth': 12, 'encoder_num_heads': 12, 'drop_path_rate': 0.2, 'num_frames': 12, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 12, 'clip_decoder_embed_dim': 768, 'clip_output_dim': 512, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 224, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'multimodal': {'enable': True}, 'embed_dim': 512, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 1e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 5, 'min_lr_multi': 0.01, 'warmup_epochs': 1}, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': False, 'entity': 'user', 'project': 'umt_ret'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': 'exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 3407, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth', 'rank': 0, 'world_size': 1, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2024-05-27T18:40:21 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
2024-05-27T18:40:21 | INFO | tasks.pretrain : Creating dataset for ret
2024-05-27T18:40:21 | INFO | tasks.shared_utils : Creating model
2024-05-27T18:40:31 | INFO | models.umt : Build vision_encoder: vit_b16
2024-05-27T18:40:31 | INFO | models.backbones.vit.vit : Num of patches: 2352
2024-05-27T18:40:31 | INFO | models.backbones.vit.vit : Use checkpoint: True
2024-05-27T18:40:31 | INFO | models.backbones.vit.vit : Checkpoint number: 12
2024-05-27T18:40:31 | INFO | models.backbones.vit.vit : Student return index: []
2024-05-27T18:40:39 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
2024-05-27T18:40:39 | INFO | models.umt : Build text_encoder bert_base
2024-05-27T18:40:40 | INFO | models.backbones.bert.xbert : build bert with cross_module: ca
2024-05-27T18:40:40 | INFO | models.criterions : Norm type: l2
2024-05-27T18:40:40 | INFO | models.criterions : Loss type: l2
2024-05-27T18:40:41 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.temp: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.weight: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.weight: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.embeddings.word_embeddings.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.embeddings.position_embeddings.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.embeddings.token_type_embeddings.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.vision_proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.text_proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.itm_head.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : param module.itm_head.bias: wd: 0, lr: 1e-05
2024-05-27T18:40:41 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0.02 len(p)=164
2024-05-27T18:40:41 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0 len(p)=304
2024-05-27T18:40:41 | INFO | tasks.shared_utils : Auto resuming
2024-05-27T18:40:41 | INFO | tasks.shared_utils : Not found checkpoint in exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
2024-05-27T18:40:41 | INFO | tasks.shared_utils : _IncompatibleKeys(missing_keys=['vision_encoder.encoder.blocks.0.lora_r', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.1.lora_r', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.2.lora_r', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.3.lora_r', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.4.lora_r', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.5.lora_r', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.6.lora_r', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.7.lora_r', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.8.lora_r', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.9.lora_r', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.10.lora_r', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.11.lora_r', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.bias'], unexpected_keys=['clip_teacher.class_embedding', 'clip_teacher.positional_embedding', 'clip_teacher.proj', 'clip_teacher.conv1.weight', 'clip_teacher.ln_pre.weight', 'clip_teacher.ln_pre.bias', 'clip_teacher.transformer.resblocks.0.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.0.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.0.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.0.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.0.ln_1.weight', 'clip_teacher.transformer.resblocks.0.ln_1.bias', 'clip_teacher.transformer.resblocks.0.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.0.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.0.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.0.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.0.ln_2.weight', 'clip_teacher.transformer.resblocks.0.ln_2.bias', 'clip_teacher.transformer.resblocks.1.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.1.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.1.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.1.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.1.ln_1.weight', 'clip_teacher.transformer.resblocks.1.ln_1.bias', 'clip_teacher.transformer.resblocks.1.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.1.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.1.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.1.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.1.ln_2.weight', 'clip_teacher.transformer.resblocks.1.ln_2.bias', 'clip_teacher.transformer.resblocks.2.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.2.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.2.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.2.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.2.ln_1.weight', 'clip_teacher.transformer.resblocks.2.ln_1.bias', 'clip_teacher.transformer.resblocks.2.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.2.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.2.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.2.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.2.ln_2.weight', 'clip_teacher.transformer.resblocks.2.ln_2.bias', 'clip_teacher.transformer.resblocks.3.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.3.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.3.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.3.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.3.ln_1.weight', 'clip_teacher.transformer.resblocks.3.ln_1.bias', 'clip_teacher.transformer.resblocks.3.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.3.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.3.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.3.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.3.ln_2.weight', 'clip_teacher.transformer.resblocks.3.ln_2.bias', 'clip_teacher.transformer.resblocks.4.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.4.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.4.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.4.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.4.ln_1.weight', 'clip_teacher.transformer.resblocks.4.ln_1.bias', 'clip_teacher.transformer.resblocks.4.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.4.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.4.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.4.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.4.ln_2.weight', 'clip_teacher.transformer.resblocks.4.ln_2.bias', 'clip_teacher.transformer.resblocks.5.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.5.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.5.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.5.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.5.ln_1.weight', 'clip_teacher.transformer.resblocks.5.ln_1.bias', 'clip_teacher.transformer.resblocks.5.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.5.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.5.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.5.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.5.ln_2.weight', 'clip_teacher.transformer.resblocks.5.ln_2.bias', 'clip_teacher.transformer.resblocks.6.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.6.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.6.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.6.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.6.ln_1.weight', 'clip_teacher.transformer.resblocks.6.ln_1.bias', 'clip_teacher.transformer.resblocks.6.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.6.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.6.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.6.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.6.ln_2.weight', 'clip_teacher.transformer.resblocks.6.ln_2.bias', 'clip_teacher.transformer.resblocks.7.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.7.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.7.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.7.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.7.ln_1.weight', 'clip_teacher.transformer.resblocks.7.ln_1.bias', 'clip_teacher.transformer.resblocks.7.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.7.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.7.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.7.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.7.ln_2.weight', 'clip_teacher.transformer.resblocks.7.ln_2.bias', 'clip_teacher.transformer.resblocks.8.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.8.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.8.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.8.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.8.ln_1.weight', 'clip_teacher.transformer.resblocks.8.ln_1.bias', 'clip_teacher.transformer.resblocks.8.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.8.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.8.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.8.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.8.ln_2.weight', 'clip_teacher.transformer.resblocks.8.ln_2.bias', 'clip_teacher.transformer.resblocks.9.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.9.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.9.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.9.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.9.ln_1.weight', 'clip_teacher.transformer.resblocks.9.ln_1.bias', 'clip_teacher.transformer.resblocks.9.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.9.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.9.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.9.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.9.ln_2.weight', 'clip_teacher.transformer.resblocks.9.ln_2.bias', 'clip_teacher.transformer.resblocks.10.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.10.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.10.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.10.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.10.ln_1.weight', 'clip_teacher.transformer.resblocks.10.ln_1.bias', 'clip_teacher.transformer.resblocks.10.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.10.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.10.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.10.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.10.ln_2.weight', 'clip_teacher.transformer.resblocks.10.ln_2.bias', 'clip_teacher.transformer.resblocks.11.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.11.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.11.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.11.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.11.ln_1.weight', 'clip_teacher.transformer.resblocks.11.ln_1.bias', 'clip_teacher.transformer.resblocks.11.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.11.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.11.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.11.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.11.ln_2.weight', 'clip_teacher.transformer.resblocks.11.ln_2.bias', 'clip_teacher.ln_post.weight', 'clip_teacher.ln_post.bias', 'vision_encoder.clip_decoder.0.head.weight', 'vision_encoder.clip_decoder.0.head.bias', 'vision_encoder.clip_decoder.0.norm.weight', 'vision_encoder.clip_decoder.0.norm.bias', 'vision_encoder.clip_decoder.1.head.weight', 'vision_encoder.clip_decoder.1.head.bias', 'vision_encoder.clip_decoder.1.norm.weight', 'vision_encoder.clip_decoder.1.norm.bias', 'vision_encoder.clip_decoder.2.head.weight', 'vision_encoder.clip_decoder.2.head.bias', 'vision_encoder.clip_decoder.2.norm.weight', 'vision_encoder.clip_decoder.2.norm.bias', 'vision_encoder.clip_decoder.3.head.weight', 'vision_encoder.clip_decoder.3.head.bias', 'vision_encoder.clip_decoder.3.norm.weight', 'vision_encoder.clip_decoder.3.norm.bias', 'vision_encoder.clip_decoder.4.head.weight', 'vision_encoder.clip_decoder.4.head.bias', 'vision_encoder.clip_decoder.4.norm.weight', 'vision_encoder.clip_decoder.4.norm.bias', 'vision_encoder.clip_decoder.5.head.weight', 'vision_encoder.clip_decoder.5.head.bias', 'vision_encoder.clip_decoder.5.norm.weight', 'vision_encoder.clip_decoder.5.norm.bias', 'text_encoder.cls.predictions.bias', 'text_encoder.cls.predictions.transform.dense.weight', 'text_encoder.cls.predictions.transform.dense.bias', 'text_encoder.cls.predictions.transform.LayerNorm.weight', 'text_encoder.cls.predictions.transform.LayerNorm.bias', 'text_encoder.cls.predictions.decoder.weight', 'text_encoder.cls.predictions.decoder.bias'])
2024-05-27T18:40:41 | INFO | tasks.shared_utils : Loaded checkpoint from /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
2024-05-27T18:40:41 | INFO | __main__ : training
2024-05-27T18:40:42 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 5792 batches in total
dataloader index=0 name=video, batch-size=32 length(#batches)=5792 
2024-05-27T18:40:42 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T18:40:42 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T18:40:42 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T18:40:42 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T18:40:42 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T18:40:42 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T18:40:42 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T18:40:42 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T18:40:42 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T18:40:42 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T18:40:43 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T18:40:43 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T18:40:56 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  builtin_warn(*args, **kwargs)

2024-05-27T18:40:56 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  builtin_warn(*args, **kwargs)

2024-05-27T18:40:56 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-05-27T18:40:56 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-05-27T18:42:42 | INFO | umt : Logging to: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2/train.log
2024-05-27T18:42:42 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
  test_file: {
      test: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test1k.json', '/data2/dy/temporal_video/dataset', 'video'] }
  test_types: ['test']
  num_workers: 6
  rtime: False
  pos_num: 1
  neg_num: 10
  stop_key: test/
  is_paragraph_retrieval: False
  is_pretrain: False
  num_frames: 12
  num_frames_test: 12
  batch_size: 32
  max_txt_l: 50
  evaluate: False
  train_shuffle: False
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 12
          sample_type: rand
          num_frames_test: 12
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 50
          video: 50 }
      batch_size: {
          image: 32
          video: 32 }
      batch_size_test: {
          image: 32
          video: 32 } }
  text_enc: bert
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_b16
          img_size: 224
          patch_size: 16
          d_model: 768
          encoder_embed_dim: 768
          encoder_depth: 12
          encoder_num_heads: 12
          drop_path_rate: 0.2
          num_frames: 12
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 12
          clip_decoder_embed_dim: 768
          clip_output_dim: 512
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 224
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      multimodal: {
          enable: True }
      embed_dim: 512
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 1e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 5
      min_lr_multi: 0.01
      warmup_epochs: 1 }
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: user
      project: umt_ret }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
  resume: False
  debug: False
  log_freq: 100
  seed: 3407
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
  rank: 0
  world_size: 1
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-05-27T18:42:42 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video'], 'test_file': {'test': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test1k.json', '/data2/dy/temporal_video/dataset', 'video']}, 'test_types': ['test'], 'num_workers': 6, 'rtime': False, 'pos_num': 1, 'neg_num': 10, 'stop_key': 'test/', 'is_paragraph_retrieval': False, 'is_pretrain': False, 'num_frames': 12, 'num_frames_test': 12, 'batch_size': 32, 'max_txt_l': 50, 'evaluate': False, 'train_shuffle': False, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 12, 'sample_type': 'rand', 'num_frames_test': 12, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 50, 'video': 50}, 'batch_size': {'image': 32, 'video': 32}, 'batch_size_test': {'image': 32, 'video': 32}}, 'text_enc': 'bert', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_b16', 'img_size': 224, 'patch_size': 16, 'd_model': 768, 'encoder_embed_dim': 768, 'encoder_depth': 12, 'encoder_num_heads': 12, 'drop_path_rate': 0.2, 'num_frames': 12, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 12, 'clip_decoder_embed_dim': 768, 'clip_output_dim': 512, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 224, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'multimodal': {'enable': True}, 'embed_dim': 512, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 1e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 5, 'min_lr_multi': 0.01, 'warmup_epochs': 1}, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': False, 'entity': 'user', 'project': 'umt_ret'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': 'exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 3407, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth', 'rank': 0, 'world_size': 1, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2024-05-27T18:42:42 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
2024-05-27T18:42:42 | INFO | tasks.pretrain : Creating dataset for ret
2024-05-27T18:42:42 | INFO | tasks.shared_utils : Creating model
2024-05-27T18:42:52 | INFO | models.umt : Build vision_encoder: vit_b16
2024-05-27T18:42:52 | INFO | models.backbones.vit.vit : Num of patches: 2352
2024-05-27T18:42:52 | INFO | models.backbones.vit.vit : Use checkpoint: True
2024-05-27T18:42:52 | INFO | models.backbones.vit.vit : Checkpoint number: 12
2024-05-27T18:42:52 | INFO | models.backbones.vit.vit : Student return index: []
2024-05-27T18:43:00 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
2024-05-27T18:43:00 | INFO | models.umt : Build text_encoder bert_base
2024-05-27T18:43:01 | INFO | models.backbones.bert.xbert : build bert with cross_module: ca
2024-05-27T18:43:02 | INFO | models.criterions : Norm type: l2
2024-05-27T18:43:02 | INFO | models.criterions : Loss type: l2
2024-05-27T18:43:02 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.temp: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.weight: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.weight: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.embeddings.word_embeddings.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.embeddings.position_embeddings.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.embeddings.token_type_embeddings.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.vision_proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.text_proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.itm_head.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : param module.itm_head.bias: wd: 0, lr: 1e-05
2024-05-27T18:43:02 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0.02 len(p)=164
2024-05-27T18:43:02 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0 len(p)=304
2024-05-27T18:43:02 | INFO | tasks.shared_utils : Auto resuming
2024-05-27T18:43:02 | INFO | tasks.shared_utils : Not found checkpoint in exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
2024-05-27T18:43:03 | INFO | tasks.shared_utils : _IncompatibleKeys(missing_keys=['vision_encoder.encoder.blocks.0.lora_r', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.1.lora_r', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.2.lora_r', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.3.lora_r', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.4.lora_r', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.5.lora_r', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.6.lora_r', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.7.lora_r', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.8.lora_r', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.9.lora_r', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.10.lora_r', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.11.lora_r', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.bias'], unexpected_keys=['clip_teacher.class_embedding', 'clip_teacher.positional_embedding', 'clip_teacher.proj', 'clip_teacher.conv1.weight', 'clip_teacher.ln_pre.weight', 'clip_teacher.ln_pre.bias', 'clip_teacher.transformer.resblocks.0.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.0.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.0.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.0.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.0.ln_1.weight', 'clip_teacher.transformer.resblocks.0.ln_1.bias', 'clip_teacher.transformer.resblocks.0.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.0.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.0.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.0.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.0.ln_2.weight', 'clip_teacher.transformer.resblocks.0.ln_2.bias', 'clip_teacher.transformer.resblocks.1.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.1.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.1.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.1.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.1.ln_1.weight', 'clip_teacher.transformer.resblocks.1.ln_1.bias', 'clip_teacher.transformer.resblocks.1.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.1.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.1.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.1.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.1.ln_2.weight', 'clip_teacher.transformer.resblocks.1.ln_2.bias', 'clip_teacher.transformer.resblocks.2.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.2.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.2.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.2.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.2.ln_1.weight', 'clip_teacher.transformer.resblocks.2.ln_1.bias', 'clip_teacher.transformer.resblocks.2.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.2.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.2.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.2.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.2.ln_2.weight', 'clip_teacher.transformer.resblocks.2.ln_2.bias', 'clip_teacher.transformer.resblocks.3.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.3.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.3.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.3.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.3.ln_1.weight', 'clip_teacher.transformer.resblocks.3.ln_1.bias', 'clip_teacher.transformer.resblocks.3.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.3.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.3.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.3.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.3.ln_2.weight', 'clip_teacher.transformer.resblocks.3.ln_2.bias', 'clip_teacher.transformer.resblocks.4.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.4.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.4.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.4.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.4.ln_1.weight', 'clip_teacher.transformer.resblocks.4.ln_1.bias', 'clip_teacher.transformer.resblocks.4.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.4.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.4.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.4.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.4.ln_2.weight', 'clip_teacher.transformer.resblocks.4.ln_2.bias', 'clip_teacher.transformer.resblocks.5.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.5.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.5.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.5.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.5.ln_1.weight', 'clip_teacher.transformer.resblocks.5.ln_1.bias', 'clip_teacher.transformer.resblocks.5.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.5.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.5.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.5.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.5.ln_2.weight', 'clip_teacher.transformer.resblocks.5.ln_2.bias', 'clip_teacher.transformer.resblocks.6.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.6.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.6.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.6.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.6.ln_1.weight', 'clip_teacher.transformer.resblocks.6.ln_1.bias', 'clip_teacher.transformer.resblocks.6.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.6.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.6.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.6.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.6.ln_2.weight', 'clip_teacher.transformer.resblocks.6.ln_2.bias', 'clip_teacher.transformer.resblocks.7.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.7.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.7.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.7.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.7.ln_1.weight', 'clip_teacher.transformer.resblocks.7.ln_1.bias', 'clip_teacher.transformer.resblocks.7.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.7.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.7.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.7.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.7.ln_2.weight', 'clip_teacher.transformer.resblocks.7.ln_2.bias', 'clip_teacher.transformer.resblocks.8.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.8.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.8.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.8.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.8.ln_1.weight', 'clip_teacher.transformer.resblocks.8.ln_1.bias', 'clip_teacher.transformer.resblocks.8.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.8.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.8.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.8.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.8.ln_2.weight', 'clip_teacher.transformer.resblocks.8.ln_2.bias', 'clip_teacher.transformer.resblocks.9.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.9.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.9.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.9.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.9.ln_1.weight', 'clip_teacher.transformer.resblocks.9.ln_1.bias', 'clip_teacher.transformer.resblocks.9.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.9.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.9.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.9.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.9.ln_2.weight', 'clip_teacher.transformer.resblocks.9.ln_2.bias', 'clip_teacher.transformer.resblocks.10.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.10.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.10.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.10.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.10.ln_1.weight', 'clip_teacher.transformer.resblocks.10.ln_1.bias', 'clip_teacher.transformer.resblocks.10.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.10.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.10.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.10.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.10.ln_2.weight', 'clip_teacher.transformer.resblocks.10.ln_2.bias', 'clip_teacher.transformer.resblocks.11.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.11.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.11.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.11.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.11.ln_1.weight', 'clip_teacher.transformer.resblocks.11.ln_1.bias', 'clip_teacher.transformer.resblocks.11.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.11.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.11.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.11.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.11.ln_2.weight', 'clip_teacher.transformer.resblocks.11.ln_2.bias', 'clip_teacher.ln_post.weight', 'clip_teacher.ln_post.bias', 'vision_encoder.clip_decoder.0.head.weight', 'vision_encoder.clip_decoder.0.head.bias', 'vision_encoder.clip_decoder.0.norm.weight', 'vision_encoder.clip_decoder.0.norm.bias', 'vision_encoder.clip_decoder.1.head.weight', 'vision_encoder.clip_decoder.1.head.bias', 'vision_encoder.clip_decoder.1.norm.weight', 'vision_encoder.clip_decoder.1.norm.bias', 'vision_encoder.clip_decoder.2.head.weight', 'vision_encoder.clip_decoder.2.head.bias', 'vision_encoder.clip_decoder.2.norm.weight', 'vision_encoder.clip_decoder.2.norm.bias', 'vision_encoder.clip_decoder.3.head.weight', 'vision_encoder.clip_decoder.3.head.bias', 'vision_encoder.clip_decoder.3.norm.weight', 'vision_encoder.clip_decoder.3.norm.bias', 'vision_encoder.clip_decoder.4.head.weight', 'vision_encoder.clip_decoder.4.head.bias', 'vision_encoder.clip_decoder.4.norm.weight', 'vision_encoder.clip_decoder.4.norm.bias', 'vision_encoder.clip_decoder.5.head.weight', 'vision_encoder.clip_decoder.5.head.bias', 'vision_encoder.clip_decoder.5.norm.weight', 'vision_encoder.clip_decoder.5.norm.bias', 'text_encoder.cls.predictions.bias', 'text_encoder.cls.predictions.transform.dense.weight', 'text_encoder.cls.predictions.transform.dense.bias', 'text_encoder.cls.predictions.transform.LayerNorm.weight', 'text_encoder.cls.predictions.transform.LayerNorm.bias', 'text_encoder.cls.predictions.decoder.weight', 'text_encoder.cls.predictions.decoder.bias'])
2024-05-27T18:43:03 | INFO | tasks.shared_utils : Loaded checkpoint from /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
2024-05-27T18:43:03 | INFO | __main__ : training
2024-05-27T18:43:04 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 5792 batches in total
dataloader index=0 name=video, batch-size=32 length(#batches)=5792 
2024-05-27T18:43:04 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T18:43:04 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T18:43:04 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T18:43:04 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T18:43:04 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T18:43:04 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T18:43:04 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T18:43:04 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T18:43:04 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T18:43:04 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T18:43:04 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T18:43:04 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T18:43:17 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  builtin_warn(*args, **kwargs)

2024-05-27T18:43:17 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  builtin_warn(*args, **kwargs)

2024-05-27T18:43:17 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-05-27T18:43:17 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-05-27T18:50:54 | INFO | umt : Logging to: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2/train.log
2024-05-27T18:50:54 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
  test_file: {
      test: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test1k.json', '/data2/dy/temporal_video/dataset', 'video'] }
  test_types: ['test']
  num_workers: 6
  rtime: False
  pos_num: 1
  neg_num: 10
  stop_key: test/
  is_paragraph_retrieval: False
  is_pretrain: False
  num_frames: 12
  num_frames_test: 12
  batch_size: 32
  max_txt_l: 50
  evaluate: False
  train_shuffle: False
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 12
          sample_type: rand
          num_frames_test: 12
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 50
          video: 50 }
      batch_size: {
          image: 32
          video: 32 }
      batch_size_test: {
          image: 32
          video: 32 } }
  text_enc: bert
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_b16
          img_size: 224
          patch_size: 16
          d_model: 768
          encoder_embed_dim: 768
          encoder_depth: 12
          encoder_num_heads: 12
          drop_path_rate: 0.2
          num_frames: 12
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 12
          clip_decoder_embed_dim: 768
          clip_output_dim: 512
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 224
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      multimodal: {
          enable: True }
      embed_dim: 512
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 1e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 5
      min_lr_multi: 0.01
      warmup_epochs: 1 }
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: user
      project: umt_ret }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
  resume: False
  debug: False
  log_freq: 100
  seed: 3407
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
  rank: 0
  world_size: 1
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-05-27T18:50:54 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video'], 'test_file': {'test': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test1k.json', '/data2/dy/temporal_video/dataset', 'video']}, 'test_types': ['test'], 'num_workers': 6, 'rtime': False, 'pos_num': 1, 'neg_num': 10, 'stop_key': 'test/', 'is_paragraph_retrieval': False, 'is_pretrain': False, 'num_frames': 12, 'num_frames_test': 12, 'batch_size': 32, 'max_txt_l': 50, 'evaluate': False, 'train_shuffle': False, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 12, 'sample_type': 'rand', 'num_frames_test': 12, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 50, 'video': 50}, 'batch_size': {'image': 32, 'video': 32}, 'batch_size_test': {'image': 32, 'video': 32}}, 'text_enc': 'bert', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_b16', 'img_size': 224, 'patch_size': 16, 'd_model': 768, 'encoder_embed_dim': 768, 'encoder_depth': 12, 'encoder_num_heads': 12, 'drop_path_rate': 0.2, 'num_frames': 12, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 12, 'clip_decoder_embed_dim': 768, 'clip_output_dim': 512, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 224, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'multimodal': {'enable': True}, 'embed_dim': 512, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 1e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 5, 'min_lr_multi': 0.01, 'warmup_epochs': 1}, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': False, 'entity': 'user', 'project': 'umt_ret'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': 'exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 3407, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth', 'rank': 0, 'world_size': 1, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2024-05-27T18:50:54 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
2024-05-27T18:50:54 | INFO | tasks.pretrain : Creating dataset for ret
2024-05-27T18:50:54 | INFO | tasks.shared_utils : Creating model
2024-05-27T18:51:04 | INFO | models.umt : Build vision_encoder: vit_b16
2024-05-27T18:51:04 | INFO | models.backbones.vit.vit : Num of patches: 2352
2024-05-27T18:51:04 | INFO | models.backbones.vit.vit : Use checkpoint: True
2024-05-27T18:51:04 | INFO | models.backbones.vit.vit : Checkpoint number: 12
2024-05-27T18:51:04 | INFO | models.backbones.vit.vit : Student return index: []
2024-05-27T18:51:12 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
2024-05-27T18:51:12 | INFO | models.umt : Build text_encoder bert_base
2024-05-27T18:51:13 | INFO | models.backbones.bert.xbert : build bert with cross_module: ca
2024-05-27T18:51:13 | INFO | models.criterions : Norm type: l2
2024-05-27T18:51:13 | INFO | models.criterions : Loss type: l2
2024-05-27T18:51:14 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-05-27T18:51:14 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:51:14 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:51:14 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:51:14 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:51:14 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:51:14 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:51:14 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:51:14 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:51:14 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:51:14 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:51:14 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:51:14 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:51:14 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:51:14 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:51:14 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:51:14 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:51:14 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:51:14 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:51:14 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:51:14 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:51:14 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:51:14 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:51:14 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:51:14 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:51:14 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:51:14 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:51:14 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:51:14 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:51:14 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:51:14 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:51:14 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:51:14 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:51:14 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:51:14 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:51:14 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:51:14 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:51:14 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:51:14 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:51:14 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:51:14 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:51:14 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:51:14 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:51:14 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:51:14 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:51:14 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:51:14 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:51:14 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:51:14 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:51:14 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:51:14 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:51:14 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:51:14 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:51:14 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:51:14 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:51:14 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:51:14 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:51:14 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:51:14 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:51:14 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:51:14 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:51:14 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:51:14 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:51:14 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:51:14 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:51:14 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:51:14 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:51:14 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:51:14 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:51:14 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:51:14 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:51:14 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:51:14 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:51:14 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0 len(p)=48
2024-05-27T18:51:14 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0.02 len(p)=24
2024-05-27T18:51:14 | INFO | tasks.shared_utils : Auto resuming
2024-05-27T18:51:14 | INFO | tasks.shared_utils : Not found checkpoint in exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
2024-05-27T18:52:47 | INFO | umt : Logging to: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2/train.log
2024-05-27T18:52:47 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
  test_file: {
      test: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test1k.json', '/data2/dy/temporal_video/dataset', 'video'] }
  test_types: ['test']
  num_workers: 6
  rtime: False
  pos_num: 1
  neg_num: 10
  stop_key: test/
  is_paragraph_retrieval: False
  is_pretrain: False
  num_frames: 12
  num_frames_test: 12
  batch_size: 32
  max_txt_l: 50
  evaluate: False
  train_shuffle: False
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 12
          sample_type: rand
          num_frames_test: 12
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 50
          video: 50 }
      batch_size: {
          image: 32
          video: 32 }
      batch_size_test: {
          image: 32
          video: 32 } }
  text_enc: bert
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_b16
          img_size: 224
          patch_size: 16
          d_model: 768
          encoder_embed_dim: 768
          encoder_depth: 12
          encoder_num_heads: 12
          drop_path_rate: 0.2
          num_frames: 12
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 12
          clip_decoder_embed_dim: 768
          clip_output_dim: 512
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 224
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      multimodal: {
          enable: True }
      embed_dim: 512
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 1e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 5
      min_lr_multi: 0.01
      warmup_epochs: 1 }
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: user
      project: umt_ret }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
  resume: False
  debug: False
  log_freq: 100
  seed: 3407
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
  rank: 0
  world_size: 1
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-05-27T18:52:47 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video'], 'test_file': {'test': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test1k.json', '/data2/dy/temporal_video/dataset', 'video']}, 'test_types': ['test'], 'num_workers': 6, 'rtime': False, 'pos_num': 1, 'neg_num': 10, 'stop_key': 'test/', 'is_paragraph_retrieval': False, 'is_pretrain': False, 'num_frames': 12, 'num_frames_test': 12, 'batch_size': 32, 'max_txt_l': 50, 'evaluate': False, 'train_shuffle': False, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 12, 'sample_type': 'rand', 'num_frames_test': 12, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 50, 'video': 50}, 'batch_size': {'image': 32, 'video': 32}, 'batch_size_test': {'image': 32, 'video': 32}}, 'text_enc': 'bert', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_b16', 'img_size': 224, 'patch_size': 16, 'd_model': 768, 'encoder_embed_dim': 768, 'encoder_depth': 12, 'encoder_num_heads': 12, 'drop_path_rate': 0.2, 'num_frames': 12, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 12, 'clip_decoder_embed_dim': 768, 'clip_output_dim': 512, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 224, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'multimodal': {'enable': True}, 'embed_dim': 512, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 1e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 5, 'min_lr_multi': 0.01, 'warmup_epochs': 1}, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': False, 'entity': 'user', 'project': 'umt_ret'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': 'exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 3407, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth', 'rank': 0, 'world_size': 1, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2024-05-27T18:52:47 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
2024-05-27T18:52:47 | INFO | tasks.pretrain : Creating dataset for ret
2024-05-27T18:52:48 | INFO | tasks.shared_utils : Creating model
2024-05-27T18:52:58 | INFO | models.umt : Build vision_encoder: vit_b16
2024-05-27T18:52:58 | INFO | models.backbones.vit.vit : Num of patches: 2352
2024-05-27T18:52:58 | INFO | models.backbones.vit.vit : Use checkpoint: True
2024-05-27T18:52:58 | INFO | models.backbones.vit.vit : Checkpoint number: 12
2024-05-27T18:52:58 | INFO | models.backbones.vit.vit : Student return index: []
2024-05-27T18:53:05 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
2024-05-27T18:53:05 | INFO | models.umt : Build text_encoder bert_base
2024-05-27T18:53:06 | INFO | models.backbones.bert.xbert : build bert with cross_module: ca
2024-05-27T18:53:07 | INFO | models.criterions : Norm type: l2
2024-05-27T18:53:07 | INFO | models.criterions : Loss type: l2
2024-05-27T18:53:07 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-05-27T18:53:07 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:53:07 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:53:07 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:53:07 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:53:07 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:53:07 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:53:07 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:53:07 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:53:07 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:53:07 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:53:07 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:53:07 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:53:07 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:53:07 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:53:07 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:53:07 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:53:07 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:53:07 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:53:07 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:53:07 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:53:07 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:53:07 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:53:07 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:53:07 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:53:07 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:53:07 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:53:07 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:53:07 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:53:07 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:53:07 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:53:07 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:53:07 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:53:07 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:53:07 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:53:07 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:53:07 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:53:07 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:53:07 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:53:07 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:53:07 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:53:07 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:53:07 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:53:07 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:53:07 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:53:07 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:53:07 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:53:07 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:53:07 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:53:07 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:53:07 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:53:07 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:53:07 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:53:07 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:53:07 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:53:07 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:53:07 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:53:07 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:53:07 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:53:07 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:53:07 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:53:07 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:53:07 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:53:07 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:53:07 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:53:07 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:53:07 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:53:07 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:53:07 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:53:07 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:53:07 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:53:07 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:53:07 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:53:07 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0 len(p)=48
2024-05-27T18:53:07 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0.02 len(p)=24
2024-05-27T18:53:07 | INFO | tasks.shared_utils : Auto resuming
2024-05-27T18:53:07 | INFO | tasks.shared_utils : Not found checkpoint in exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
2024-05-27T18:56:07 | INFO | umt : Logging to: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2/train.log
2024-05-27T18:56:07 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
  test_file: {
      test: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test1k.json', '/data2/dy/temporal_video/dataset', 'video'] }
  test_types: ['test']
  num_workers: 6
  rtime: False
  pos_num: 1
  neg_num: 10
  stop_key: test/
  is_paragraph_retrieval: False
  is_pretrain: False
  num_frames: 12
  num_frames_test: 12
  batch_size: 32
  max_txt_l: 50
  evaluate: False
  train_shuffle: False
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 12
          sample_type: rand
          num_frames_test: 12
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 50
          video: 50 }
      batch_size: {
          image: 32
          video: 32 }
      batch_size_test: {
          image: 32
          video: 32 } }
  text_enc: bert
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_b16
          img_size: 224
          patch_size: 16
          d_model: 768
          encoder_embed_dim: 768
          encoder_depth: 12
          encoder_num_heads: 12
          drop_path_rate: 0.2
          num_frames: 12
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 12
          clip_decoder_embed_dim: 768
          clip_output_dim: 512
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 224
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      multimodal: {
          enable: True }
      embed_dim: 512
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 1e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 5
      min_lr_multi: 0.01
      warmup_epochs: 1 }
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: user
      project: umt_ret }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
  resume: False
  debug: False
  log_freq: 100
  seed: 3407
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
  rank: 0
  world_size: 1
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-05-27T18:56:07 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video'], 'test_file': {'test': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test1k.json', '/data2/dy/temporal_video/dataset', 'video']}, 'test_types': ['test'], 'num_workers': 6, 'rtime': False, 'pos_num': 1, 'neg_num': 10, 'stop_key': 'test/', 'is_paragraph_retrieval': False, 'is_pretrain': False, 'num_frames': 12, 'num_frames_test': 12, 'batch_size': 32, 'max_txt_l': 50, 'evaluate': False, 'train_shuffle': False, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 12, 'sample_type': 'rand', 'num_frames_test': 12, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 50, 'video': 50}, 'batch_size': {'image': 32, 'video': 32}, 'batch_size_test': {'image': 32, 'video': 32}}, 'text_enc': 'bert', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_b16', 'img_size': 224, 'patch_size': 16, 'd_model': 768, 'encoder_embed_dim': 768, 'encoder_depth': 12, 'encoder_num_heads': 12, 'drop_path_rate': 0.2, 'num_frames': 12, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 12, 'clip_decoder_embed_dim': 768, 'clip_output_dim': 512, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 224, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'multimodal': {'enable': True}, 'embed_dim': 512, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 1e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 5, 'min_lr_multi': 0.01, 'warmup_epochs': 1}, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': False, 'entity': 'user', 'project': 'umt_ret'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': 'exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 3407, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth', 'rank': 0, 'world_size': 1, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2024-05-27T18:56:07 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
2024-05-27T18:56:07 | INFO | tasks.pretrain : Creating dataset for ret
2024-05-27T18:56:07 | INFO | tasks.shared_utils : Creating model
2024-05-27T18:56:17 | INFO | models.umt : Build vision_encoder: vit_b16
2024-05-27T18:56:17 | INFO | models.backbones.vit.vit : Num of patches: 2352
2024-05-27T18:56:17 | INFO | models.backbones.vit.vit : Use checkpoint: True
2024-05-27T18:56:17 | INFO | models.backbones.vit.vit : Checkpoint number: 12
2024-05-27T18:56:17 | INFO | models.backbones.vit.vit : Student return index: []
2024-05-27T18:56:25 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
2024-05-27T18:56:26 | INFO | models.umt : Build text_encoder bert_base
2024-05-27T18:56:27 | INFO | models.backbones.bert.xbert : build bert with cross_module: ca
2024-05-27T18:56:27 | INFO | models.criterions : Norm type: l2
2024-05-27T18:56:27 | INFO | models.criterions : Loss type: l2
2024-05-27T18:56:27 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-05-27T18:56:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:56:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:56:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:56:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:56:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:56:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:56:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:56:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:56:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:56:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:56:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:56:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:56:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:56:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:56:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:56:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:56:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:56:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:56:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:56:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:56:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:56:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:56:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:56:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:56:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:56:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:56:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:56:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:56:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:56:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:56:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:56:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:56:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:56:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:56:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:56:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:56:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:56:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:56:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:56:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:56:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:56:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:56:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:56:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:56:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:56:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:56:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:56:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:56:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:56:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:56:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:56:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:56:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:56:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:56:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:56:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:56:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:56:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:56:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:56:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:56:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:56:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:56:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:56:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:56:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:56:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:56:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:56:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:56:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:56:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:56:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:56:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:56:27 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0 len(p)=48
2024-05-27T18:56:27 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0.02 len(p)=24
2024-05-27T18:56:27 | INFO | tasks.shared_utils : Auto resuming
2024-05-27T18:56:27 | INFO | tasks.shared_utils : Not found checkpoint in exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
2024-05-27T18:56:28 | INFO | tasks.shared_utils : _IncompatibleKeys(missing_keys=['vision_encoder.encoder.blocks.0.lora_r', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.1.lora_r', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.2.lora_r', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.3.lora_r', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.4.lora_r', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.5.lora_r', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.6.lora_r', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.7.lora_r', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.8.lora_r', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.9.lora_r', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.10.lora_r', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.11.lora_r', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.bias'], unexpected_keys=['clip_teacher.class_embedding', 'clip_teacher.positional_embedding', 'clip_teacher.proj', 'clip_teacher.conv1.weight', 'clip_teacher.ln_pre.weight', 'clip_teacher.ln_pre.bias', 'clip_teacher.transformer.resblocks.0.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.0.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.0.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.0.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.0.ln_1.weight', 'clip_teacher.transformer.resblocks.0.ln_1.bias', 'clip_teacher.transformer.resblocks.0.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.0.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.0.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.0.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.0.ln_2.weight', 'clip_teacher.transformer.resblocks.0.ln_2.bias', 'clip_teacher.transformer.resblocks.1.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.1.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.1.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.1.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.1.ln_1.weight', 'clip_teacher.transformer.resblocks.1.ln_1.bias', 'clip_teacher.transformer.resblocks.1.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.1.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.1.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.1.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.1.ln_2.weight', 'clip_teacher.transformer.resblocks.1.ln_2.bias', 'clip_teacher.transformer.resblocks.2.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.2.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.2.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.2.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.2.ln_1.weight', 'clip_teacher.transformer.resblocks.2.ln_1.bias', 'clip_teacher.transformer.resblocks.2.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.2.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.2.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.2.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.2.ln_2.weight', 'clip_teacher.transformer.resblocks.2.ln_2.bias', 'clip_teacher.transformer.resblocks.3.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.3.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.3.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.3.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.3.ln_1.weight', 'clip_teacher.transformer.resblocks.3.ln_1.bias', 'clip_teacher.transformer.resblocks.3.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.3.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.3.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.3.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.3.ln_2.weight', 'clip_teacher.transformer.resblocks.3.ln_2.bias', 'clip_teacher.transformer.resblocks.4.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.4.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.4.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.4.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.4.ln_1.weight', 'clip_teacher.transformer.resblocks.4.ln_1.bias', 'clip_teacher.transformer.resblocks.4.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.4.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.4.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.4.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.4.ln_2.weight', 'clip_teacher.transformer.resblocks.4.ln_2.bias', 'clip_teacher.transformer.resblocks.5.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.5.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.5.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.5.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.5.ln_1.weight', 'clip_teacher.transformer.resblocks.5.ln_1.bias', 'clip_teacher.transformer.resblocks.5.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.5.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.5.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.5.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.5.ln_2.weight', 'clip_teacher.transformer.resblocks.5.ln_2.bias', 'clip_teacher.transformer.resblocks.6.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.6.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.6.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.6.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.6.ln_1.weight', 'clip_teacher.transformer.resblocks.6.ln_1.bias', 'clip_teacher.transformer.resblocks.6.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.6.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.6.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.6.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.6.ln_2.weight', 'clip_teacher.transformer.resblocks.6.ln_2.bias', 'clip_teacher.transformer.resblocks.7.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.7.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.7.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.7.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.7.ln_1.weight', 'clip_teacher.transformer.resblocks.7.ln_1.bias', 'clip_teacher.transformer.resblocks.7.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.7.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.7.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.7.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.7.ln_2.weight', 'clip_teacher.transformer.resblocks.7.ln_2.bias', 'clip_teacher.transformer.resblocks.8.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.8.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.8.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.8.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.8.ln_1.weight', 'clip_teacher.transformer.resblocks.8.ln_1.bias', 'clip_teacher.transformer.resblocks.8.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.8.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.8.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.8.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.8.ln_2.weight', 'clip_teacher.transformer.resblocks.8.ln_2.bias', 'clip_teacher.transformer.resblocks.9.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.9.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.9.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.9.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.9.ln_1.weight', 'clip_teacher.transformer.resblocks.9.ln_1.bias', 'clip_teacher.transformer.resblocks.9.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.9.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.9.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.9.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.9.ln_2.weight', 'clip_teacher.transformer.resblocks.9.ln_2.bias', 'clip_teacher.transformer.resblocks.10.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.10.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.10.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.10.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.10.ln_1.weight', 'clip_teacher.transformer.resblocks.10.ln_1.bias', 'clip_teacher.transformer.resblocks.10.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.10.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.10.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.10.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.10.ln_2.weight', 'clip_teacher.transformer.resblocks.10.ln_2.bias', 'clip_teacher.transformer.resblocks.11.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.11.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.11.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.11.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.11.ln_1.weight', 'clip_teacher.transformer.resblocks.11.ln_1.bias', 'clip_teacher.transformer.resblocks.11.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.11.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.11.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.11.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.11.ln_2.weight', 'clip_teacher.transformer.resblocks.11.ln_2.bias', 'clip_teacher.ln_post.weight', 'clip_teacher.ln_post.bias', 'vision_encoder.clip_decoder.0.head.weight', 'vision_encoder.clip_decoder.0.head.bias', 'vision_encoder.clip_decoder.0.norm.weight', 'vision_encoder.clip_decoder.0.norm.bias', 'vision_encoder.clip_decoder.1.head.weight', 'vision_encoder.clip_decoder.1.head.bias', 'vision_encoder.clip_decoder.1.norm.weight', 'vision_encoder.clip_decoder.1.norm.bias', 'vision_encoder.clip_decoder.2.head.weight', 'vision_encoder.clip_decoder.2.head.bias', 'vision_encoder.clip_decoder.2.norm.weight', 'vision_encoder.clip_decoder.2.norm.bias', 'vision_encoder.clip_decoder.3.head.weight', 'vision_encoder.clip_decoder.3.head.bias', 'vision_encoder.clip_decoder.3.norm.weight', 'vision_encoder.clip_decoder.3.norm.bias', 'vision_encoder.clip_decoder.4.head.weight', 'vision_encoder.clip_decoder.4.head.bias', 'vision_encoder.clip_decoder.4.norm.weight', 'vision_encoder.clip_decoder.4.norm.bias', 'vision_encoder.clip_decoder.5.head.weight', 'vision_encoder.clip_decoder.5.head.bias', 'vision_encoder.clip_decoder.5.norm.weight', 'vision_encoder.clip_decoder.5.norm.bias', 'text_encoder.cls.predictions.bias', 'text_encoder.cls.predictions.transform.dense.weight', 'text_encoder.cls.predictions.transform.dense.bias', 'text_encoder.cls.predictions.transform.LayerNorm.weight', 'text_encoder.cls.predictions.transform.LayerNorm.bias', 'text_encoder.cls.predictions.decoder.weight', 'text_encoder.cls.predictions.decoder.bias'])
2024-05-27T18:56:28 | INFO | tasks.shared_utils : Loaded checkpoint from /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
2024-05-27T18:56:28 | INFO | __main__ : training
2024-05-27T18:56:29 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T18:56:29 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T18:56:29 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 5792 batches in total
dataloader index=0 name=video, batch-size=32 length(#batches)=5792 
2024-05-27T18:56:29 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T18:56:29 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T18:56:29 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T18:56:29 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T18:56:29 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T18:56:29 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T18:56:29 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T18:56:29 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T18:56:29 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T18:56:29 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T18:56:43 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  builtin_warn(*args, **kwargs)

2024-05-27T18:56:43 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  builtin_warn(*args, **kwargs)

2024-05-27T18:56:43 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-05-27T18:56:43 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-05-27T18:58:38 | INFO | umt : Logging to: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2/train.log
2024-05-27T18:58:38 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
  test_file: {
      test: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test1k.json', '/data2/dy/temporal_video/dataset', 'video'] }
  test_types: ['test']
  num_workers: 6
  rtime: False
  pos_num: 1
  neg_num: 10
  stop_key: test/
  is_paragraph_retrieval: False
  is_pretrain: False
  num_frames: 12
  num_frames_test: 12
  batch_size: 32
  max_txt_l: 50
  evaluate: False
  train_shuffle: False
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 12
          sample_type: rand
          num_frames_test: 12
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 50
          video: 50 }
      batch_size: {
          image: 32
          video: 32 }
      batch_size_test: {
          image: 32
          video: 32 } }
  text_enc: bert
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_b16
          img_size: 224
          patch_size: 16
          d_model: 768
          encoder_embed_dim: 768
          encoder_depth: 12
          encoder_num_heads: 12
          drop_path_rate: 0.2
          num_frames: 12
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 12
          clip_decoder_embed_dim: 768
          clip_output_dim: 512
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 224
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      multimodal: {
          enable: True }
      embed_dim: 512
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 1e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 5
      min_lr_multi: 0.01
      warmup_epochs: 1 }
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: user
      project: umt_ret }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
  resume: False
  debug: False
  log_freq: 100
  seed: 3407
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
  rank: 0
  world_size: 1
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-05-27T18:58:38 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video'], 'test_file': {'test': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test1k.json', '/data2/dy/temporal_video/dataset', 'video']}, 'test_types': ['test'], 'num_workers': 6, 'rtime': False, 'pos_num': 1, 'neg_num': 10, 'stop_key': 'test/', 'is_paragraph_retrieval': False, 'is_pretrain': False, 'num_frames': 12, 'num_frames_test': 12, 'batch_size': 32, 'max_txt_l': 50, 'evaluate': False, 'train_shuffle': False, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 12, 'sample_type': 'rand', 'num_frames_test': 12, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 50, 'video': 50}, 'batch_size': {'image': 32, 'video': 32}, 'batch_size_test': {'image': 32, 'video': 32}}, 'text_enc': 'bert', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_b16', 'img_size': 224, 'patch_size': 16, 'd_model': 768, 'encoder_embed_dim': 768, 'encoder_depth': 12, 'encoder_num_heads': 12, 'drop_path_rate': 0.2, 'num_frames': 12, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 12, 'clip_decoder_embed_dim': 768, 'clip_output_dim': 512, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 224, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'multimodal': {'enable': True}, 'embed_dim': 512, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 1e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 5, 'min_lr_multi': 0.01, 'warmup_epochs': 1}, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': False, 'entity': 'user', 'project': 'umt_ret'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': 'exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 3407, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth', 'rank': 0, 'world_size': 1, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2024-05-27T18:58:38 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
2024-05-27T18:58:38 | INFO | tasks.pretrain : Creating dataset for ret
2024-05-27T18:58:39 | INFO | tasks.shared_utils : Creating model
2024-05-27T18:58:49 | INFO | models.umt : Build vision_encoder: vit_b16
2024-05-27T18:58:49 | INFO | models.backbones.vit.vit : Num of patches: 2352
2024-05-27T18:58:49 | INFO | models.backbones.vit.vit : Use checkpoint: True
2024-05-27T18:58:49 | INFO | models.backbones.vit.vit : Checkpoint number: 12
2024-05-27T18:58:49 | INFO | models.backbones.vit.vit : Student return index: []
2024-05-27T18:58:56 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
2024-05-27T18:58:56 | INFO | models.umt : Build text_encoder bert_base
2024-05-27T18:58:58 | INFO | models.backbones.bert.xbert : build bert with cross_module: ca
2024-05-27T18:58:58 | INFO | models.criterions : Norm type: l2
2024-05-27T18:58:58 | INFO | models.criterions : Loss type: l2
2024-05-27T18:58:58 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-05-27T18:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.lora_r: wd: 0, lr: 1e-05
2024-05-27T18:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T18:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T18:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T18:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T18:58:58 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0 len(p)=48
2024-05-27T18:58:58 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0.02 len(p)=24
2024-05-27T18:58:58 | INFO | tasks.shared_utils : Auto resuming
2024-05-27T18:58:58 | INFO | tasks.shared_utils : Not found checkpoint in exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
2024-05-27T19:03:27 | INFO | umt : Logging to: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2/train.log
2024-05-27T19:03:27 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
  test_file: {
      test: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test1k.json', '/data2/dy/temporal_video/dataset', 'video'] }
  test_types: ['test']
  num_workers: 6
  rtime: False
  pos_num: 1
  neg_num: 10
  stop_key: test/
  is_paragraph_retrieval: False
  is_pretrain: False
  num_frames: 12
  num_frames_test: 12
  batch_size: 32
  max_txt_l: 50
  evaluate: False
  train_shuffle: False
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 12
          sample_type: rand
          num_frames_test: 12
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 50
          video: 50 }
      batch_size: {
          image: 32
          video: 32 }
      batch_size_test: {
          image: 32
          video: 32 } }
  text_enc: bert
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_b16
          img_size: 224
          patch_size: 16
          d_model: 768
          encoder_embed_dim: 768
          encoder_depth: 12
          encoder_num_heads: 12
          drop_path_rate: 0.2
          num_frames: 12
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 12
          clip_decoder_embed_dim: 768
          clip_output_dim: 512
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 224
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      multimodal: {
          enable: True }
      embed_dim: 512
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 1e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 5
      min_lr_multi: 0.01
      warmup_epochs: 1 }
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: user
      project: umt_ret }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
  resume: False
  debug: False
  log_freq: 100
  seed: 3407
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
  rank: 0
  world_size: 1
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-05-27T19:03:27 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video'], 'test_file': {'test': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test1k.json', '/data2/dy/temporal_video/dataset', 'video']}, 'test_types': ['test'], 'num_workers': 6, 'rtime': False, 'pos_num': 1, 'neg_num': 10, 'stop_key': 'test/', 'is_paragraph_retrieval': False, 'is_pretrain': False, 'num_frames': 12, 'num_frames_test': 12, 'batch_size': 32, 'max_txt_l': 50, 'evaluate': False, 'train_shuffle': False, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 12, 'sample_type': 'rand', 'num_frames_test': 12, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 50, 'video': 50}, 'batch_size': {'image': 32, 'video': 32}, 'batch_size_test': {'image': 32, 'video': 32}}, 'text_enc': 'bert', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_b16', 'img_size': 224, 'patch_size': 16, 'd_model': 768, 'encoder_embed_dim': 768, 'encoder_depth': 12, 'encoder_num_heads': 12, 'drop_path_rate': 0.2, 'num_frames': 12, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 12, 'clip_decoder_embed_dim': 768, 'clip_output_dim': 512, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 224, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'multimodal': {'enable': True}, 'embed_dim': 512, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 1e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 5, 'min_lr_multi': 0.01, 'warmup_epochs': 1}, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': False, 'entity': 'user', 'project': 'umt_ret'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': 'exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 3407, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth', 'rank': 0, 'world_size': 1, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2024-05-27T19:03:27 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
2024-05-27T19:03:27 | INFO | tasks.pretrain : Creating dataset for ret
2024-05-27T19:03:28 | INFO | tasks.shared_utils : Creating model
2024-05-27T19:04:08 | INFO | models.umt : Build vision_encoder: vit_b16
2024-05-27T19:04:08 | INFO | models.backbones.vit.vit : Num of patches: 2352
2024-05-27T19:04:08 | INFO | models.backbones.vit.vit : Use checkpoint: True
2024-05-27T19:04:08 | INFO | models.backbones.vit.vit : Checkpoint number: 12
2024-05-27T19:04:08 | INFO | models.backbones.vit.vit : Student return index: []
2024-05-27T19:04:15 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
2024-05-27T19:04:16 | INFO | models.umt : Build text_encoder bert_base
2024-05-27T19:04:17 | INFO | models.backbones.bert.xbert : build bert with cross_module: ca
2024-05-27T19:04:17 | INFO | models.criterions : Norm type: l2
2024-05-27T19:04:17 | INFO | models.criterions : Loss type: l2
2024-05-27T19:04:17 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-05-27T19:04:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:04:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:04:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:04:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:04:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:04:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:04:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:04:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:04:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:04:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:04:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:04:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:04:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:04:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:04:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:04:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:04:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:04:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:04:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:04:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:04:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:04:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:04:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:04:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:04:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:04:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:04:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:04:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:04:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:04:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:04:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:04:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:04:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:04:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:04:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:04:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:04:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:04:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:04:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:04:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:04:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:04:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:04:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:04:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:04:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:04:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:04:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:04:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:04:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:04:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:04:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:04:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:04:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:04:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:04:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:04:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:04:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:04:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:04:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:04:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:04:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:04:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:04:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:04:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:04:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:04:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:04:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:04:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:04:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:04:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:04:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:04:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:04:17 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0 len(p)=48
2024-05-27T19:04:17 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0.02 len(p)=24
2024-05-27T19:04:17 | INFO | tasks.shared_utils : Auto resuming
2024-05-27T19:04:17 | INFO | tasks.shared_utils : Not found checkpoint in exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
2024-05-27T19:04:27 | INFO | tasks.shared_utils : _IncompatibleKeys(missing_keys=['vision_encoder.encoder.blocks.0.lora_r', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.1.lora_r', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.2.lora_r', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.3.lora_r', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.4.lora_r', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.5.lora_r', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.6.lora_r', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.7.lora_r', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.8.lora_r', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.9.lora_r', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.10.lora_r', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.11.lora_r', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.bias'], unexpected_keys=['clip_teacher.class_embedding', 'clip_teacher.positional_embedding', 'clip_teacher.proj', 'clip_teacher.conv1.weight', 'clip_teacher.ln_pre.weight', 'clip_teacher.ln_pre.bias', 'clip_teacher.transformer.resblocks.0.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.0.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.0.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.0.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.0.ln_1.weight', 'clip_teacher.transformer.resblocks.0.ln_1.bias', 'clip_teacher.transformer.resblocks.0.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.0.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.0.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.0.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.0.ln_2.weight', 'clip_teacher.transformer.resblocks.0.ln_2.bias', 'clip_teacher.transformer.resblocks.1.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.1.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.1.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.1.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.1.ln_1.weight', 'clip_teacher.transformer.resblocks.1.ln_1.bias', 'clip_teacher.transformer.resblocks.1.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.1.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.1.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.1.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.1.ln_2.weight', 'clip_teacher.transformer.resblocks.1.ln_2.bias', 'clip_teacher.transformer.resblocks.2.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.2.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.2.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.2.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.2.ln_1.weight', 'clip_teacher.transformer.resblocks.2.ln_1.bias', 'clip_teacher.transformer.resblocks.2.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.2.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.2.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.2.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.2.ln_2.weight', 'clip_teacher.transformer.resblocks.2.ln_2.bias', 'clip_teacher.transformer.resblocks.3.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.3.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.3.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.3.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.3.ln_1.weight', 'clip_teacher.transformer.resblocks.3.ln_1.bias', 'clip_teacher.transformer.resblocks.3.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.3.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.3.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.3.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.3.ln_2.weight', 'clip_teacher.transformer.resblocks.3.ln_2.bias', 'clip_teacher.transformer.resblocks.4.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.4.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.4.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.4.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.4.ln_1.weight', 'clip_teacher.transformer.resblocks.4.ln_1.bias', 'clip_teacher.transformer.resblocks.4.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.4.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.4.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.4.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.4.ln_2.weight', 'clip_teacher.transformer.resblocks.4.ln_2.bias', 'clip_teacher.transformer.resblocks.5.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.5.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.5.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.5.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.5.ln_1.weight', 'clip_teacher.transformer.resblocks.5.ln_1.bias', 'clip_teacher.transformer.resblocks.5.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.5.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.5.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.5.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.5.ln_2.weight', 'clip_teacher.transformer.resblocks.5.ln_2.bias', 'clip_teacher.transformer.resblocks.6.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.6.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.6.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.6.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.6.ln_1.weight', 'clip_teacher.transformer.resblocks.6.ln_1.bias', 'clip_teacher.transformer.resblocks.6.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.6.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.6.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.6.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.6.ln_2.weight', 'clip_teacher.transformer.resblocks.6.ln_2.bias', 'clip_teacher.transformer.resblocks.7.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.7.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.7.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.7.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.7.ln_1.weight', 'clip_teacher.transformer.resblocks.7.ln_1.bias', 'clip_teacher.transformer.resblocks.7.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.7.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.7.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.7.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.7.ln_2.weight', 'clip_teacher.transformer.resblocks.7.ln_2.bias', 'clip_teacher.transformer.resblocks.8.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.8.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.8.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.8.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.8.ln_1.weight', 'clip_teacher.transformer.resblocks.8.ln_1.bias', 'clip_teacher.transformer.resblocks.8.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.8.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.8.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.8.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.8.ln_2.weight', 'clip_teacher.transformer.resblocks.8.ln_2.bias', 'clip_teacher.transformer.resblocks.9.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.9.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.9.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.9.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.9.ln_1.weight', 'clip_teacher.transformer.resblocks.9.ln_1.bias', 'clip_teacher.transformer.resblocks.9.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.9.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.9.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.9.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.9.ln_2.weight', 'clip_teacher.transformer.resblocks.9.ln_2.bias', 'clip_teacher.transformer.resblocks.10.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.10.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.10.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.10.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.10.ln_1.weight', 'clip_teacher.transformer.resblocks.10.ln_1.bias', 'clip_teacher.transformer.resblocks.10.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.10.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.10.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.10.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.10.ln_2.weight', 'clip_teacher.transformer.resblocks.10.ln_2.bias', 'clip_teacher.transformer.resblocks.11.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.11.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.11.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.11.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.11.ln_1.weight', 'clip_teacher.transformer.resblocks.11.ln_1.bias', 'clip_teacher.transformer.resblocks.11.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.11.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.11.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.11.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.11.ln_2.weight', 'clip_teacher.transformer.resblocks.11.ln_2.bias', 'clip_teacher.ln_post.weight', 'clip_teacher.ln_post.bias', 'vision_encoder.clip_decoder.0.head.weight', 'vision_encoder.clip_decoder.0.head.bias', 'vision_encoder.clip_decoder.0.norm.weight', 'vision_encoder.clip_decoder.0.norm.bias', 'vision_encoder.clip_decoder.1.head.weight', 'vision_encoder.clip_decoder.1.head.bias', 'vision_encoder.clip_decoder.1.norm.weight', 'vision_encoder.clip_decoder.1.norm.bias', 'vision_encoder.clip_decoder.2.head.weight', 'vision_encoder.clip_decoder.2.head.bias', 'vision_encoder.clip_decoder.2.norm.weight', 'vision_encoder.clip_decoder.2.norm.bias', 'vision_encoder.clip_decoder.3.head.weight', 'vision_encoder.clip_decoder.3.head.bias', 'vision_encoder.clip_decoder.3.norm.weight', 'vision_encoder.clip_decoder.3.norm.bias', 'vision_encoder.clip_decoder.4.head.weight', 'vision_encoder.clip_decoder.4.head.bias', 'vision_encoder.clip_decoder.4.norm.weight', 'vision_encoder.clip_decoder.4.norm.bias', 'vision_encoder.clip_decoder.5.head.weight', 'vision_encoder.clip_decoder.5.head.bias', 'vision_encoder.clip_decoder.5.norm.weight', 'vision_encoder.clip_decoder.5.norm.bias', 'text_encoder.cls.predictions.bias', 'text_encoder.cls.predictions.transform.dense.weight', 'text_encoder.cls.predictions.transform.dense.bias', 'text_encoder.cls.predictions.transform.LayerNorm.weight', 'text_encoder.cls.predictions.transform.LayerNorm.bias', 'text_encoder.cls.predictions.decoder.weight', 'text_encoder.cls.predictions.decoder.bias'])
2024-05-27T19:04:27 | INFO | tasks.shared_utils : Loaded checkpoint from /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
2024-05-27T19:04:27 | INFO | __main__ : training
2024-05-27T19:04:28 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 5792 batches in total
dataloader index=0 name=video, batch-size=32 length(#batches)=5792 
2024-05-27T19:04:28 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:04:28 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:04:28 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:04:28 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:04:28 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:04:28 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:04:28 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:04:28 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:04:28 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:04:28 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:04:28 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:04:28 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:04:41 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  builtin_warn(*args, **kwargs)

2024-05-27T19:04:41 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  builtin_warn(*args, **kwargs)

2024-05-27T19:04:41 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-05-27T19:04:41 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-05-27T19:08:45 | INFO | umt : Logging to: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2/train.log
2024-05-27T19:08:45 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
  test_file: {
      test: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test1k.json', '/data2/dy/temporal_video/dataset', 'video'] }
  test_types: ['test']
  num_workers: 6
  rtime: False
  pos_num: 1
  neg_num: 10
  stop_key: test/
  is_paragraph_retrieval: False
  is_pretrain: False
  num_frames: 12
  num_frames_test: 12
  batch_size: 32
  max_txt_l: 50
  evaluate: False
  train_shuffle: False
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 12
          sample_type: rand
          num_frames_test: 12
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 50
          video: 50 }
      batch_size: {
          image: 32
          video: 32 }
      batch_size_test: {
          image: 32
          video: 32 } }
  text_enc: bert
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_b16
          img_size: 224
          patch_size: 16
          d_model: 768
          encoder_embed_dim: 768
          encoder_depth: 12
          encoder_num_heads: 12
          drop_path_rate: 0.2
          num_frames: 12
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 12
          clip_decoder_embed_dim: 768
          clip_output_dim: 512
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 224
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      multimodal: {
          enable: True }
      embed_dim: 512
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 1e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 5
      min_lr_multi: 0.01
      warmup_epochs: 1 }
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: user
      project: umt_ret }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
  resume: False
  debug: False
  log_freq: 100
  seed: 3407
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
  rank: 0
  world_size: 1
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-05-27T19:08:45 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video'], 'test_file': {'test': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test1k.json', '/data2/dy/temporal_video/dataset', 'video']}, 'test_types': ['test'], 'num_workers': 6, 'rtime': False, 'pos_num': 1, 'neg_num': 10, 'stop_key': 'test/', 'is_paragraph_retrieval': False, 'is_pretrain': False, 'num_frames': 12, 'num_frames_test': 12, 'batch_size': 32, 'max_txt_l': 50, 'evaluate': False, 'train_shuffle': False, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 12, 'sample_type': 'rand', 'num_frames_test': 12, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 50, 'video': 50}, 'batch_size': {'image': 32, 'video': 32}, 'batch_size_test': {'image': 32, 'video': 32}}, 'text_enc': 'bert', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_b16', 'img_size': 224, 'patch_size': 16, 'd_model': 768, 'encoder_embed_dim': 768, 'encoder_depth': 12, 'encoder_num_heads': 12, 'drop_path_rate': 0.2, 'num_frames': 12, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 12, 'clip_decoder_embed_dim': 768, 'clip_output_dim': 512, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 224, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'multimodal': {'enable': True}, 'embed_dim': 512, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 1e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 5, 'min_lr_multi': 0.01, 'warmup_epochs': 1}, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': False, 'entity': 'user', 'project': 'umt_ret'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': 'exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 3407, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth', 'rank': 0, 'world_size': 1, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2024-05-27T19:08:45 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
2024-05-27T19:08:45 | INFO | tasks.pretrain : Creating dataset for ret
2024-05-27T19:08:46 | INFO | tasks.shared_utils : Creating model
2024-05-27T19:08:56 | INFO | models.umt : Build vision_encoder: vit_b16
2024-05-27T19:08:56 | INFO | models.backbones.vit.vit : Num of patches: 2352
2024-05-27T19:08:56 | INFO | models.backbones.vit.vit : Use checkpoint: True
2024-05-27T19:08:56 | INFO | models.backbones.vit.vit : Checkpoint number: 12
2024-05-27T19:08:56 | INFO | models.backbones.vit.vit : Student return index: []
2024-05-27T19:09:03 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
2024-05-27T19:09:04 | INFO | models.umt : Build text_encoder bert_base
2024-05-27T19:09:05 | INFO | models.backbones.bert.xbert : build bert with cross_module: ca
2024-05-27T19:09:05 | INFO | models.criterions : Norm type: l2
2024-05-27T19:09:05 | INFO | models.criterions : Loss type: l2
2024-05-27T19:09:05 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-05-27T19:09:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:09:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:09:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:09:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:09:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:09:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:09:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:09:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:09:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:09:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:09:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:09:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:09:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:09:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:09:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:09:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:09:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:09:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:09:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:09:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:09:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:09:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:09:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:09:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:09:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:09:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:09:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:09:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:09:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:09:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:09:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:09:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:09:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:09:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:09:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:09:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:09:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:09:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:09:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:09:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:09:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:09:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:09:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:09:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:09:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:09:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:09:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:09:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:09:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:09:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:09:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:09:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:09:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:09:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:09:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:09:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:09:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:09:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:09:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:09:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:09:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:09:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:09:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:09:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:09:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:09:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:09:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:09:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:09:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:09:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:09:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:09:05 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:09:05 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0 len(p)=48
2024-05-27T19:09:05 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0.02 len(p)=24
2024-05-27T19:09:05 | INFO | tasks.shared_utils : Auto resuming
2024-05-27T19:09:05 | INFO | tasks.shared_utils : Not found checkpoint in exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
2024-05-27T19:09:21 | INFO | tasks.shared_utils : _IncompatibleKeys(missing_keys=['vision_encoder.encoder.blocks.0.lora_r', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.1.lora_r', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.2.lora_r', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.3.lora_r', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.4.lora_r', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.5.lora_r', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.6.lora_r', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.7.lora_r', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.8.lora_r', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.9.lora_r', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.10.lora_r', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.11.lora_r', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.bias'], unexpected_keys=['clip_teacher.class_embedding', 'clip_teacher.positional_embedding', 'clip_teacher.proj', 'clip_teacher.conv1.weight', 'clip_teacher.ln_pre.weight', 'clip_teacher.ln_pre.bias', 'clip_teacher.transformer.resblocks.0.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.0.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.0.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.0.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.0.ln_1.weight', 'clip_teacher.transformer.resblocks.0.ln_1.bias', 'clip_teacher.transformer.resblocks.0.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.0.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.0.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.0.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.0.ln_2.weight', 'clip_teacher.transformer.resblocks.0.ln_2.bias', 'clip_teacher.transformer.resblocks.1.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.1.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.1.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.1.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.1.ln_1.weight', 'clip_teacher.transformer.resblocks.1.ln_1.bias', 'clip_teacher.transformer.resblocks.1.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.1.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.1.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.1.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.1.ln_2.weight', 'clip_teacher.transformer.resblocks.1.ln_2.bias', 'clip_teacher.transformer.resblocks.2.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.2.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.2.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.2.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.2.ln_1.weight', 'clip_teacher.transformer.resblocks.2.ln_1.bias', 'clip_teacher.transformer.resblocks.2.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.2.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.2.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.2.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.2.ln_2.weight', 'clip_teacher.transformer.resblocks.2.ln_2.bias', 'clip_teacher.transformer.resblocks.3.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.3.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.3.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.3.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.3.ln_1.weight', 'clip_teacher.transformer.resblocks.3.ln_1.bias', 'clip_teacher.transformer.resblocks.3.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.3.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.3.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.3.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.3.ln_2.weight', 'clip_teacher.transformer.resblocks.3.ln_2.bias', 'clip_teacher.transformer.resblocks.4.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.4.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.4.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.4.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.4.ln_1.weight', 'clip_teacher.transformer.resblocks.4.ln_1.bias', 'clip_teacher.transformer.resblocks.4.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.4.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.4.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.4.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.4.ln_2.weight', 'clip_teacher.transformer.resblocks.4.ln_2.bias', 'clip_teacher.transformer.resblocks.5.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.5.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.5.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.5.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.5.ln_1.weight', 'clip_teacher.transformer.resblocks.5.ln_1.bias', 'clip_teacher.transformer.resblocks.5.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.5.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.5.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.5.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.5.ln_2.weight', 'clip_teacher.transformer.resblocks.5.ln_2.bias', 'clip_teacher.transformer.resblocks.6.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.6.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.6.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.6.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.6.ln_1.weight', 'clip_teacher.transformer.resblocks.6.ln_1.bias', 'clip_teacher.transformer.resblocks.6.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.6.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.6.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.6.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.6.ln_2.weight', 'clip_teacher.transformer.resblocks.6.ln_2.bias', 'clip_teacher.transformer.resblocks.7.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.7.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.7.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.7.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.7.ln_1.weight', 'clip_teacher.transformer.resblocks.7.ln_1.bias', 'clip_teacher.transformer.resblocks.7.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.7.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.7.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.7.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.7.ln_2.weight', 'clip_teacher.transformer.resblocks.7.ln_2.bias', 'clip_teacher.transformer.resblocks.8.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.8.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.8.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.8.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.8.ln_1.weight', 'clip_teacher.transformer.resblocks.8.ln_1.bias', 'clip_teacher.transformer.resblocks.8.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.8.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.8.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.8.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.8.ln_2.weight', 'clip_teacher.transformer.resblocks.8.ln_2.bias', 'clip_teacher.transformer.resblocks.9.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.9.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.9.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.9.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.9.ln_1.weight', 'clip_teacher.transformer.resblocks.9.ln_1.bias', 'clip_teacher.transformer.resblocks.9.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.9.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.9.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.9.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.9.ln_2.weight', 'clip_teacher.transformer.resblocks.9.ln_2.bias', 'clip_teacher.transformer.resblocks.10.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.10.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.10.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.10.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.10.ln_1.weight', 'clip_teacher.transformer.resblocks.10.ln_1.bias', 'clip_teacher.transformer.resblocks.10.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.10.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.10.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.10.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.10.ln_2.weight', 'clip_teacher.transformer.resblocks.10.ln_2.bias', 'clip_teacher.transformer.resblocks.11.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.11.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.11.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.11.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.11.ln_1.weight', 'clip_teacher.transformer.resblocks.11.ln_1.bias', 'clip_teacher.transformer.resblocks.11.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.11.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.11.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.11.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.11.ln_2.weight', 'clip_teacher.transformer.resblocks.11.ln_2.bias', 'clip_teacher.ln_post.weight', 'clip_teacher.ln_post.bias', 'vision_encoder.clip_decoder.0.head.weight', 'vision_encoder.clip_decoder.0.head.bias', 'vision_encoder.clip_decoder.0.norm.weight', 'vision_encoder.clip_decoder.0.norm.bias', 'vision_encoder.clip_decoder.1.head.weight', 'vision_encoder.clip_decoder.1.head.bias', 'vision_encoder.clip_decoder.1.norm.weight', 'vision_encoder.clip_decoder.1.norm.bias', 'vision_encoder.clip_decoder.2.head.weight', 'vision_encoder.clip_decoder.2.head.bias', 'vision_encoder.clip_decoder.2.norm.weight', 'vision_encoder.clip_decoder.2.norm.bias', 'vision_encoder.clip_decoder.3.head.weight', 'vision_encoder.clip_decoder.3.head.bias', 'vision_encoder.clip_decoder.3.norm.weight', 'vision_encoder.clip_decoder.3.norm.bias', 'vision_encoder.clip_decoder.4.head.weight', 'vision_encoder.clip_decoder.4.head.bias', 'vision_encoder.clip_decoder.4.norm.weight', 'vision_encoder.clip_decoder.4.norm.bias', 'vision_encoder.clip_decoder.5.head.weight', 'vision_encoder.clip_decoder.5.head.bias', 'vision_encoder.clip_decoder.5.norm.weight', 'vision_encoder.clip_decoder.5.norm.bias', 'text_encoder.cls.predictions.bias', 'text_encoder.cls.predictions.transform.dense.weight', 'text_encoder.cls.predictions.transform.dense.bias', 'text_encoder.cls.predictions.transform.LayerNorm.weight', 'text_encoder.cls.predictions.transform.LayerNorm.bias', 'text_encoder.cls.predictions.decoder.weight', 'text_encoder.cls.predictions.decoder.bias'])
2024-05-27T19:09:21 | INFO | tasks.shared_utils : Loaded checkpoint from /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
2024-05-27T19:09:21 | INFO | __main__ : training
2024-05-27T19:09:22 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:09:22 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:09:22 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:09:22 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:09:22 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 5792 batches in total
dataloader index=0 name=video, batch-size=32 length(#batches)=5792 
2024-05-27T19:09:22 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:09:22 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:09:22 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:09:22 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:09:22 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:09:22 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:09:22 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:09:22 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:09:36 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  builtin_warn(*args, **kwargs)

2024-05-27T19:09:36 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  builtin_warn(*args, **kwargs)

2024-05-27T19:09:36 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-05-27T19:09:36 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-05-27T19:12:22 | INFO | umt : Logging to: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2/train.log
2024-05-27T19:12:22 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
  test_file: {
      test: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test1k.json', '/data2/dy/temporal_video/dataset', 'video'] }
  test_types: ['test']
  num_workers: 6
  rtime: False
  pos_num: 1
  neg_num: 10
  stop_key: test/
  is_paragraph_retrieval: False
  is_pretrain: False
  num_frames: 12
  num_frames_test: 12
  batch_size: 32
  max_txt_l: 50
  evaluate: False
  train_shuffle: False
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 12
          sample_type: rand
          num_frames_test: 12
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 50
          video: 50 }
      batch_size: {
          image: 32
          video: 32 }
      batch_size_test: {
          image: 32
          video: 32 } }
  text_enc: bert
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_b16
          img_size: 224
          patch_size: 16
          d_model: 768
          encoder_embed_dim: 768
          encoder_depth: 12
          encoder_num_heads: 12
          drop_path_rate: 0.2
          num_frames: 12
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 12
          clip_decoder_embed_dim: 768
          clip_output_dim: 512
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 224
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      multimodal: {
          enable: True }
      embed_dim: 512
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 1e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 5
      min_lr_multi: 0.01
      warmup_epochs: 1 }
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: user
      project: umt_ret }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
  resume: False
  debug: False
  log_freq: 100
  seed: 3407
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
  rank: 0
  world_size: 1
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-05-27T19:12:22 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video'], 'test_file': {'test': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test1k.json', '/data2/dy/temporal_video/dataset', 'video']}, 'test_types': ['test'], 'num_workers': 6, 'rtime': False, 'pos_num': 1, 'neg_num': 10, 'stop_key': 'test/', 'is_paragraph_retrieval': False, 'is_pretrain': False, 'num_frames': 12, 'num_frames_test': 12, 'batch_size': 32, 'max_txt_l': 50, 'evaluate': False, 'train_shuffle': False, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 12, 'sample_type': 'rand', 'num_frames_test': 12, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 50, 'video': 50}, 'batch_size': {'image': 32, 'video': 32}, 'batch_size_test': {'image': 32, 'video': 32}}, 'text_enc': 'bert', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_b16', 'img_size': 224, 'patch_size': 16, 'd_model': 768, 'encoder_embed_dim': 768, 'encoder_depth': 12, 'encoder_num_heads': 12, 'drop_path_rate': 0.2, 'num_frames': 12, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 12, 'clip_decoder_embed_dim': 768, 'clip_output_dim': 512, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 224, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'multimodal': {'enable': True}, 'embed_dim': 512, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 1e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 5, 'min_lr_multi': 0.01, 'warmup_epochs': 1}, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': False, 'entity': 'user', 'project': 'umt_ret'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': 'exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 3407, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth', 'rank': 0, 'world_size': 1, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2024-05-27T19:12:22 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
2024-05-27T19:12:22 | INFO | tasks.pretrain : Creating dataset for ret
2024-05-27T19:12:23 | INFO | tasks.shared_utils : Creating model
2024-05-27T19:12:33 | INFO | models.umt : Build vision_encoder: vit_b16
2024-05-27T19:12:33 | INFO | models.backbones.vit.vit : Num of patches: 2352
2024-05-27T19:12:33 | INFO | models.backbones.vit.vit : Use checkpoint: True
2024-05-27T19:12:33 | INFO | models.backbones.vit.vit : Checkpoint number: 12
2024-05-27T19:12:33 | INFO | models.backbones.vit.vit : Student return index: []
2024-05-27T19:12:40 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
2024-05-27T19:12:41 | INFO | models.umt : Build text_encoder bert_base
2024-05-27T19:12:42 | INFO | models.backbones.bert.xbert : build bert with cross_module: ca
2024-05-27T19:12:42 | INFO | models.criterions : Norm type: l2
2024-05-27T19:12:42 | INFO | models.criterions : Loss type: l2
2024-05-27T19:12:42 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-05-27T19:12:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:12:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:12:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:12:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:12:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:12:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:12:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:12:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:12:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:12:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:12:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:12:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:12:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:12:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:12:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:12:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:12:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:12:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:12:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:12:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:12:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:12:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:12:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:12:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:12:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:12:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:12:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:12:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:12:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:12:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:12:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:12:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:12:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:12:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:12:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:12:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:12:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:12:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:12:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:12:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:12:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:12:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:12:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:12:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:12:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:12:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:12:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:12:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:12:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:12:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:12:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:12:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:12:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:12:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:12:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:12:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:12:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:12:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:12:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:12:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:12:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:12:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:12:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:12:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:12:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:12:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:12:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:12:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:12:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:12:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:12:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:12:42 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:12:42 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0 len(p)=48
2024-05-27T19:12:42 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0.02 len(p)=24
2024-05-27T19:12:42 | INFO | tasks.shared_utils : Auto resuming
2024-05-27T19:12:42 | INFO | tasks.shared_utils : Not found checkpoint in exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
2024-05-27T19:12:45 | INFO | tasks.shared_utils : _IncompatibleKeys(missing_keys=['vision_encoder.encoder.blocks.0.lora_r', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.1.lora_r', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.2.lora_r', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.3.lora_r', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.4.lora_r', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.5.lora_r', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.6.lora_r', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.7.lora_r', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.8.lora_r', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.9.lora_r', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.10.lora_r', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.11.lora_r', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.bias'], unexpected_keys=['clip_teacher.class_embedding', 'clip_teacher.positional_embedding', 'clip_teacher.proj', 'clip_teacher.conv1.weight', 'clip_teacher.ln_pre.weight', 'clip_teacher.ln_pre.bias', 'clip_teacher.transformer.resblocks.0.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.0.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.0.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.0.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.0.ln_1.weight', 'clip_teacher.transformer.resblocks.0.ln_1.bias', 'clip_teacher.transformer.resblocks.0.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.0.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.0.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.0.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.0.ln_2.weight', 'clip_teacher.transformer.resblocks.0.ln_2.bias', 'clip_teacher.transformer.resblocks.1.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.1.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.1.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.1.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.1.ln_1.weight', 'clip_teacher.transformer.resblocks.1.ln_1.bias', 'clip_teacher.transformer.resblocks.1.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.1.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.1.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.1.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.1.ln_2.weight', 'clip_teacher.transformer.resblocks.1.ln_2.bias', 'clip_teacher.transformer.resblocks.2.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.2.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.2.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.2.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.2.ln_1.weight', 'clip_teacher.transformer.resblocks.2.ln_1.bias', 'clip_teacher.transformer.resblocks.2.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.2.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.2.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.2.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.2.ln_2.weight', 'clip_teacher.transformer.resblocks.2.ln_2.bias', 'clip_teacher.transformer.resblocks.3.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.3.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.3.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.3.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.3.ln_1.weight', 'clip_teacher.transformer.resblocks.3.ln_1.bias', 'clip_teacher.transformer.resblocks.3.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.3.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.3.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.3.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.3.ln_2.weight', 'clip_teacher.transformer.resblocks.3.ln_2.bias', 'clip_teacher.transformer.resblocks.4.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.4.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.4.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.4.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.4.ln_1.weight', 'clip_teacher.transformer.resblocks.4.ln_1.bias', 'clip_teacher.transformer.resblocks.4.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.4.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.4.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.4.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.4.ln_2.weight', 'clip_teacher.transformer.resblocks.4.ln_2.bias', 'clip_teacher.transformer.resblocks.5.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.5.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.5.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.5.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.5.ln_1.weight', 'clip_teacher.transformer.resblocks.5.ln_1.bias', 'clip_teacher.transformer.resblocks.5.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.5.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.5.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.5.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.5.ln_2.weight', 'clip_teacher.transformer.resblocks.5.ln_2.bias', 'clip_teacher.transformer.resblocks.6.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.6.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.6.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.6.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.6.ln_1.weight', 'clip_teacher.transformer.resblocks.6.ln_1.bias', 'clip_teacher.transformer.resblocks.6.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.6.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.6.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.6.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.6.ln_2.weight', 'clip_teacher.transformer.resblocks.6.ln_2.bias', 'clip_teacher.transformer.resblocks.7.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.7.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.7.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.7.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.7.ln_1.weight', 'clip_teacher.transformer.resblocks.7.ln_1.bias', 'clip_teacher.transformer.resblocks.7.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.7.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.7.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.7.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.7.ln_2.weight', 'clip_teacher.transformer.resblocks.7.ln_2.bias', 'clip_teacher.transformer.resblocks.8.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.8.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.8.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.8.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.8.ln_1.weight', 'clip_teacher.transformer.resblocks.8.ln_1.bias', 'clip_teacher.transformer.resblocks.8.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.8.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.8.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.8.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.8.ln_2.weight', 'clip_teacher.transformer.resblocks.8.ln_2.bias', 'clip_teacher.transformer.resblocks.9.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.9.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.9.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.9.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.9.ln_1.weight', 'clip_teacher.transformer.resblocks.9.ln_1.bias', 'clip_teacher.transformer.resblocks.9.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.9.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.9.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.9.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.9.ln_2.weight', 'clip_teacher.transformer.resblocks.9.ln_2.bias', 'clip_teacher.transformer.resblocks.10.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.10.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.10.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.10.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.10.ln_1.weight', 'clip_teacher.transformer.resblocks.10.ln_1.bias', 'clip_teacher.transformer.resblocks.10.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.10.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.10.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.10.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.10.ln_2.weight', 'clip_teacher.transformer.resblocks.10.ln_2.bias', 'clip_teacher.transformer.resblocks.11.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.11.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.11.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.11.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.11.ln_1.weight', 'clip_teacher.transformer.resblocks.11.ln_1.bias', 'clip_teacher.transformer.resblocks.11.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.11.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.11.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.11.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.11.ln_2.weight', 'clip_teacher.transformer.resblocks.11.ln_2.bias', 'clip_teacher.ln_post.weight', 'clip_teacher.ln_post.bias', 'vision_encoder.clip_decoder.0.head.weight', 'vision_encoder.clip_decoder.0.head.bias', 'vision_encoder.clip_decoder.0.norm.weight', 'vision_encoder.clip_decoder.0.norm.bias', 'vision_encoder.clip_decoder.1.head.weight', 'vision_encoder.clip_decoder.1.head.bias', 'vision_encoder.clip_decoder.1.norm.weight', 'vision_encoder.clip_decoder.1.norm.bias', 'vision_encoder.clip_decoder.2.head.weight', 'vision_encoder.clip_decoder.2.head.bias', 'vision_encoder.clip_decoder.2.norm.weight', 'vision_encoder.clip_decoder.2.norm.bias', 'vision_encoder.clip_decoder.3.head.weight', 'vision_encoder.clip_decoder.3.head.bias', 'vision_encoder.clip_decoder.3.norm.weight', 'vision_encoder.clip_decoder.3.norm.bias', 'vision_encoder.clip_decoder.4.head.weight', 'vision_encoder.clip_decoder.4.head.bias', 'vision_encoder.clip_decoder.4.norm.weight', 'vision_encoder.clip_decoder.4.norm.bias', 'vision_encoder.clip_decoder.5.head.weight', 'vision_encoder.clip_decoder.5.head.bias', 'vision_encoder.clip_decoder.5.norm.weight', 'vision_encoder.clip_decoder.5.norm.bias', 'text_encoder.cls.predictions.bias', 'text_encoder.cls.predictions.transform.dense.weight', 'text_encoder.cls.predictions.transform.dense.bias', 'text_encoder.cls.predictions.transform.LayerNorm.weight', 'text_encoder.cls.predictions.transform.LayerNorm.bias', 'text_encoder.cls.predictions.decoder.weight', 'text_encoder.cls.predictions.decoder.bias'])
2024-05-27T19:12:45 | INFO | tasks.shared_utils : Loaded checkpoint from /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
2024-05-27T19:12:45 | INFO | __main__ : training
2024-05-27T19:12:46 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:12:46 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:12:46 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 5792 batches in total
dataloader index=0 name=video, batch-size=32 length(#batches)=5792 
2024-05-27T19:12:46 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:12:46 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:12:46 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:12:46 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:12:46 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:12:46 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:12:47 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:12:47 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:12:47 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:12:47 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:13:00 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  builtin_warn(*args, **kwargs)

2024-05-27T19:13:00 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  builtin_warn(*args, **kwargs)

2024-05-27T19:13:00 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-05-27T19:13:00 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-05-27T19:17:27 | INFO | umt : Logging to: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2/train.log
2024-05-27T19:17:27 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
  test_file: {
      test: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test1k.json', '/data2/dy/temporal_video/dataset', 'video'] }
  test_types: ['test']
  num_workers: 6
  rtime: False
  pos_num: 1
  neg_num: 10
  stop_key: test/
  is_paragraph_retrieval: False
  is_pretrain: False
  num_frames: 12
  num_frames_test: 12
  batch_size: 32
  max_txt_l: 50
  evaluate: False
  train_shuffle: False
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 12
          sample_type: rand
          num_frames_test: 12
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 50
          video: 50 }
      batch_size: {
          image: 32
          video: 32 }
      batch_size_test: {
          image: 32
          video: 32 } }
  text_enc: bert
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_b16
          img_size: 224
          patch_size: 16
          d_model: 768
          encoder_embed_dim: 768
          encoder_depth: 12
          encoder_num_heads: 12
          drop_path_rate: 0.2
          num_frames: 12
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 12
          clip_decoder_embed_dim: 768
          clip_output_dim: 512
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 224
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      multimodal: {
          enable: True }
      embed_dim: 512
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 1e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 5
      min_lr_multi: 0.01
      warmup_epochs: 1 }
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: user
      project: umt_ret }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
  resume: False
  debug: False
  log_freq: 100
  seed: 3407
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
  rank: 0
  world_size: 1
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-05-27T19:17:27 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video'], 'test_file': {'test': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test1k.json', '/data2/dy/temporal_video/dataset', 'video']}, 'test_types': ['test'], 'num_workers': 6, 'rtime': False, 'pos_num': 1, 'neg_num': 10, 'stop_key': 'test/', 'is_paragraph_retrieval': False, 'is_pretrain': False, 'num_frames': 12, 'num_frames_test': 12, 'batch_size': 32, 'max_txt_l': 50, 'evaluate': False, 'train_shuffle': False, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 12, 'sample_type': 'rand', 'num_frames_test': 12, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 50, 'video': 50}, 'batch_size': {'image': 32, 'video': 32}, 'batch_size_test': {'image': 32, 'video': 32}}, 'text_enc': 'bert', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_b16', 'img_size': 224, 'patch_size': 16, 'd_model': 768, 'encoder_embed_dim': 768, 'encoder_depth': 12, 'encoder_num_heads': 12, 'drop_path_rate': 0.2, 'num_frames': 12, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 12, 'clip_decoder_embed_dim': 768, 'clip_output_dim': 512, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 224, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'multimodal': {'enable': True}, 'embed_dim': 512, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 1e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 5, 'min_lr_multi': 0.01, 'warmup_epochs': 1}, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': False, 'entity': 'user', 'project': 'umt_ret'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': 'exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 3407, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth', 'rank': 0, 'world_size': 1, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2024-05-27T19:17:27 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
2024-05-27T19:17:27 | INFO | tasks.pretrain : Creating dataset for ret
2024-05-27T19:17:27 | INFO | tasks.shared_utils : Creating model
2024-05-27T19:17:37 | INFO | models.umt : Build vision_encoder: vit_b16
2024-05-27T19:17:37 | INFO | models.backbones.vit.vit : Num of patches: 2352
2024-05-27T19:17:37 | INFO | models.backbones.vit.vit : Use checkpoint: True
2024-05-27T19:17:37 | INFO | models.backbones.vit.vit : Checkpoint number: 12
2024-05-27T19:17:37 | INFO | models.backbones.vit.vit : Student return index: []
2024-05-27T19:17:46 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
2024-05-27T19:17:47 | INFO | models.umt : Build text_encoder bert_base
2024-05-27T19:17:48 | INFO | models.backbones.bert.xbert : build bert with cross_module: ca
2024-05-27T19:17:48 | INFO | models.criterions : Norm type: l2
2024-05-27T19:17:48 | INFO | models.criterions : Loss type: l2
2024-05-27T19:17:48 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-05-27T19:17:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:17:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:17:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:17:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:17:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:17:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:17:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:17:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:17:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:17:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:17:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:17:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:17:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:17:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:17:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:17:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:17:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:17:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:17:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:17:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:17:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:17:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:17:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:17:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:17:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:17:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:17:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:17:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:17:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:17:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:17:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:17:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:17:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:17:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:17:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:17:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:17:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:17:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:17:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:17:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:17:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:17:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:17:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:17:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:17:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:17:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:17:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:17:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:17:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:17:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:17:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:17:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:17:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:17:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:17:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:17:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:17:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:17:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:17:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:17:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:17:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:17:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:17:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:17:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:17:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:17:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:17:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:17:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:17:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:17:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:17:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:17:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:17:48 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0 len(p)=48
2024-05-27T19:17:48 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0.02 len(p)=24
2024-05-27T19:17:48 | INFO | tasks.shared_utils : Auto resuming
2024-05-27T19:17:48 | INFO | tasks.shared_utils : Not found checkpoint in exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
2024-05-27T19:17:49 | INFO | tasks.shared_utils : _IncompatibleKeys(missing_keys=['vision_encoder.encoder.blocks.0.lora_r', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.1.lora_r', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.2.lora_r', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.3.lora_r', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.4.lora_r', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.5.lora_r', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.6.lora_r', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.7.lora_r', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.8.lora_r', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.9.lora_r', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.10.lora_r', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.11.lora_r', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.bias'], unexpected_keys=['clip_teacher.class_embedding', 'clip_teacher.positional_embedding', 'clip_teacher.proj', 'clip_teacher.conv1.weight', 'clip_teacher.ln_pre.weight', 'clip_teacher.ln_pre.bias', 'clip_teacher.transformer.resblocks.0.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.0.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.0.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.0.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.0.ln_1.weight', 'clip_teacher.transformer.resblocks.0.ln_1.bias', 'clip_teacher.transformer.resblocks.0.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.0.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.0.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.0.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.0.ln_2.weight', 'clip_teacher.transformer.resblocks.0.ln_2.bias', 'clip_teacher.transformer.resblocks.1.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.1.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.1.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.1.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.1.ln_1.weight', 'clip_teacher.transformer.resblocks.1.ln_1.bias', 'clip_teacher.transformer.resblocks.1.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.1.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.1.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.1.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.1.ln_2.weight', 'clip_teacher.transformer.resblocks.1.ln_2.bias', 'clip_teacher.transformer.resblocks.2.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.2.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.2.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.2.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.2.ln_1.weight', 'clip_teacher.transformer.resblocks.2.ln_1.bias', 'clip_teacher.transformer.resblocks.2.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.2.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.2.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.2.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.2.ln_2.weight', 'clip_teacher.transformer.resblocks.2.ln_2.bias', 'clip_teacher.transformer.resblocks.3.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.3.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.3.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.3.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.3.ln_1.weight', 'clip_teacher.transformer.resblocks.3.ln_1.bias', 'clip_teacher.transformer.resblocks.3.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.3.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.3.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.3.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.3.ln_2.weight', 'clip_teacher.transformer.resblocks.3.ln_2.bias', 'clip_teacher.transformer.resblocks.4.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.4.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.4.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.4.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.4.ln_1.weight', 'clip_teacher.transformer.resblocks.4.ln_1.bias', 'clip_teacher.transformer.resblocks.4.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.4.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.4.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.4.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.4.ln_2.weight', 'clip_teacher.transformer.resblocks.4.ln_2.bias', 'clip_teacher.transformer.resblocks.5.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.5.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.5.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.5.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.5.ln_1.weight', 'clip_teacher.transformer.resblocks.5.ln_1.bias', 'clip_teacher.transformer.resblocks.5.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.5.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.5.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.5.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.5.ln_2.weight', 'clip_teacher.transformer.resblocks.5.ln_2.bias', 'clip_teacher.transformer.resblocks.6.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.6.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.6.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.6.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.6.ln_1.weight', 'clip_teacher.transformer.resblocks.6.ln_1.bias', 'clip_teacher.transformer.resblocks.6.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.6.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.6.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.6.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.6.ln_2.weight', 'clip_teacher.transformer.resblocks.6.ln_2.bias', 'clip_teacher.transformer.resblocks.7.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.7.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.7.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.7.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.7.ln_1.weight', 'clip_teacher.transformer.resblocks.7.ln_1.bias', 'clip_teacher.transformer.resblocks.7.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.7.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.7.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.7.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.7.ln_2.weight', 'clip_teacher.transformer.resblocks.7.ln_2.bias', 'clip_teacher.transformer.resblocks.8.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.8.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.8.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.8.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.8.ln_1.weight', 'clip_teacher.transformer.resblocks.8.ln_1.bias', 'clip_teacher.transformer.resblocks.8.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.8.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.8.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.8.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.8.ln_2.weight', 'clip_teacher.transformer.resblocks.8.ln_2.bias', 'clip_teacher.transformer.resblocks.9.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.9.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.9.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.9.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.9.ln_1.weight', 'clip_teacher.transformer.resblocks.9.ln_1.bias', 'clip_teacher.transformer.resblocks.9.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.9.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.9.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.9.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.9.ln_2.weight', 'clip_teacher.transformer.resblocks.9.ln_2.bias', 'clip_teacher.transformer.resblocks.10.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.10.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.10.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.10.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.10.ln_1.weight', 'clip_teacher.transformer.resblocks.10.ln_1.bias', 'clip_teacher.transformer.resblocks.10.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.10.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.10.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.10.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.10.ln_2.weight', 'clip_teacher.transformer.resblocks.10.ln_2.bias', 'clip_teacher.transformer.resblocks.11.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.11.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.11.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.11.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.11.ln_1.weight', 'clip_teacher.transformer.resblocks.11.ln_1.bias', 'clip_teacher.transformer.resblocks.11.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.11.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.11.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.11.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.11.ln_2.weight', 'clip_teacher.transformer.resblocks.11.ln_2.bias', 'clip_teacher.ln_post.weight', 'clip_teacher.ln_post.bias', 'vision_encoder.clip_decoder.0.head.weight', 'vision_encoder.clip_decoder.0.head.bias', 'vision_encoder.clip_decoder.0.norm.weight', 'vision_encoder.clip_decoder.0.norm.bias', 'vision_encoder.clip_decoder.1.head.weight', 'vision_encoder.clip_decoder.1.head.bias', 'vision_encoder.clip_decoder.1.norm.weight', 'vision_encoder.clip_decoder.1.norm.bias', 'vision_encoder.clip_decoder.2.head.weight', 'vision_encoder.clip_decoder.2.head.bias', 'vision_encoder.clip_decoder.2.norm.weight', 'vision_encoder.clip_decoder.2.norm.bias', 'vision_encoder.clip_decoder.3.head.weight', 'vision_encoder.clip_decoder.3.head.bias', 'vision_encoder.clip_decoder.3.norm.weight', 'vision_encoder.clip_decoder.3.norm.bias', 'vision_encoder.clip_decoder.4.head.weight', 'vision_encoder.clip_decoder.4.head.bias', 'vision_encoder.clip_decoder.4.norm.weight', 'vision_encoder.clip_decoder.4.norm.bias', 'vision_encoder.clip_decoder.5.head.weight', 'vision_encoder.clip_decoder.5.head.bias', 'vision_encoder.clip_decoder.5.norm.weight', 'vision_encoder.clip_decoder.5.norm.bias', 'text_encoder.cls.predictions.bias', 'text_encoder.cls.predictions.transform.dense.weight', 'text_encoder.cls.predictions.transform.dense.bias', 'text_encoder.cls.predictions.transform.LayerNorm.weight', 'text_encoder.cls.predictions.transform.LayerNorm.bias', 'text_encoder.cls.predictions.decoder.weight', 'text_encoder.cls.predictions.decoder.bias'])
2024-05-27T19:17:49 | INFO | tasks.shared_utils : Loaded checkpoint from /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
2024-05-27T19:17:49 | INFO | __main__ : training
2024-05-27T19:17:50 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:17:50 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:17:50 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 5792 batches in total
dataloader index=0 name=video, batch-size=32 length(#batches)=5792 
2024-05-27T19:17:50 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:17:50 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:17:50 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:17:50 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:17:50 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:17:50 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:17:50 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:17:50 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:17:50 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:17:50 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:18:04 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  builtin_warn(*args, **kwargs)

2024-05-27T19:18:04 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  builtin_warn(*args, **kwargs)

2024-05-27T19:18:04 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-05-27T19:18:04 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-05-27T19:18:31 | WARNING | dataset.base_dataset : Caught exception  when loading video /data2/dy/temporal_video/dataset/forward/946.mp4, randomly sample a new video as replacement
2024-05-27T19:19:12 | INFO | umt : Logging to: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2/train.log
2024-05-27T19:19:12 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
  test_file: {
      test: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test1k.json', '/data2/dy/temporal_video/dataset', 'video'] }
  test_types: ['test']
  num_workers: 6
  rtime: False
  pos_num: 1
  neg_num: 10
  stop_key: test/
  is_paragraph_retrieval: False
  is_pretrain: False
  num_frames: 12
  num_frames_test: 12
  batch_size: 32
  max_txt_l: 50
  evaluate: False
  train_shuffle: False
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 12
          sample_type: rand
          num_frames_test: 12
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 50
          video: 50 }
      batch_size: {
          image: 32
          video: 32 }
      batch_size_test: {
          image: 32
          video: 32 } }
  text_enc: bert
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_b16
          img_size: 224
          patch_size: 16
          d_model: 768
          encoder_embed_dim: 768
          encoder_depth: 12
          encoder_num_heads: 12
          drop_path_rate: 0.2
          num_frames: 12
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 12
          clip_decoder_embed_dim: 768
          clip_output_dim: 512
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 224
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      multimodal: {
          enable: True }
      embed_dim: 512
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 1e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 5
      min_lr_multi: 0.01
      warmup_epochs: 1 }
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: user
      project: umt_ret }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
  resume: False
  debug: False
  log_freq: 100
  seed: 3407
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
  rank: 0
  world_size: 1
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-05-27T19:19:12 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video'], 'test_file': {'test': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test1k.json', '/data2/dy/temporal_video/dataset', 'video']}, 'test_types': ['test'], 'num_workers': 6, 'rtime': False, 'pos_num': 1, 'neg_num': 10, 'stop_key': 'test/', 'is_paragraph_retrieval': False, 'is_pretrain': False, 'num_frames': 12, 'num_frames_test': 12, 'batch_size': 32, 'max_txt_l': 50, 'evaluate': False, 'train_shuffle': False, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 12, 'sample_type': 'rand', 'num_frames_test': 12, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 50, 'video': 50}, 'batch_size': {'image': 32, 'video': 32}, 'batch_size_test': {'image': 32, 'video': 32}}, 'text_enc': 'bert', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_b16', 'img_size': 224, 'patch_size': 16, 'd_model': 768, 'encoder_embed_dim': 768, 'encoder_depth': 12, 'encoder_num_heads': 12, 'drop_path_rate': 0.2, 'num_frames': 12, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 12, 'clip_decoder_embed_dim': 768, 'clip_output_dim': 512, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 224, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'multimodal': {'enable': True}, 'embed_dim': 512, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 1e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 5, 'min_lr_multi': 0.01, 'warmup_epochs': 1}, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': False, 'entity': 'user', 'project': 'umt_ret'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': 'exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 3407, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth', 'rank': 0, 'world_size': 1, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2024-05-27T19:19:12 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
2024-05-27T19:19:12 | INFO | tasks.pretrain : Creating dataset for ret
2024-05-27T19:19:12 | INFO | tasks.shared_utils : Creating model
2024-05-27T19:19:22 | INFO | models.umt : Build vision_encoder: vit_b16
2024-05-27T19:19:22 | INFO | models.backbones.vit.vit : Num of patches: 2352
2024-05-27T19:19:22 | INFO | models.backbones.vit.vit : Use checkpoint: True
2024-05-27T19:19:22 | INFO | models.backbones.vit.vit : Checkpoint number: 12
2024-05-27T19:19:22 | INFO | models.backbones.vit.vit : Student return index: []
2024-05-27T19:19:29 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
2024-05-27T19:19:30 | INFO | models.umt : Build text_encoder bert_base
2024-05-27T19:19:31 | INFO | models.backbones.bert.xbert : build bert with cross_module: ca
2024-05-27T19:19:31 | INFO | models.criterions : Norm type: l2
2024-05-27T19:19:31 | INFO | models.criterions : Loss type: l2
2024-05-27T19:19:31 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-05-27T19:19:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:19:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:19:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:19:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:19:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:19:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:19:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:19:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:19:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:19:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:19:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:19:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:19:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:19:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:19:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:19:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:19:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:19:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:19:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:19:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:19:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:19:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:19:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:19:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:19:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:19:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:19:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:19:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:19:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:19:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:19:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:19:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:19:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:19:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:19:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:19:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:19:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:19:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:19:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:19:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:19:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:19:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:19:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:19:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:19:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:19:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:19:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:19:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:19:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:19:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:19:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:19:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:19:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:19:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:19:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:19:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:19:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:19:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:19:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:19:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:19:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:19:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:19:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:19:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:19:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:19:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:19:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:19:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:19:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:19:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:19:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:19:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:19:31 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0 len(p)=48
2024-05-27T19:19:31 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0.02 len(p)=24
2024-05-27T19:19:31 | INFO | tasks.shared_utils : Auto resuming
2024-05-27T19:19:31 | INFO | tasks.shared_utils : Not found checkpoint in exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
2024-05-27T19:19:32 | INFO | tasks.shared_utils : _IncompatibleKeys(missing_keys=['vision_encoder.encoder.blocks.0.lora_r', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.1.lora_r', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.2.lora_r', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.3.lora_r', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.4.lora_r', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.5.lora_r', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.6.lora_r', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.7.lora_r', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.8.lora_r', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.9.lora_r', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.10.lora_r', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.11.lora_r', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.bias'], unexpected_keys=['clip_teacher.class_embedding', 'clip_teacher.positional_embedding', 'clip_teacher.proj', 'clip_teacher.conv1.weight', 'clip_teacher.ln_pre.weight', 'clip_teacher.ln_pre.bias', 'clip_teacher.transformer.resblocks.0.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.0.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.0.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.0.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.0.ln_1.weight', 'clip_teacher.transformer.resblocks.0.ln_1.bias', 'clip_teacher.transformer.resblocks.0.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.0.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.0.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.0.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.0.ln_2.weight', 'clip_teacher.transformer.resblocks.0.ln_2.bias', 'clip_teacher.transformer.resblocks.1.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.1.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.1.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.1.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.1.ln_1.weight', 'clip_teacher.transformer.resblocks.1.ln_1.bias', 'clip_teacher.transformer.resblocks.1.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.1.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.1.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.1.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.1.ln_2.weight', 'clip_teacher.transformer.resblocks.1.ln_2.bias', 'clip_teacher.transformer.resblocks.2.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.2.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.2.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.2.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.2.ln_1.weight', 'clip_teacher.transformer.resblocks.2.ln_1.bias', 'clip_teacher.transformer.resblocks.2.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.2.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.2.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.2.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.2.ln_2.weight', 'clip_teacher.transformer.resblocks.2.ln_2.bias', 'clip_teacher.transformer.resblocks.3.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.3.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.3.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.3.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.3.ln_1.weight', 'clip_teacher.transformer.resblocks.3.ln_1.bias', 'clip_teacher.transformer.resblocks.3.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.3.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.3.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.3.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.3.ln_2.weight', 'clip_teacher.transformer.resblocks.3.ln_2.bias', 'clip_teacher.transformer.resblocks.4.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.4.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.4.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.4.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.4.ln_1.weight', 'clip_teacher.transformer.resblocks.4.ln_1.bias', 'clip_teacher.transformer.resblocks.4.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.4.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.4.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.4.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.4.ln_2.weight', 'clip_teacher.transformer.resblocks.4.ln_2.bias', 'clip_teacher.transformer.resblocks.5.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.5.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.5.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.5.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.5.ln_1.weight', 'clip_teacher.transformer.resblocks.5.ln_1.bias', 'clip_teacher.transformer.resblocks.5.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.5.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.5.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.5.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.5.ln_2.weight', 'clip_teacher.transformer.resblocks.5.ln_2.bias', 'clip_teacher.transformer.resblocks.6.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.6.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.6.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.6.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.6.ln_1.weight', 'clip_teacher.transformer.resblocks.6.ln_1.bias', 'clip_teacher.transformer.resblocks.6.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.6.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.6.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.6.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.6.ln_2.weight', 'clip_teacher.transformer.resblocks.6.ln_2.bias', 'clip_teacher.transformer.resblocks.7.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.7.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.7.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.7.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.7.ln_1.weight', 'clip_teacher.transformer.resblocks.7.ln_1.bias', 'clip_teacher.transformer.resblocks.7.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.7.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.7.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.7.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.7.ln_2.weight', 'clip_teacher.transformer.resblocks.7.ln_2.bias', 'clip_teacher.transformer.resblocks.8.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.8.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.8.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.8.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.8.ln_1.weight', 'clip_teacher.transformer.resblocks.8.ln_1.bias', 'clip_teacher.transformer.resblocks.8.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.8.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.8.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.8.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.8.ln_2.weight', 'clip_teacher.transformer.resblocks.8.ln_2.bias', 'clip_teacher.transformer.resblocks.9.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.9.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.9.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.9.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.9.ln_1.weight', 'clip_teacher.transformer.resblocks.9.ln_1.bias', 'clip_teacher.transformer.resblocks.9.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.9.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.9.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.9.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.9.ln_2.weight', 'clip_teacher.transformer.resblocks.9.ln_2.bias', 'clip_teacher.transformer.resblocks.10.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.10.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.10.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.10.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.10.ln_1.weight', 'clip_teacher.transformer.resblocks.10.ln_1.bias', 'clip_teacher.transformer.resblocks.10.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.10.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.10.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.10.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.10.ln_2.weight', 'clip_teacher.transformer.resblocks.10.ln_2.bias', 'clip_teacher.transformer.resblocks.11.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.11.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.11.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.11.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.11.ln_1.weight', 'clip_teacher.transformer.resblocks.11.ln_1.bias', 'clip_teacher.transformer.resblocks.11.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.11.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.11.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.11.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.11.ln_2.weight', 'clip_teacher.transformer.resblocks.11.ln_2.bias', 'clip_teacher.ln_post.weight', 'clip_teacher.ln_post.bias', 'vision_encoder.clip_decoder.0.head.weight', 'vision_encoder.clip_decoder.0.head.bias', 'vision_encoder.clip_decoder.0.norm.weight', 'vision_encoder.clip_decoder.0.norm.bias', 'vision_encoder.clip_decoder.1.head.weight', 'vision_encoder.clip_decoder.1.head.bias', 'vision_encoder.clip_decoder.1.norm.weight', 'vision_encoder.clip_decoder.1.norm.bias', 'vision_encoder.clip_decoder.2.head.weight', 'vision_encoder.clip_decoder.2.head.bias', 'vision_encoder.clip_decoder.2.norm.weight', 'vision_encoder.clip_decoder.2.norm.bias', 'vision_encoder.clip_decoder.3.head.weight', 'vision_encoder.clip_decoder.3.head.bias', 'vision_encoder.clip_decoder.3.norm.weight', 'vision_encoder.clip_decoder.3.norm.bias', 'vision_encoder.clip_decoder.4.head.weight', 'vision_encoder.clip_decoder.4.head.bias', 'vision_encoder.clip_decoder.4.norm.weight', 'vision_encoder.clip_decoder.4.norm.bias', 'vision_encoder.clip_decoder.5.head.weight', 'vision_encoder.clip_decoder.5.head.bias', 'vision_encoder.clip_decoder.5.norm.weight', 'vision_encoder.clip_decoder.5.norm.bias', 'text_encoder.cls.predictions.bias', 'text_encoder.cls.predictions.transform.dense.weight', 'text_encoder.cls.predictions.transform.dense.bias', 'text_encoder.cls.predictions.transform.LayerNorm.weight', 'text_encoder.cls.predictions.transform.LayerNorm.bias', 'text_encoder.cls.predictions.decoder.weight', 'text_encoder.cls.predictions.decoder.bias'])
2024-05-27T19:19:32 | INFO | tasks.shared_utils : Loaded checkpoint from /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
2024-05-27T19:19:32 | INFO | __main__ : training
2024-05-27T19:19:33 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:19:33 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:19:33 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:19:33 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:19:33 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 5792 batches in total
dataloader index=0 name=video, batch-size=32 length(#batches)=5792 
2024-05-27T19:19:33 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:19:33 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:19:33 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:19:33 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:19:33 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:19:33 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:19:33 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:19:33 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:19:46 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  builtin_warn(*args, **kwargs)

2024-05-27T19:19:46 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  builtin_warn(*args, **kwargs)

2024-05-27T19:19:46 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-05-27T19:19:46 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-05-27T19:23:27 | INFO | umt : Logging to: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2/train.log
2024-05-27T19:23:27 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
  test_file: {
      test: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test1k.json', '/data2/dy/temporal_video/dataset', 'video'] }
  test_types: ['test']
  num_workers: 6
  rtime: False
  pos_num: 1
  neg_num: 10
  stop_key: test/
  is_paragraph_retrieval: False
  is_pretrain: False
  num_frames: 12
  num_frames_test: 12
  batch_size: 32
  max_txt_l: 50
  evaluate: False
  train_shuffle: False
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 12
          sample_type: rand
          num_frames_test: 12
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 50
          video: 50 }
      batch_size: {
          image: 32
          video: 32 }
      batch_size_test: {
          image: 32
          video: 32 } }
  text_enc: bert
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_b16
          img_size: 224
          patch_size: 16
          d_model: 768
          encoder_embed_dim: 768
          encoder_depth: 12
          encoder_num_heads: 12
          drop_path_rate: 0.2
          num_frames: 12
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 12
          clip_decoder_embed_dim: 768
          clip_output_dim: 512
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 224
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      multimodal: {
          enable: True }
      embed_dim: 512
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 1e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 5
      min_lr_multi: 0.01
      warmup_epochs: 1 }
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: user
      project: umt_ret }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
  resume: False
  debug: False
  log_freq: 100
  seed: 3407
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
  rank: 0
  world_size: 1
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-05-27T19:23:27 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video'], 'test_file': {'test': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test1k.json', '/data2/dy/temporal_video/dataset', 'video']}, 'test_types': ['test'], 'num_workers': 6, 'rtime': False, 'pos_num': 1, 'neg_num': 10, 'stop_key': 'test/', 'is_paragraph_retrieval': False, 'is_pretrain': False, 'num_frames': 12, 'num_frames_test': 12, 'batch_size': 32, 'max_txt_l': 50, 'evaluate': False, 'train_shuffle': False, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 12, 'sample_type': 'rand', 'num_frames_test': 12, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 50, 'video': 50}, 'batch_size': {'image': 32, 'video': 32}, 'batch_size_test': {'image': 32, 'video': 32}}, 'text_enc': 'bert', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_b16', 'img_size': 224, 'patch_size': 16, 'd_model': 768, 'encoder_embed_dim': 768, 'encoder_depth': 12, 'encoder_num_heads': 12, 'drop_path_rate': 0.2, 'num_frames': 12, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 12, 'clip_decoder_embed_dim': 768, 'clip_output_dim': 512, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 224, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'multimodal': {'enable': True}, 'embed_dim': 512, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 1e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 5, 'min_lr_multi': 0.01, 'warmup_epochs': 1}, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': False, 'entity': 'user', 'project': 'umt_ret'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': 'exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 3407, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth', 'rank': 0, 'world_size': 1, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2024-05-27T19:23:27 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
2024-05-27T19:23:27 | INFO | tasks.pretrain : Creating dataset for ret
2024-05-27T19:23:27 | INFO | tasks.shared_utils : Creating model
2024-05-27T19:23:37 | INFO | models.umt : Build vision_encoder: vit_b16
2024-05-27T19:23:37 | INFO | models.backbones.vit.vit : Num of patches: 2352
2024-05-27T19:23:37 | INFO | models.backbones.vit.vit : Use checkpoint: True
2024-05-27T19:23:37 | INFO | models.backbones.vit.vit : Checkpoint number: 12
2024-05-27T19:23:37 | INFO | models.backbones.vit.vit : Student return index: []
2024-05-27T19:23:45 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
2024-05-27T19:23:45 | INFO | models.umt : Build text_encoder bert_base
2024-05-27T19:23:46 | INFO | models.backbones.bert.xbert : build bert with cross_module: ca
2024-05-27T19:23:46 | INFO | models.criterions : Norm type: l2
2024-05-27T19:23:46 | INFO | models.criterions : Loss type: l2
2024-05-27T19:23:47 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-05-27T19:23:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:23:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:23:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:23:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:23:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:23:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:23:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:23:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:23:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:23:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:23:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:23:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:23:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:23:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:23:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:23:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:23:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:23:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:23:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:23:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:23:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:23:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:23:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:23:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:23:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:23:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:23:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:23:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:23:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:23:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:23:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:23:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:23:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:23:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:23:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:23:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:23:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:23:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:23:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:23:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:23:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:23:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:23:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:23:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:23:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:23:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:23:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:23:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:23:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:23:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:23:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:23:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:23:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:23:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:23:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:23:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:23:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:23:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:23:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:23:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:23:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:23:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:23:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:23:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:23:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:23:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:23:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:23:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:23:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:23:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:23:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:23:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:23:47 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0 len(p)=48
2024-05-27T19:23:47 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0.02 len(p)=24
2024-05-27T19:23:47 | INFO | tasks.shared_utils : Auto resuming
2024-05-27T19:23:47 | INFO | tasks.shared_utils : Not found checkpoint in exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
2024-05-27T19:23:47 | INFO | tasks.shared_utils : _IncompatibleKeys(missing_keys=['vision_encoder.encoder.blocks.0.lora_r', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.1.lora_r', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.2.lora_r', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.3.lora_r', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.4.lora_r', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.5.lora_r', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.6.lora_r', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.7.lora_r', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.8.lora_r', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.9.lora_r', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.10.lora_r', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.11.lora_r', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.bias'], unexpected_keys=['clip_teacher.class_embedding', 'clip_teacher.positional_embedding', 'clip_teacher.proj', 'clip_teacher.conv1.weight', 'clip_teacher.ln_pre.weight', 'clip_teacher.ln_pre.bias', 'clip_teacher.transformer.resblocks.0.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.0.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.0.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.0.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.0.ln_1.weight', 'clip_teacher.transformer.resblocks.0.ln_1.bias', 'clip_teacher.transformer.resblocks.0.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.0.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.0.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.0.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.0.ln_2.weight', 'clip_teacher.transformer.resblocks.0.ln_2.bias', 'clip_teacher.transformer.resblocks.1.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.1.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.1.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.1.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.1.ln_1.weight', 'clip_teacher.transformer.resblocks.1.ln_1.bias', 'clip_teacher.transformer.resblocks.1.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.1.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.1.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.1.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.1.ln_2.weight', 'clip_teacher.transformer.resblocks.1.ln_2.bias', 'clip_teacher.transformer.resblocks.2.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.2.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.2.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.2.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.2.ln_1.weight', 'clip_teacher.transformer.resblocks.2.ln_1.bias', 'clip_teacher.transformer.resblocks.2.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.2.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.2.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.2.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.2.ln_2.weight', 'clip_teacher.transformer.resblocks.2.ln_2.bias', 'clip_teacher.transformer.resblocks.3.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.3.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.3.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.3.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.3.ln_1.weight', 'clip_teacher.transformer.resblocks.3.ln_1.bias', 'clip_teacher.transformer.resblocks.3.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.3.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.3.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.3.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.3.ln_2.weight', 'clip_teacher.transformer.resblocks.3.ln_2.bias', 'clip_teacher.transformer.resblocks.4.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.4.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.4.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.4.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.4.ln_1.weight', 'clip_teacher.transformer.resblocks.4.ln_1.bias', 'clip_teacher.transformer.resblocks.4.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.4.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.4.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.4.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.4.ln_2.weight', 'clip_teacher.transformer.resblocks.4.ln_2.bias', 'clip_teacher.transformer.resblocks.5.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.5.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.5.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.5.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.5.ln_1.weight', 'clip_teacher.transformer.resblocks.5.ln_1.bias', 'clip_teacher.transformer.resblocks.5.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.5.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.5.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.5.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.5.ln_2.weight', 'clip_teacher.transformer.resblocks.5.ln_2.bias', 'clip_teacher.transformer.resblocks.6.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.6.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.6.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.6.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.6.ln_1.weight', 'clip_teacher.transformer.resblocks.6.ln_1.bias', 'clip_teacher.transformer.resblocks.6.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.6.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.6.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.6.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.6.ln_2.weight', 'clip_teacher.transformer.resblocks.6.ln_2.bias', 'clip_teacher.transformer.resblocks.7.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.7.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.7.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.7.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.7.ln_1.weight', 'clip_teacher.transformer.resblocks.7.ln_1.bias', 'clip_teacher.transformer.resblocks.7.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.7.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.7.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.7.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.7.ln_2.weight', 'clip_teacher.transformer.resblocks.7.ln_2.bias', 'clip_teacher.transformer.resblocks.8.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.8.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.8.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.8.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.8.ln_1.weight', 'clip_teacher.transformer.resblocks.8.ln_1.bias', 'clip_teacher.transformer.resblocks.8.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.8.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.8.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.8.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.8.ln_2.weight', 'clip_teacher.transformer.resblocks.8.ln_2.bias', 'clip_teacher.transformer.resblocks.9.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.9.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.9.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.9.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.9.ln_1.weight', 'clip_teacher.transformer.resblocks.9.ln_1.bias', 'clip_teacher.transformer.resblocks.9.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.9.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.9.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.9.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.9.ln_2.weight', 'clip_teacher.transformer.resblocks.9.ln_2.bias', 'clip_teacher.transformer.resblocks.10.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.10.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.10.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.10.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.10.ln_1.weight', 'clip_teacher.transformer.resblocks.10.ln_1.bias', 'clip_teacher.transformer.resblocks.10.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.10.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.10.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.10.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.10.ln_2.weight', 'clip_teacher.transformer.resblocks.10.ln_2.bias', 'clip_teacher.transformer.resblocks.11.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.11.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.11.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.11.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.11.ln_1.weight', 'clip_teacher.transformer.resblocks.11.ln_1.bias', 'clip_teacher.transformer.resblocks.11.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.11.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.11.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.11.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.11.ln_2.weight', 'clip_teacher.transformer.resblocks.11.ln_2.bias', 'clip_teacher.ln_post.weight', 'clip_teacher.ln_post.bias', 'vision_encoder.clip_decoder.0.head.weight', 'vision_encoder.clip_decoder.0.head.bias', 'vision_encoder.clip_decoder.0.norm.weight', 'vision_encoder.clip_decoder.0.norm.bias', 'vision_encoder.clip_decoder.1.head.weight', 'vision_encoder.clip_decoder.1.head.bias', 'vision_encoder.clip_decoder.1.norm.weight', 'vision_encoder.clip_decoder.1.norm.bias', 'vision_encoder.clip_decoder.2.head.weight', 'vision_encoder.clip_decoder.2.head.bias', 'vision_encoder.clip_decoder.2.norm.weight', 'vision_encoder.clip_decoder.2.norm.bias', 'vision_encoder.clip_decoder.3.head.weight', 'vision_encoder.clip_decoder.3.head.bias', 'vision_encoder.clip_decoder.3.norm.weight', 'vision_encoder.clip_decoder.3.norm.bias', 'vision_encoder.clip_decoder.4.head.weight', 'vision_encoder.clip_decoder.4.head.bias', 'vision_encoder.clip_decoder.4.norm.weight', 'vision_encoder.clip_decoder.4.norm.bias', 'vision_encoder.clip_decoder.5.head.weight', 'vision_encoder.clip_decoder.5.head.bias', 'vision_encoder.clip_decoder.5.norm.weight', 'vision_encoder.clip_decoder.5.norm.bias', 'text_encoder.cls.predictions.bias', 'text_encoder.cls.predictions.transform.dense.weight', 'text_encoder.cls.predictions.transform.dense.bias', 'text_encoder.cls.predictions.transform.LayerNorm.weight', 'text_encoder.cls.predictions.transform.LayerNorm.bias', 'text_encoder.cls.predictions.decoder.weight', 'text_encoder.cls.predictions.decoder.bias'])
2024-05-27T19:23:47 | INFO | tasks.shared_utils : Loaded checkpoint from /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
2024-05-27T19:23:47 | INFO | __main__ : training
2024-05-27T19:23:48 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:23:48 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:23:48 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:23:48 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:23:48 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 5792 batches in total
dataloader index=0 name=video, batch-size=32 length(#batches)=5792 
2024-05-27T19:23:48 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:23:48 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:23:48 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:23:48 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:23:48 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:23:48 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:23:49 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:23:49 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:24:02 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  builtin_warn(*args, **kwargs)

2024-05-27T19:24:02 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  builtin_warn(*args, **kwargs)

2024-05-27T19:24:02 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-05-27T19:24:02 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-05-27T19:24:56 | INFO | umt : Logging to: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2/train.log
2024-05-27T19:24:56 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
  test_file: {
      test: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test1k.json', '/data2/dy/temporal_video/dataset', 'video'] }
  test_types: ['test']
  num_workers: 6
  rtime: False
  pos_num: 1
  neg_num: 10
  stop_key: test/
  is_paragraph_retrieval: False
  is_pretrain: False
  num_frames: 12
  num_frames_test: 12
  batch_size: 32
  max_txt_l: 50
  evaluate: False
  train_shuffle: False
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 12
          sample_type: rand
          num_frames_test: 12
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 50
          video: 50 }
      batch_size: {
          image: 32
          video: 32 }
      batch_size_test: {
          image: 32
          video: 32 } }
  text_enc: bert
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_b16
          img_size: 224
          patch_size: 16
          d_model: 768
          encoder_embed_dim: 768
          encoder_depth: 12
          encoder_num_heads: 12
          drop_path_rate: 0.2
          num_frames: 12
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 12
          clip_decoder_embed_dim: 768
          clip_output_dim: 512
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 224
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      multimodal: {
          enable: True }
      embed_dim: 512
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 1e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 5
      min_lr_multi: 0.01
      warmup_epochs: 1 }
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: user
      project: umt_ret }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
  resume: False
  debug: False
  log_freq: 100
  seed: 3407
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
  rank: 0
  world_size: 1
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-05-27T19:24:56 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video'], 'test_file': {'test': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test1k.json', '/data2/dy/temporal_video/dataset', 'video']}, 'test_types': ['test'], 'num_workers': 6, 'rtime': False, 'pos_num': 1, 'neg_num': 10, 'stop_key': 'test/', 'is_paragraph_retrieval': False, 'is_pretrain': False, 'num_frames': 12, 'num_frames_test': 12, 'batch_size': 32, 'max_txt_l': 50, 'evaluate': False, 'train_shuffle': False, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 12, 'sample_type': 'rand', 'num_frames_test': 12, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 50, 'video': 50}, 'batch_size': {'image': 32, 'video': 32}, 'batch_size_test': {'image': 32, 'video': 32}}, 'text_enc': 'bert', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_b16', 'img_size': 224, 'patch_size': 16, 'd_model': 768, 'encoder_embed_dim': 768, 'encoder_depth': 12, 'encoder_num_heads': 12, 'drop_path_rate': 0.2, 'num_frames': 12, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 12, 'clip_decoder_embed_dim': 768, 'clip_output_dim': 512, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 224, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'multimodal': {'enable': True}, 'embed_dim': 512, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 1e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 5, 'min_lr_multi': 0.01, 'warmup_epochs': 1}, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': False, 'entity': 'user', 'project': 'umt_ret'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': 'exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 3407, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth', 'rank': 0, 'world_size': 1, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2024-05-27T19:24:56 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
2024-05-27T19:24:56 | INFO | tasks.pretrain : Creating dataset for ret
2024-05-27T19:24:57 | INFO | tasks.shared_utils : Creating model
2024-05-27T19:25:07 | INFO | models.umt : Build vision_encoder: vit_b16
2024-05-27T19:25:07 | INFO | models.backbones.vit.vit : Num of patches: 2352
2024-05-27T19:25:07 | INFO | models.backbones.vit.vit : Use checkpoint: True
2024-05-27T19:25:07 | INFO | models.backbones.vit.vit : Checkpoint number: 12
2024-05-27T19:25:07 | INFO | models.backbones.vit.vit : Student return index: []
2024-05-27T19:25:15 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
2024-05-27T19:25:15 | INFO | models.umt : Build text_encoder bert_base
2024-05-27T19:25:16 | INFO | models.backbones.bert.xbert : build bert with cross_module: ca
2024-05-27T19:25:16 | INFO | models.criterions : Norm type: l2
2024-05-27T19:25:16 | INFO | models.criterions : Loss type: l2
2024-05-27T19:25:17 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-05-27T19:25:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:25:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:25:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:25:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:25:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:25:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:25:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:25:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:25:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:25:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:25:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:25:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:25:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:25:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:25:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:25:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:25:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:25:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:25:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:25:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:25:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:25:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:25:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:25:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:25:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:25:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:25:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:25:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:25:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:25:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:25:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:25:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:25:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:25:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:25:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:25:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:25:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:25:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:25:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:25:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:25:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:25:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:25:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:25:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:25:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:25:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:25:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:25:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:25:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:25:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:25:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:25:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:25:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:25:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:25:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:25:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:25:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:25:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:25:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:25:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:25:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:25:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:25:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:25:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:25:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:25:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:25:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:25:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:25:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:25:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:25:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:25:17 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:25:17 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0 len(p)=48
2024-05-27T19:25:17 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0.02 len(p)=24
2024-05-27T19:25:17 | INFO | tasks.shared_utils : Auto resuming
2024-05-27T19:25:17 | INFO | tasks.shared_utils : Not found checkpoint in exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
2024-05-27T19:25:17 | INFO | tasks.shared_utils : _IncompatibleKeys(missing_keys=['vision_encoder.encoder.blocks.0.lora_r', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.1.lora_r', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.2.lora_r', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.3.lora_r', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.4.lora_r', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.5.lora_r', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.6.lora_r', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.7.lora_r', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.8.lora_r', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.9.lora_r', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.10.lora_r', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.11.lora_r', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.bias'], unexpected_keys=['clip_teacher.class_embedding', 'clip_teacher.positional_embedding', 'clip_teacher.proj', 'clip_teacher.conv1.weight', 'clip_teacher.ln_pre.weight', 'clip_teacher.ln_pre.bias', 'clip_teacher.transformer.resblocks.0.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.0.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.0.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.0.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.0.ln_1.weight', 'clip_teacher.transformer.resblocks.0.ln_1.bias', 'clip_teacher.transformer.resblocks.0.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.0.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.0.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.0.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.0.ln_2.weight', 'clip_teacher.transformer.resblocks.0.ln_2.bias', 'clip_teacher.transformer.resblocks.1.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.1.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.1.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.1.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.1.ln_1.weight', 'clip_teacher.transformer.resblocks.1.ln_1.bias', 'clip_teacher.transformer.resblocks.1.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.1.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.1.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.1.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.1.ln_2.weight', 'clip_teacher.transformer.resblocks.1.ln_2.bias', 'clip_teacher.transformer.resblocks.2.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.2.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.2.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.2.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.2.ln_1.weight', 'clip_teacher.transformer.resblocks.2.ln_1.bias', 'clip_teacher.transformer.resblocks.2.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.2.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.2.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.2.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.2.ln_2.weight', 'clip_teacher.transformer.resblocks.2.ln_2.bias', 'clip_teacher.transformer.resblocks.3.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.3.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.3.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.3.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.3.ln_1.weight', 'clip_teacher.transformer.resblocks.3.ln_1.bias', 'clip_teacher.transformer.resblocks.3.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.3.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.3.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.3.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.3.ln_2.weight', 'clip_teacher.transformer.resblocks.3.ln_2.bias', 'clip_teacher.transformer.resblocks.4.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.4.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.4.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.4.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.4.ln_1.weight', 'clip_teacher.transformer.resblocks.4.ln_1.bias', 'clip_teacher.transformer.resblocks.4.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.4.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.4.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.4.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.4.ln_2.weight', 'clip_teacher.transformer.resblocks.4.ln_2.bias', 'clip_teacher.transformer.resblocks.5.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.5.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.5.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.5.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.5.ln_1.weight', 'clip_teacher.transformer.resblocks.5.ln_1.bias', 'clip_teacher.transformer.resblocks.5.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.5.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.5.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.5.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.5.ln_2.weight', 'clip_teacher.transformer.resblocks.5.ln_2.bias', 'clip_teacher.transformer.resblocks.6.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.6.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.6.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.6.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.6.ln_1.weight', 'clip_teacher.transformer.resblocks.6.ln_1.bias', 'clip_teacher.transformer.resblocks.6.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.6.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.6.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.6.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.6.ln_2.weight', 'clip_teacher.transformer.resblocks.6.ln_2.bias', 'clip_teacher.transformer.resblocks.7.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.7.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.7.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.7.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.7.ln_1.weight', 'clip_teacher.transformer.resblocks.7.ln_1.bias', 'clip_teacher.transformer.resblocks.7.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.7.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.7.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.7.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.7.ln_2.weight', 'clip_teacher.transformer.resblocks.7.ln_2.bias', 'clip_teacher.transformer.resblocks.8.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.8.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.8.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.8.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.8.ln_1.weight', 'clip_teacher.transformer.resblocks.8.ln_1.bias', 'clip_teacher.transformer.resblocks.8.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.8.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.8.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.8.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.8.ln_2.weight', 'clip_teacher.transformer.resblocks.8.ln_2.bias', 'clip_teacher.transformer.resblocks.9.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.9.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.9.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.9.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.9.ln_1.weight', 'clip_teacher.transformer.resblocks.9.ln_1.bias', 'clip_teacher.transformer.resblocks.9.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.9.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.9.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.9.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.9.ln_2.weight', 'clip_teacher.transformer.resblocks.9.ln_2.bias', 'clip_teacher.transformer.resblocks.10.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.10.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.10.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.10.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.10.ln_1.weight', 'clip_teacher.transformer.resblocks.10.ln_1.bias', 'clip_teacher.transformer.resblocks.10.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.10.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.10.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.10.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.10.ln_2.weight', 'clip_teacher.transformer.resblocks.10.ln_2.bias', 'clip_teacher.transformer.resblocks.11.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.11.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.11.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.11.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.11.ln_1.weight', 'clip_teacher.transformer.resblocks.11.ln_1.bias', 'clip_teacher.transformer.resblocks.11.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.11.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.11.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.11.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.11.ln_2.weight', 'clip_teacher.transformer.resblocks.11.ln_2.bias', 'clip_teacher.ln_post.weight', 'clip_teacher.ln_post.bias', 'vision_encoder.clip_decoder.0.head.weight', 'vision_encoder.clip_decoder.0.head.bias', 'vision_encoder.clip_decoder.0.norm.weight', 'vision_encoder.clip_decoder.0.norm.bias', 'vision_encoder.clip_decoder.1.head.weight', 'vision_encoder.clip_decoder.1.head.bias', 'vision_encoder.clip_decoder.1.norm.weight', 'vision_encoder.clip_decoder.1.norm.bias', 'vision_encoder.clip_decoder.2.head.weight', 'vision_encoder.clip_decoder.2.head.bias', 'vision_encoder.clip_decoder.2.norm.weight', 'vision_encoder.clip_decoder.2.norm.bias', 'vision_encoder.clip_decoder.3.head.weight', 'vision_encoder.clip_decoder.3.head.bias', 'vision_encoder.clip_decoder.3.norm.weight', 'vision_encoder.clip_decoder.3.norm.bias', 'vision_encoder.clip_decoder.4.head.weight', 'vision_encoder.clip_decoder.4.head.bias', 'vision_encoder.clip_decoder.4.norm.weight', 'vision_encoder.clip_decoder.4.norm.bias', 'vision_encoder.clip_decoder.5.head.weight', 'vision_encoder.clip_decoder.5.head.bias', 'vision_encoder.clip_decoder.5.norm.weight', 'vision_encoder.clip_decoder.5.norm.bias', 'text_encoder.cls.predictions.bias', 'text_encoder.cls.predictions.transform.dense.weight', 'text_encoder.cls.predictions.transform.dense.bias', 'text_encoder.cls.predictions.transform.LayerNorm.weight', 'text_encoder.cls.predictions.transform.LayerNorm.bias', 'text_encoder.cls.predictions.decoder.weight', 'text_encoder.cls.predictions.decoder.bias'])
2024-05-27T19:25:17 | INFO | tasks.shared_utils : Loaded checkpoint from /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
2024-05-27T19:25:17 | INFO | __main__ : training
2024-05-27T19:25:18 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:25:18 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:25:18 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:25:18 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:25:18 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 5792 batches in total
dataloader index=0 name=video, batch-size=32 length(#batches)=5792 
2024-05-27T19:25:18 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:25:18 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:25:18 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:25:18 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:25:18 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:25:18 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:25:19 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:25:19 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:25:32 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  builtin_warn(*args, **kwargs)

2024-05-27T19:25:32 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  builtin_warn(*args, **kwargs)

2024-05-27T19:25:32 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-05-27T19:25:32 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-05-27T19:26:11 | INFO | umt : Logging to: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2/train.log
2024-05-27T19:26:11 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
  test_file: {
      test: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test1k.json', '/data2/dy/temporal_video/dataset', 'video'] }
  test_types: ['test']
  num_workers: 6
  rtime: False
  pos_num: 1
  neg_num: 10
  stop_key: test/
  is_paragraph_retrieval: False
  is_pretrain: False
  num_frames: 12
  num_frames_test: 12
  batch_size: 32
  max_txt_l: 50
  evaluate: False
  train_shuffle: False
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 12
          sample_type: rand
          num_frames_test: 12
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 50
          video: 50 }
      batch_size: {
          image: 32
          video: 32 }
      batch_size_test: {
          image: 32
          video: 32 } }
  text_enc: bert
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_b16
          img_size: 224
          patch_size: 16
          d_model: 768
          encoder_embed_dim: 768
          encoder_depth: 12
          encoder_num_heads: 12
          drop_path_rate: 0.2
          num_frames: 12
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 12
          clip_decoder_embed_dim: 768
          clip_output_dim: 512
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 224
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      multimodal: {
          enable: True }
      embed_dim: 512
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 1e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 5
      min_lr_multi: 0.01
      warmup_epochs: 1 }
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: user
      project: umt_ret }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
  resume: False
  debug: False
  log_freq: 100
  seed: 3407
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
  rank: 0
  world_size: 1
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-05-27T19:26:11 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video'], 'test_file': {'test': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test1k.json', '/data2/dy/temporal_video/dataset', 'video']}, 'test_types': ['test'], 'num_workers': 6, 'rtime': False, 'pos_num': 1, 'neg_num': 10, 'stop_key': 'test/', 'is_paragraph_retrieval': False, 'is_pretrain': False, 'num_frames': 12, 'num_frames_test': 12, 'batch_size': 32, 'max_txt_l': 50, 'evaluate': False, 'train_shuffle': False, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 12, 'sample_type': 'rand', 'num_frames_test': 12, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 50, 'video': 50}, 'batch_size': {'image': 32, 'video': 32}, 'batch_size_test': {'image': 32, 'video': 32}}, 'text_enc': 'bert', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_b16', 'img_size': 224, 'patch_size': 16, 'd_model': 768, 'encoder_embed_dim': 768, 'encoder_depth': 12, 'encoder_num_heads': 12, 'drop_path_rate': 0.2, 'num_frames': 12, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 12, 'clip_decoder_embed_dim': 768, 'clip_output_dim': 512, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 224, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'multimodal': {'enable': True}, 'embed_dim': 512, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 1e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 5, 'min_lr_multi': 0.01, 'warmup_epochs': 1}, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': False, 'entity': 'user', 'project': 'umt_ret'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': 'exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 3407, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth', 'rank': 0, 'world_size': 1, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2024-05-27T19:26:11 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
2024-05-27T19:26:11 | INFO | tasks.pretrain : Creating dataset for ret
2024-05-27T19:26:11 | INFO | tasks.shared_utils : Creating model
2024-05-27T19:26:21 | INFO | models.umt : Build vision_encoder: vit_b16
2024-05-27T19:26:21 | INFO | models.backbones.vit.vit : Num of patches: 2352
2024-05-27T19:26:21 | INFO | models.backbones.vit.vit : Use checkpoint: True
2024-05-27T19:26:21 | INFO | models.backbones.vit.vit : Checkpoint number: 12
2024-05-27T19:26:21 | INFO | models.backbones.vit.vit : Student return index: []
2024-05-27T19:26:29 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
2024-05-27T19:26:29 | INFO | models.umt : Build text_encoder bert_base
2024-05-27T19:26:30 | INFO | models.backbones.bert.xbert : build bert with cross_module: ca
2024-05-27T19:26:30 | INFO | models.criterions : Norm type: l2
2024-05-27T19:26:30 | INFO | models.criterions : Loss type: l2
2024-05-27T19:26:31 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-05-27T19:26:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:26:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:26:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:26:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:26:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:26:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:26:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:26:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:26:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:26:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:26:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:26:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:26:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:26:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:26:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:26:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:26:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:26:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:26:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:26:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:26:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:26:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:26:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:26:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:26:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:26:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:26:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:26:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:26:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:26:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:26:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:26:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:26:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:26:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:26:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:26:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:26:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:26:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:26:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:26:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:26:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:26:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:26:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:26:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:26:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:26:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:26:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:26:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:26:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:26:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:26:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:26:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:26:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:26:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:26:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:26:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:26:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:26:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:26:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:26:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:26:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:26:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:26:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:26:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:26:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:26:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:26:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:26:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:26:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:26:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:26:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:26:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:26:31 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0 len(p)=48
2024-05-27T19:26:31 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0.02 len(p)=24
2024-05-27T19:26:31 | INFO | tasks.shared_utils : Auto resuming
2024-05-27T19:26:31 | INFO | tasks.shared_utils : Not found checkpoint in exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
2024-05-27T19:26:31 | INFO | tasks.shared_utils : _IncompatibleKeys(missing_keys=['vision_encoder.encoder.blocks.0.lora_r', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.1.lora_r', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.2.lora_r', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.3.lora_r', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.4.lora_r', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.5.lora_r', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.6.lora_r', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.7.lora_r', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.8.lora_r', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.9.lora_r', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.10.lora_r', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.11.lora_r', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.bias'], unexpected_keys=['clip_teacher.class_embedding', 'clip_teacher.positional_embedding', 'clip_teacher.proj', 'clip_teacher.conv1.weight', 'clip_teacher.ln_pre.weight', 'clip_teacher.ln_pre.bias', 'clip_teacher.transformer.resblocks.0.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.0.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.0.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.0.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.0.ln_1.weight', 'clip_teacher.transformer.resblocks.0.ln_1.bias', 'clip_teacher.transformer.resblocks.0.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.0.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.0.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.0.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.0.ln_2.weight', 'clip_teacher.transformer.resblocks.0.ln_2.bias', 'clip_teacher.transformer.resblocks.1.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.1.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.1.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.1.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.1.ln_1.weight', 'clip_teacher.transformer.resblocks.1.ln_1.bias', 'clip_teacher.transformer.resblocks.1.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.1.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.1.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.1.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.1.ln_2.weight', 'clip_teacher.transformer.resblocks.1.ln_2.bias', 'clip_teacher.transformer.resblocks.2.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.2.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.2.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.2.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.2.ln_1.weight', 'clip_teacher.transformer.resblocks.2.ln_1.bias', 'clip_teacher.transformer.resblocks.2.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.2.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.2.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.2.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.2.ln_2.weight', 'clip_teacher.transformer.resblocks.2.ln_2.bias', 'clip_teacher.transformer.resblocks.3.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.3.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.3.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.3.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.3.ln_1.weight', 'clip_teacher.transformer.resblocks.3.ln_1.bias', 'clip_teacher.transformer.resblocks.3.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.3.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.3.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.3.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.3.ln_2.weight', 'clip_teacher.transformer.resblocks.3.ln_2.bias', 'clip_teacher.transformer.resblocks.4.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.4.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.4.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.4.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.4.ln_1.weight', 'clip_teacher.transformer.resblocks.4.ln_1.bias', 'clip_teacher.transformer.resblocks.4.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.4.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.4.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.4.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.4.ln_2.weight', 'clip_teacher.transformer.resblocks.4.ln_2.bias', 'clip_teacher.transformer.resblocks.5.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.5.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.5.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.5.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.5.ln_1.weight', 'clip_teacher.transformer.resblocks.5.ln_1.bias', 'clip_teacher.transformer.resblocks.5.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.5.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.5.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.5.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.5.ln_2.weight', 'clip_teacher.transformer.resblocks.5.ln_2.bias', 'clip_teacher.transformer.resblocks.6.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.6.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.6.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.6.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.6.ln_1.weight', 'clip_teacher.transformer.resblocks.6.ln_1.bias', 'clip_teacher.transformer.resblocks.6.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.6.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.6.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.6.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.6.ln_2.weight', 'clip_teacher.transformer.resblocks.6.ln_2.bias', 'clip_teacher.transformer.resblocks.7.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.7.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.7.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.7.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.7.ln_1.weight', 'clip_teacher.transformer.resblocks.7.ln_1.bias', 'clip_teacher.transformer.resblocks.7.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.7.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.7.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.7.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.7.ln_2.weight', 'clip_teacher.transformer.resblocks.7.ln_2.bias', 'clip_teacher.transformer.resblocks.8.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.8.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.8.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.8.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.8.ln_1.weight', 'clip_teacher.transformer.resblocks.8.ln_1.bias', 'clip_teacher.transformer.resblocks.8.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.8.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.8.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.8.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.8.ln_2.weight', 'clip_teacher.transformer.resblocks.8.ln_2.bias', 'clip_teacher.transformer.resblocks.9.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.9.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.9.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.9.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.9.ln_1.weight', 'clip_teacher.transformer.resblocks.9.ln_1.bias', 'clip_teacher.transformer.resblocks.9.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.9.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.9.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.9.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.9.ln_2.weight', 'clip_teacher.transformer.resblocks.9.ln_2.bias', 'clip_teacher.transformer.resblocks.10.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.10.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.10.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.10.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.10.ln_1.weight', 'clip_teacher.transformer.resblocks.10.ln_1.bias', 'clip_teacher.transformer.resblocks.10.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.10.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.10.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.10.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.10.ln_2.weight', 'clip_teacher.transformer.resblocks.10.ln_2.bias', 'clip_teacher.transformer.resblocks.11.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.11.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.11.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.11.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.11.ln_1.weight', 'clip_teacher.transformer.resblocks.11.ln_1.bias', 'clip_teacher.transformer.resblocks.11.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.11.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.11.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.11.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.11.ln_2.weight', 'clip_teacher.transformer.resblocks.11.ln_2.bias', 'clip_teacher.ln_post.weight', 'clip_teacher.ln_post.bias', 'vision_encoder.clip_decoder.0.head.weight', 'vision_encoder.clip_decoder.0.head.bias', 'vision_encoder.clip_decoder.0.norm.weight', 'vision_encoder.clip_decoder.0.norm.bias', 'vision_encoder.clip_decoder.1.head.weight', 'vision_encoder.clip_decoder.1.head.bias', 'vision_encoder.clip_decoder.1.norm.weight', 'vision_encoder.clip_decoder.1.norm.bias', 'vision_encoder.clip_decoder.2.head.weight', 'vision_encoder.clip_decoder.2.head.bias', 'vision_encoder.clip_decoder.2.norm.weight', 'vision_encoder.clip_decoder.2.norm.bias', 'vision_encoder.clip_decoder.3.head.weight', 'vision_encoder.clip_decoder.3.head.bias', 'vision_encoder.clip_decoder.3.norm.weight', 'vision_encoder.clip_decoder.3.norm.bias', 'vision_encoder.clip_decoder.4.head.weight', 'vision_encoder.clip_decoder.4.head.bias', 'vision_encoder.clip_decoder.4.norm.weight', 'vision_encoder.clip_decoder.4.norm.bias', 'vision_encoder.clip_decoder.5.head.weight', 'vision_encoder.clip_decoder.5.head.bias', 'vision_encoder.clip_decoder.5.norm.weight', 'vision_encoder.clip_decoder.5.norm.bias', 'text_encoder.cls.predictions.bias', 'text_encoder.cls.predictions.transform.dense.weight', 'text_encoder.cls.predictions.transform.dense.bias', 'text_encoder.cls.predictions.transform.LayerNorm.weight', 'text_encoder.cls.predictions.transform.LayerNorm.bias', 'text_encoder.cls.predictions.decoder.weight', 'text_encoder.cls.predictions.decoder.bias'])
2024-05-27T19:26:31 | INFO | tasks.shared_utils : Loaded checkpoint from /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
2024-05-27T19:26:32 | INFO | __main__ : training
2024-05-27T19:26:32 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:26:32 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:26:32 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 5792 batches in total
dataloader index=0 name=video, batch-size=32 length(#batches)=5792 
2024-05-27T19:26:32 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:26:32 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:26:32 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:26:32 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:26:32 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:26:32 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:26:32 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:26:32 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:26:33 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:26:33 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:26:46 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  builtin_warn(*args, **kwargs)

2024-05-27T19:26:46 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  builtin_warn(*args, **kwargs)

2024-05-27T19:26:46 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-05-27T19:26:46 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-05-27T19:27:31 | INFO | umt : Logging to: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2/train.log
2024-05-27T19:27:31 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
  test_file: {
      test: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test1k.json', '/data2/dy/temporal_video/dataset', 'video'] }
  test_types: ['test']
  num_workers: 6
  rtime: False
  pos_num: 1
  neg_num: 10
  stop_key: test/
  is_paragraph_retrieval: False
  is_pretrain: False
  num_frames: 12
  num_frames_test: 12
  batch_size: 32
  max_txt_l: 50
  evaluate: False
  train_shuffle: False
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 12
          sample_type: rand
          num_frames_test: 12
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 50
          video: 50 }
      batch_size: {
          image: 32
          video: 32 }
      batch_size_test: {
          image: 32
          video: 32 } }
  text_enc: bert
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_b16
          img_size: 224
          patch_size: 16
          d_model: 768
          encoder_embed_dim: 768
          encoder_depth: 12
          encoder_num_heads: 12
          drop_path_rate: 0.2
          num_frames: 12
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 12
          clip_decoder_embed_dim: 768
          clip_output_dim: 512
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 224
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      multimodal: {
          enable: True }
      embed_dim: 512
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 1e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 5
      min_lr_multi: 0.01
      warmup_epochs: 1 }
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: user
      project: umt_ret }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
  resume: False
  debug: False
  log_freq: 100
  seed: 3407
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
  rank: 0
  world_size: 1
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-05-27T19:27:31 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video'], 'test_file': {'test': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test1k.json', '/data2/dy/temporal_video/dataset', 'video']}, 'test_types': ['test'], 'num_workers': 6, 'rtime': False, 'pos_num': 1, 'neg_num': 10, 'stop_key': 'test/', 'is_paragraph_retrieval': False, 'is_pretrain': False, 'num_frames': 12, 'num_frames_test': 12, 'batch_size': 32, 'max_txt_l': 50, 'evaluate': False, 'train_shuffle': False, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 12, 'sample_type': 'rand', 'num_frames_test': 12, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 50, 'video': 50}, 'batch_size': {'image': 32, 'video': 32}, 'batch_size_test': {'image': 32, 'video': 32}}, 'text_enc': 'bert', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_b16', 'img_size': 224, 'patch_size': 16, 'd_model': 768, 'encoder_embed_dim': 768, 'encoder_depth': 12, 'encoder_num_heads': 12, 'drop_path_rate': 0.2, 'num_frames': 12, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 12, 'clip_decoder_embed_dim': 768, 'clip_output_dim': 512, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 224, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'multimodal': {'enable': True}, 'embed_dim': 512, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 1e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 5, 'min_lr_multi': 0.01, 'warmup_epochs': 1}, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': False, 'entity': 'user', 'project': 'umt_ret'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': 'exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 3407, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth', 'rank': 0, 'world_size': 1, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2024-05-27T19:27:31 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
2024-05-27T19:27:31 | INFO | tasks.pretrain : Creating dataset for ret
2024-05-27T19:27:31 | INFO | tasks.shared_utils : Creating model
2024-05-27T19:27:41 | INFO | models.umt : Build vision_encoder: vit_b16
2024-05-27T19:27:41 | INFO | models.backbones.vit.vit : Num of patches: 2352
2024-05-27T19:27:42 | INFO | models.backbones.vit.vit : Use checkpoint: True
2024-05-27T19:27:42 | INFO | models.backbones.vit.vit : Checkpoint number: 12
2024-05-27T19:27:42 | INFO | models.backbones.vit.vit : Student return index: []
2024-05-27T19:27:49 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
2024-05-27T19:27:49 | INFO | models.umt : Build text_encoder bert_base
2024-05-27T19:27:50 | INFO | models.backbones.bert.xbert : build bert with cross_module: ca
2024-05-27T19:27:51 | INFO | models.criterions : Norm type: l2
2024-05-27T19:27:51 | INFO | models.criterions : Loss type: l2
2024-05-27T19:27:51 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.temp: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.weight: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.weight: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.embeddings.word_embeddings.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.embeddings.position_embeddings.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.embeddings.token_type_embeddings.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.vision_proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.text_proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.itm_head.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : param module.itm_head.bias: wd: 0, lr: 1e-05
2024-05-27T19:27:51 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0.02 len(p)=164
2024-05-27T19:27:51 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0 len(p)=304
2024-05-27T19:27:51 | INFO | tasks.shared_utils : Auto resuming
2024-05-27T19:27:51 | INFO | tasks.shared_utils : Not found checkpoint in exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
2024-05-27T19:27:52 | INFO | tasks.shared_utils : _IncompatibleKeys(missing_keys=['vision_encoder.encoder.blocks.0.lora_r', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.1.lora_r', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.2.lora_r', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.3.lora_r', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.4.lora_r', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.5.lora_r', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.6.lora_r', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.7.lora_r', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.8.lora_r', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.9.lora_r', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.10.lora_r', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.11.lora_r', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.bias'], unexpected_keys=['clip_teacher.class_embedding', 'clip_teacher.positional_embedding', 'clip_teacher.proj', 'clip_teacher.conv1.weight', 'clip_teacher.ln_pre.weight', 'clip_teacher.ln_pre.bias', 'clip_teacher.transformer.resblocks.0.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.0.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.0.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.0.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.0.ln_1.weight', 'clip_teacher.transformer.resblocks.0.ln_1.bias', 'clip_teacher.transformer.resblocks.0.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.0.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.0.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.0.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.0.ln_2.weight', 'clip_teacher.transformer.resblocks.0.ln_2.bias', 'clip_teacher.transformer.resblocks.1.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.1.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.1.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.1.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.1.ln_1.weight', 'clip_teacher.transformer.resblocks.1.ln_1.bias', 'clip_teacher.transformer.resblocks.1.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.1.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.1.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.1.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.1.ln_2.weight', 'clip_teacher.transformer.resblocks.1.ln_2.bias', 'clip_teacher.transformer.resblocks.2.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.2.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.2.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.2.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.2.ln_1.weight', 'clip_teacher.transformer.resblocks.2.ln_1.bias', 'clip_teacher.transformer.resblocks.2.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.2.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.2.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.2.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.2.ln_2.weight', 'clip_teacher.transformer.resblocks.2.ln_2.bias', 'clip_teacher.transformer.resblocks.3.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.3.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.3.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.3.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.3.ln_1.weight', 'clip_teacher.transformer.resblocks.3.ln_1.bias', 'clip_teacher.transformer.resblocks.3.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.3.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.3.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.3.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.3.ln_2.weight', 'clip_teacher.transformer.resblocks.3.ln_2.bias', 'clip_teacher.transformer.resblocks.4.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.4.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.4.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.4.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.4.ln_1.weight', 'clip_teacher.transformer.resblocks.4.ln_1.bias', 'clip_teacher.transformer.resblocks.4.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.4.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.4.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.4.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.4.ln_2.weight', 'clip_teacher.transformer.resblocks.4.ln_2.bias', 'clip_teacher.transformer.resblocks.5.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.5.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.5.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.5.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.5.ln_1.weight', 'clip_teacher.transformer.resblocks.5.ln_1.bias', 'clip_teacher.transformer.resblocks.5.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.5.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.5.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.5.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.5.ln_2.weight', 'clip_teacher.transformer.resblocks.5.ln_2.bias', 'clip_teacher.transformer.resblocks.6.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.6.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.6.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.6.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.6.ln_1.weight', 'clip_teacher.transformer.resblocks.6.ln_1.bias', 'clip_teacher.transformer.resblocks.6.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.6.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.6.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.6.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.6.ln_2.weight', 'clip_teacher.transformer.resblocks.6.ln_2.bias', 'clip_teacher.transformer.resblocks.7.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.7.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.7.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.7.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.7.ln_1.weight', 'clip_teacher.transformer.resblocks.7.ln_1.bias', 'clip_teacher.transformer.resblocks.7.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.7.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.7.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.7.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.7.ln_2.weight', 'clip_teacher.transformer.resblocks.7.ln_2.bias', 'clip_teacher.transformer.resblocks.8.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.8.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.8.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.8.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.8.ln_1.weight', 'clip_teacher.transformer.resblocks.8.ln_1.bias', 'clip_teacher.transformer.resblocks.8.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.8.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.8.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.8.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.8.ln_2.weight', 'clip_teacher.transformer.resblocks.8.ln_2.bias', 'clip_teacher.transformer.resblocks.9.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.9.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.9.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.9.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.9.ln_1.weight', 'clip_teacher.transformer.resblocks.9.ln_1.bias', 'clip_teacher.transformer.resblocks.9.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.9.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.9.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.9.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.9.ln_2.weight', 'clip_teacher.transformer.resblocks.9.ln_2.bias', 'clip_teacher.transformer.resblocks.10.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.10.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.10.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.10.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.10.ln_1.weight', 'clip_teacher.transformer.resblocks.10.ln_1.bias', 'clip_teacher.transformer.resblocks.10.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.10.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.10.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.10.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.10.ln_2.weight', 'clip_teacher.transformer.resblocks.10.ln_2.bias', 'clip_teacher.transformer.resblocks.11.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.11.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.11.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.11.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.11.ln_1.weight', 'clip_teacher.transformer.resblocks.11.ln_1.bias', 'clip_teacher.transformer.resblocks.11.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.11.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.11.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.11.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.11.ln_2.weight', 'clip_teacher.transformer.resblocks.11.ln_2.bias', 'clip_teacher.ln_post.weight', 'clip_teacher.ln_post.bias', 'vision_encoder.clip_decoder.0.head.weight', 'vision_encoder.clip_decoder.0.head.bias', 'vision_encoder.clip_decoder.0.norm.weight', 'vision_encoder.clip_decoder.0.norm.bias', 'vision_encoder.clip_decoder.1.head.weight', 'vision_encoder.clip_decoder.1.head.bias', 'vision_encoder.clip_decoder.1.norm.weight', 'vision_encoder.clip_decoder.1.norm.bias', 'vision_encoder.clip_decoder.2.head.weight', 'vision_encoder.clip_decoder.2.head.bias', 'vision_encoder.clip_decoder.2.norm.weight', 'vision_encoder.clip_decoder.2.norm.bias', 'vision_encoder.clip_decoder.3.head.weight', 'vision_encoder.clip_decoder.3.head.bias', 'vision_encoder.clip_decoder.3.norm.weight', 'vision_encoder.clip_decoder.3.norm.bias', 'vision_encoder.clip_decoder.4.head.weight', 'vision_encoder.clip_decoder.4.head.bias', 'vision_encoder.clip_decoder.4.norm.weight', 'vision_encoder.clip_decoder.4.norm.bias', 'vision_encoder.clip_decoder.5.head.weight', 'vision_encoder.clip_decoder.5.head.bias', 'vision_encoder.clip_decoder.5.norm.weight', 'vision_encoder.clip_decoder.5.norm.bias', 'text_encoder.cls.predictions.bias', 'text_encoder.cls.predictions.transform.dense.weight', 'text_encoder.cls.predictions.transform.dense.bias', 'text_encoder.cls.predictions.transform.LayerNorm.weight', 'text_encoder.cls.predictions.transform.LayerNorm.bias', 'text_encoder.cls.predictions.decoder.weight', 'text_encoder.cls.predictions.decoder.bias'])
2024-05-27T19:27:52 | INFO | tasks.shared_utils : Loaded checkpoint from /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
2024-05-27T19:27:52 | INFO | __main__ : training
2024-05-27T19:27:52 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:27:52 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:27:52 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 5792 batches in total
dataloader index=0 name=video, batch-size=32 length(#batches)=5792 
2024-05-27T19:27:52 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:27:52 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:27:52 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:27:52 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:27:52 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:27:52 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:27:53 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:27:53 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:27:53 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:27:53 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:28:06 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  builtin_warn(*args, **kwargs)

2024-05-27T19:28:06 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  builtin_warn(*args, **kwargs)

2024-05-27T19:29:09 | INFO | umt : Logging to: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2/train.log
2024-05-27T19:29:09 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
  test_file: {
      test: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test1k.json', '/data2/dy/temporal_video/dataset', 'video'] }
  test_types: ['test']
  num_workers: 6
  rtime: False
  pos_num: 1
  neg_num: 10
  stop_key: test/
  is_paragraph_retrieval: False
  is_pretrain: False
  num_frames: 12
  num_frames_test: 12
  batch_size: 2
  max_txt_l: 50
  evaluate: False
  train_shuffle: False
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 12
          sample_type: rand
          num_frames_test: 12
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 50
          video: 50 }
      batch_size: {
          image: 2
          video: 2 }
      batch_size_test: {
          image: 2
          video: 2 } }
  text_enc: bert
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_b16
          img_size: 224
          patch_size: 16
          d_model: 768
          encoder_embed_dim: 768
          encoder_depth: 12
          encoder_num_heads: 12
          drop_path_rate: 0.2
          num_frames: 12
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 12
          clip_decoder_embed_dim: 768
          clip_output_dim: 512
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 224
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      multimodal: {
          enable: True }
      embed_dim: 512
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 1e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 5
      min_lr_multi: 0.01
      warmup_epochs: 1 }
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: user
      project: umt_ret }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
  resume: False
  debug: False
  log_freq: 100
  seed: 3407
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
  rank: 0
  world_size: 1
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-05-27T19:29:09 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video'], 'test_file': {'test': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test1k.json', '/data2/dy/temporal_video/dataset', 'video']}, 'test_types': ['test'], 'num_workers': 6, 'rtime': False, 'pos_num': 1, 'neg_num': 10, 'stop_key': 'test/', 'is_paragraph_retrieval': False, 'is_pretrain': False, 'num_frames': 12, 'num_frames_test': 12, 'batch_size': 2, 'max_txt_l': 50, 'evaluate': False, 'train_shuffle': False, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 12, 'sample_type': 'rand', 'num_frames_test': 12, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 50, 'video': 50}, 'batch_size': {'image': 2, 'video': 2}, 'batch_size_test': {'image': 2, 'video': 2}}, 'text_enc': 'bert', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_b16', 'img_size': 224, 'patch_size': 16, 'd_model': 768, 'encoder_embed_dim': 768, 'encoder_depth': 12, 'encoder_num_heads': 12, 'drop_path_rate': 0.2, 'num_frames': 12, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 12, 'clip_decoder_embed_dim': 768, 'clip_output_dim': 512, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 224, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'multimodal': {'enable': True}, 'embed_dim': 512, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 1e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 5, 'min_lr_multi': 0.01, 'warmup_epochs': 1}, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': False, 'entity': 'user', 'project': 'umt_ret'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': 'exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 3407, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth', 'rank': 0, 'world_size': 1, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2024-05-27T19:29:09 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
2024-05-27T19:29:09 | INFO | tasks.pretrain : Creating dataset for ret
2024-05-27T19:29:10 | INFO | tasks.shared_utils : Creating model
2024-05-27T19:29:20 | INFO | models.umt : Build vision_encoder: vit_b16
2024-05-27T19:29:20 | INFO | models.backbones.vit.vit : Num of patches: 2352
2024-05-27T19:29:20 | INFO | models.backbones.vit.vit : Use checkpoint: True
2024-05-27T19:29:20 | INFO | models.backbones.vit.vit : Checkpoint number: 12
2024-05-27T19:29:20 | INFO | models.backbones.vit.vit : Student return index: []
2024-05-27T19:29:27 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
2024-05-27T19:29:28 | INFO | models.umt : Build text_encoder bert_base
2024-05-27T19:29:29 | INFO | models.backbones.bert.xbert : build bert with cross_module: ca
2024-05-27T19:29:29 | INFO | models.criterions : Norm type: l2
2024-05-27T19:29:29 | INFO | models.criterions : Loss type: l2
2024-05-27T19:29:29 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.temp: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.weight: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.weight: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.embeddings.word_embeddings.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.embeddings.position_embeddings.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.embeddings.token_type_embeddings.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.vision_proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.text_proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.itm_head.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : param module.itm_head.bias: wd: 0, lr: 1e-05
2024-05-27T19:29:29 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0.02 len(p)=164
2024-05-27T19:29:29 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0 len(p)=304
2024-05-27T19:29:29 | INFO | tasks.shared_utils : Auto resuming
2024-05-27T19:29:29 | INFO | tasks.shared_utils : Not found checkpoint in exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
2024-05-27T19:29:30 | INFO | tasks.shared_utils : _IncompatibleKeys(missing_keys=['vision_encoder.encoder.blocks.0.lora_r', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.1.lora_r', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.2.lora_r', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.3.lora_r', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.4.lora_r', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.5.lora_r', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.6.lora_r', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.7.lora_r', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.8.lora_r', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.9.lora_r', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.10.lora_r', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.11.lora_r', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.bias'], unexpected_keys=['clip_teacher.class_embedding', 'clip_teacher.positional_embedding', 'clip_teacher.proj', 'clip_teacher.conv1.weight', 'clip_teacher.ln_pre.weight', 'clip_teacher.ln_pre.bias', 'clip_teacher.transformer.resblocks.0.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.0.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.0.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.0.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.0.ln_1.weight', 'clip_teacher.transformer.resblocks.0.ln_1.bias', 'clip_teacher.transformer.resblocks.0.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.0.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.0.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.0.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.0.ln_2.weight', 'clip_teacher.transformer.resblocks.0.ln_2.bias', 'clip_teacher.transformer.resblocks.1.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.1.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.1.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.1.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.1.ln_1.weight', 'clip_teacher.transformer.resblocks.1.ln_1.bias', 'clip_teacher.transformer.resblocks.1.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.1.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.1.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.1.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.1.ln_2.weight', 'clip_teacher.transformer.resblocks.1.ln_2.bias', 'clip_teacher.transformer.resblocks.2.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.2.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.2.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.2.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.2.ln_1.weight', 'clip_teacher.transformer.resblocks.2.ln_1.bias', 'clip_teacher.transformer.resblocks.2.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.2.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.2.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.2.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.2.ln_2.weight', 'clip_teacher.transformer.resblocks.2.ln_2.bias', 'clip_teacher.transformer.resblocks.3.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.3.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.3.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.3.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.3.ln_1.weight', 'clip_teacher.transformer.resblocks.3.ln_1.bias', 'clip_teacher.transformer.resblocks.3.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.3.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.3.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.3.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.3.ln_2.weight', 'clip_teacher.transformer.resblocks.3.ln_2.bias', 'clip_teacher.transformer.resblocks.4.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.4.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.4.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.4.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.4.ln_1.weight', 'clip_teacher.transformer.resblocks.4.ln_1.bias', 'clip_teacher.transformer.resblocks.4.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.4.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.4.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.4.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.4.ln_2.weight', 'clip_teacher.transformer.resblocks.4.ln_2.bias', 'clip_teacher.transformer.resblocks.5.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.5.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.5.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.5.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.5.ln_1.weight', 'clip_teacher.transformer.resblocks.5.ln_1.bias', 'clip_teacher.transformer.resblocks.5.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.5.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.5.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.5.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.5.ln_2.weight', 'clip_teacher.transformer.resblocks.5.ln_2.bias', 'clip_teacher.transformer.resblocks.6.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.6.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.6.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.6.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.6.ln_1.weight', 'clip_teacher.transformer.resblocks.6.ln_1.bias', 'clip_teacher.transformer.resblocks.6.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.6.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.6.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.6.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.6.ln_2.weight', 'clip_teacher.transformer.resblocks.6.ln_2.bias', 'clip_teacher.transformer.resblocks.7.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.7.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.7.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.7.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.7.ln_1.weight', 'clip_teacher.transformer.resblocks.7.ln_1.bias', 'clip_teacher.transformer.resblocks.7.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.7.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.7.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.7.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.7.ln_2.weight', 'clip_teacher.transformer.resblocks.7.ln_2.bias', 'clip_teacher.transformer.resblocks.8.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.8.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.8.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.8.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.8.ln_1.weight', 'clip_teacher.transformer.resblocks.8.ln_1.bias', 'clip_teacher.transformer.resblocks.8.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.8.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.8.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.8.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.8.ln_2.weight', 'clip_teacher.transformer.resblocks.8.ln_2.bias', 'clip_teacher.transformer.resblocks.9.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.9.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.9.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.9.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.9.ln_1.weight', 'clip_teacher.transformer.resblocks.9.ln_1.bias', 'clip_teacher.transformer.resblocks.9.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.9.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.9.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.9.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.9.ln_2.weight', 'clip_teacher.transformer.resblocks.9.ln_2.bias', 'clip_teacher.transformer.resblocks.10.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.10.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.10.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.10.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.10.ln_1.weight', 'clip_teacher.transformer.resblocks.10.ln_1.bias', 'clip_teacher.transformer.resblocks.10.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.10.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.10.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.10.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.10.ln_2.weight', 'clip_teacher.transformer.resblocks.10.ln_2.bias', 'clip_teacher.transformer.resblocks.11.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.11.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.11.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.11.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.11.ln_1.weight', 'clip_teacher.transformer.resblocks.11.ln_1.bias', 'clip_teacher.transformer.resblocks.11.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.11.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.11.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.11.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.11.ln_2.weight', 'clip_teacher.transformer.resblocks.11.ln_2.bias', 'clip_teacher.ln_post.weight', 'clip_teacher.ln_post.bias', 'vision_encoder.clip_decoder.0.head.weight', 'vision_encoder.clip_decoder.0.head.bias', 'vision_encoder.clip_decoder.0.norm.weight', 'vision_encoder.clip_decoder.0.norm.bias', 'vision_encoder.clip_decoder.1.head.weight', 'vision_encoder.clip_decoder.1.head.bias', 'vision_encoder.clip_decoder.1.norm.weight', 'vision_encoder.clip_decoder.1.norm.bias', 'vision_encoder.clip_decoder.2.head.weight', 'vision_encoder.clip_decoder.2.head.bias', 'vision_encoder.clip_decoder.2.norm.weight', 'vision_encoder.clip_decoder.2.norm.bias', 'vision_encoder.clip_decoder.3.head.weight', 'vision_encoder.clip_decoder.3.head.bias', 'vision_encoder.clip_decoder.3.norm.weight', 'vision_encoder.clip_decoder.3.norm.bias', 'vision_encoder.clip_decoder.4.head.weight', 'vision_encoder.clip_decoder.4.head.bias', 'vision_encoder.clip_decoder.4.norm.weight', 'vision_encoder.clip_decoder.4.norm.bias', 'vision_encoder.clip_decoder.5.head.weight', 'vision_encoder.clip_decoder.5.head.bias', 'vision_encoder.clip_decoder.5.norm.weight', 'vision_encoder.clip_decoder.5.norm.bias', 'text_encoder.cls.predictions.bias', 'text_encoder.cls.predictions.transform.dense.weight', 'text_encoder.cls.predictions.transform.dense.bias', 'text_encoder.cls.predictions.transform.LayerNorm.weight', 'text_encoder.cls.predictions.transform.LayerNorm.bias', 'text_encoder.cls.predictions.decoder.weight', 'text_encoder.cls.predictions.decoder.bias'])
2024-05-27T19:29:30 | INFO | tasks.shared_utils : Loaded checkpoint from /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
2024-05-27T19:29:30 | INFO | __main__ : training
2024-05-27T19:29:31 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:29:31 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:29:31 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:29:31 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:29:31 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:29:31 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:29:31 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:29:31 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:29:31 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:29:31 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:29:31 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:29:31 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:29:31 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 92685 batches in total
dataloader index=0 name=video, batch-size=2 length(#batches)=92685 
2024-05-27T19:29:32 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  builtin_warn(*args, **kwargs)

2024-05-27T19:29:32 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  builtin_warn(*args, **kwargs)

2024-05-27T19:29:33 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  builtin_warn(*args, **kwargs)

2024-05-27T19:29:33 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  builtin_warn(*args, **kwargs)

2024-05-27T19:29:33 | INFO | utils.basic_utils : Train Epoch: [0]  [    0/92685]  eta: 1 day, 14:36:13  lr: 0.000000  temperature: 0.0112  video-loss_vtc: 2.2963  video-loss_vtm: 1.5841  time: 1.4994  data: 0.3734  max mem: 5348 res mem: 5698
2024-05-27T19:30:42 | INFO | umt : Logging to: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2/train.log
2024-05-27T19:30:42 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
  test_file: {
      test: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test1k.json', '/data2/dy/temporal_video/dataset', 'video'] }
  test_types: ['test']
  num_workers: 6
  rtime: False
  pos_num: 1
  neg_num: 10
  stop_key: test/
  is_paragraph_retrieval: False
  is_pretrain: False
  num_frames: 12
  num_frames_test: 12
  batch_size: 2
  max_txt_l: 50
  evaluate: False
  train_shuffle: False
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 12
          sample_type: rand
          num_frames_test: 12
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 50
          video: 50 }
      batch_size: {
          image: 2
          video: 2 }
      batch_size_test: {
          image: 2
          video: 2 } }
  text_enc: bert
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_b16
          img_size: 224
          patch_size: 16
          d_model: 768
          encoder_embed_dim: 768
          encoder_depth: 12
          encoder_num_heads: 12
          drop_path_rate: 0.2
          num_frames: 12
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 12
          clip_decoder_embed_dim: 768
          clip_output_dim: 512
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 224
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      multimodal: {
          enable: True }
      embed_dim: 512
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 1e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 5
      min_lr_multi: 0.01
      warmup_epochs: 1 }
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: user
      project: umt_ret }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
  resume: False
  debug: False
  log_freq: 100
  seed: 3407
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
  rank: 0
  world_size: 1
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-05-27T19:30:42 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video'], 'test_file': {'test': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test1k.json', '/data2/dy/temporal_video/dataset', 'video']}, 'test_types': ['test'], 'num_workers': 6, 'rtime': False, 'pos_num': 1, 'neg_num': 10, 'stop_key': 'test/', 'is_paragraph_retrieval': False, 'is_pretrain': False, 'num_frames': 12, 'num_frames_test': 12, 'batch_size': 2, 'max_txt_l': 50, 'evaluate': False, 'train_shuffle': False, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 12, 'sample_type': 'rand', 'num_frames_test': 12, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 50, 'video': 50}, 'batch_size': {'image': 2, 'video': 2}, 'batch_size_test': {'image': 2, 'video': 2}}, 'text_enc': 'bert', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_b16', 'img_size': 224, 'patch_size': 16, 'd_model': 768, 'encoder_embed_dim': 768, 'encoder_depth': 12, 'encoder_num_heads': 12, 'drop_path_rate': 0.2, 'num_frames': 12, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 12, 'clip_decoder_embed_dim': 768, 'clip_output_dim': 512, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 224, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'multimodal': {'enable': True}, 'embed_dim': 512, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 1e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 5, 'min_lr_multi': 0.01, 'warmup_epochs': 1}, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': False, 'entity': 'user', 'project': 'umt_ret'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': 'exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 3407, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth', 'rank': 0, 'world_size': 1, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2024-05-27T19:30:42 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
2024-05-27T19:30:42 | INFO | tasks.pretrain : Creating dataset for ret
2024-05-27T19:30:43 | INFO | tasks.shared_utils : Creating model
2024-05-27T19:30:53 | INFO | models.umt : Build vision_encoder: vit_b16
2024-05-27T19:30:53 | INFO | models.backbones.vit.vit : Num of patches: 2352
2024-05-27T19:30:53 | INFO | models.backbones.vit.vit : Use checkpoint: True
2024-05-27T19:30:53 | INFO | models.backbones.vit.vit : Checkpoint number: 12
2024-05-27T19:30:53 | INFO | models.backbones.vit.vit : Student return index: []
2024-05-27T19:31:00 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
2024-05-27T19:31:01 | INFO | models.umt : Build text_encoder bert_base
2024-05-27T19:31:02 | INFO | models.backbones.bert.xbert : build bert with cross_module: ca
2024-05-27T19:31:02 | INFO | models.criterions : Norm type: l2
2024-05-27T19:31:02 | INFO | models.criterions : Loss type: l2
2024-05-27T19:31:02 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-05-27T19:31:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:31:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:31:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:31:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:31:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:31:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:31:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:31:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:31:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:31:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:31:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:31:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:31:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:31:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:31:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:31:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:31:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:31:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:31:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:31:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:31:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:31:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:31:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:31:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:31:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:31:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:31:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:31:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:31:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:31:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:31:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:31:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:31:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:31:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:31:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:31:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:31:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:31:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:31:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:31:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:31:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:31:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:31:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:31:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:31:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:31:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:31:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:31:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:31:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:31:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:31:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:31:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:31:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:31:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:31:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:31:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:31:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:31:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:31:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:31:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:31:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:31:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:31:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:31:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:31:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:31:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:31:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:31:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:31:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:31:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:31:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:31:02 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:31:02 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0 len(p)=48
2024-05-27T19:31:02 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0.02 len(p)=24
2024-05-27T19:31:02 | INFO | tasks.shared_utils : Auto resuming
2024-05-27T19:31:02 | INFO | tasks.shared_utils : Not found checkpoint in exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
2024-05-27T19:31:03 | INFO | tasks.shared_utils : _IncompatibleKeys(missing_keys=['vision_encoder.encoder.blocks.0.lora_r', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.1.lora_r', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.2.lora_r', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.3.lora_r', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.4.lora_r', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.5.lora_r', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.6.lora_r', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.7.lora_r', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.8.lora_r', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.9.lora_r', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.10.lora_r', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.11.lora_r', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.bias'], unexpected_keys=['clip_teacher.class_embedding', 'clip_teacher.positional_embedding', 'clip_teacher.proj', 'clip_teacher.conv1.weight', 'clip_teacher.ln_pre.weight', 'clip_teacher.ln_pre.bias', 'clip_teacher.transformer.resblocks.0.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.0.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.0.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.0.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.0.ln_1.weight', 'clip_teacher.transformer.resblocks.0.ln_1.bias', 'clip_teacher.transformer.resblocks.0.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.0.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.0.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.0.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.0.ln_2.weight', 'clip_teacher.transformer.resblocks.0.ln_2.bias', 'clip_teacher.transformer.resblocks.1.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.1.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.1.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.1.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.1.ln_1.weight', 'clip_teacher.transformer.resblocks.1.ln_1.bias', 'clip_teacher.transformer.resblocks.1.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.1.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.1.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.1.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.1.ln_2.weight', 'clip_teacher.transformer.resblocks.1.ln_2.bias', 'clip_teacher.transformer.resblocks.2.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.2.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.2.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.2.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.2.ln_1.weight', 'clip_teacher.transformer.resblocks.2.ln_1.bias', 'clip_teacher.transformer.resblocks.2.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.2.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.2.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.2.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.2.ln_2.weight', 'clip_teacher.transformer.resblocks.2.ln_2.bias', 'clip_teacher.transformer.resblocks.3.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.3.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.3.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.3.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.3.ln_1.weight', 'clip_teacher.transformer.resblocks.3.ln_1.bias', 'clip_teacher.transformer.resblocks.3.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.3.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.3.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.3.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.3.ln_2.weight', 'clip_teacher.transformer.resblocks.3.ln_2.bias', 'clip_teacher.transformer.resblocks.4.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.4.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.4.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.4.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.4.ln_1.weight', 'clip_teacher.transformer.resblocks.4.ln_1.bias', 'clip_teacher.transformer.resblocks.4.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.4.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.4.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.4.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.4.ln_2.weight', 'clip_teacher.transformer.resblocks.4.ln_2.bias', 'clip_teacher.transformer.resblocks.5.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.5.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.5.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.5.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.5.ln_1.weight', 'clip_teacher.transformer.resblocks.5.ln_1.bias', 'clip_teacher.transformer.resblocks.5.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.5.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.5.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.5.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.5.ln_2.weight', 'clip_teacher.transformer.resblocks.5.ln_2.bias', 'clip_teacher.transformer.resblocks.6.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.6.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.6.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.6.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.6.ln_1.weight', 'clip_teacher.transformer.resblocks.6.ln_1.bias', 'clip_teacher.transformer.resblocks.6.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.6.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.6.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.6.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.6.ln_2.weight', 'clip_teacher.transformer.resblocks.6.ln_2.bias', 'clip_teacher.transformer.resblocks.7.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.7.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.7.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.7.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.7.ln_1.weight', 'clip_teacher.transformer.resblocks.7.ln_1.bias', 'clip_teacher.transformer.resblocks.7.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.7.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.7.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.7.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.7.ln_2.weight', 'clip_teacher.transformer.resblocks.7.ln_2.bias', 'clip_teacher.transformer.resblocks.8.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.8.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.8.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.8.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.8.ln_1.weight', 'clip_teacher.transformer.resblocks.8.ln_1.bias', 'clip_teacher.transformer.resblocks.8.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.8.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.8.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.8.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.8.ln_2.weight', 'clip_teacher.transformer.resblocks.8.ln_2.bias', 'clip_teacher.transformer.resblocks.9.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.9.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.9.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.9.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.9.ln_1.weight', 'clip_teacher.transformer.resblocks.9.ln_1.bias', 'clip_teacher.transformer.resblocks.9.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.9.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.9.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.9.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.9.ln_2.weight', 'clip_teacher.transformer.resblocks.9.ln_2.bias', 'clip_teacher.transformer.resblocks.10.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.10.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.10.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.10.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.10.ln_1.weight', 'clip_teacher.transformer.resblocks.10.ln_1.bias', 'clip_teacher.transformer.resblocks.10.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.10.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.10.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.10.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.10.ln_2.weight', 'clip_teacher.transformer.resblocks.10.ln_2.bias', 'clip_teacher.transformer.resblocks.11.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.11.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.11.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.11.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.11.ln_1.weight', 'clip_teacher.transformer.resblocks.11.ln_1.bias', 'clip_teacher.transformer.resblocks.11.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.11.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.11.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.11.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.11.ln_2.weight', 'clip_teacher.transformer.resblocks.11.ln_2.bias', 'clip_teacher.ln_post.weight', 'clip_teacher.ln_post.bias', 'vision_encoder.clip_decoder.0.head.weight', 'vision_encoder.clip_decoder.0.head.bias', 'vision_encoder.clip_decoder.0.norm.weight', 'vision_encoder.clip_decoder.0.norm.bias', 'vision_encoder.clip_decoder.1.head.weight', 'vision_encoder.clip_decoder.1.head.bias', 'vision_encoder.clip_decoder.1.norm.weight', 'vision_encoder.clip_decoder.1.norm.bias', 'vision_encoder.clip_decoder.2.head.weight', 'vision_encoder.clip_decoder.2.head.bias', 'vision_encoder.clip_decoder.2.norm.weight', 'vision_encoder.clip_decoder.2.norm.bias', 'vision_encoder.clip_decoder.3.head.weight', 'vision_encoder.clip_decoder.3.head.bias', 'vision_encoder.clip_decoder.3.norm.weight', 'vision_encoder.clip_decoder.3.norm.bias', 'vision_encoder.clip_decoder.4.head.weight', 'vision_encoder.clip_decoder.4.head.bias', 'vision_encoder.clip_decoder.4.norm.weight', 'vision_encoder.clip_decoder.4.norm.bias', 'vision_encoder.clip_decoder.5.head.weight', 'vision_encoder.clip_decoder.5.head.bias', 'vision_encoder.clip_decoder.5.norm.weight', 'vision_encoder.clip_decoder.5.norm.bias', 'text_encoder.cls.predictions.bias', 'text_encoder.cls.predictions.transform.dense.weight', 'text_encoder.cls.predictions.transform.dense.bias', 'text_encoder.cls.predictions.transform.LayerNorm.weight', 'text_encoder.cls.predictions.transform.LayerNorm.bias', 'text_encoder.cls.predictions.decoder.weight', 'text_encoder.cls.predictions.decoder.bias'])
2024-05-27T19:31:03 | INFO | tasks.shared_utils : Loaded checkpoint from /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
2024-05-27T19:31:03 | INFO | __main__ : training
2024-05-27T19:31:04 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:31:04 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:31:04 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:31:04 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:31:04 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:31:04 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:31:04 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:31:04 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:31:04 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:31:04 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:31:04 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:31:04 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:31:04 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 92685 batches in total
dataloader index=0 name=video, batch-size=2 length(#batches)=92685 
2024-05-27T19:31:05 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  builtin_warn(*args, **kwargs)

2024-05-27T19:31:05 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  builtin_warn(*args, **kwargs)

2024-05-27T19:31:05 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-05-27T19:31:05 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-05-27T19:35:37 | INFO | umt : Logging to: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2/train.log
2024-05-27T19:35:37 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
  test_file: {
      test: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test1k.json', '/data2/dy/temporal_video/dataset', 'video'] }
  test_types: ['test']
  num_workers: 6
  rtime: False
  pos_num: 1
  neg_num: 10
  stop_key: test/
  is_paragraph_retrieval: False
  is_pretrain: False
  num_frames: 12
  num_frames_test: 12
  batch_size: 2
  max_txt_l: 50
  evaluate: False
  train_shuffle: False
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 12
          sample_type: rand
          num_frames_test: 12
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 50
          video: 50 }
      batch_size: {
          image: 2
          video: 2 }
      batch_size_test: {
          image: 2
          video: 2 } }
  text_enc: bert
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_b16
          img_size: 224
          patch_size: 16
          d_model: 768
          encoder_embed_dim: 768
          encoder_depth: 12
          encoder_num_heads: 12
          drop_path_rate: 0.2
          num_frames: 12
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 12
          clip_decoder_embed_dim: 768
          clip_output_dim: 512
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 224
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      multimodal: {
          enable: True }
      embed_dim: 512
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 1e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 5
      min_lr_multi: 0.01
      warmup_epochs: 1 }
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: user
      project: umt_ret }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
  resume: False
  debug: False
  log_freq: 100
  seed: 3407
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
  rank: 0
  world_size: 1
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-05-27T19:35:37 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video'], 'test_file': {'test': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test1k.json', '/data2/dy/temporal_video/dataset', 'video']}, 'test_types': ['test'], 'num_workers': 6, 'rtime': False, 'pos_num': 1, 'neg_num': 10, 'stop_key': 'test/', 'is_paragraph_retrieval': False, 'is_pretrain': False, 'num_frames': 12, 'num_frames_test': 12, 'batch_size': 2, 'max_txt_l': 50, 'evaluate': False, 'train_shuffle': False, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 12, 'sample_type': 'rand', 'num_frames_test': 12, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 50, 'video': 50}, 'batch_size': {'image': 2, 'video': 2}, 'batch_size_test': {'image': 2, 'video': 2}}, 'text_enc': 'bert', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_b16', 'img_size': 224, 'patch_size': 16, 'd_model': 768, 'encoder_embed_dim': 768, 'encoder_depth': 12, 'encoder_num_heads': 12, 'drop_path_rate': 0.2, 'num_frames': 12, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 12, 'clip_decoder_embed_dim': 768, 'clip_output_dim': 512, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 224, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'multimodal': {'enable': True}, 'embed_dim': 512, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 1e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 5, 'min_lr_multi': 0.01, 'warmup_epochs': 1}, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': False, 'entity': 'user', 'project': 'umt_ret'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': 'exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 3407, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth', 'rank': 0, 'world_size': 1, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2024-05-27T19:35:37 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
2024-05-27T19:35:37 | INFO | tasks.pretrain : Creating dataset for ret
2024-05-27T19:35:38 | INFO | tasks.shared_utils : Creating model
2024-05-27T19:35:48 | INFO | models.umt : Build vision_encoder: vit_b16
2024-05-27T19:35:48 | INFO | models.backbones.vit.vit : Num of patches: 2352
2024-05-27T19:35:48 | INFO | models.backbones.vit.vit : Use checkpoint: True
2024-05-27T19:35:48 | INFO | models.backbones.vit.vit : Checkpoint number: 12
2024-05-27T19:35:48 | INFO | models.backbones.vit.vit : Student return index: []
2024-05-27T19:35:56 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
2024-05-27T19:35:57 | INFO | models.umt : Build text_encoder bert_base
2024-05-27T19:35:58 | INFO | models.backbones.bert.xbert : build bert with cross_module: ca
2024-05-27T19:35:58 | INFO | models.criterions : Norm type: l2
2024-05-27T19:35:58 | INFO | models.criterions : Loss type: l2
2024-05-27T19:39:02 | INFO | umt : Logging to: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2/train.log
2024-05-27T19:39:02 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
  test_file: {
      test: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test1k.json', '/data2/dy/temporal_video/dataset', 'video'] }
  test_types: ['test']
  num_workers: 6
  rtime: False
  pos_num: 1
  neg_num: 10
  stop_key: test/
  is_paragraph_retrieval: False
  is_pretrain: False
  num_frames: 12
  num_frames_test: 12
  batch_size: 2
  max_txt_l: 50
  evaluate: False
  train_shuffle: False
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 12
          sample_type: rand
          num_frames_test: 12
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 50
          video: 50 }
      batch_size: {
          image: 2
          video: 2 }
      batch_size_test: {
          image: 2
          video: 2 } }
  text_enc: bert
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_b16
          img_size: 224
          patch_size: 16
          d_model: 768
          encoder_embed_dim: 768
          encoder_depth: 12
          encoder_num_heads: 12
          drop_path_rate: 0.2
          num_frames: 12
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 12
          clip_decoder_embed_dim: 768
          clip_output_dim: 512
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 224
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      multimodal: {
          enable: True }
      embed_dim: 512
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 1e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 5
      min_lr_multi: 0.01
      warmup_epochs: 1 }
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: user
      project: umt_ret }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
  resume: False
  debug: False
  log_freq: 100
  seed: 3407
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
  rank: 0
  world_size: 1
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-05-27T19:39:02 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video'], 'test_file': {'test': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test1k.json', '/data2/dy/temporal_video/dataset', 'video']}, 'test_types': ['test'], 'num_workers': 6, 'rtime': False, 'pos_num': 1, 'neg_num': 10, 'stop_key': 'test/', 'is_paragraph_retrieval': False, 'is_pretrain': False, 'num_frames': 12, 'num_frames_test': 12, 'batch_size': 2, 'max_txt_l': 50, 'evaluate': False, 'train_shuffle': False, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 12, 'sample_type': 'rand', 'num_frames_test': 12, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 50, 'video': 50}, 'batch_size': {'image': 2, 'video': 2}, 'batch_size_test': {'image': 2, 'video': 2}}, 'text_enc': 'bert', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_b16', 'img_size': 224, 'patch_size': 16, 'd_model': 768, 'encoder_embed_dim': 768, 'encoder_depth': 12, 'encoder_num_heads': 12, 'drop_path_rate': 0.2, 'num_frames': 12, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 12, 'clip_decoder_embed_dim': 768, 'clip_output_dim': 512, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 224, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'multimodal': {'enable': True}, 'embed_dim': 512, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 1e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 5, 'min_lr_multi': 0.01, 'warmup_epochs': 1}, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': False, 'entity': 'user', 'project': 'umt_ret'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': 'exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 3407, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth', 'rank': 0, 'world_size': 1, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2024-05-27T19:39:02 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
2024-05-27T19:39:02 | INFO | tasks.pretrain : Creating dataset for ret
2024-05-27T19:39:03 | INFO | tasks.shared_utils : Creating model
2024-05-27T19:39:13 | INFO | models.umt : Build vision_encoder: vit_b16
2024-05-27T19:39:13 | INFO | models.backbones.vit.vit : Num of patches: 2352
2024-05-27T19:39:13 | INFO | models.backbones.vit.vit : Use checkpoint: True
2024-05-27T19:39:13 | INFO | models.backbones.vit.vit : Checkpoint number: 12
2024-05-27T19:39:13 | INFO | models.backbones.vit.vit : Student return index: []
2024-05-27T19:39:20 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
2024-05-27T19:39:21 | INFO | models.umt : Build text_encoder bert_base
2024-05-27T19:39:22 | INFO | models.backbones.bert.xbert : build bert with cross_module: ca
2024-05-27T19:39:22 | INFO | models.criterions : Norm type: l2
2024-05-27T19:39:22 | INFO | models.criterions : Loss type: l2
2024-05-27T19:39:22 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-05-27T19:39:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:39:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:39:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:39:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:39:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:39:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:39:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:39:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:39:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:39:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:39:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:39:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:39:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:39:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:39:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:39:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:39:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:39:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:39:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:39:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:39:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:39:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:39:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:39:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:39:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:39:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:39:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:39:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:39:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:39:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:39:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:39:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:39:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:39:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:39:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:39:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:39:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:39:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:39:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:39:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:39:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:39:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:39:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:39:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:39:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:39:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:39:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:39:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:39:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:39:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:39:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:39:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:39:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:39:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:39:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:39:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:39:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:39:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:39:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:39:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:39:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:39:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:39:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:39:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:39:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:39:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:39:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:39:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:39:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:39:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:39:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:39:22 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:39:22 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0 len(p)=48
2024-05-27T19:39:22 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0.02 len(p)=24
2024-05-27T19:39:22 | INFO | tasks.shared_utils : Auto resuming
2024-05-27T19:39:22 | INFO | tasks.shared_utils : Not found checkpoint in exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
2024-05-27T19:39:23 | INFO | tasks.shared_utils : _IncompatibleKeys(missing_keys=['vision_encoder.encoder.blocks.0.lora_r', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.1.lora_r', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.2.lora_r', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.3.lora_r', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.4.lora_r', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.5.lora_r', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.6.lora_r', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.7.lora_r', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.8.lora_r', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.9.lora_r', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.10.lora_r', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.11.lora_r', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.bias'], unexpected_keys=['clip_teacher.class_embedding', 'clip_teacher.positional_embedding', 'clip_teacher.proj', 'clip_teacher.conv1.weight', 'clip_teacher.ln_pre.weight', 'clip_teacher.ln_pre.bias', 'clip_teacher.transformer.resblocks.0.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.0.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.0.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.0.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.0.ln_1.weight', 'clip_teacher.transformer.resblocks.0.ln_1.bias', 'clip_teacher.transformer.resblocks.0.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.0.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.0.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.0.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.0.ln_2.weight', 'clip_teacher.transformer.resblocks.0.ln_2.bias', 'clip_teacher.transformer.resblocks.1.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.1.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.1.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.1.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.1.ln_1.weight', 'clip_teacher.transformer.resblocks.1.ln_1.bias', 'clip_teacher.transformer.resblocks.1.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.1.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.1.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.1.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.1.ln_2.weight', 'clip_teacher.transformer.resblocks.1.ln_2.bias', 'clip_teacher.transformer.resblocks.2.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.2.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.2.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.2.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.2.ln_1.weight', 'clip_teacher.transformer.resblocks.2.ln_1.bias', 'clip_teacher.transformer.resblocks.2.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.2.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.2.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.2.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.2.ln_2.weight', 'clip_teacher.transformer.resblocks.2.ln_2.bias', 'clip_teacher.transformer.resblocks.3.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.3.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.3.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.3.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.3.ln_1.weight', 'clip_teacher.transformer.resblocks.3.ln_1.bias', 'clip_teacher.transformer.resblocks.3.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.3.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.3.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.3.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.3.ln_2.weight', 'clip_teacher.transformer.resblocks.3.ln_2.bias', 'clip_teacher.transformer.resblocks.4.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.4.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.4.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.4.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.4.ln_1.weight', 'clip_teacher.transformer.resblocks.4.ln_1.bias', 'clip_teacher.transformer.resblocks.4.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.4.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.4.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.4.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.4.ln_2.weight', 'clip_teacher.transformer.resblocks.4.ln_2.bias', 'clip_teacher.transformer.resblocks.5.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.5.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.5.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.5.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.5.ln_1.weight', 'clip_teacher.transformer.resblocks.5.ln_1.bias', 'clip_teacher.transformer.resblocks.5.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.5.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.5.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.5.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.5.ln_2.weight', 'clip_teacher.transformer.resblocks.5.ln_2.bias', 'clip_teacher.transformer.resblocks.6.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.6.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.6.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.6.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.6.ln_1.weight', 'clip_teacher.transformer.resblocks.6.ln_1.bias', 'clip_teacher.transformer.resblocks.6.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.6.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.6.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.6.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.6.ln_2.weight', 'clip_teacher.transformer.resblocks.6.ln_2.bias', 'clip_teacher.transformer.resblocks.7.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.7.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.7.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.7.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.7.ln_1.weight', 'clip_teacher.transformer.resblocks.7.ln_1.bias', 'clip_teacher.transformer.resblocks.7.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.7.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.7.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.7.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.7.ln_2.weight', 'clip_teacher.transformer.resblocks.7.ln_2.bias', 'clip_teacher.transformer.resblocks.8.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.8.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.8.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.8.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.8.ln_1.weight', 'clip_teacher.transformer.resblocks.8.ln_1.bias', 'clip_teacher.transformer.resblocks.8.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.8.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.8.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.8.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.8.ln_2.weight', 'clip_teacher.transformer.resblocks.8.ln_2.bias', 'clip_teacher.transformer.resblocks.9.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.9.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.9.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.9.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.9.ln_1.weight', 'clip_teacher.transformer.resblocks.9.ln_1.bias', 'clip_teacher.transformer.resblocks.9.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.9.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.9.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.9.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.9.ln_2.weight', 'clip_teacher.transformer.resblocks.9.ln_2.bias', 'clip_teacher.transformer.resblocks.10.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.10.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.10.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.10.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.10.ln_1.weight', 'clip_teacher.transformer.resblocks.10.ln_1.bias', 'clip_teacher.transformer.resblocks.10.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.10.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.10.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.10.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.10.ln_2.weight', 'clip_teacher.transformer.resblocks.10.ln_2.bias', 'clip_teacher.transformer.resblocks.11.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.11.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.11.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.11.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.11.ln_1.weight', 'clip_teacher.transformer.resblocks.11.ln_1.bias', 'clip_teacher.transformer.resblocks.11.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.11.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.11.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.11.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.11.ln_2.weight', 'clip_teacher.transformer.resblocks.11.ln_2.bias', 'clip_teacher.ln_post.weight', 'clip_teacher.ln_post.bias', 'vision_encoder.clip_decoder.0.head.weight', 'vision_encoder.clip_decoder.0.head.bias', 'vision_encoder.clip_decoder.0.norm.weight', 'vision_encoder.clip_decoder.0.norm.bias', 'vision_encoder.clip_decoder.1.head.weight', 'vision_encoder.clip_decoder.1.head.bias', 'vision_encoder.clip_decoder.1.norm.weight', 'vision_encoder.clip_decoder.1.norm.bias', 'vision_encoder.clip_decoder.2.head.weight', 'vision_encoder.clip_decoder.2.head.bias', 'vision_encoder.clip_decoder.2.norm.weight', 'vision_encoder.clip_decoder.2.norm.bias', 'vision_encoder.clip_decoder.3.head.weight', 'vision_encoder.clip_decoder.3.head.bias', 'vision_encoder.clip_decoder.3.norm.weight', 'vision_encoder.clip_decoder.3.norm.bias', 'vision_encoder.clip_decoder.4.head.weight', 'vision_encoder.clip_decoder.4.head.bias', 'vision_encoder.clip_decoder.4.norm.weight', 'vision_encoder.clip_decoder.4.norm.bias', 'vision_encoder.clip_decoder.5.head.weight', 'vision_encoder.clip_decoder.5.head.bias', 'vision_encoder.clip_decoder.5.norm.weight', 'vision_encoder.clip_decoder.5.norm.bias', 'text_encoder.cls.predictions.bias', 'text_encoder.cls.predictions.transform.dense.weight', 'text_encoder.cls.predictions.transform.dense.bias', 'text_encoder.cls.predictions.transform.LayerNorm.weight', 'text_encoder.cls.predictions.transform.LayerNorm.bias', 'text_encoder.cls.predictions.decoder.weight', 'text_encoder.cls.predictions.decoder.bias'])
2024-05-27T19:39:23 | INFO | tasks.shared_utils : Loaded checkpoint from /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
2024-05-27T19:39:23 | INFO | __main__ : training
2024-05-27T19:39:24 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:39:24 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:39:24 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:39:24 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:39:24 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:39:24 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:39:24 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:39:24 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:39:24 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:39:24 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:39:24 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:39:24 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:39:24 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 92685 batches in total
dataloader index=0 name=video, batch-size=2 length(#batches)=92685 
2024-05-27T19:39:25 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  builtin_warn(*args, **kwargs)

2024-05-27T19:39:25 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  builtin_warn(*args, **kwargs)

2024-05-27T19:39:25 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-05-27T19:39:25 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-05-27T19:43:23 | INFO | umt : Logging to: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2/train.log
2024-05-27T19:43:23 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
  test_file: {
      test: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test1k.json', '/data2/dy/temporal_video/dataset', 'video'] }
  test_types: ['test']
  num_workers: 6
  rtime: False
  pos_num: 1
  neg_num: 10
  stop_key: test/
  is_paragraph_retrieval: False
  is_pretrain: False
  num_frames: 12
  num_frames_test: 12
  batch_size: 2
  max_txt_l: 50
  evaluate: False
  train_shuffle: False
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 12
          sample_type: rand
          num_frames_test: 12
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 50
          video: 50 }
      batch_size: {
          image: 2
          video: 2 }
      batch_size_test: {
          image: 2
          video: 2 } }
  text_enc: bert
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_b16
          img_size: 224
          patch_size: 16
          d_model: 768
          encoder_embed_dim: 768
          encoder_depth: 12
          encoder_num_heads: 12
          drop_path_rate: 0.2
          num_frames: 12
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 12
          clip_decoder_embed_dim: 768
          clip_output_dim: 512
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 224
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      multimodal: {
          enable: True }
      embed_dim: 512
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 1e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 5
      min_lr_multi: 0.01
      warmup_epochs: 1 }
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: user
      project: umt_ret }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
  resume: False
  debug: False
  log_freq: 100
  seed: 3407
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
  rank: 0
  world_size: 1
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-05-27T19:43:23 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video'], 'test_file': {'test': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test1k.json', '/data2/dy/temporal_video/dataset', 'video']}, 'test_types': ['test'], 'num_workers': 6, 'rtime': False, 'pos_num': 1, 'neg_num': 10, 'stop_key': 'test/', 'is_paragraph_retrieval': False, 'is_pretrain': False, 'num_frames': 12, 'num_frames_test': 12, 'batch_size': 2, 'max_txt_l': 50, 'evaluate': False, 'train_shuffle': False, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 12, 'sample_type': 'rand', 'num_frames_test': 12, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 50, 'video': 50}, 'batch_size': {'image': 2, 'video': 2}, 'batch_size_test': {'image': 2, 'video': 2}}, 'text_enc': 'bert', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_b16', 'img_size': 224, 'patch_size': 16, 'd_model': 768, 'encoder_embed_dim': 768, 'encoder_depth': 12, 'encoder_num_heads': 12, 'drop_path_rate': 0.2, 'num_frames': 12, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 12, 'clip_decoder_embed_dim': 768, 'clip_output_dim': 512, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 224, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'multimodal': {'enable': True}, 'embed_dim': 512, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 1e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 5, 'min_lr_multi': 0.01, 'warmup_epochs': 1}, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': False, 'entity': 'user', 'project': 'umt_ret'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': 'exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 3407, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth', 'rank': 0, 'world_size': 1, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2024-05-27T19:43:23 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
2024-05-27T19:43:23 | INFO | tasks.pretrain : Creating dataset for ret
2024-05-27T19:43:23 | INFO | tasks.shared_utils : Creating model
2024-05-27T19:43:33 | INFO | models.umt : Build vision_encoder: vit_b16
2024-05-27T19:43:33 | INFO | models.backbones.vit.vit : Num of patches: 2352
2024-05-27T19:43:33 | INFO | models.backbones.vit.vit : Use checkpoint: True
2024-05-27T19:43:33 | INFO | models.backbones.vit.vit : Checkpoint number: 12
2024-05-27T19:43:33 | INFO | models.backbones.vit.vit : Student return index: []
2024-05-27T19:43:41 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
2024-05-27T19:43:41 | INFO | models.umt : Build text_encoder bert_base
2024-05-27T19:43:42 | INFO | models.backbones.bert.xbert : build bert with cross_module: ca
2024-05-27T19:43:43 | INFO | models.criterions : Norm type: l2
2024-05-27T19:43:43 | INFO | models.criterions : Loss type: l2
2024-05-27T19:43:43 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.temp: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.weight: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.weight: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.weight: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.weight: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.embeddings.word_embeddings.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.embeddings.position_embeddings.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.embeddings.token_type_embeddings.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.weight: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.vision_proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.text_proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.itm_head.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : param module.itm_head.bias: wd: 0, lr: 1e-05
2024-05-27T19:43:43 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0.02 len(p)=164
2024-05-27T19:43:43 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0 len(p)=304
2024-05-27T19:43:43 | INFO | tasks.shared_utils : Auto resuming
2024-05-27T19:43:43 | INFO | tasks.shared_utils : Not found checkpoint in exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
2024-05-27T19:43:44 | INFO | tasks.shared_utils : _IncompatibleKeys(missing_keys=['vision_encoder.encoder.blocks.0.lora_r', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.1.lora_r', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.2.lora_r', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.3.lora_r', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.4.lora_r', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.5.lora_r', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.6.lora_r', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.7.lora_r', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.8.lora_r', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.9.lora_r', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.10.lora_r', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.11.lora_r', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.bias'], unexpected_keys=['clip_teacher.class_embedding', 'clip_teacher.positional_embedding', 'clip_teacher.proj', 'clip_teacher.conv1.weight', 'clip_teacher.ln_pre.weight', 'clip_teacher.ln_pre.bias', 'clip_teacher.transformer.resblocks.0.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.0.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.0.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.0.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.0.ln_1.weight', 'clip_teacher.transformer.resblocks.0.ln_1.bias', 'clip_teacher.transformer.resblocks.0.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.0.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.0.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.0.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.0.ln_2.weight', 'clip_teacher.transformer.resblocks.0.ln_2.bias', 'clip_teacher.transformer.resblocks.1.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.1.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.1.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.1.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.1.ln_1.weight', 'clip_teacher.transformer.resblocks.1.ln_1.bias', 'clip_teacher.transformer.resblocks.1.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.1.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.1.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.1.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.1.ln_2.weight', 'clip_teacher.transformer.resblocks.1.ln_2.bias', 'clip_teacher.transformer.resblocks.2.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.2.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.2.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.2.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.2.ln_1.weight', 'clip_teacher.transformer.resblocks.2.ln_1.bias', 'clip_teacher.transformer.resblocks.2.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.2.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.2.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.2.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.2.ln_2.weight', 'clip_teacher.transformer.resblocks.2.ln_2.bias', 'clip_teacher.transformer.resblocks.3.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.3.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.3.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.3.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.3.ln_1.weight', 'clip_teacher.transformer.resblocks.3.ln_1.bias', 'clip_teacher.transformer.resblocks.3.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.3.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.3.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.3.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.3.ln_2.weight', 'clip_teacher.transformer.resblocks.3.ln_2.bias', 'clip_teacher.transformer.resblocks.4.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.4.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.4.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.4.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.4.ln_1.weight', 'clip_teacher.transformer.resblocks.4.ln_1.bias', 'clip_teacher.transformer.resblocks.4.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.4.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.4.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.4.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.4.ln_2.weight', 'clip_teacher.transformer.resblocks.4.ln_2.bias', 'clip_teacher.transformer.resblocks.5.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.5.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.5.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.5.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.5.ln_1.weight', 'clip_teacher.transformer.resblocks.5.ln_1.bias', 'clip_teacher.transformer.resblocks.5.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.5.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.5.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.5.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.5.ln_2.weight', 'clip_teacher.transformer.resblocks.5.ln_2.bias', 'clip_teacher.transformer.resblocks.6.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.6.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.6.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.6.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.6.ln_1.weight', 'clip_teacher.transformer.resblocks.6.ln_1.bias', 'clip_teacher.transformer.resblocks.6.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.6.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.6.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.6.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.6.ln_2.weight', 'clip_teacher.transformer.resblocks.6.ln_2.bias', 'clip_teacher.transformer.resblocks.7.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.7.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.7.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.7.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.7.ln_1.weight', 'clip_teacher.transformer.resblocks.7.ln_1.bias', 'clip_teacher.transformer.resblocks.7.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.7.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.7.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.7.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.7.ln_2.weight', 'clip_teacher.transformer.resblocks.7.ln_2.bias', 'clip_teacher.transformer.resblocks.8.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.8.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.8.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.8.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.8.ln_1.weight', 'clip_teacher.transformer.resblocks.8.ln_1.bias', 'clip_teacher.transformer.resblocks.8.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.8.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.8.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.8.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.8.ln_2.weight', 'clip_teacher.transformer.resblocks.8.ln_2.bias', 'clip_teacher.transformer.resblocks.9.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.9.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.9.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.9.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.9.ln_1.weight', 'clip_teacher.transformer.resblocks.9.ln_1.bias', 'clip_teacher.transformer.resblocks.9.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.9.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.9.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.9.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.9.ln_2.weight', 'clip_teacher.transformer.resblocks.9.ln_2.bias', 'clip_teacher.transformer.resblocks.10.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.10.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.10.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.10.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.10.ln_1.weight', 'clip_teacher.transformer.resblocks.10.ln_1.bias', 'clip_teacher.transformer.resblocks.10.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.10.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.10.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.10.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.10.ln_2.weight', 'clip_teacher.transformer.resblocks.10.ln_2.bias', 'clip_teacher.transformer.resblocks.11.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.11.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.11.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.11.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.11.ln_1.weight', 'clip_teacher.transformer.resblocks.11.ln_1.bias', 'clip_teacher.transformer.resblocks.11.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.11.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.11.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.11.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.11.ln_2.weight', 'clip_teacher.transformer.resblocks.11.ln_2.bias', 'clip_teacher.ln_post.weight', 'clip_teacher.ln_post.bias', 'vision_encoder.clip_decoder.0.head.weight', 'vision_encoder.clip_decoder.0.head.bias', 'vision_encoder.clip_decoder.0.norm.weight', 'vision_encoder.clip_decoder.0.norm.bias', 'vision_encoder.clip_decoder.1.head.weight', 'vision_encoder.clip_decoder.1.head.bias', 'vision_encoder.clip_decoder.1.norm.weight', 'vision_encoder.clip_decoder.1.norm.bias', 'vision_encoder.clip_decoder.2.head.weight', 'vision_encoder.clip_decoder.2.head.bias', 'vision_encoder.clip_decoder.2.norm.weight', 'vision_encoder.clip_decoder.2.norm.bias', 'vision_encoder.clip_decoder.3.head.weight', 'vision_encoder.clip_decoder.3.head.bias', 'vision_encoder.clip_decoder.3.norm.weight', 'vision_encoder.clip_decoder.3.norm.bias', 'vision_encoder.clip_decoder.4.head.weight', 'vision_encoder.clip_decoder.4.head.bias', 'vision_encoder.clip_decoder.4.norm.weight', 'vision_encoder.clip_decoder.4.norm.bias', 'vision_encoder.clip_decoder.5.head.weight', 'vision_encoder.clip_decoder.5.head.bias', 'vision_encoder.clip_decoder.5.norm.weight', 'vision_encoder.clip_decoder.5.norm.bias', 'text_encoder.cls.predictions.bias', 'text_encoder.cls.predictions.transform.dense.weight', 'text_encoder.cls.predictions.transform.dense.bias', 'text_encoder.cls.predictions.transform.LayerNorm.weight', 'text_encoder.cls.predictions.transform.LayerNorm.bias', 'text_encoder.cls.predictions.decoder.weight', 'text_encoder.cls.predictions.decoder.bias'])
2024-05-27T19:43:44 | INFO | tasks.shared_utils : Loaded checkpoint from /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
2024-05-27T19:43:44 | INFO | __main__ : training
2024-05-27T19:43:44 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:43:44 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:43:44 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:43:44 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:43:44 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:43:44 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:43:44 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:43:44 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:43:44 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:43:44 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:43:44 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:43:44 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:43:44 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 92685 batches in total
dataloader index=0 name=video, batch-size=2 length(#batches)=92685 
2024-05-27T19:43:45 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  builtin_warn(*args, **kwargs)

2024-05-27T19:43:45 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  builtin_warn(*args, **kwargs)

2024-05-27T19:50:04 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  builtin_warn(*args, **kwargs)

2024-05-27T19:50:04 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  builtin_warn(*args, **kwargs)

2024-05-27T19:50:04 | INFO | utils.basic_utils : Train Epoch: [0]  [    0/92685]  eta: 406 days, 21:05:33  lr: 0.000000  temperature: 0.0112  video-loss_vtc: 2.2963  video-loss_vtm: 1.5841  time: 379.2883  data: 0.4047  max mem: 5348 res mem: 5698
2024-05-27T19:54:07 | INFO | umt : Logging to: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2/train.log
2024-05-27T19:54:07 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
  test_file: {
      test: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test1k.json', '/data2/dy/temporal_video/dataset', 'video'] }
  test_types: ['test']
  num_workers: 6
  rtime: False
  pos_num: 1
  neg_num: 10
  stop_key: test/
  is_paragraph_retrieval: False
  is_pretrain: False
  num_frames: 12
  num_frames_test: 12
  batch_size: 2
  max_txt_l: 50
  evaluate: False
  train_shuffle: False
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 12
          sample_type: rand
          num_frames_test: 12
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 50
          video: 50 }
      batch_size: {
          image: 2
          video: 2 }
      batch_size_test: {
          image: 2
          video: 2 } }
  text_enc: bert
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_b16
          img_size: 224
          patch_size: 16
          d_model: 768
          encoder_embed_dim: 768
          encoder_depth: 12
          encoder_num_heads: 12
          drop_path_rate: 0.2
          num_frames: 12
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 12
          clip_decoder_embed_dim: 768
          clip_output_dim: 512
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 224
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      multimodal: {
          enable: True }
      embed_dim: 512
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 1e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 5
      min_lr_multi: 0.01
      warmup_epochs: 1 }
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: user
      project: umt_ret }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
  resume: False
  debug: False
  log_freq: 100
  seed: 3407
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
  rank: 0
  world_size: 1
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-05-27T19:54:07 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video'], 'test_file': {'test': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test1k.json', '/data2/dy/temporal_video/dataset', 'video']}, 'test_types': ['test'], 'num_workers': 6, 'rtime': False, 'pos_num': 1, 'neg_num': 10, 'stop_key': 'test/', 'is_paragraph_retrieval': False, 'is_pretrain': False, 'num_frames': 12, 'num_frames_test': 12, 'batch_size': 2, 'max_txt_l': 50, 'evaluate': False, 'train_shuffle': False, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 12, 'sample_type': 'rand', 'num_frames_test': 12, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 50, 'video': 50}, 'batch_size': {'image': 2, 'video': 2}, 'batch_size_test': {'image': 2, 'video': 2}}, 'text_enc': 'bert', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_b16', 'img_size': 224, 'patch_size': 16, 'd_model': 768, 'encoder_embed_dim': 768, 'encoder_depth': 12, 'encoder_num_heads': 12, 'drop_path_rate': 0.2, 'num_frames': 12, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 12, 'clip_decoder_embed_dim': 768, 'clip_output_dim': 512, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 224, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'multimodal': {'enable': True}, 'embed_dim': 512, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 1e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 5, 'min_lr_multi': 0.01, 'warmup_epochs': 1}, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': False, 'entity': 'user', 'project': 'umt_ret'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': 'exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 3407, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth', 'rank': 0, 'world_size': 1, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2024-05-27T19:54:07 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
2024-05-27T19:54:07 | INFO | tasks.pretrain : Creating dataset for ret
2024-05-27T19:54:08 | INFO | tasks.shared_utils : Creating model
2024-05-27T19:54:18 | INFO | models.umt : Build vision_encoder: vit_b16
2024-05-27T19:54:18 | INFO | models.backbones.vit.vit : Num of patches: 2352
2024-05-27T19:54:18 | INFO | models.backbones.vit.vit : Use checkpoint: True
2024-05-27T19:54:18 | INFO | models.backbones.vit.vit : Checkpoint number: 12
2024-05-27T19:54:18 | INFO | models.backbones.vit.vit : Student return index: []
2024-05-27T19:54:25 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
2024-05-27T19:54:25 | INFO | models.umt : Build text_encoder bert_base
2024-05-27T19:54:26 | INFO | models.backbones.bert.xbert : build bert with cross_module: ca
2024-05-27T19:54:27 | INFO | models.criterions : Norm type: l2
2024-05-27T19:54:27 | INFO | models.criterions : Loss type: l2
2024-05-27T19:54:27 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.bias: wd: 0, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.bias: wd: 0, lr: 1e-05
2024-05-27T19:54:27 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0 len(p)=72
2024-05-27T19:54:27 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0.02 len(p)=48
2024-05-27T19:54:27 | INFO | tasks.shared_utils : Auto resuming
2024-05-27T19:54:27 | INFO | tasks.shared_utils : Not found checkpoint in exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
2024-05-27T19:54:28 | INFO | tasks.shared_utils : _IncompatibleKeys(missing_keys=['vision_encoder.encoder.blocks.0.lora_r', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.1.lora_r', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.2.lora_r', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.3.lora_r', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.4.lora_r', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.5.lora_r', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.6.lora_r', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.7.lora_r', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.8.lora_r', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.9.lora_r', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.10.lora_r', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.11.lora_r', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.bias'], unexpected_keys=['clip_teacher.class_embedding', 'clip_teacher.positional_embedding', 'clip_teacher.proj', 'clip_teacher.conv1.weight', 'clip_teacher.ln_pre.weight', 'clip_teacher.ln_pre.bias', 'clip_teacher.transformer.resblocks.0.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.0.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.0.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.0.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.0.ln_1.weight', 'clip_teacher.transformer.resblocks.0.ln_1.bias', 'clip_teacher.transformer.resblocks.0.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.0.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.0.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.0.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.0.ln_2.weight', 'clip_teacher.transformer.resblocks.0.ln_2.bias', 'clip_teacher.transformer.resblocks.1.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.1.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.1.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.1.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.1.ln_1.weight', 'clip_teacher.transformer.resblocks.1.ln_1.bias', 'clip_teacher.transformer.resblocks.1.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.1.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.1.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.1.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.1.ln_2.weight', 'clip_teacher.transformer.resblocks.1.ln_2.bias', 'clip_teacher.transformer.resblocks.2.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.2.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.2.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.2.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.2.ln_1.weight', 'clip_teacher.transformer.resblocks.2.ln_1.bias', 'clip_teacher.transformer.resblocks.2.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.2.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.2.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.2.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.2.ln_2.weight', 'clip_teacher.transformer.resblocks.2.ln_2.bias', 'clip_teacher.transformer.resblocks.3.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.3.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.3.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.3.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.3.ln_1.weight', 'clip_teacher.transformer.resblocks.3.ln_1.bias', 'clip_teacher.transformer.resblocks.3.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.3.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.3.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.3.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.3.ln_2.weight', 'clip_teacher.transformer.resblocks.3.ln_2.bias', 'clip_teacher.transformer.resblocks.4.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.4.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.4.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.4.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.4.ln_1.weight', 'clip_teacher.transformer.resblocks.4.ln_1.bias', 'clip_teacher.transformer.resblocks.4.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.4.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.4.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.4.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.4.ln_2.weight', 'clip_teacher.transformer.resblocks.4.ln_2.bias', 'clip_teacher.transformer.resblocks.5.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.5.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.5.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.5.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.5.ln_1.weight', 'clip_teacher.transformer.resblocks.5.ln_1.bias', 'clip_teacher.transformer.resblocks.5.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.5.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.5.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.5.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.5.ln_2.weight', 'clip_teacher.transformer.resblocks.5.ln_2.bias', 'clip_teacher.transformer.resblocks.6.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.6.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.6.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.6.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.6.ln_1.weight', 'clip_teacher.transformer.resblocks.6.ln_1.bias', 'clip_teacher.transformer.resblocks.6.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.6.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.6.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.6.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.6.ln_2.weight', 'clip_teacher.transformer.resblocks.6.ln_2.bias', 'clip_teacher.transformer.resblocks.7.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.7.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.7.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.7.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.7.ln_1.weight', 'clip_teacher.transformer.resblocks.7.ln_1.bias', 'clip_teacher.transformer.resblocks.7.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.7.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.7.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.7.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.7.ln_2.weight', 'clip_teacher.transformer.resblocks.7.ln_2.bias', 'clip_teacher.transformer.resblocks.8.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.8.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.8.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.8.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.8.ln_1.weight', 'clip_teacher.transformer.resblocks.8.ln_1.bias', 'clip_teacher.transformer.resblocks.8.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.8.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.8.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.8.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.8.ln_2.weight', 'clip_teacher.transformer.resblocks.8.ln_2.bias', 'clip_teacher.transformer.resblocks.9.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.9.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.9.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.9.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.9.ln_1.weight', 'clip_teacher.transformer.resblocks.9.ln_1.bias', 'clip_teacher.transformer.resblocks.9.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.9.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.9.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.9.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.9.ln_2.weight', 'clip_teacher.transformer.resblocks.9.ln_2.bias', 'clip_teacher.transformer.resblocks.10.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.10.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.10.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.10.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.10.ln_1.weight', 'clip_teacher.transformer.resblocks.10.ln_1.bias', 'clip_teacher.transformer.resblocks.10.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.10.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.10.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.10.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.10.ln_2.weight', 'clip_teacher.transformer.resblocks.10.ln_2.bias', 'clip_teacher.transformer.resblocks.11.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.11.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.11.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.11.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.11.ln_1.weight', 'clip_teacher.transformer.resblocks.11.ln_1.bias', 'clip_teacher.transformer.resblocks.11.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.11.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.11.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.11.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.11.ln_2.weight', 'clip_teacher.transformer.resblocks.11.ln_2.bias', 'clip_teacher.ln_post.weight', 'clip_teacher.ln_post.bias', 'vision_encoder.clip_decoder.0.head.weight', 'vision_encoder.clip_decoder.0.head.bias', 'vision_encoder.clip_decoder.0.norm.weight', 'vision_encoder.clip_decoder.0.norm.bias', 'vision_encoder.clip_decoder.1.head.weight', 'vision_encoder.clip_decoder.1.head.bias', 'vision_encoder.clip_decoder.1.norm.weight', 'vision_encoder.clip_decoder.1.norm.bias', 'vision_encoder.clip_decoder.2.head.weight', 'vision_encoder.clip_decoder.2.head.bias', 'vision_encoder.clip_decoder.2.norm.weight', 'vision_encoder.clip_decoder.2.norm.bias', 'vision_encoder.clip_decoder.3.head.weight', 'vision_encoder.clip_decoder.3.head.bias', 'vision_encoder.clip_decoder.3.norm.weight', 'vision_encoder.clip_decoder.3.norm.bias', 'vision_encoder.clip_decoder.4.head.weight', 'vision_encoder.clip_decoder.4.head.bias', 'vision_encoder.clip_decoder.4.norm.weight', 'vision_encoder.clip_decoder.4.norm.bias', 'vision_encoder.clip_decoder.5.head.weight', 'vision_encoder.clip_decoder.5.head.bias', 'vision_encoder.clip_decoder.5.norm.weight', 'vision_encoder.clip_decoder.5.norm.bias', 'text_encoder.cls.predictions.bias', 'text_encoder.cls.predictions.transform.dense.weight', 'text_encoder.cls.predictions.transform.dense.bias', 'text_encoder.cls.predictions.transform.LayerNorm.weight', 'text_encoder.cls.predictions.transform.LayerNorm.bias', 'text_encoder.cls.predictions.decoder.weight', 'text_encoder.cls.predictions.decoder.bias'])
2024-05-27T19:54:28 | INFO | tasks.shared_utils : Loaded checkpoint from /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
2024-05-27T19:54:28 | INFO | __main__ : training
2024-05-27T19:54:28 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:54:28 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:54:28 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:54:28 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:54:28 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:54:28 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:54:28 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:54:28 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:54:28 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:54:28 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:54:29 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:54:29 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:54:29 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 92685 batches in total
dataloader index=0 name=video, batch-size=2 length(#batches)=92685 
2024-05-27T19:54:29 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  builtin_warn(*args, **kwargs)

2024-05-27T19:54:29 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  builtin_warn(*args, **kwargs)

2024-05-27T19:54:29 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-05-27T19:54:29 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-05-27T19:56:14 | INFO | umt : Logging to: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2/train.log
2024-05-27T19:56:14 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
  test_file: {
      test: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test1k.json', '/data2/dy/temporal_video/dataset', 'video'] }
  test_types: ['test']
  num_workers: 6
  rtime: False
  pos_num: 1
  neg_num: 10
  stop_key: test/
  is_paragraph_retrieval: False
  is_pretrain: False
  num_frames: 12
  num_frames_test: 12
  batch_size: 2
  max_txt_l: 50
  evaluate: False
  train_shuffle: False
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 12
          sample_type: rand
          num_frames_test: 12
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 50
          video: 50 }
      batch_size: {
          image: 2
          video: 2 }
      batch_size_test: {
          image: 2
          video: 2 } }
  text_enc: bert
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_b16
          img_size: 224
          patch_size: 16
          d_model: 768
          encoder_embed_dim: 768
          encoder_depth: 12
          encoder_num_heads: 12
          drop_path_rate: 0.2
          num_frames: 12
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 12
          clip_decoder_embed_dim: 768
          clip_output_dim: 512
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 224
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      multimodal: {
          enable: True }
      embed_dim: 512
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 1e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 5
      min_lr_multi: 0.01
      warmup_epochs: 1 }
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: user
      project: umt_ret }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
  resume: False
  debug: False
  log_freq: 100
  seed: 3407
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
  rank: 0
  world_size: 1
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-05-27T19:56:14 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video'], 'test_file': {'test': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test1k.json', '/data2/dy/temporal_video/dataset', 'video']}, 'test_types': ['test'], 'num_workers': 6, 'rtime': False, 'pos_num': 1, 'neg_num': 10, 'stop_key': 'test/', 'is_paragraph_retrieval': False, 'is_pretrain': False, 'num_frames': 12, 'num_frames_test': 12, 'batch_size': 2, 'max_txt_l': 50, 'evaluate': False, 'train_shuffle': False, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 12, 'sample_type': 'rand', 'num_frames_test': 12, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 50, 'video': 50}, 'batch_size': {'image': 2, 'video': 2}, 'batch_size_test': {'image': 2, 'video': 2}}, 'text_enc': 'bert', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_b16', 'img_size': 224, 'patch_size': 16, 'd_model': 768, 'encoder_embed_dim': 768, 'encoder_depth': 12, 'encoder_num_heads': 12, 'drop_path_rate': 0.2, 'num_frames': 12, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 12, 'clip_decoder_embed_dim': 768, 'clip_output_dim': 512, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 224, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'multimodal': {'enable': True}, 'embed_dim': 512, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 1e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 5, 'min_lr_multi': 0.01, 'warmup_epochs': 1}, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': False, 'entity': 'user', 'project': 'umt_ret'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': 'exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 3407, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth', 'rank': 0, 'world_size': 1, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2024-05-27T19:56:14 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
2024-05-27T19:56:14 | INFO | tasks.pretrain : Creating dataset for ret
2024-05-27T19:56:14 | INFO | tasks.shared_utils : Creating model
2024-05-27T19:56:24 | INFO | models.umt : Build vision_encoder: vit_b16
2024-05-27T19:56:24 | INFO | models.backbones.vit.vit : Num of patches: 2352
2024-05-27T19:56:24 | INFO | models.backbones.vit.vit : Use checkpoint: True
2024-05-27T19:56:24 | INFO | models.backbones.vit.vit : Checkpoint number: 12
2024-05-27T19:56:24 | INFO | models.backbones.vit.vit : Student return index: []
2024-05-27T19:56:32 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
2024-05-27T19:56:32 | INFO | models.umt : Build text_encoder bert_base
2024-05-27T19:56:33 | INFO | models.backbones.bert.xbert : build bert with cross_module: ca
2024-05-27T19:56:33 | INFO | models.criterions : Norm type: l2
2024-05-27T19:56:33 | INFO | models.criterions : Loss type: l2
2024-05-27T19:56:34 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-05-27T19:56:34 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:56:34 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:56:34 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:56:34 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:56:34 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:56:34 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:56:34 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:56:34 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:56:34 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:56:34 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:56:34 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:56:34 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:56:34 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:56:34 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:56:34 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:56:34 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:56:34 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:56:34 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:56:34 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:56:34 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:56:34 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:56:34 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:56:34 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:56:34 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:56:34 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:56:34 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:56:34 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:56:34 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:56:34 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:56:34 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:56:34 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:56:34 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:56:34 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:56:34 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:56:34 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:56:34 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:56:34 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:56:34 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:56:34 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:56:34 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:56:34 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:56:34 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:56:34 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:56:34 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:56:34 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:56:34 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:56:34 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:56:34 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:56:34 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:56:34 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:56:34 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:56:34 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:56:34 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:56:34 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:56:34 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:56:34 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:56:34 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:56:34 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:56:34 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:56:34 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:56:34 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:56:34 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:56:34 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:56:34 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:56:34 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:56:34 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:56:34 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.lora_r: wd: 0, lr: 1e-05
2024-05-27T19:56:34 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T19:56:34 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T19:56:34 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:56:34 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:56:34 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:56:34 | INFO | utils.optimizer : param module.vision_proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T19:56:34 | INFO | utils.optimizer : param module.vision_proj.bias: wd: 0, lr: 1e-05
2024-05-27T19:56:34 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0 len(p)=49
2024-05-27T19:56:34 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0.02 len(p)=25
2024-05-27T19:56:34 | INFO | tasks.shared_utils : Auto resuming
2024-05-27T19:56:34 | INFO | tasks.shared_utils : Not found checkpoint in exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
2024-05-27T19:56:34 | INFO | tasks.shared_utils : _IncompatibleKeys(missing_keys=['vision_encoder.encoder.blocks.0.lora_r', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.1.lora_r', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.2.lora_r', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.3.lora_r', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.4.lora_r', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.5.lora_r', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.6.lora_r', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.7.lora_r', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.8.lora_r', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.9.lora_r', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.10.lora_r', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.11.lora_r', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.bias'], unexpected_keys=['clip_teacher.class_embedding', 'clip_teacher.positional_embedding', 'clip_teacher.proj', 'clip_teacher.conv1.weight', 'clip_teacher.ln_pre.weight', 'clip_teacher.ln_pre.bias', 'clip_teacher.transformer.resblocks.0.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.0.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.0.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.0.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.0.ln_1.weight', 'clip_teacher.transformer.resblocks.0.ln_1.bias', 'clip_teacher.transformer.resblocks.0.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.0.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.0.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.0.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.0.ln_2.weight', 'clip_teacher.transformer.resblocks.0.ln_2.bias', 'clip_teacher.transformer.resblocks.1.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.1.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.1.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.1.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.1.ln_1.weight', 'clip_teacher.transformer.resblocks.1.ln_1.bias', 'clip_teacher.transformer.resblocks.1.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.1.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.1.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.1.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.1.ln_2.weight', 'clip_teacher.transformer.resblocks.1.ln_2.bias', 'clip_teacher.transformer.resblocks.2.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.2.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.2.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.2.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.2.ln_1.weight', 'clip_teacher.transformer.resblocks.2.ln_1.bias', 'clip_teacher.transformer.resblocks.2.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.2.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.2.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.2.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.2.ln_2.weight', 'clip_teacher.transformer.resblocks.2.ln_2.bias', 'clip_teacher.transformer.resblocks.3.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.3.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.3.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.3.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.3.ln_1.weight', 'clip_teacher.transformer.resblocks.3.ln_1.bias', 'clip_teacher.transformer.resblocks.3.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.3.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.3.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.3.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.3.ln_2.weight', 'clip_teacher.transformer.resblocks.3.ln_2.bias', 'clip_teacher.transformer.resblocks.4.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.4.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.4.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.4.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.4.ln_1.weight', 'clip_teacher.transformer.resblocks.4.ln_1.bias', 'clip_teacher.transformer.resblocks.4.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.4.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.4.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.4.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.4.ln_2.weight', 'clip_teacher.transformer.resblocks.4.ln_2.bias', 'clip_teacher.transformer.resblocks.5.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.5.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.5.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.5.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.5.ln_1.weight', 'clip_teacher.transformer.resblocks.5.ln_1.bias', 'clip_teacher.transformer.resblocks.5.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.5.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.5.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.5.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.5.ln_2.weight', 'clip_teacher.transformer.resblocks.5.ln_2.bias', 'clip_teacher.transformer.resblocks.6.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.6.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.6.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.6.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.6.ln_1.weight', 'clip_teacher.transformer.resblocks.6.ln_1.bias', 'clip_teacher.transformer.resblocks.6.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.6.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.6.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.6.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.6.ln_2.weight', 'clip_teacher.transformer.resblocks.6.ln_2.bias', 'clip_teacher.transformer.resblocks.7.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.7.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.7.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.7.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.7.ln_1.weight', 'clip_teacher.transformer.resblocks.7.ln_1.bias', 'clip_teacher.transformer.resblocks.7.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.7.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.7.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.7.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.7.ln_2.weight', 'clip_teacher.transformer.resblocks.7.ln_2.bias', 'clip_teacher.transformer.resblocks.8.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.8.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.8.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.8.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.8.ln_1.weight', 'clip_teacher.transformer.resblocks.8.ln_1.bias', 'clip_teacher.transformer.resblocks.8.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.8.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.8.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.8.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.8.ln_2.weight', 'clip_teacher.transformer.resblocks.8.ln_2.bias', 'clip_teacher.transformer.resblocks.9.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.9.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.9.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.9.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.9.ln_1.weight', 'clip_teacher.transformer.resblocks.9.ln_1.bias', 'clip_teacher.transformer.resblocks.9.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.9.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.9.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.9.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.9.ln_2.weight', 'clip_teacher.transformer.resblocks.9.ln_2.bias', 'clip_teacher.transformer.resblocks.10.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.10.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.10.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.10.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.10.ln_1.weight', 'clip_teacher.transformer.resblocks.10.ln_1.bias', 'clip_teacher.transformer.resblocks.10.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.10.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.10.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.10.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.10.ln_2.weight', 'clip_teacher.transformer.resblocks.10.ln_2.bias', 'clip_teacher.transformer.resblocks.11.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.11.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.11.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.11.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.11.ln_1.weight', 'clip_teacher.transformer.resblocks.11.ln_1.bias', 'clip_teacher.transformer.resblocks.11.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.11.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.11.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.11.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.11.ln_2.weight', 'clip_teacher.transformer.resblocks.11.ln_2.bias', 'clip_teacher.ln_post.weight', 'clip_teacher.ln_post.bias', 'vision_encoder.clip_decoder.0.head.weight', 'vision_encoder.clip_decoder.0.head.bias', 'vision_encoder.clip_decoder.0.norm.weight', 'vision_encoder.clip_decoder.0.norm.bias', 'vision_encoder.clip_decoder.1.head.weight', 'vision_encoder.clip_decoder.1.head.bias', 'vision_encoder.clip_decoder.1.norm.weight', 'vision_encoder.clip_decoder.1.norm.bias', 'vision_encoder.clip_decoder.2.head.weight', 'vision_encoder.clip_decoder.2.head.bias', 'vision_encoder.clip_decoder.2.norm.weight', 'vision_encoder.clip_decoder.2.norm.bias', 'vision_encoder.clip_decoder.3.head.weight', 'vision_encoder.clip_decoder.3.head.bias', 'vision_encoder.clip_decoder.3.norm.weight', 'vision_encoder.clip_decoder.3.norm.bias', 'vision_encoder.clip_decoder.4.head.weight', 'vision_encoder.clip_decoder.4.head.bias', 'vision_encoder.clip_decoder.4.norm.weight', 'vision_encoder.clip_decoder.4.norm.bias', 'vision_encoder.clip_decoder.5.head.weight', 'vision_encoder.clip_decoder.5.head.bias', 'vision_encoder.clip_decoder.5.norm.weight', 'vision_encoder.clip_decoder.5.norm.bias', 'text_encoder.cls.predictions.bias', 'text_encoder.cls.predictions.transform.dense.weight', 'text_encoder.cls.predictions.transform.dense.bias', 'text_encoder.cls.predictions.transform.LayerNorm.weight', 'text_encoder.cls.predictions.transform.LayerNorm.bias', 'text_encoder.cls.predictions.decoder.weight', 'text_encoder.cls.predictions.decoder.bias'])
2024-05-27T19:57:12 | INFO | tasks.shared_utils : Loaded checkpoint from /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
2024-05-27T19:57:12 | INFO | __main__ : training
2024-05-27T19:57:12 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:57:12 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:57:12 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:57:12 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:57:12 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:57:12 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:57:12 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:57:12 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:57:12 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:57:12 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:57:12 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:57:12 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T19:57:12 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 92685 batches in total
dataloader index=0 name=video, batch-size=2 length(#batches)=92685 
2024-05-27T19:57:13 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  builtin_warn(*args, **kwargs)

2024-05-27T19:57:13 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  builtin_warn(*args, **kwargs)

2024-05-27T19:57:13 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-05-27T19:57:13 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-05-27T19:57:15 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  builtin_warn(*args, **kwargs)

2024-05-27T19:57:15 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  builtin_warn(*args, **kwargs)

2024-05-27T19:57:15 | INFO | utils.basic_utils : Train Epoch: [0]  [    0/92685]  eta: 2 days, 19:42:14  lr: 0.000000  temperature: 0.0112  video-loss_vtc: 2.2963  video-loss_vtm: 1.5841  time: 2.6297  data: 0.3712  max mem: 1925 res mem: 2504
2024-05-27T20:00:01 | INFO | umt : Logging to: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2/train.log
2024-05-27T20:00:01 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
  test_file: {
      test: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test1k.json', '/data2/dy/temporal_video/dataset', 'video'] }
  test_types: ['test']
  num_workers: 6
  rtime: False
  pos_num: 1
  neg_num: 10
  stop_key: test/
  is_paragraph_retrieval: False
  is_pretrain: False
  num_frames: 12
  num_frames_test: 12
  batch_size: 2
  max_txt_l: 50
  evaluate: False
  train_shuffle: False
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 12
          sample_type: rand
          num_frames_test: 12
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 50
          video: 50 }
      batch_size: {
          image: 2
          video: 2 }
      batch_size_test: {
          image: 2
          video: 2 } }
  text_enc: bert
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_b16
          img_size: 224
          patch_size: 16
          d_model: 768
          encoder_embed_dim: 768
          encoder_depth: 12
          encoder_num_heads: 12
          drop_path_rate: 0.2
          num_frames: 12
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 12
          clip_decoder_embed_dim: 768
          clip_output_dim: 512
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 224
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      multimodal: {
          enable: True }
      embed_dim: 512
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 1e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 5
      min_lr_multi: 0.01
      warmup_epochs: 1 }
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: user
      project: umt_ret }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
  resume: False
  debug: False
  log_freq: 100
  seed: 3407
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
  rank: 0
  world_size: 1
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-05-27T20:00:01 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video'], 'test_file': {'test': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test1k.json', '/data2/dy/temporal_video/dataset', 'video']}, 'test_types': ['test'], 'num_workers': 6, 'rtime': False, 'pos_num': 1, 'neg_num': 10, 'stop_key': 'test/', 'is_paragraph_retrieval': False, 'is_pretrain': False, 'num_frames': 12, 'num_frames_test': 12, 'batch_size': 2, 'max_txt_l': 50, 'evaluate': False, 'train_shuffle': False, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 12, 'sample_type': 'rand', 'num_frames_test': 12, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 50, 'video': 50}, 'batch_size': {'image': 2, 'video': 2}, 'batch_size_test': {'image': 2, 'video': 2}}, 'text_enc': 'bert', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_b16', 'img_size': 224, 'patch_size': 16, 'd_model': 768, 'encoder_embed_dim': 768, 'encoder_depth': 12, 'encoder_num_heads': 12, 'drop_path_rate': 0.2, 'num_frames': 12, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 12, 'clip_decoder_embed_dim': 768, 'clip_output_dim': 512, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 224, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'multimodal': {'enable': True}, 'embed_dim': 512, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 1e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 5, 'min_lr_multi': 0.01, 'warmup_epochs': 1}, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': False, 'entity': 'user', 'project': 'umt_ret'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': 'exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 3407, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth', 'rank': 0, 'world_size': 1, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2024-05-27T20:00:01 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
2024-05-27T20:00:01 | INFO | tasks.pretrain : Creating dataset for ret
2024-05-27T20:00:01 | INFO | tasks.shared_utils : Creating model
2024-05-27T20:00:11 | INFO | models.umt : Build vision_encoder: vit_b16
2024-05-27T20:00:11 | INFO | models.backbones.vit.vit : Num of patches: 2352
2024-05-27T20:00:11 | INFO | models.backbones.vit.vit : Use checkpoint: True
2024-05-27T20:00:11 | INFO | models.backbones.vit.vit : Checkpoint number: 12
2024-05-27T20:00:11 | INFO | models.backbones.vit.vit : Student return index: []
2024-05-27T20:00:19 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
2024-05-27T20:00:19 | INFO | models.umt : Build text_encoder bert_base
2024-05-27T20:00:20 | INFO | models.backbones.bert.xbert : build bert with cross_module: ca
2024-05-27T20:00:20 | INFO | models.criterions : Norm type: l2
2024-05-27T20:00:20 | INFO | models.criterions : Loss type: l2
2024-05-27T20:00:21 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-05-27T20:00:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.lora_r: wd: 0, lr: 1e-05
2024-05-27T20:00:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T20:00:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T20:00:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:00:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:00:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T20:00:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.lora_r: wd: 0, lr: 1e-05
2024-05-27T20:00:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T20:00:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T20:00:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:00:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:00:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T20:00:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.lora_r: wd: 0, lr: 1e-05
2024-05-27T20:00:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T20:00:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T20:00:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:00:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:00:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T20:00:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.lora_r: wd: 0, lr: 1e-05
2024-05-27T20:00:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T20:00:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T20:00:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:00:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:00:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T20:00:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.lora_r: wd: 0, lr: 1e-05
2024-05-27T20:00:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T20:00:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T20:00:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:00:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:00:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T20:00:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.lora_r: wd: 0, lr: 1e-05
2024-05-27T20:00:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T20:00:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T20:00:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:00:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:00:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T20:00:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.lora_r: wd: 0, lr: 1e-05
2024-05-27T20:00:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T20:00:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T20:00:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:00:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:00:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T20:00:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.lora_r: wd: 0, lr: 1e-05
2024-05-27T20:00:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T20:00:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T20:00:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:00:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:00:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T20:00:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.lora_r: wd: 0, lr: 1e-05
2024-05-27T20:00:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T20:00:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T20:00:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:00:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:00:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T20:00:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.lora_r: wd: 0, lr: 1e-05
2024-05-27T20:00:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T20:00:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T20:00:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:00:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:00:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T20:00:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.lora_r: wd: 0, lr: 1e-05
2024-05-27T20:00:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T20:00:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T20:00:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:00:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:00:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T20:00:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.lora_r: wd: 0, lr: 1e-05
2024-05-27T20:00:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T20:00:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T20:00:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:00:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:00:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T20:00:21 | INFO | utils.optimizer : param module.vision_proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:00:21 | INFO | utils.optimizer : param module.vision_proj.bias: wd: 0, lr: 1e-05
2024-05-27T20:00:21 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0 len(p)=49
2024-05-27T20:00:21 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0.02 len(p)=25
2024-05-27T20:00:21 | INFO | tasks.shared_utils : Auto resuming
2024-05-27T20:00:21 | INFO | tasks.shared_utils : Not found checkpoint in exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
2024-05-27T20:00:21 | INFO | tasks.shared_utils : _IncompatibleKeys(missing_keys=['vision_encoder.encoder.blocks.0.lora_r', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.1.lora_r', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.2.lora_r', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.3.lora_r', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.4.lora_r', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.5.lora_r', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.6.lora_r', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.7.lora_r', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.8.lora_r', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.9.lora_r', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.10.lora_r', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.11.lora_r', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.bias'], unexpected_keys=['clip_teacher.class_embedding', 'clip_teacher.positional_embedding', 'clip_teacher.proj', 'clip_teacher.conv1.weight', 'clip_teacher.ln_pre.weight', 'clip_teacher.ln_pre.bias', 'clip_teacher.transformer.resblocks.0.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.0.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.0.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.0.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.0.ln_1.weight', 'clip_teacher.transformer.resblocks.0.ln_1.bias', 'clip_teacher.transformer.resblocks.0.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.0.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.0.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.0.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.0.ln_2.weight', 'clip_teacher.transformer.resblocks.0.ln_2.bias', 'clip_teacher.transformer.resblocks.1.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.1.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.1.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.1.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.1.ln_1.weight', 'clip_teacher.transformer.resblocks.1.ln_1.bias', 'clip_teacher.transformer.resblocks.1.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.1.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.1.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.1.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.1.ln_2.weight', 'clip_teacher.transformer.resblocks.1.ln_2.bias', 'clip_teacher.transformer.resblocks.2.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.2.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.2.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.2.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.2.ln_1.weight', 'clip_teacher.transformer.resblocks.2.ln_1.bias', 'clip_teacher.transformer.resblocks.2.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.2.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.2.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.2.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.2.ln_2.weight', 'clip_teacher.transformer.resblocks.2.ln_2.bias', 'clip_teacher.transformer.resblocks.3.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.3.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.3.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.3.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.3.ln_1.weight', 'clip_teacher.transformer.resblocks.3.ln_1.bias', 'clip_teacher.transformer.resblocks.3.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.3.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.3.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.3.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.3.ln_2.weight', 'clip_teacher.transformer.resblocks.3.ln_2.bias', 'clip_teacher.transformer.resblocks.4.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.4.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.4.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.4.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.4.ln_1.weight', 'clip_teacher.transformer.resblocks.4.ln_1.bias', 'clip_teacher.transformer.resblocks.4.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.4.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.4.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.4.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.4.ln_2.weight', 'clip_teacher.transformer.resblocks.4.ln_2.bias', 'clip_teacher.transformer.resblocks.5.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.5.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.5.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.5.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.5.ln_1.weight', 'clip_teacher.transformer.resblocks.5.ln_1.bias', 'clip_teacher.transformer.resblocks.5.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.5.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.5.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.5.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.5.ln_2.weight', 'clip_teacher.transformer.resblocks.5.ln_2.bias', 'clip_teacher.transformer.resblocks.6.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.6.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.6.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.6.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.6.ln_1.weight', 'clip_teacher.transformer.resblocks.6.ln_1.bias', 'clip_teacher.transformer.resblocks.6.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.6.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.6.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.6.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.6.ln_2.weight', 'clip_teacher.transformer.resblocks.6.ln_2.bias', 'clip_teacher.transformer.resblocks.7.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.7.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.7.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.7.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.7.ln_1.weight', 'clip_teacher.transformer.resblocks.7.ln_1.bias', 'clip_teacher.transformer.resblocks.7.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.7.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.7.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.7.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.7.ln_2.weight', 'clip_teacher.transformer.resblocks.7.ln_2.bias', 'clip_teacher.transformer.resblocks.8.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.8.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.8.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.8.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.8.ln_1.weight', 'clip_teacher.transformer.resblocks.8.ln_1.bias', 'clip_teacher.transformer.resblocks.8.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.8.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.8.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.8.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.8.ln_2.weight', 'clip_teacher.transformer.resblocks.8.ln_2.bias', 'clip_teacher.transformer.resblocks.9.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.9.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.9.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.9.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.9.ln_1.weight', 'clip_teacher.transformer.resblocks.9.ln_1.bias', 'clip_teacher.transformer.resblocks.9.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.9.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.9.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.9.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.9.ln_2.weight', 'clip_teacher.transformer.resblocks.9.ln_2.bias', 'clip_teacher.transformer.resblocks.10.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.10.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.10.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.10.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.10.ln_1.weight', 'clip_teacher.transformer.resblocks.10.ln_1.bias', 'clip_teacher.transformer.resblocks.10.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.10.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.10.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.10.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.10.ln_2.weight', 'clip_teacher.transformer.resblocks.10.ln_2.bias', 'clip_teacher.transformer.resblocks.11.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.11.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.11.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.11.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.11.ln_1.weight', 'clip_teacher.transformer.resblocks.11.ln_1.bias', 'clip_teacher.transformer.resblocks.11.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.11.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.11.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.11.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.11.ln_2.weight', 'clip_teacher.transformer.resblocks.11.ln_2.bias', 'clip_teacher.ln_post.weight', 'clip_teacher.ln_post.bias', 'vision_encoder.clip_decoder.0.head.weight', 'vision_encoder.clip_decoder.0.head.bias', 'vision_encoder.clip_decoder.0.norm.weight', 'vision_encoder.clip_decoder.0.norm.bias', 'vision_encoder.clip_decoder.1.head.weight', 'vision_encoder.clip_decoder.1.head.bias', 'vision_encoder.clip_decoder.1.norm.weight', 'vision_encoder.clip_decoder.1.norm.bias', 'vision_encoder.clip_decoder.2.head.weight', 'vision_encoder.clip_decoder.2.head.bias', 'vision_encoder.clip_decoder.2.norm.weight', 'vision_encoder.clip_decoder.2.norm.bias', 'vision_encoder.clip_decoder.3.head.weight', 'vision_encoder.clip_decoder.3.head.bias', 'vision_encoder.clip_decoder.3.norm.weight', 'vision_encoder.clip_decoder.3.norm.bias', 'vision_encoder.clip_decoder.4.head.weight', 'vision_encoder.clip_decoder.4.head.bias', 'vision_encoder.clip_decoder.4.norm.weight', 'vision_encoder.clip_decoder.4.norm.bias', 'vision_encoder.clip_decoder.5.head.weight', 'vision_encoder.clip_decoder.5.head.bias', 'vision_encoder.clip_decoder.5.norm.weight', 'vision_encoder.clip_decoder.5.norm.bias', 'text_encoder.cls.predictions.bias', 'text_encoder.cls.predictions.transform.dense.weight', 'text_encoder.cls.predictions.transform.dense.bias', 'text_encoder.cls.predictions.transform.LayerNorm.weight', 'text_encoder.cls.predictions.transform.LayerNorm.bias', 'text_encoder.cls.predictions.decoder.weight', 'text_encoder.cls.predictions.decoder.bias'])
2024-05-27T20:00:21 | INFO | tasks.shared_utils : Loaded checkpoint from /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
2024-05-27T20:00:21 | INFO | __main__ : training
2024-05-27T20:00:22 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T20:00:22 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T20:00:22 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T20:00:22 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T20:00:22 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T20:00:22 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T20:00:22 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T20:00:22 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T20:00:22 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T20:00:22 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T20:00:22 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T20:00:22 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T20:00:22 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 92685 batches in total
dataloader index=0 name=video, batch-size=2 length(#batches)=92685 
2024-05-27T20:00:23 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  builtin_warn(*args, **kwargs)

2024-05-27T20:00:23 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  builtin_warn(*args, **kwargs)

2024-05-27T20:00:23 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-05-27T20:00:23 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-05-27T20:00:43 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  builtin_warn(*args, **kwargs)

2024-05-27T20:00:43 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  builtin_warn(*args, **kwargs)

2024-05-27T20:00:43 | INFO | utils.basic_utils : Train Epoch: [0]  [    0/92685]  eta: 22 days, 12:37:21  lr: 0.000000  temperature: 0.0112  video-loss_vtc: 2.2963  video-loss_vtm: 1.5841  time: 20.9985  data: 0.3488  max mem: 1924 res mem: 2508
2024-05-27T20:01:23 | INFO | umt : Logging to: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2/train.log
2024-05-27T20:01:23 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
  test_file: {
      test: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test1k.json', '/data2/dy/temporal_video/dataset', 'video'] }
  test_types: ['test']
  num_workers: 6
  rtime: False
  pos_num: 1
  neg_num: 10
  stop_key: test/
  is_paragraph_retrieval: False
  is_pretrain: False
  num_frames: 12
  num_frames_test: 12
  batch_size: 2
  max_txt_l: 50
  evaluate: False
  train_shuffle: False
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 12
          sample_type: rand
          num_frames_test: 12
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 50
          video: 50 }
      batch_size: {
          image: 2
          video: 2 }
      batch_size_test: {
          image: 2
          video: 2 } }
  text_enc: bert
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_b16
          img_size: 224
          patch_size: 16
          d_model: 768
          encoder_embed_dim: 768
          encoder_depth: 12
          encoder_num_heads: 12
          drop_path_rate: 0.2
          num_frames: 12
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 12
          clip_decoder_embed_dim: 768
          clip_output_dim: 512
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 224
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      multimodal: {
          enable: True }
      embed_dim: 512
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 1e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 5
      min_lr_multi: 0.01
      warmup_epochs: 1 }
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: user
      project: umt_ret }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
  resume: False
  debug: False
  log_freq: 100
  seed: 3407
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
  rank: 0
  world_size: 1
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-05-27T20:01:23 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video'], 'test_file': {'test': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test1k.json', '/data2/dy/temporal_video/dataset', 'video']}, 'test_types': ['test'], 'num_workers': 6, 'rtime': False, 'pos_num': 1, 'neg_num': 10, 'stop_key': 'test/', 'is_paragraph_retrieval': False, 'is_pretrain': False, 'num_frames': 12, 'num_frames_test': 12, 'batch_size': 2, 'max_txt_l': 50, 'evaluate': False, 'train_shuffle': False, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 12, 'sample_type': 'rand', 'num_frames_test': 12, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 50, 'video': 50}, 'batch_size': {'image': 2, 'video': 2}, 'batch_size_test': {'image': 2, 'video': 2}}, 'text_enc': 'bert', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_b16', 'img_size': 224, 'patch_size': 16, 'd_model': 768, 'encoder_embed_dim': 768, 'encoder_depth': 12, 'encoder_num_heads': 12, 'drop_path_rate': 0.2, 'num_frames': 12, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 12, 'clip_decoder_embed_dim': 768, 'clip_output_dim': 512, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 224, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'multimodal': {'enable': True}, 'embed_dim': 512, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 1e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 5, 'min_lr_multi': 0.01, 'warmup_epochs': 1}, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': False, 'entity': 'user', 'project': 'umt_ret'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': 'exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 3407, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth', 'rank': 0, 'world_size': 1, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2024-05-27T20:01:23 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
2024-05-27T20:01:23 | INFO | tasks.pretrain : Creating dataset for ret
2024-05-27T20:01:24 | INFO | tasks.shared_utils : Creating model
2024-05-27T20:01:34 | INFO | models.umt : Build vision_encoder: vit_b16
2024-05-27T20:01:34 | INFO | models.backbones.vit.vit : Num of patches: 2352
2024-05-27T20:01:34 | INFO | models.backbones.vit.vit : Use checkpoint: True
2024-05-27T20:01:34 | INFO | models.backbones.vit.vit : Checkpoint number: 12
2024-05-27T20:01:34 | INFO | models.backbones.vit.vit : Student return index: []
2024-05-27T20:01:41 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
2024-05-27T20:01:42 | INFO | models.umt : Build text_encoder bert_base
2024-05-27T20:01:43 | INFO | models.backbones.bert.xbert : build bert with cross_module: ca
2024-05-27T20:01:43 | INFO | models.criterions : Norm type: l2
2024-05-27T20:01:43 | INFO | models.criterions : Loss type: l2
2024-05-27T20:01:43 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-05-27T20:01:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.lora_r: wd: 0, lr: 1e-05
2024-05-27T20:01:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T20:01:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T20:01:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:01:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:01:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T20:01:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.lora_r: wd: 0, lr: 1e-05
2024-05-27T20:01:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T20:01:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T20:01:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:01:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:01:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T20:01:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.lora_r: wd: 0, lr: 1e-05
2024-05-27T20:01:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T20:01:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T20:01:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:01:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:01:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T20:01:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.lora_r: wd: 0, lr: 1e-05
2024-05-27T20:01:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T20:01:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T20:01:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:01:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:01:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T20:01:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.lora_r: wd: 0, lr: 1e-05
2024-05-27T20:01:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T20:01:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T20:01:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:01:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:01:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T20:01:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.lora_r: wd: 0, lr: 1e-05
2024-05-27T20:01:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T20:01:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T20:01:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:01:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:01:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T20:01:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.lora_r: wd: 0, lr: 1e-05
2024-05-27T20:01:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T20:01:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T20:01:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:01:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:01:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T20:01:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.lora_r: wd: 0, lr: 1e-05
2024-05-27T20:01:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T20:01:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T20:01:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:01:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:01:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T20:01:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.lora_r: wd: 0, lr: 1e-05
2024-05-27T20:01:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T20:01:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T20:01:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:01:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:01:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T20:01:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.lora_r: wd: 0, lr: 1e-05
2024-05-27T20:01:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T20:01:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T20:01:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:01:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:01:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T20:01:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.lora_r: wd: 0, lr: 1e-05
2024-05-27T20:01:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T20:01:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T20:01:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:01:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:01:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T20:01:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.lora_r: wd: 0, lr: 1e-05
2024-05-27T20:01:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T20:01:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T20:01:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:01:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:01:43 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T20:01:43 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0 len(p)=48
2024-05-27T20:01:43 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0.02 len(p)=24
2024-05-27T20:01:43 | INFO | tasks.shared_utils : Auto resuming
2024-05-27T20:01:43 | INFO | tasks.shared_utils : Not found checkpoint in exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
2024-05-27T20:01:44 | INFO | tasks.shared_utils : _IncompatibleKeys(missing_keys=['vision_encoder.encoder.blocks.0.lora_r', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.1.lora_r', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.2.lora_r', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.3.lora_r', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.4.lora_r', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.5.lora_r', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.6.lora_r', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.7.lora_r', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.8.lora_r', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.9.lora_r', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.10.lora_r', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.11.lora_r', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.bias'], unexpected_keys=['clip_teacher.class_embedding', 'clip_teacher.positional_embedding', 'clip_teacher.proj', 'clip_teacher.conv1.weight', 'clip_teacher.ln_pre.weight', 'clip_teacher.ln_pre.bias', 'clip_teacher.transformer.resblocks.0.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.0.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.0.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.0.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.0.ln_1.weight', 'clip_teacher.transformer.resblocks.0.ln_1.bias', 'clip_teacher.transformer.resblocks.0.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.0.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.0.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.0.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.0.ln_2.weight', 'clip_teacher.transformer.resblocks.0.ln_2.bias', 'clip_teacher.transformer.resblocks.1.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.1.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.1.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.1.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.1.ln_1.weight', 'clip_teacher.transformer.resblocks.1.ln_1.bias', 'clip_teacher.transformer.resblocks.1.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.1.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.1.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.1.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.1.ln_2.weight', 'clip_teacher.transformer.resblocks.1.ln_2.bias', 'clip_teacher.transformer.resblocks.2.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.2.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.2.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.2.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.2.ln_1.weight', 'clip_teacher.transformer.resblocks.2.ln_1.bias', 'clip_teacher.transformer.resblocks.2.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.2.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.2.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.2.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.2.ln_2.weight', 'clip_teacher.transformer.resblocks.2.ln_2.bias', 'clip_teacher.transformer.resblocks.3.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.3.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.3.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.3.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.3.ln_1.weight', 'clip_teacher.transformer.resblocks.3.ln_1.bias', 'clip_teacher.transformer.resblocks.3.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.3.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.3.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.3.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.3.ln_2.weight', 'clip_teacher.transformer.resblocks.3.ln_2.bias', 'clip_teacher.transformer.resblocks.4.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.4.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.4.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.4.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.4.ln_1.weight', 'clip_teacher.transformer.resblocks.4.ln_1.bias', 'clip_teacher.transformer.resblocks.4.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.4.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.4.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.4.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.4.ln_2.weight', 'clip_teacher.transformer.resblocks.4.ln_2.bias', 'clip_teacher.transformer.resblocks.5.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.5.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.5.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.5.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.5.ln_1.weight', 'clip_teacher.transformer.resblocks.5.ln_1.bias', 'clip_teacher.transformer.resblocks.5.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.5.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.5.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.5.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.5.ln_2.weight', 'clip_teacher.transformer.resblocks.5.ln_2.bias', 'clip_teacher.transformer.resblocks.6.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.6.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.6.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.6.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.6.ln_1.weight', 'clip_teacher.transformer.resblocks.6.ln_1.bias', 'clip_teacher.transformer.resblocks.6.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.6.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.6.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.6.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.6.ln_2.weight', 'clip_teacher.transformer.resblocks.6.ln_2.bias', 'clip_teacher.transformer.resblocks.7.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.7.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.7.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.7.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.7.ln_1.weight', 'clip_teacher.transformer.resblocks.7.ln_1.bias', 'clip_teacher.transformer.resblocks.7.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.7.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.7.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.7.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.7.ln_2.weight', 'clip_teacher.transformer.resblocks.7.ln_2.bias', 'clip_teacher.transformer.resblocks.8.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.8.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.8.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.8.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.8.ln_1.weight', 'clip_teacher.transformer.resblocks.8.ln_1.bias', 'clip_teacher.transformer.resblocks.8.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.8.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.8.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.8.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.8.ln_2.weight', 'clip_teacher.transformer.resblocks.8.ln_2.bias', 'clip_teacher.transformer.resblocks.9.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.9.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.9.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.9.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.9.ln_1.weight', 'clip_teacher.transformer.resblocks.9.ln_1.bias', 'clip_teacher.transformer.resblocks.9.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.9.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.9.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.9.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.9.ln_2.weight', 'clip_teacher.transformer.resblocks.9.ln_2.bias', 'clip_teacher.transformer.resblocks.10.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.10.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.10.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.10.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.10.ln_1.weight', 'clip_teacher.transformer.resblocks.10.ln_1.bias', 'clip_teacher.transformer.resblocks.10.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.10.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.10.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.10.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.10.ln_2.weight', 'clip_teacher.transformer.resblocks.10.ln_2.bias', 'clip_teacher.transformer.resblocks.11.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.11.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.11.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.11.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.11.ln_1.weight', 'clip_teacher.transformer.resblocks.11.ln_1.bias', 'clip_teacher.transformer.resblocks.11.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.11.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.11.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.11.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.11.ln_2.weight', 'clip_teacher.transformer.resblocks.11.ln_2.bias', 'clip_teacher.ln_post.weight', 'clip_teacher.ln_post.bias', 'vision_encoder.clip_decoder.0.head.weight', 'vision_encoder.clip_decoder.0.head.bias', 'vision_encoder.clip_decoder.0.norm.weight', 'vision_encoder.clip_decoder.0.norm.bias', 'vision_encoder.clip_decoder.1.head.weight', 'vision_encoder.clip_decoder.1.head.bias', 'vision_encoder.clip_decoder.1.norm.weight', 'vision_encoder.clip_decoder.1.norm.bias', 'vision_encoder.clip_decoder.2.head.weight', 'vision_encoder.clip_decoder.2.head.bias', 'vision_encoder.clip_decoder.2.norm.weight', 'vision_encoder.clip_decoder.2.norm.bias', 'vision_encoder.clip_decoder.3.head.weight', 'vision_encoder.clip_decoder.3.head.bias', 'vision_encoder.clip_decoder.3.norm.weight', 'vision_encoder.clip_decoder.3.norm.bias', 'vision_encoder.clip_decoder.4.head.weight', 'vision_encoder.clip_decoder.4.head.bias', 'vision_encoder.clip_decoder.4.norm.weight', 'vision_encoder.clip_decoder.4.norm.bias', 'vision_encoder.clip_decoder.5.head.weight', 'vision_encoder.clip_decoder.5.head.bias', 'vision_encoder.clip_decoder.5.norm.weight', 'vision_encoder.clip_decoder.5.norm.bias', 'text_encoder.cls.predictions.bias', 'text_encoder.cls.predictions.transform.dense.weight', 'text_encoder.cls.predictions.transform.dense.bias', 'text_encoder.cls.predictions.transform.LayerNorm.weight', 'text_encoder.cls.predictions.transform.LayerNorm.bias', 'text_encoder.cls.predictions.decoder.weight', 'text_encoder.cls.predictions.decoder.bias'])
2024-05-27T20:01:44 | INFO | tasks.shared_utils : Loaded checkpoint from /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
2024-05-27T20:01:44 | INFO | __main__ : training
2024-05-27T20:01:45 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T20:01:45 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T20:01:45 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T20:01:45 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T20:01:45 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T20:01:45 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T20:01:45 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T20:01:45 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T20:01:45 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T20:01:45 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T20:01:45 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T20:01:45 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T20:01:45 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 92685 batches in total
dataloader index=0 name=video, batch-size=2 length(#batches)=92685 
2024-05-27T20:01:46 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  builtin_warn(*args, **kwargs)

2024-05-27T20:01:46 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  builtin_warn(*args, **kwargs)

2024-05-27T20:01:46 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-05-27T20:01:46 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-05-27T20:08:37 | INFO | umt : Logging to: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2/train.log
2024-05-27T20:08:37 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
  test_file: {
      test: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test1k.json', '/data2/dy/temporal_video/dataset', 'video'] }
  test_types: ['test']
  num_workers: 6
  rtime: False
  pos_num: 1
  neg_num: 10
  stop_key: test/
  is_paragraph_retrieval: False
  is_pretrain: False
  num_frames: 12
  num_frames_test: 12
  batch_size: 2
  max_txt_l: 50
  evaluate: False
  train_shuffle: False
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 12
          sample_type: rand
          num_frames_test: 12
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 50
          video: 50 }
      batch_size: {
          image: 2
          video: 2 }
      batch_size_test: {
          image: 2
          video: 2 } }
  text_enc: bert
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_b16
          img_size: 224
          patch_size: 16
          d_model: 768
          encoder_embed_dim: 768
          encoder_depth: 12
          encoder_num_heads: 12
          drop_path_rate: 0.2
          num_frames: 12
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 12
          clip_decoder_embed_dim: 768
          clip_output_dim: 512
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 224
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      multimodal: {
          enable: True }
      embed_dim: 512
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 1e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 5
      min_lr_multi: 0.01
      warmup_epochs: 1 }
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: user
      project: umt_ret }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
  resume: False
  debug: False
  log_freq: 100
  seed: 3407
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
  rank: 0
  world_size: 1
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-05-27T20:08:37 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video'], 'test_file': {'test': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test1k.json', '/data2/dy/temporal_video/dataset', 'video']}, 'test_types': ['test'], 'num_workers': 6, 'rtime': False, 'pos_num': 1, 'neg_num': 10, 'stop_key': 'test/', 'is_paragraph_retrieval': False, 'is_pretrain': False, 'num_frames': 12, 'num_frames_test': 12, 'batch_size': 2, 'max_txt_l': 50, 'evaluate': False, 'train_shuffle': False, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 12, 'sample_type': 'rand', 'num_frames_test': 12, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 50, 'video': 50}, 'batch_size': {'image': 2, 'video': 2}, 'batch_size_test': {'image': 2, 'video': 2}}, 'text_enc': 'bert', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_b16', 'img_size': 224, 'patch_size': 16, 'd_model': 768, 'encoder_embed_dim': 768, 'encoder_depth': 12, 'encoder_num_heads': 12, 'drop_path_rate': 0.2, 'num_frames': 12, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 12, 'clip_decoder_embed_dim': 768, 'clip_output_dim': 512, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 224, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'multimodal': {'enable': True}, 'embed_dim': 512, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 1e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 5, 'min_lr_multi': 0.01, 'warmup_epochs': 1}, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': False, 'entity': 'user', 'project': 'umt_ret'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': 'exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 3407, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth', 'rank': 0, 'world_size': 1, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2024-05-27T20:08:37 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
2024-05-27T20:08:37 | INFO | tasks.pretrain : Creating dataset for ret
2024-05-27T20:08:38 | INFO | tasks.shared_utils : Creating model
2024-05-27T20:08:48 | INFO | models.umt : Build vision_encoder: vit_b16
2024-05-27T20:08:48 | INFO | models.backbones.vit.vit : Num of patches: 2352
2024-05-27T20:08:48 | INFO | models.backbones.vit.vit : Use checkpoint: True
2024-05-27T20:08:48 | INFO | models.backbones.vit.vit : Checkpoint number: 12
2024-05-27T20:08:48 | INFO | models.backbones.vit.vit : Student return index: []
2024-05-27T20:08:55 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
2024-05-27T20:08:56 | INFO | models.umt : Build text_encoder bert_base
2024-05-27T20:08:57 | INFO | models.backbones.bert.xbert : build bert with cross_module: ca
2024-05-27T20:08:57 | INFO | models.criterions : Norm type: l2
2024-05-27T20:08:57 | INFO | models.criterions : Loss type: l2
2024-05-27T20:08:57 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-05-27T20:08:57 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.lora_r: wd: 0, lr: 1e-05
2024-05-27T20:08:57 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T20:08:57 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T20:08:57 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:08:57 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:08:57 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T20:08:57 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.lora_r: wd: 0, lr: 1e-05
2024-05-27T20:08:57 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T20:08:57 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T20:08:57 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:08:57 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:08:57 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T20:08:57 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.lora_r: wd: 0, lr: 1e-05
2024-05-27T20:08:57 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T20:08:57 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T20:08:57 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:08:57 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:08:57 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T20:08:57 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.lora_r: wd: 0, lr: 1e-05
2024-05-27T20:08:57 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T20:08:57 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T20:08:57 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:08:57 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:08:57 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T20:08:57 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.lora_r: wd: 0, lr: 1e-05
2024-05-27T20:08:57 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T20:08:57 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T20:08:57 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:08:57 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:08:57 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T20:08:57 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.lora_r: wd: 0, lr: 1e-05
2024-05-27T20:08:57 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T20:08:57 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T20:08:57 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:08:57 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:08:57 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T20:08:57 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.lora_r: wd: 0, lr: 1e-05
2024-05-27T20:08:57 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T20:08:57 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T20:08:57 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:08:57 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:08:57 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T20:08:57 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.lora_r: wd: 0, lr: 1e-05
2024-05-27T20:08:57 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T20:08:57 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T20:08:57 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:08:57 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:08:57 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T20:08:57 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.lora_r: wd: 0, lr: 1e-05
2024-05-27T20:08:57 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T20:08:57 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T20:08:57 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:08:57 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:08:57 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T20:08:57 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.lora_r: wd: 0, lr: 1e-05
2024-05-27T20:08:57 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T20:08:57 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T20:08:57 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:08:57 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:08:57 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T20:08:57 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.lora_r: wd: 0, lr: 1e-05
2024-05-27T20:08:57 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T20:08:57 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T20:08:57 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:08:57 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:08:57 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T20:08:57 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.lora_r: wd: 0, lr: 1e-05
2024-05-27T20:08:57 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T20:08:57 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T20:08:57 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:08:57 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:08:57 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T20:08:57 | INFO | utils.optimizer : param module.vision_proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:08:57 | INFO | utils.optimizer : param module.vision_proj.bias: wd: 0, lr: 1e-05
2024-05-27T20:08:57 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0 len(p)=49
2024-05-27T20:08:57 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0.02 len(p)=25
2024-05-27T20:08:57 | INFO | tasks.shared_utils : Auto resuming
2024-05-27T20:08:57 | INFO | tasks.shared_utils : Not found checkpoint in exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
2024-05-27T20:08:58 | INFO | tasks.shared_utils : _IncompatibleKeys(missing_keys=['vision_encoder.encoder.blocks.0.lora_r', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.1.lora_r', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.2.lora_r', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.3.lora_r', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.4.lora_r', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.5.lora_r', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.6.lora_r', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.7.lora_r', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.8.lora_r', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.9.lora_r', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.10.lora_r', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.11.lora_r', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.bias'], unexpected_keys=['clip_teacher.class_embedding', 'clip_teacher.positional_embedding', 'clip_teacher.proj', 'clip_teacher.conv1.weight', 'clip_teacher.ln_pre.weight', 'clip_teacher.ln_pre.bias', 'clip_teacher.transformer.resblocks.0.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.0.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.0.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.0.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.0.ln_1.weight', 'clip_teacher.transformer.resblocks.0.ln_1.bias', 'clip_teacher.transformer.resblocks.0.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.0.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.0.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.0.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.0.ln_2.weight', 'clip_teacher.transformer.resblocks.0.ln_2.bias', 'clip_teacher.transformer.resblocks.1.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.1.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.1.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.1.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.1.ln_1.weight', 'clip_teacher.transformer.resblocks.1.ln_1.bias', 'clip_teacher.transformer.resblocks.1.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.1.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.1.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.1.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.1.ln_2.weight', 'clip_teacher.transformer.resblocks.1.ln_2.bias', 'clip_teacher.transformer.resblocks.2.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.2.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.2.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.2.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.2.ln_1.weight', 'clip_teacher.transformer.resblocks.2.ln_1.bias', 'clip_teacher.transformer.resblocks.2.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.2.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.2.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.2.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.2.ln_2.weight', 'clip_teacher.transformer.resblocks.2.ln_2.bias', 'clip_teacher.transformer.resblocks.3.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.3.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.3.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.3.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.3.ln_1.weight', 'clip_teacher.transformer.resblocks.3.ln_1.bias', 'clip_teacher.transformer.resblocks.3.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.3.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.3.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.3.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.3.ln_2.weight', 'clip_teacher.transformer.resblocks.3.ln_2.bias', 'clip_teacher.transformer.resblocks.4.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.4.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.4.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.4.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.4.ln_1.weight', 'clip_teacher.transformer.resblocks.4.ln_1.bias', 'clip_teacher.transformer.resblocks.4.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.4.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.4.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.4.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.4.ln_2.weight', 'clip_teacher.transformer.resblocks.4.ln_2.bias', 'clip_teacher.transformer.resblocks.5.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.5.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.5.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.5.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.5.ln_1.weight', 'clip_teacher.transformer.resblocks.5.ln_1.bias', 'clip_teacher.transformer.resblocks.5.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.5.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.5.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.5.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.5.ln_2.weight', 'clip_teacher.transformer.resblocks.5.ln_2.bias', 'clip_teacher.transformer.resblocks.6.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.6.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.6.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.6.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.6.ln_1.weight', 'clip_teacher.transformer.resblocks.6.ln_1.bias', 'clip_teacher.transformer.resblocks.6.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.6.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.6.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.6.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.6.ln_2.weight', 'clip_teacher.transformer.resblocks.6.ln_2.bias', 'clip_teacher.transformer.resblocks.7.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.7.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.7.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.7.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.7.ln_1.weight', 'clip_teacher.transformer.resblocks.7.ln_1.bias', 'clip_teacher.transformer.resblocks.7.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.7.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.7.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.7.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.7.ln_2.weight', 'clip_teacher.transformer.resblocks.7.ln_2.bias', 'clip_teacher.transformer.resblocks.8.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.8.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.8.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.8.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.8.ln_1.weight', 'clip_teacher.transformer.resblocks.8.ln_1.bias', 'clip_teacher.transformer.resblocks.8.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.8.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.8.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.8.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.8.ln_2.weight', 'clip_teacher.transformer.resblocks.8.ln_2.bias', 'clip_teacher.transformer.resblocks.9.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.9.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.9.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.9.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.9.ln_1.weight', 'clip_teacher.transformer.resblocks.9.ln_1.bias', 'clip_teacher.transformer.resblocks.9.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.9.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.9.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.9.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.9.ln_2.weight', 'clip_teacher.transformer.resblocks.9.ln_2.bias', 'clip_teacher.transformer.resblocks.10.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.10.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.10.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.10.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.10.ln_1.weight', 'clip_teacher.transformer.resblocks.10.ln_1.bias', 'clip_teacher.transformer.resblocks.10.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.10.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.10.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.10.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.10.ln_2.weight', 'clip_teacher.transformer.resblocks.10.ln_2.bias', 'clip_teacher.transformer.resblocks.11.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.11.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.11.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.11.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.11.ln_1.weight', 'clip_teacher.transformer.resblocks.11.ln_1.bias', 'clip_teacher.transformer.resblocks.11.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.11.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.11.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.11.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.11.ln_2.weight', 'clip_teacher.transformer.resblocks.11.ln_2.bias', 'clip_teacher.ln_post.weight', 'clip_teacher.ln_post.bias', 'vision_encoder.clip_decoder.0.head.weight', 'vision_encoder.clip_decoder.0.head.bias', 'vision_encoder.clip_decoder.0.norm.weight', 'vision_encoder.clip_decoder.0.norm.bias', 'vision_encoder.clip_decoder.1.head.weight', 'vision_encoder.clip_decoder.1.head.bias', 'vision_encoder.clip_decoder.1.norm.weight', 'vision_encoder.clip_decoder.1.norm.bias', 'vision_encoder.clip_decoder.2.head.weight', 'vision_encoder.clip_decoder.2.head.bias', 'vision_encoder.clip_decoder.2.norm.weight', 'vision_encoder.clip_decoder.2.norm.bias', 'vision_encoder.clip_decoder.3.head.weight', 'vision_encoder.clip_decoder.3.head.bias', 'vision_encoder.clip_decoder.3.norm.weight', 'vision_encoder.clip_decoder.3.norm.bias', 'vision_encoder.clip_decoder.4.head.weight', 'vision_encoder.clip_decoder.4.head.bias', 'vision_encoder.clip_decoder.4.norm.weight', 'vision_encoder.clip_decoder.4.norm.bias', 'vision_encoder.clip_decoder.5.head.weight', 'vision_encoder.clip_decoder.5.head.bias', 'vision_encoder.clip_decoder.5.norm.weight', 'vision_encoder.clip_decoder.5.norm.bias', 'text_encoder.cls.predictions.bias', 'text_encoder.cls.predictions.transform.dense.weight', 'text_encoder.cls.predictions.transform.dense.bias', 'text_encoder.cls.predictions.transform.LayerNorm.weight', 'text_encoder.cls.predictions.transform.LayerNorm.bias', 'text_encoder.cls.predictions.decoder.weight', 'text_encoder.cls.predictions.decoder.bias'])
2024-05-27T20:08:58 | INFO | tasks.shared_utils : Loaded checkpoint from /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
2024-05-27T20:08:58 | INFO | __main__ : training
2024-05-27T20:08:59 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T20:08:59 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T20:08:59 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T20:08:59 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T20:08:59 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T20:08:59 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T20:08:59 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T20:08:59 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T20:08:59 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T20:08:59 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T20:08:59 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T20:08:59 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T20:08:59 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 92685 batches in total
dataloader index=0 name=video, batch-size=2 length(#batches)=92685 
2024-05-27T20:09:00 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  builtin_warn(*args, **kwargs)

2024-05-27T20:09:00 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  builtin_warn(*args, **kwargs)

2024-05-27T20:09:00 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-05-27T20:09:00 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-05-27T20:09:03 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  builtin_warn(*args, **kwargs)

2024-05-27T20:09:03 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  builtin_warn(*args, **kwargs)

2024-05-27T20:09:03 | INFO | utils.basic_utils : Train Epoch: [0]  [    0/92685]  eta: 4 days, 10:44:53  lr: 0.000000  temperature: 0.0112  video-loss_vtc: 2.2963  video-loss_vtm: 1.5841  time: 4.1462  data: 0.4043  max mem: 1924 res mem: 2508
2024-05-27T20:09:49 | INFO | umt : Logging to: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2/train.log
2024-05-27T20:09:49 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
  test_file: {
      test: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test1k.json', '/data2/dy/temporal_video/dataset', 'video'] }
  test_types: ['test']
  num_workers: 6
  rtime: False
  pos_num: 1
  neg_num: 10
  stop_key: test/
  is_paragraph_retrieval: False
  is_pretrain: False
  num_frames: 12
  num_frames_test: 12
  batch_size: 32
  max_txt_l: 50
  evaluate: False
  train_shuffle: False
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 12
          sample_type: rand
          num_frames_test: 12
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 50
          video: 50 }
      batch_size: {
          image: 32
          video: 32 }
      batch_size_test: {
          image: 32
          video: 32 } }
  text_enc: bert
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_b16
          img_size: 224
          patch_size: 16
          d_model: 768
          encoder_embed_dim: 768
          encoder_depth: 12
          encoder_num_heads: 12
          drop_path_rate: 0.2
          num_frames: 12
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 12
          clip_decoder_embed_dim: 768
          clip_output_dim: 512
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 224
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      multimodal: {
          enable: True }
      embed_dim: 512
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 1e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 5
      min_lr_multi: 0.01
      warmup_epochs: 1 }
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: user
      project: umt_ret }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
  resume: False
  debug: False
  log_freq: 100
  seed: 3407
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
  rank: 0
  world_size: 4
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-05-27T20:09:49 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video'], 'test_file': {'test': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test1k.json', '/data2/dy/temporal_video/dataset', 'video']}, 'test_types': ['test'], 'num_workers': 6, 'rtime': False, 'pos_num': 1, 'neg_num': 10, 'stop_key': 'test/', 'is_paragraph_retrieval': False, 'is_pretrain': False, 'num_frames': 12, 'num_frames_test': 12, 'batch_size': 32, 'max_txt_l': 50, 'evaluate': False, 'train_shuffle': False, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 12, 'sample_type': 'rand', 'num_frames_test': 12, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 50, 'video': 50}, 'batch_size': {'image': 32, 'video': 32}, 'batch_size_test': {'image': 32, 'video': 32}}, 'text_enc': 'bert', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_b16', 'img_size': 224, 'patch_size': 16, 'd_model': 768, 'encoder_embed_dim': 768, 'encoder_depth': 12, 'encoder_num_heads': 12, 'drop_path_rate': 0.2, 'num_frames': 12, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 12, 'clip_decoder_embed_dim': 768, 'clip_output_dim': 512, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 224, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'multimodal': {'enable': True}, 'embed_dim': 512, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 1e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 5, 'min_lr_multi': 0.01, 'warmup_epochs': 1}, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': False, 'entity': 'user', 'project': 'umt_ret'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': 'exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 3407, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth', 'rank': 0, 'world_size': 4, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2024-05-27T20:09:49 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
2024-05-27T20:09:49 | INFO | tasks.pretrain : Creating dataset for ret
2024-05-27T20:09:49 | INFO | tasks.shared_utils : Creating model
2024-05-27T20:09:59 | INFO | models.umt : Build vision_encoder: vit_b16
2024-05-27T20:09:59 | INFO | models.backbones.vit.vit : Num of patches: 2352
2024-05-27T20:09:59 | INFO | models.backbones.vit.vit : Use checkpoint: True
2024-05-27T20:09:59 | INFO | models.backbones.vit.vit : Checkpoint number: 12
2024-05-27T20:09:59 | INFO | models.backbones.vit.vit : Student return index: []
2024-05-27T20:10:07 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
2024-05-27T20:10:08 | INFO | models.umt : Build text_encoder bert_base
2024-05-27T20:10:09 | INFO | models.backbones.bert.xbert : build bert with cross_module: ca
2024-05-27T20:10:09 | INFO | models.criterions : Norm type: l2
2024-05-27T20:10:09 | INFO | models.criterions : Loss type: l2
2024-05-27T20:10:10 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-05-27T20:10:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.lora_r: wd: 0, lr: 1e-05
2024-05-27T20:10:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T20:10:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T20:10:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:10:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:10:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T20:10:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.lora_r: wd: 0, lr: 1e-05
2024-05-27T20:10:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T20:10:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T20:10:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:10:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:10:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T20:10:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.lora_r: wd: 0, lr: 1e-05
2024-05-27T20:10:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T20:10:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T20:10:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:10:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:10:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T20:10:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.lora_r: wd: 0, lr: 1e-05
2024-05-27T20:10:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T20:10:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T20:10:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:10:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:10:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T20:10:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.lora_r: wd: 0, lr: 1e-05
2024-05-27T20:10:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T20:10:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T20:10:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:10:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:10:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T20:10:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.lora_r: wd: 0, lr: 1e-05
2024-05-27T20:10:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T20:10:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T20:10:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:10:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:10:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T20:10:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.lora_r: wd: 0, lr: 1e-05
2024-05-27T20:10:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T20:10:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T20:10:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:10:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:10:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T20:10:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.lora_r: wd: 0, lr: 1e-05
2024-05-27T20:10:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T20:10:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T20:10:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:10:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:10:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T20:10:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.lora_r: wd: 0, lr: 1e-05
2024-05-27T20:10:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T20:10:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T20:10:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:10:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:10:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T20:10:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.lora_r: wd: 0, lr: 1e-05
2024-05-27T20:10:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T20:10:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T20:10:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:10:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:10:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T20:10:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.lora_r: wd: 0, lr: 1e-05
2024-05-27T20:10:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T20:10:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T20:10:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:10:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:10:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T20:10:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.lora_r: wd: 0, lr: 1e-05
2024-05-27T20:10:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-27T20:10:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-27T20:10:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:10:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:10:10 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-27T20:10:10 | INFO | utils.optimizer : param module.vision_proj.weight: wd: 0.02, lr: 1e-05
2024-05-27T20:10:10 | INFO | utils.optimizer : param module.vision_proj.bias: wd: 0, lr: 1e-05
2024-05-27T20:10:10 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0 len(p)=49
2024-05-27T20:10:10 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0.02 len(p)=25
2024-05-27T20:10:10 | INFO | tasks.shared_utils : Auto resuming
2024-05-27T20:10:10 | INFO | tasks.shared_utils : Not found checkpoint in exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
2024-05-27T20:10:11 | INFO | tasks.shared_utils : _IncompatibleKeys(missing_keys=['vision_encoder.encoder.blocks.0.lora_r', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.1.lora_r', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.2.lora_r', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.3.lora_r', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.4.lora_r', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.5.lora_r', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.6.lora_r', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.7.lora_r', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.8.lora_r', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.9.lora_r', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.10.lora_r', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.11.lora_r', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.bias'], unexpected_keys=['clip_teacher.class_embedding', 'clip_teacher.positional_embedding', 'clip_teacher.proj', 'clip_teacher.conv1.weight', 'clip_teacher.ln_pre.weight', 'clip_teacher.ln_pre.bias', 'clip_teacher.transformer.resblocks.0.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.0.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.0.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.0.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.0.ln_1.weight', 'clip_teacher.transformer.resblocks.0.ln_1.bias', 'clip_teacher.transformer.resblocks.0.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.0.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.0.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.0.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.0.ln_2.weight', 'clip_teacher.transformer.resblocks.0.ln_2.bias', 'clip_teacher.transformer.resblocks.1.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.1.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.1.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.1.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.1.ln_1.weight', 'clip_teacher.transformer.resblocks.1.ln_1.bias', 'clip_teacher.transformer.resblocks.1.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.1.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.1.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.1.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.1.ln_2.weight', 'clip_teacher.transformer.resblocks.1.ln_2.bias', 'clip_teacher.transformer.resblocks.2.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.2.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.2.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.2.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.2.ln_1.weight', 'clip_teacher.transformer.resblocks.2.ln_1.bias', 'clip_teacher.transformer.resblocks.2.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.2.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.2.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.2.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.2.ln_2.weight', 'clip_teacher.transformer.resblocks.2.ln_2.bias', 'clip_teacher.transformer.resblocks.3.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.3.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.3.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.3.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.3.ln_1.weight', 'clip_teacher.transformer.resblocks.3.ln_1.bias', 'clip_teacher.transformer.resblocks.3.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.3.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.3.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.3.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.3.ln_2.weight', 'clip_teacher.transformer.resblocks.3.ln_2.bias', 'clip_teacher.transformer.resblocks.4.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.4.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.4.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.4.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.4.ln_1.weight', 'clip_teacher.transformer.resblocks.4.ln_1.bias', 'clip_teacher.transformer.resblocks.4.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.4.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.4.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.4.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.4.ln_2.weight', 'clip_teacher.transformer.resblocks.4.ln_2.bias', 'clip_teacher.transformer.resblocks.5.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.5.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.5.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.5.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.5.ln_1.weight', 'clip_teacher.transformer.resblocks.5.ln_1.bias', 'clip_teacher.transformer.resblocks.5.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.5.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.5.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.5.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.5.ln_2.weight', 'clip_teacher.transformer.resblocks.5.ln_2.bias', 'clip_teacher.transformer.resblocks.6.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.6.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.6.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.6.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.6.ln_1.weight', 'clip_teacher.transformer.resblocks.6.ln_1.bias', 'clip_teacher.transformer.resblocks.6.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.6.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.6.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.6.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.6.ln_2.weight', 'clip_teacher.transformer.resblocks.6.ln_2.bias', 'clip_teacher.transformer.resblocks.7.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.7.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.7.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.7.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.7.ln_1.weight', 'clip_teacher.transformer.resblocks.7.ln_1.bias', 'clip_teacher.transformer.resblocks.7.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.7.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.7.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.7.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.7.ln_2.weight', 'clip_teacher.transformer.resblocks.7.ln_2.bias', 'clip_teacher.transformer.resblocks.8.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.8.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.8.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.8.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.8.ln_1.weight', 'clip_teacher.transformer.resblocks.8.ln_1.bias', 'clip_teacher.transformer.resblocks.8.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.8.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.8.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.8.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.8.ln_2.weight', 'clip_teacher.transformer.resblocks.8.ln_2.bias', 'clip_teacher.transformer.resblocks.9.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.9.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.9.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.9.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.9.ln_1.weight', 'clip_teacher.transformer.resblocks.9.ln_1.bias', 'clip_teacher.transformer.resblocks.9.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.9.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.9.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.9.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.9.ln_2.weight', 'clip_teacher.transformer.resblocks.9.ln_2.bias', 'clip_teacher.transformer.resblocks.10.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.10.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.10.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.10.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.10.ln_1.weight', 'clip_teacher.transformer.resblocks.10.ln_1.bias', 'clip_teacher.transformer.resblocks.10.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.10.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.10.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.10.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.10.ln_2.weight', 'clip_teacher.transformer.resblocks.10.ln_2.bias', 'clip_teacher.transformer.resblocks.11.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.11.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.11.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.11.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.11.ln_1.weight', 'clip_teacher.transformer.resblocks.11.ln_1.bias', 'clip_teacher.transformer.resblocks.11.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.11.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.11.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.11.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.11.ln_2.weight', 'clip_teacher.transformer.resblocks.11.ln_2.bias', 'clip_teacher.ln_post.weight', 'clip_teacher.ln_post.bias', 'vision_encoder.clip_decoder.0.head.weight', 'vision_encoder.clip_decoder.0.head.bias', 'vision_encoder.clip_decoder.0.norm.weight', 'vision_encoder.clip_decoder.0.norm.bias', 'vision_encoder.clip_decoder.1.head.weight', 'vision_encoder.clip_decoder.1.head.bias', 'vision_encoder.clip_decoder.1.norm.weight', 'vision_encoder.clip_decoder.1.norm.bias', 'vision_encoder.clip_decoder.2.head.weight', 'vision_encoder.clip_decoder.2.head.bias', 'vision_encoder.clip_decoder.2.norm.weight', 'vision_encoder.clip_decoder.2.norm.bias', 'vision_encoder.clip_decoder.3.head.weight', 'vision_encoder.clip_decoder.3.head.bias', 'vision_encoder.clip_decoder.3.norm.weight', 'vision_encoder.clip_decoder.3.norm.bias', 'vision_encoder.clip_decoder.4.head.weight', 'vision_encoder.clip_decoder.4.head.bias', 'vision_encoder.clip_decoder.4.norm.weight', 'vision_encoder.clip_decoder.4.norm.bias', 'vision_encoder.clip_decoder.5.head.weight', 'vision_encoder.clip_decoder.5.head.bias', 'vision_encoder.clip_decoder.5.norm.weight', 'vision_encoder.clip_decoder.5.norm.bias', 'text_encoder.cls.predictions.bias', 'text_encoder.cls.predictions.transform.dense.weight', 'text_encoder.cls.predictions.transform.dense.bias', 'text_encoder.cls.predictions.transform.LayerNorm.weight', 'text_encoder.cls.predictions.transform.LayerNorm.bias', 'text_encoder.cls.predictions.decoder.weight', 'text_encoder.cls.predictions.decoder.bias'])
2024-05-27T20:10:11 | INFO | tasks.shared_utils : Loaded checkpoint from /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
2024-05-27T20:10:11 | INFO | __main__ : training
2024-05-27T20:10:11 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T20:10:11 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T20:10:11 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T20:10:11 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T20:10:11 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T20:10:11 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T20:10:11 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T20:10:11 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T20:10:11 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 1448 batches in total
dataloader index=0 name=video, batch-size=32 length(#batches)=1448 
2024-05-27T20:10:12 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T20:10:12 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T20:10:12 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T20:10:12 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T20:10:27 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  builtin_warn(*args, **kwargs)

2024-05-27T20:10:27 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  builtin_warn(*args, **kwargs)

2024-05-27T20:10:27 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-05-27T20:10:27 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-05-27T20:10:30 | INFO | utils.basic_utils : Train Epoch: [0]  [   0/1448]  eta: 7:25:28  lr: 0.000000  temperature: 0.0112  video-loss_vtc: 2.5536  video-loss_vtm: 0.5447  time: 18.4588  data: 15.1860  max mem: 14768 res mem: 22898
2024-05-27T20:15:56 | INFO | utils.basic_utils : Train Epoch: [0]  [ 100/1448]  eta: 1:16:42  lr: 0.000001  temperature: 0.0112  video-loss_vtc: 2.6353  video-loss_vtm: 0.6143  time: 3.0166  data: 0.0016  max mem: 14783 res mem: 22900
2024-05-27T20:21:07 | INFO | utils.basic_utils : Train Epoch: [0]  [ 200/1448]  eta: 1:07:47  lr: 0.000001  temperature: 0.0112  video-loss_vtc: 2.7845  video-loss_vtm: 0.7969  time: 3.0047  data: 0.0023  max mem: 14783 res mem: 22900
2024-05-27T20:25:53 | INFO | utils.basic_utils : Train Epoch: [0]  [ 300/1448]  eta: 0:59:49  lr: 0.000002  temperature: 0.0112  video-loss_vtc: 2.0444  video-loss_vtm: 0.2924  time: 2.9068  data: 0.2238  max mem: 14783 res mem: 22900
2024-05-27T20:30:31 | INFO | utils.basic_utils : Train Epoch: [0]  [ 400/1448]  eta: 0:53:06  lr: 0.000003  temperature: 0.0112  video-loss_vtc: 2.5409  video-loss_vtm: 0.5999  time: 2.7053  data: 0.0702  max mem: 14783 res mem: 22900
2024-05-27T20:34:51 | INFO | utils.basic_utils : Train Epoch: [0]  [ 500/1448]  eta: 0:46:39  lr: 0.000003  temperature: 0.0112  video-loss_vtc: 2.6473  video-loss_vtm: 0.6523  time: 2.7335  data: 0.5686  max mem: 14783 res mem: 22900
2024-05-27T20:39:08 | INFO | utils.basic_utils : Train Epoch: [0]  [ 600/1448]  eta: 0:40:50  lr: 0.000004  temperature: 0.0112  video-loss_vtc: 2.4108  video-loss_vtm: 0.5087  time: 2.4322  data: 0.1460  max mem: 14783 res mem: 22900
2024-05-27T20:43:30 | INFO | utils.basic_utils : Train Epoch: [0]  [ 700/1448]  eta: 0:35:32  lr: 0.000005  temperature: 0.0112  video-loss_vtc: 2.6092  video-loss_vtm: 0.5732  time: 2.5498  data: 0.1841  max mem: 14783 res mem: 22900
2024-05-27T20:47:51 | INFO | utils.basic_utils : Train Epoch: [0]  [ 800/1448]  eta: 0:30:27  lr: 0.000006  temperature: 0.0112  video-loss_vtc: 2.1121  video-loss_vtm: 0.6493  time: 2.6564  data: 0.0020  max mem: 14783 res mem: 22900
2024-05-27T20:52:08 | INFO | utils.basic_utils : Train Epoch: [0]  [ 900/1448]  eta: 0:25:30  lr: 0.000006  temperature: 0.0112  video-loss_vtc: 1.8767  video-loss_vtm: 0.4761  time: 2.6022  data: 0.0019  max mem: 14783 res mem: 22900
2024-05-27T20:56:22 | INFO | utils.basic_utils : Train Epoch: [0]  [1000/1448]  eta: 0:20:40  lr: 0.000007  temperature: 0.0112  video-loss_vtc: 2.3285  video-loss_vtm: 0.8198  time: 2.3882  data: 0.0015  max mem: 14783 res mem: 22900
2024-05-27T21:00:37 | INFO | utils.basic_utils : Train Epoch: [0]  [1100/1448]  eta: 0:15:56  lr: 0.000008  temperature: 0.0112  video-loss_vtc: 2.4236  video-loss_vtm: 0.5128  time: 2.6492  data: 0.0019  max mem: 14783 res mem: 22900
2024-05-27T21:04:54 | INFO | utils.basic_utils : Train Epoch: [0]  [1200/1448]  eta: 0:11:17  lr: 0.000008  temperature: 0.0112  video-loss_vtc: 2.0469  video-loss_vtm: 0.7175  time: 2.6602  data: 0.0254  max mem: 14783 res mem: 22900
2024-05-27T21:09:11 | INFO | utils.basic_utils : Train Epoch: [0]  [1300/1448]  eta: 0:06:42  lr: 0.000009  temperature: 0.0112  video-loss_vtc: 2.1237  video-loss_vtm: 0.4691  time: 2.5421  data: 0.0019  max mem: 14783 res mem: 22900
2024-05-27T21:13:28 | INFO | utils.basic_utils : Train Epoch: [0]  [1400/1448]  eta: 0:02:10  lr: 0.000010  temperature: 0.0112  video-loss_vtc: 2.2197  video-loss_vtm: 0.7498  time: 2.5984  data: 0.4862  max mem: 14783 res mem: 22900
2024-05-27T21:15:29 | INFO | utils.basic_utils : Train Epoch: [0]  [1447/1448]  eta: 0:00:02  lr: 0.000010  temperature: 0.0112  video-loss_vtc: 1.8155  video-loss_vtm: 0.4899  time: 2.5093  data: 0.3963  max mem: 14783 res mem: 22900
2024-05-27T21:15:29 | INFO | utils.basic_utils : Train Epoch: [0] Total time: 1:05:17 (2.7057 s / it)
2024-05-27T21:15:29 | INFO | __main__ : Averaged train stats: lr: 0.0000  temperature: 0.0112  video-loss_vtc: 2.2684  video-loss_vtm: 0.5406
2024-05-27T21:15:29 | INFO | tasks.retrieval_utils : Start evaluation for media_type=video
2024-05-27T21:15:29 | INFO | tasks.retrieval_utils : Computing dual encoder features...
2024-05-27T21:15:30 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T21:15:30 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T21:15:31 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T21:15:31 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T21:15:31 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T21:15:31 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T21:15:31 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T21:15:31 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T21:15:31 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T21:15:31 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T21:15:31 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-27T21:15:31 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T01:53:01 | INFO | umt : Logging to: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2/train.log
2024-05-28T01:53:01 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
  test_file: {
      test: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test1k.json', '/data2/dy/temporal_video/dataset', 'video'] }
  test_types: ['test']
  num_workers: 6
  rtime: False
  pos_num: 1
  neg_num: 10
  stop_key: test/
  is_paragraph_retrieval: False
  is_pretrain: False
  num_frames: 12
  num_frames_test: 12
  batch_size: 32
  max_txt_l: 50
  evaluate: False
  train_shuffle: False
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 12
          sample_type: rand
          num_frames_test: 12
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 50
          video: 50 }
      batch_size: {
          image: 32
          video: 32 }
      batch_size_test: {
          image: 32
          video: 32 } }
  text_enc: bert
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_b16
          img_size: 224
          patch_size: 16
          d_model: 768
          encoder_embed_dim: 768
          encoder_depth: 12
          encoder_num_heads: 12
          drop_path_rate: 0.2
          num_frames: 12
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 12
          clip_decoder_embed_dim: 768
          clip_output_dim: 512
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 224
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      multimodal: {
          enable: True }
      embed_dim: 512
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 1e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 5
      min_lr_multi: 0.01
      warmup_epochs: 1 }
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: user
      project: umt_ret }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
  resume: False
  debug: False
  log_freq: 100
  seed: 3407
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
  rank: 0
  world_size: 1
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-05-28T01:53:01 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video'], 'test_file': {'test': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test1k.json', '/data2/dy/temporal_video/dataset', 'video']}, 'test_types': ['test'], 'num_workers': 6, 'rtime': False, 'pos_num': 1, 'neg_num': 10, 'stop_key': 'test/', 'is_paragraph_retrieval': False, 'is_pretrain': False, 'num_frames': 12, 'num_frames_test': 12, 'batch_size': 32, 'max_txt_l': 50, 'evaluate': False, 'train_shuffle': False, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 12, 'sample_type': 'rand', 'num_frames_test': 12, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 50, 'video': 50}, 'batch_size': {'image': 32, 'video': 32}, 'batch_size_test': {'image': 32, 'video': 32}}, 'text_enc': 'bert', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_b16', 'img_size': 224, 'patch_size': 16, 'd_model': 768, 'encoder_embed_dim': 768, 'encoder_depth': 12, 'encoder_num_heads': 12, 'drop_path_rate': 0.2, 'num_frames': 12, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 12, 'clip_decoder_embed_dim': 768, 'clip_output_dim': 512, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 224, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'multimodal': {'enable': True}, 'embed_dim': 512, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 1e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 5, 'min_lr_multi': 0.01, 'warmup_epochs': 1}, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': False, 'entity': 'user', 'project': 'umt_ret'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': 'exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 3407, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth', 'rank': 0, 'world_size': 1, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2024-05-28T01:53:01 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
2024-05-28T01:53:01 | INFO | tasks.pretrain : Creating dataset for ret
2024-05-28T01:53:02 | INFO | tasks.shared_utils : Creating model
2024-05-28T01:53:12 | INFO | models.umt : Build vision_encoder: vit_b16
2024-05-28T01:53:12 | INFO | models.backbones.vit.vit : Num of patches: 2352
2024-05-28T01:53:12 | INFO | models.backbones.vit.vit : Use checkpoint: True
2024-05-28T01:53:12 | INFO | models.backbones.vit.vit : Checkpoint number: 12
2024-05-28T01:53:12 | INFO | models.backbones.vit.vit : Student return index: []
2024-05-28T01:53:21 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
2024-05-28T01:53:21 | INFO | models.umt : Build text_encoder bert_base
2024-05-28T01:53:22 | INFO | models.backbones.bert.xbert : build bert with cross_module: ca
2024-05-28T01:53:22 | INFO | models.criterions : Norm type: l2
2024-05-28T01:53:22 | INFO | models.criterions : Loss type: l2
2024-05-28T01:53:23 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-05-28T01:53:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.lora_r: wd: 0, lr: 1e-05
2024-05-28T01:53:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T01:53:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T01:53:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T01:53:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T01:53:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T01:53:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.lora_r: wd: 0, lr: 1e-05
2024-05-28T01:53:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T01:53:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T01:53:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T01:53:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T01:53:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T01:53:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.lora_r: wd: 0, lr: 1e-05
2024-05-28T01:53:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T01:53:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T01:53:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T01:53:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T01:53:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T01:53:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.lora_r: wd: 0, lr: 1e-05
2024-05-28T01:53:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T01:53:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T01:53:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T01:53:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T01:53:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T01:53:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.lora_r: wd: 0, lr: 1e-05
2024-05-28T01:53:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T01:53:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T01:53:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T01:53:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T01:53:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T01:53:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.lora_r: wd: 0, lr: 1e-05
2024-05-28T01:53:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T01:53:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T01:53:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T01:53:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T01:53:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T01:53:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.lora_r: wd: 0, lr: 1e-05
2024-05-28T01:53:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T01:53:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T01:53:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T01:53:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T01:53:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T01:53:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.lora_r: wd: 0, lr: 1e-05
2024-05-28T01:53:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T01:53:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T01:53:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T01:53:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T01:53:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T01:53:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.lora_r: wd: 0, lr: 1e-05
2024-05-28T01:53:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T01:53:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T01:53:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T01:53:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T01:53:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T01:53:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.lora_r: wd: 0, lr: 1e-05
2024-05-28T01:53:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T01:53:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T01:53:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T01:53:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T01:53:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T01:53:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.lora_r: wd: 0, lr: 1e-05
2024-05-28T01:53:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T01:53:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T01:53:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T01:53:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T01:53:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T01:53:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.lora_r: wd: 0, lr: 1e-05
2024-05-28T01:53:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T01:53:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T01:53:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T01:53:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T01:53:23 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T01:53:23 | INFO | utils.optimizer : param module.vision_proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T01:53:23 | INFO | utils.optimizer : param module.vision_proj.bias: wd: 0, lr: 1e-05
2024-05-28T01:53:23 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0 len(p)=49
2024-05-28T01:53:23 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0.02 len(p)=25
2024-05-28T01:53:23 | INFO | tasks.shared_utils : Auto resuming
2024-05-28T01:53:23 | INFO | tasks.shared_utils : Not found checkpoint in exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
2024-05-28T01:53:23 | INFO | tasks.shared_utils : _IncompatibleKeys(missing_keys=['vision_encoder.encoder.blocks.0.lora_r', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.1.lora_r', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.2.lora_r', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.3.lora_r', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.4.lora_r', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.5.lora_r', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.6.lora_r', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.7.lora_r', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.8.lora_r', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.9.lora_r', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.10.lora_r', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.11.lora_r', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.bias'], unexpected_keys=['clip_teacher.class_embedding', 'clip_teacher.positional_embedding', 'clip_teacher.proj', 'clip_teacher.conv1.weight', 'clip_teacher.ln_pre.weight', 'clip_teacher.ln_pre.bias', 'clip_teacher.transformer.resblocks.0.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.0.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.0.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.0.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.0.ln_1.weight', 'clip_teacher.transformer.resblocks.0.ln_1.bias', 'clip_teacher.transformer.resblocks.0.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.0.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.0.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.0.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.0.ln_2.weight', 'clip_teacher.transformer.resblocks.0.ln_2.bias', 'clip_teacher.transformer.resblocks.1.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.1.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.1.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.1.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.1.ln_1.weight', 'clip_teacher.transformer.resblocks.1.ln_1.bias', 'clip_teacher.transformer.resblocks.1.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.1.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.1.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.1.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.1.ln_2.weight', 'clip_teacher.transformer.resblocks.1.ln_2.bias', 'clip_teacher.transformer.resblocks.2.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.2.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.2.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.2.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.2.ln_1.weight', 'clip_teacher.transformer.resblocks.2.ln_1.bias', 'clip_teacher.transformer.resblocks.2.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.2.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.2.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.2.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.2.ln_2.weight', 'clip_teacher.transformer.resblocks.2.ln_2.bias', 'clip_teacher.transformer.resblocks.3.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.3.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.3.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.3.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.3.ln_1.weight', 'clip_teacher.transformer.resblocks.3.ln_1.bias', 'clip_teacher.transformer.resblocks.3.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.3.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.3.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.3.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.3.ln_2.weight', 'clip_teacher.transformer.resblocks.3.ln_2.bias', 'clip_teacher.transformer.resblocks.4.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.4.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.4.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.4.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.4.ln_1.weight', 'clip_teacher.transformer.resblocks.4.ln_1.bias', 'clip_teacher.transformer.resblocks.4.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.4.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.4.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.4.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.4.ln_2.weight', 'clip_teacher.transformer.resblocks.4.ln_2.bias', 'clip_teacher.transformer.resblocks.5.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.5.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.5.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.5.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.5.ln_1.weight', 'clip_teacher.transformer.resblocks.5.ln_1.bias', 'clip_teacher.transformer.resblocks.5.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.5.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.5.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.5.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.5.ln_2.weight', 'clip_teacher.transformer.resblocks.5.ln_2.bias', 'clip_teacher.transformer.resblocks.6.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.6.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.6.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.6.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.6.ln_1.weight', 'clip_teacher.transformer.resblocks.6.ln_1.bias', 'clip_teacher.transformer.resblocks.6.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.6.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.6.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.6.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.6.ln_2.weight', 'clip_teacher.transformer.resblocks.6.ln_2.bias', 'clip_teacher.transformer.resblocks.7.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.7.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.7.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.7.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.7.ln_1.weight', 'clip_teacher.transformer.resblocks.7.ln_1.bias', 'clip_teacher.transformer.resblocks.7.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.7.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.7.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.7.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.7.ln_2.weight', 'clip_teacher.transformer.resblocks.7.ln_2.bias', 'clip_teacher.transformer.resblocks.8.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.8.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.8.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.8.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.8.ln_1.weight', 'clip_teacher.transformer.resblocks.8.ln_1.bias', 'clip_teacher.transformer.resblocks.8.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.8.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.8.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.8.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.8.ln_2.weight', 'clip_teacher.transformer.resblocks.8.ln_2.bias', 'clip_teacher.transformer.resblocks.9.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.9.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.9.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.9.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.9.ln_1.weight', 'clip_teacher.transformer.resblocks.9.ln_1.bias', 'clip_teacher.transformer.resblocks.9.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.9.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.9.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.9.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.9.ln_2.weight', 'clip_teacher.transformer.resblocks.9.ln_2.bias', 'clip_teacher.transformer.resblocks.10.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.10.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.10.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.10.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.10.ln_1.weight', 'clip_teacher.transformer.resblocks.10.ln_1.bias', 'clip_teacher.transformer.resblocks.10.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.10.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.10.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.10.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.10.ln_2.weight', 'clip_teacher.transformer.resblocks.10.ln_2.bias', 'clip_teacher.transformer.resblocks.11.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.11.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.11.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.11.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.11.ln_1.weight', 'clip_teacher.transformer.resblocks.11.ln_1.bias', 'clip_teacher.transformer.resblocks.11.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.11.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.11.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.11.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.11.ln_2.weight', 'clip_teacher.transformer.resblocks.11.ln_2.bias', 'clip_teacher.ln_post.weight', 'clip_teacher.ln_post.bias', 'vision_encoder.clip_decoder.0.head.weight', 'vision_encoder.clip_decoder.0.head.bias', 'vision_encoder.clip_decoder.0.norm.weight', 'vision_encoder.clip_decoder.0.norm.bias', 'vision_encoder.clip_decoder.1.head.weight', 'vision_encoder.clip_decoder.1.head.bias', 'vision_encoder.clip_decoder.1.norm.weight', 'vision_encoder.clip_decoder.1.norm.bias', 'vision_encoder.clip_decoder.2.head.weight', 'vision_encoder.clip_decoder.2.head.bias', 'vision_encoder.clip_decoder.2.norm.weight', 'vision_encoder.clip_decoder.2.norm.bias', 'vision_encoder.clip_decoder.3.head.weight', 'vision_encoder.clip_decoder.3.head.bias', 'vision_encoder.clip_decoder.3.norm.weight', 'vision_encoder.clip_decoder.3.norm.bias', 'vision_encoder.clip_decoder.4.head.weight', 'vision_encoder.clip_decoder.4.head.bias', 'vision_encoder.clip_decoder.4.norm.weight', 'vision_encoder.clip_decoder.4.norm.bias', 'vision_encoder.clip_decoder.5.head.weight', 'vision_encoder.clip_decoder.5.head.bias', 'vision_encoder.clip_decoder.5.norm.weight', 'vision_encoder.clip_decoder.5.norm.bias', 'text_encoder.cls.predictions.bias', 'text_encoder.cls.predictions.transform.dense.weight', 'text_encoder.cls.predictions.transform.dense.bias', 'text_encoder.cls.predictions.transform.LayerNorm.weight', 'text_encoder.cls.predictions.transform.LayerNorm.bias', 'text_encoder.cls.predictions.decoder.weight', 'text_encoder.cls.predictions.decoder.bias'])
2024-05-28T01:53:23 | INFO | tasks.shared_utils : Loaded checkpoint from /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
2024-05-28T01:53:23 | INFO | __main__ : training
2024-05-28T01:53:23 | INFO | tasks.retrieval_utils : Start evaluation for media_type=video
2024-05-28T01:53:23 | INFO | tasks.retrieval_utils : Computing dual encoder features...
2024-05-28T01:53:24 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T01:53:24 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T01:53:25 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T01:53:25 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T01:53:25 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T01:53:25 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T01:53:25 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T01:53:25 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T01:53:25 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T01:53:25 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T01:53:25 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T01:53:25 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T01:55:19 | INFO | umt : Logging to: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2/train.log
2024-05-28T01:55:19 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
  test_file: {
      test: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test1k.json', '/data2/dy/temporal_video/dataset', 'video'] }
  test_types: ['test']
  num_workers: 6
  rtime: False
  pos_num: 1
  neg_num: 10
  stop_key: test/
  is_paragraph_retrieval: False
  is_pretrain: False
  num_frames: 12
  num_frames_test: 12
  batch_size: 32
  max_txt_l: 50
  evaluate: False
  train_shuffle: False
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 12
          sample_type: rand
          num_frames_test: 12
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 50
          video: 50 }
      batch_size: {
          image: 32
          video: 32 }
      batch_size_test: {
          image: 32
          video: 32 } }
  text_enc: bert
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_b16
          img_size: 224
          patch_size: 16
          d_model: 768
          encoder_embed_dim: 768
          encoder_depth: 12
          encoder_num_heads: 12
          drop_path_rate: 0.2
          num_frames: 12
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 12
          clip_decoder_embed_dim: 768
          clip_output_dim: 512
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 224
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      multimodal: {
          enable: True }
      embed_dim: 512
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 1e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 5
      min_lr_multi: 0.01
      warmup_epochs: 1 }
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: user
      project: umt_ret }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
  resume: False
  debug: False
  log_freq: 100
  seed: 3407
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
  rank: 0
  world_size: 1
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-05-28T01:55:19 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video'], 'test_file': {'test': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test1k.json', '/data2/dy/temporal_video/dataset', 'video']}, 'test_types': ['test'], 'num_workers': 6, 'rtime': False, 'pos_num': 1, 'neg_num': 10, 'stop_key': 'test/', 'is_paragraph_retrieval': False, 'is_pretrain': False, 'num_frames': 12, 'num_frames_test': 12, 'batch_size': 32, 'max_txt_l': 50, 'evaluate': False, 'train_shuffle': False, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 12, 'sample_type': 'rand', 'num_frames_test': 12, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 50, 'video': 50}, 'batch_size': {'image': 32, 'video': 32}, 'batch_size_test': {'image': 32, 'video': 32}}, 'text_enc': 'bert', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_b16', 'img_size': 224, 'patch_size': 16, 'd_model': 768, 'encoder_embed_dim': 768, 'encoder_depth': 12, 'encoder_num_heads': 12, 'drop_path_rate': 0.2, 'num_frames': 12, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 12, 'clip_decoder_embed_dim': 768, 'clip_output_dim': 512, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 224, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'multimodal': {'enable': True}, 'embed_dim': 512, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 1e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 5, 'min_lr_multi': 0.01, 'warmup_epochs': 1}, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': False, 'entity': 'user', 'project': 'umt_ret'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': 'exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 3407, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth', 'rank': 0, 'world_size': 1, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2024-05-28T01:55:19 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
2024-05-28T01:55:19 | INFO | tasks.pretrain : Creating dataset for ret
2024-05-28T01:55:20 | INFO | tasks.shared_utils : Creating model
2024-05-28T01:55:30 | INFO | models.umt : Build vision_encoder: vit_b16
2024-05-28T01:55:30 | INFO | models.backbones.vit.vit : Num of patches: 2352
2024-05-28T01:55:30 | INFO | models.backbones.vit.vit : Use checkpoint: True
2024-05-28T01:55:30 | INFO | models.backbones.vit.vit : Checkpoint number: 12
2024-05-28T01:55:30 | INFO | models.backbones.vit.vit : Student return index: []
2024-05-28T01:55:37 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
2024-05-28T01:55:37 | INFO | models.umt : Build text_encoder bert_base
2024-05-28T01:55:38 | INFO | models.backbones.bert.xbert : build bert with cross_module: ca
2024-05-28T01:55:39 | INFO | models.criterions : Norm type: l2
2024-05-28T01:55:39 | INFO | models.criterions : Loss type: l2
2024-05-28T01:55:39 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-05-28T01:55:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.lora_r: wd: 0, lr: 1e-05
2024-05-28T01:55:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T01:55:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T01:55:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T01:55:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T01:55:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T01:55:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.lora_r: wd: 0, lr: 1e-05
2024-05-28T01:55:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T01:55:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T01:55:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T01:55:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T01:55:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T01:55:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.lora_r: wd: 0, lr: 1e-05
2024-05-28T01:55:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T01:55:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T01:55:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T01:55:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T01:55:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T01:55:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.lora_r: wd: 0, lr: 1e-05
2024-05-28T01:55:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T01:55:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T01:55:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T01:55:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T01:55:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T01:55:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.lora_r: wd: 0, lr: 1e-05
2024-05-28T01:55:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T01:55:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T01:55:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T01:55:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T01:55:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T01:55:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.lora_r: wd: 0, lr: 1e-05
2024-05-28T01:55:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T01:55:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T01:55:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T01:55:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T01:55:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T01:55:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.lora_r: wd: 0, lr: 1e-05
2024-05-28T01:55:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T01:55:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T01:55:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T01:55:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T01:55:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T01:55:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.lora_r: wd: 0, lr: 1e-05
2024-05-28T01:55:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T01:55:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T01:55:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T01:55:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T01:55:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T01:55:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.lora_r: wd: 0, lr: 1e-05
2024-05-28T01:55:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T01:55:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T01:55:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T01:55:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T01:55:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T01:55:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.lora_r: wd: 0, lr: 1e-05
2024-05-28T01:55:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T01:55:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T01:55:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T01:55:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T01:55:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T01:55:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.lora_r: wd: 0, lr: 1e-05
2024-05-28T01:55:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T01:55:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T01:55:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T01:55:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T01:55:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T01:55:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.lora_r: wd: 0, lr: 1e-05
2024-05-28T01:55:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T01:55:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T01:55:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T01:55:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T01:55:39 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T01:55:39 | INFO | utils.optimizer : param module.vision_proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T01:55:39 | INFO | utils.optimizer : param module.vision_proj.bias: wd: 0, lr: 1e-05
2024-05-28T01:55:39 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0 len(p)=49
2024-05-28T01:55:39 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0.02 len(p)=25
2024-05-28T01:55:39 | INFO | tasks.shared_utils : Auto resuming
2024-05-28T01:55:39 | INFO | tasks.shared_utils : Not found checkpoint in exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
2024-05-28T01:55:40 | INFO | tasks.shared_utils : _IncompatibleKeys(missing_keys=['vision_encoder.encoder.blocks.0.lora_r', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.1.lora_r', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.2.lora_r', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.3.lora_r', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.4.lora_r', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.5.lora_r', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.6.lora_r', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.7.lora_r', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.8.lora_r', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.9.lora_r', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.10.lora_r', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.11.lora_r', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.bias'], unexpected_keys=['clip_teacher.class_embedding', 'clip_teacher.positional_embedding', 'clip_teacher.proj', 'clip_teacher.conv1.weight', 'clip_teacher.ln_pre.weight', 'clip_teacher.ln_pre.bias', 'clip_teacher.transformer.resblocks.0.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.0.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.0.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.0.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.0.ln_1.weight', 'clip_teacher.transformer.resblocks.0.ln_1.bias', 'clip_teacher.transformer.resblocks.0.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.0.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.0.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.0.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.0.ln_2.weight', 'clip_teacher.transformer.resblocks.0.ln_2.bias', 'clip_teacher.transformer.resblocks.1.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.1.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.1.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.1.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.1.ln_1.weight', 'clip_teacher.transformer.resblocks.1.ln_1.bias', 'clip_teacher.transformer.resblocks.1.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.1.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.1.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.1.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.1.ln_2.weight', 'clip_teacher.transformer.resblocks.1.ln_2.bias', 'clip_teacher.transformer.resblocks.2.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.2.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.2.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.2.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.2.ln_1.weight', 'clip_teacher.transformer.resblocks.2.ln_1.bias', 'clip_teacher.transformer.resblocks.2.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.2.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.2.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.2.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.2.ln_2.weight', 'clip_teacher.transformer.resblocks.2.ln_2.bias', 'clip_teacher.transformer.resblocks.3.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.3.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.3.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.3.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.3.ln_1.weight', 'clip_teacher.transformer.resblocks.3.ln_1.bias', 'clip_teacher.transformer.resblocks.3.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.3.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.3.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.3.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.3.ln_2.weight', 'clip_teacher.transformer.resblocks.3.ln_2.bias', 'clip_teacher.transformer.resblocks.4.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.4.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.4.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.4.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.4.ln_1.weight', 'clip_teacher.transformer.resblocks.4.ln_1.bias', 'clip_teacher.transformer.resblocks.4.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.4.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.4.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.4.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.4.ln_2.weight', 'clip_teacher.transformer.resblocks.4.ln_2.bias', 'clip_teacher.transformer.resblocks.5.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.5.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.5.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.5.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.5.ln_1.weight', 'clip_teacher.transformer.resblocks.5.ln_1.bias', 'clip_teacher.transformer.resblocks.5.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.5.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.5.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.5.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.5.ln_2.weight', 'clip_teacher.transformer.resblocks.5.ln_2.bias', 'clip_teacher.transformer.resblocks.6.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.6.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.6.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.6.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.6.ln_1.weight', 'clip_teacher.transformer.resblocks.6.ln_1.bias', 'clip_teacher.transformer.resblocks.6.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.6.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.6.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.6.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.6.ln_2.weight', 'clip_teacher.transformer.resblocks.6.ln_2.bias', 'clip_teacher.transformer.resblocks.7.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.7.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.7.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.7.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.7.ln_1.weight', 'clip_teacher.transformer.resblocks.7.ln_1.bias', 'clip_teacher.transformer.resblocks.7.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.7.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.7.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.7.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.7.ln_2.weight', 'clip_teacher.transformer.resblocks.7.ln_2.bias', 'clip_teacher.transformer.resblocks.8.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.8.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.8.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.8.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.8.ln_1.weight', 'clip_teacher.transformer.resblocks.8.ln_1.bias', 'clip_teacher.transformer.resblocks.8.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.8.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.8.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.8.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.8.ln_2.weight', 'clip_teacher.transformer.resblocks.8.ln_2.bias', 'clip_teacher.transformer.resblocks.9.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.9.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.9.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.9.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.9.ln_1.weight', 'clip_teacher.transformer.resblocks.9.ln_1.bias', 'clip_teacher.transformer.resblocks.9.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.9.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.9.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.9.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.9.ln_2.weight', 'clip_teacher.transformer.resblocks.9.ln_2.bias', 'clip_teacher.transformer.resblocks.10.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.10.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.10.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.10.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.10.ln_1.weight', 'clip_teacher.transformer.resblocks.10.ln_1.bias', 'clip_teacher.transformer.resblocks.10.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.10.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.10.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.10.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.10.ln_2.weight', 'clip_teacher.transformer.resblocks.10.ln_2.bias', 'clip_teacher.transformer.resblocks.11.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.11.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.11.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.11.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.11.ln_1.weight', 'clip_teacher.transformer.resblocks.11.ln_1.bias', 'clip_teacher.transformer.resblocks.11.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.11.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.11.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.11.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.11.ln_2.weight', 'clip_teacher.transformer.resblocks.11.ln_2.bias', 'clip_teacher.ln_post.weight', 'clip_teacher.ln_post.bias', 'vision_encoder.clip_decoder.0.head.weight', 'vision_encoder.clip_decoder.0.head.bias', 'vision_encoder.clip_decoder.0.norm.weight', 'vision_encoder.clip_decoder.0.norm.bias', 'vision_encoder.clip_decoder.1.head.weight', 'vision_encoder.clip_decoder.1.head.bias', 'vision_encoder.clip_decoder.1.norm.weight', 'vision_encoder.clip_decoder.1.norm.bias', 'vision_encoder.clip_decoder.2.head.weight', 'vision_encoder.clip_decoder.2.head.bias', 'vision_encoder.clip_decoder.2.norm.weight', 'vision_encoder.clip_decoder.2.norm.bias', 'vision_encoder.clip_decoder.3.head.weight', 'vision_encoder.clip_decoder.3.head.bias', 'vision_encoder.clip_decoder.3.norm.weight', 'vision_encoder.clip_decoder.3.norm.bias', 'vision_encoder.clip_decoder.4.head.weight', 'vision_encoder.clip_decoder.4.head.bias', 'vision_encoder.clip_decoder.4.norm.weight', 'vision_encoder.clip_decoder.4.norm.bias', 'vision_encoder.clip_decoder.5.head.weight', 'vision_encoder.clip_decoder.5.head.bias', 'vision_encoder.clip_decoder.5.norm.weight', 'vision_encoder.clip_decoder.5.norm.bias', 'text_encoder.cls.predictions.bias', 'text_encoder.cls.predictions.transform.dense.weight', 'text_encoder.cls.predictions.transform.dense.bias', 'text_encoder.cls.predictions.transform.LayerNorm.weight', 'text_encoder.cls.predictions.transform.LayerNorm.bias', 'text_encoder.cls.predictions.decoder.weight', 'text_encoder.cls.predictions.decoder.bias'])
2024-05-28T01:55:40 | INFO | tasks.shared_utils : Loaded checkpoint from /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
2024-05-28T01:55:40 | INFO | __main__ : training
2024-05-28T01:55:40 | INFO | tasks.retrieval_utils : Start evaluation for media_type=video
2024-05-28T01:55:40 | INFO | tasks.retrieval_utils : Computing dual encoder features...
2024-05-28T01:55:41 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T01:55:41 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T01:55:41 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T01:55:41 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T01:55:41 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T01:55:41 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T01:55:41 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T01:55:41 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T01:55:41 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T01:55:41 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T01:55:41 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T01:55:41 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T01:59:01 | INFO | umt : Logging to: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2/train.log
2024-05-28T01:59:01 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
  test_file: {
      test: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test1k.json', '/data2/dy/temporal_video/dataset', 'video'] }
  test_types: ['test']
  num_workers: 6
  rtime: False
  pos_num: 1
  neg_num: 10
  stop_key: test/
  is_paragraph_retrieval: False
  is_pretrain: False
  num_frames: 12
  num_frames_test: 12
  batch_size: 32
  max_txt_l: 50
  evaluate: False
  train_shuffle: False
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 12
          sample_type: rand
          num_frames_test: 12
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 50
          video: 50 }
      batch_size: {
          image: 32
          video: 32 }
      batch_size_test: {
          image: 32
          video: 32 } }
  text_enc: bert
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_b16
          img_size: 224
          patch_size: 16
          d_model: 768
          encoder_embed_dim: 768
          encoder_depth: 12
          encoder_num_heads: 12
          drop_path_rate: 0.2
          num_frames: 12
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 12
          clip_decoder_embed_dim: 768
          clip_output_dim: 512
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 224
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      multimodal: {
          enable: True }
      embed_dim: 512
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 1e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 5
      min_lr_multi: 0.01
      warmup_epochs: 1 }
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: user
      project: umt_ret }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
  resume: False
  debug: False
  log_freq: 100
  seed: 3407
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
  rank: 0
  world_size: 1
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-05-28T01:59:01 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video'], 'test_file': {'test': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test1k.json', '/data2/dy/temporal_video/dataset', 'video']}, 'test_types': ['test'], 'num_workers': 6, 'rtime': False, 'pos_num': 1, 'neg_num': 10, 'stop_key': 'test/', 'is_paragraph_retrieval': False, 'is_pretrain': False, 'num_frames': 12, 'num_frames_test': 12, 'batch_size': 32, 'max_txt_l': 50, 'evaluate': False, 'train_shuffle': False, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 12, 'sample_type': 'rand', 'num_frames_test': 12, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 50, 'video': 50}, 'batch_size': {'image': 32, 'video': 32}, 'batch_size_test': {'image': 32, 'video': 32}}, 'text_enc': 'bert', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_b16', 'img_size': 224, 'patch_size': 16, 'd_model': 768, 'encoder_embed_dim': 768, 'encoder_depth': 12, 'encoder_num_heads': 12, 'drop_path_rate': 0.2, 'num_frames': 12, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 12, 'clip_decoder_embed_dim': 768, 'clip_output_dim': 512, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 224, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'multimodal': {'enable': True}, 'embed_dim': 512, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 1e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 5, 'min_lr_multi': 0.01, 'warmup_epochs': 1}, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': False, 'entity': 'user', 'project': 'umt_ret'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': 'exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 3407, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth', 'rank': 0, 'world_size': 1, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2024-05-28T01:59:01 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
2024-05-28T01:59:01 | INFO | tasks.pretrain : Creating dataset for ret
2024-05-28T01:59:01 | INFO | tasks.shared_utils : Creating model
2024-05-28T01:59:11 | INFO | models.umt : Build vision_encoder: vit_b16
2024-05-28T01:59:11 | INFO | models.backbones.vit.vit : Num of patches: 2352
2024-05-28T01:59:11 | INFO | models.backbones.vit.vit : Use checkpoint: True
2024-05-28T01:59:11 | INFO | models.backbones.vit.vit : Checkpoint number: 12
2024-05-28T01:59:11 | INFO | models.backbones.vit.vit : Student return index: []
2024-05-28T01:59:19 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
2024-05-28T01:59:19 | INFO | models.umt : Build text_encoder bert_base
2024-05-28T01:59:20 | INFO | models.backbones.bert.xbert : build bert with cross_module: ca
2024-05-28T01:59:21 | INFO | models.criterions : Norm type: l2
2024-05-28T01:59:21 | INFO | models.criterions : Loss type: l2
2024-05-28T01:59:21 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-05-28T01:59:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.lora_r: wd: 0, lr: 1e-05
2024-05-28T01:59:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T01:59:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T01:59:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T01:59:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T01:59:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T01:59:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.lora_r: wd: 0, lr: 1e-05
2024-05-28T01:59:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T01:59:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T01:59:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T01:59:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T01:59:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T01:59:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.lora_r: wd: 0, lr: 1e-05
2024-05-28T01:59:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T01:59:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T01:59:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T01:59:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T01:59:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T01:59:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.lora_r: wd: 0, lr: 1e-05
2024-05-28T01:59:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T01:59:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T01:59:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T01:59:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T01:59:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T01:59:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.lora_r: wd: 0, lr: 1e-05
2024-05-28T01:59:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T01:59:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T01:59:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T01:59:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T01:59:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T01:59:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.lora_r: wd: 0, lr: 1e-05
2024-05-28T01:59:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T01:59:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T01:59:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T01:59:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T01:59:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T01:59:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.lora_r: wd: 0, lr: 1e-05
2024-05-28T01:59:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T01:59:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T01:59:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T01:59:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T01:59:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T01:59:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.lora_r: wd: 0, lr: 1e-05
2024-05-28T01:59:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T01:59:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T01:59:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T01:59:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T01:59:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T01:59:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.lora_r: wd: 0, lr: 1e-05
2024-05-28T01:59:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T01:59:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T01:59:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T01:59:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T01:59:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T01:59:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.lora_r: wd: 0, lr: 1e-05
2024-05-28T01:59:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T01:59:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T01:59:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T01:59:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T01:59:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T01:59:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.lora_r: wd: 0, lr: 1e-05
2024-05-28T01:59:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T01:59:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T01:59:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T01:59:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T01:59:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T01:59:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.lora_r: wd: 0, lr: 1e-05
2024-05-28T01:59:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T01:59:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T01:59:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T01:59:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T01:59:21 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T01:59:21 | INFO | utils.optimizer : param module.vision_proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T01:59:21 | INFO | utils.optimizer : param module.vision_proj.bias: wd: 0, lr: 1e-05
2024-05-28T01:59:21 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0 len(p)=49
2024-05-28T01:59:21 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0.02 len(p)=25
2024-05-28T01:59:21 | INFO | tasks.shared_utils : Auto resuming
2024-05-28T01:59:21 | INFO | tasks.shared_utils : Not found checkpoint in exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
2024-05-28T01:59:21 | INFO | tasks.shared_utils : _IncompatibleKeys(missing_keys=['vision_encoder.encoder.blocks.0.lora_r', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.1.lora_r', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.2.lora_r', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.3.lora_r', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.4.lora_r', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.5.lora_r', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.6.lora_r', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.7.lora_r', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.8.lora_r', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.9.lora_r', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.10.lora_r', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.11.lora_r', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.bias'], unexpected_keys=['clip_teacher.class_embedding', 'clip_teacher.positional_embedding', 'clip_teacher.proj', 'clip_teacher.conv1.weight', 'clip_teacher.ln_pre.weight', 'clip_teacher.ln_pre.bias', 'clip_teacher.transformer.resblocks.0.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.0.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.0.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.0.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.0.ln_1.weight', 'clip_teacher.transformer.resblocks.0.ln_1.bias', 'clip_teacher.transformer.resblocks.0.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.0.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.0.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.0.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.0.ln_2.weight', 'clip_teacher.transformer.resblocks.0.ln_2.bias', 'clip_teacher.transformer.resblocks.1.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.1.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.1.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.1.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.1.ln_1.weight', 'clip_teacher.transformer.resblocks.1.ln_1.bias', 'clip_teacher.transformer.resblocks.1.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.1.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.1.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.1.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.1.ln_2.weight', 'clip_teacher.transformer.resblocks.1.ln_2.bias', 'clip_teacher.transformer.resblocks.2.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.2.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.2.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.2.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.2.ln_1.weight', 'clip_teacher.transformer.resblocks.2.ln_1.bias', 'clip_teacher.transformer.resblocks.2.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.2.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.2.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.2.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.2.ln_2.weight', 'clip_teacher.transformer.resblocks.2.ln_2.bias', 'clip_teacher.transformer.resblocks.3.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.3.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.3.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.3.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.3.ln_1.weight', 'clip_teacher.transformer.resblocks.3.ln_1.bias', 'clip_teacher.transformer.resblocks.3.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.3.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.3.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.3.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.3.ln_2.weight', 'clip_teacher.transformer.resblocks.3.ln_2.bias', 'clip_teacher.transformer.resblocks.4.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.4.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.4.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.4.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.4.ln_1.weight', 'clip_teacher.transformer.resblocks.4.ln_1.bias', 'clip_teacher.transformer.resblocks.4.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.4.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.4.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.4.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.4.ln_2.weight', 'clip_teacher.transformer.resblocks.4.ln_2.bias', 'clip_teacher.transformer.resblocks.5.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.5.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.5.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.5.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.5.ln_1.weight', 'clip_teacher.transformer.resblocks.5.ln_1.bias', 'clip_teacher.transformer.resblocks.5.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.5.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.5.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.5.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.5.ln_2.weight', 'clip_teacher.transformer.resblocks.5.ln_2.bias', 'clip_teacher.transformer.resblocks.6.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.6.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.6.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.6.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.6.ln_1.weight', 'clip_teacher.transformer.resblocks.6.ln_1.bias', 'clip_teacher.transformer.resblocks.6.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.6.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.6.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.6.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.6.ln_2.weight', 'clip_teacher.transformer.resblocks.6.ln_2.bias', 'clip_teacher.transformer.resblocks.7.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.7.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.7.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.7.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.7.ln_1.weight', 'clip_teacher.transformer.resblocks.7.ln_1.bias', 'clip_teacher.transformer.resblocks.7.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.7.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.7.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.7.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.7.ln_2.weight', 'clip_teacher.transformer.resblocks.7.ln_2.bias', 'clip_teacher.transformer.resblocks.8.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.8.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.8.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.8.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.8.ln_1.weight', 'clip_teacher.transformer.resblocks.8.ln_1.bias', 'clip_teacher.transformer.resblocks.8.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.8.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.8.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.8.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.8.ln_2.weight', 'clip_teacher.transformer.resblocks.8.ln_2.bias', 'clip_teacher.transformer.resblocks.9.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.9.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.9.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.9.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.9.ln_1.weight', 'clip_teacher.transformer.resblocks.9.ln_1.bias', 'clip_teacher.transformer.resblocks.9.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.9.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.9.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.9.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.9.ln_2.weight', 'clip_teacher.transformer.resblocks.9.ln_2.bias', 'clip_teacher.transformer.resblocks.10.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.10.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.10.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.10.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.10.ln_1.weight', 'clip_teacher.transformer.resblocks.10.ln_1.bias', 'clip_teacher.transformer.resblocks.10.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.10.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.10.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.10.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.10.ln_2.weight', 'clip_teacher.transformer.resblocks.10.ln_2.bias', 'clip_teacher.transformer.resblocks.11.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.11.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.11.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.11.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.11.ln_1.weight', 'clip_teacher.transformer.resblocks.11.ln_1.bias', 'clip_teacher.transformer.resblocks.11.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.11.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.11.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.11.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.11.ln_2.weight', 'clip_teacher.transformer.resblocks.11.ln_2.bias', 'clip_teacher.ln_post.weight', 'clip_teacher.ln_post.bias', 'vision_encoder.clip_decoder.0.head.weight', 'vision_encoder.clip_decoder.0.head.bias', 'vision_encoder.clip_decoder.0.norm.weight', 'vision_encoder.clip_decoder.0.norm.bias', 'vision_encoder.clip_decoder.1.head.weight', 'vision_encoder.clip_decoder.1.head.bias', 'vision_encoder.clip_decoder.1.norm.weight', 'vision_encoder.clip_decoder.1.norm.bias', 'vision_encoder.clip_decoder.2.head.weight', 'vision_encoder.clip_decoder.2.head.bias', 'vision_encoder.clip_decoder.2.norm.weight', 'vision_encoder.clip_decoder.2.norm.bias', 'vision_encoder.clip_decoder.3.head.weight', 'vision_encoder.clip_decoder.3.head.bias', 'vision_encoder.clip_decoder.3.norm.weight', 'vision_encoder.clip_decoder.3.norm.bias', 'vision_encoder.clip_decoder.4.head.weight', 'vision_encoder.clip_decoder.4.head.bias', 'vision_encoder.clip_decoder.4.norm.weight', 'vision_encoder.clip_decoder.4.norm.bias', 'vision_encoder.clip_decoder.5.head.weight', 'vision_encoder.clip_decoder.5.head.bias', 'vision_encoder.clip_decoder.5.norm.weight', 'vision_encoder.clip_decoder.5.norm.bias', 'text_encoder.cls.predictions.bias', 'text_encoder.cls.predictions.transform.dense.weight', 'text_encoder.cls.predictions.transform.dense.bias', 'text_encoder.cls.predictions.transform.LayerNorm.weight', 'text_encoder.cls.predictions.transform.LayerNorm.bias', 'text_encoder.cls.predictions.decoder.weight', 'text_encoder.cls.predictions.decoder.bias'])
2024-05-28T01:59:21 | INFO | tasks.shared_utils : Loaded checkpoint from /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
2024-05-28T01:59:21 | INFO | __main__ : training
2024-05-28T01:59:21 | INFO | tasks.retrieval_utils : Start evaluation for media_type=video
2024-05-28T01:59:21 | INFO | tasks.retrieval_utils : Computing dual encoder features...
2024-05-28T01:59:23 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T01:59:23 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T01:59:23 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T01:59:23 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T01:59:23 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T01:59:23 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T01:59:23 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T01:59:23 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T01:59:23 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T01:59:23 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T01:59:23 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T01:59:23 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T02:00:46 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  builtin_warn(*args, **kwargs)

2024-05-28T02:00:46 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  builtin_warn(*args, **kwargs)

2024-05-28T02:00:46 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-05-28T02:00:46 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-05-28T02:00:47 | INFO | utils.basic_utils : extracting image feats  [ 0/32]  eta: 0:45:26    time: 85.2028  data: 15.5638  max mem: 14917 res mem: 23234
2024-05-28T02:01:27 | INFO | umt : Logging to: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2/train.log
2024-05-28T02:01:27 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
  test_file: {
      test: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test1k.json', '/data2/dy/temporal_video/dataset', 'video'] }
  test_types: ['test']
  num_workers: 6
  rtime: False
  pos_num: 1
  neg_num: 10
  stop_key: test/
  is_paragraph_retrieval: False
  is_pretrain: False
  num_frames: 12
  num_frames_test: 12
  batch_size: 32
  max_txt_l: 50
  evaluate: False
  train_shuffle: False
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 12
          sample_type: rand
          num_frames_test: 12
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 50
          video: 50 }
      batch_size: {
          image: 32
          video: 32 }
      batch_size_test: {
          image: 32
          video: 32 } }
  text_enc: bert
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_b16
          img_size: 224
          patch_size: 16
          d_model: 768
          encoder_embed_dim: 768
          encoder_depth: 12
          encoder_num_heads: 12
          drop_path_rate: 0.2
          num_frames: 12
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 12
          clip_decoder_embed_dim: 768
          clip_output_dim: 512
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 224
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      multimodal: {
          enable: True }
      embed_dim: 512
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 1e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 5
      min_lr_multi: 0.01
      warmup_epochs: 1 }
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: user
      project: umt_ret }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
  resume: False
  debug: False
  log_freq: 100
  seed: 3407
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
  rank: 0
  world_size: 1
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-05-28T02:01:27 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video'], 'test_file': {'test': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test1k.json', '/data2/dy/temporal_video/dataset', 'video']}, 'test_types': ['test'], 'num_workers': 6, 'rtime': False, 'pos_num': 1, 'neg_num': 10, 'stop_key': 'test/', 'is_paragraph_retrieval': False, 'is_pretrain': False, 'num_frames': 12, 'num_frames_test': 12, 'batch_size': 32, 'max_txt_l': 50, 'evaluate': False, 'train_shuffle': False, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 12, 'sample_type': 'rand', 'num_frames_test': 12, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 50, 'video': 50}, 'batch_size': {'image': 32, 'video': 32}, 'batch_size_test': {'image': 32, 'video': 32}}, 'text_enc': 'bert', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_b16', 'img_size': 224, 'patch_size': 16, 'd_model': 768, 'encoder_embed_dim': 768, 'encoder_depth': 12, 'encoder_num_heads': 12, 'drop_path_rate': 0.2, 'num_frames': 12, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 12, 'clip_decoder_embed_dim': 768, 'clip_output_dim': 512, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 224, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'multimodal': {'enable': True}, 'embed_dim': 512, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 1e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 5, 'min_lr_multi': 0.01, 'warmup_epochs': 1}, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': False, 'entity': 'user', 'project': 'umt_ret'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': 'exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 3407, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth', 'rank': 0, 'world_size': 1, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2024-05-28T02:01:27 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
2024-05-28T02:01:27 | INFO | tasks.pretrain : Creating dataset for ret
2024-05-28T02:01:28 | INFO | tasks.shared_utils : Creating model
2024-05-28T02:01:38 | INFO | models.umt : Build vision_encoder: vit_b16
2024-05-28T02:01:38 | INFO | models.backbones.vit.vit : Num of patches: 2352
2024-05-28T02:01:38 | INFO | models.backbones.vit.vit : Use checkpoint: True
2024-05-28T02:01:38 | INFO | models.backbones.vit.vit : Checkpoint number: 12
2024-05-28T02:01:38 | INFO | models.backbones.vit.vit : Student return index: []
2024-05-28T02:01:46 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
2024-05-28T02:01:46 | INFO | models.umt : Build text_encoder bert_base
2024-05-28T02:01:47 | INFO | models.backbones.bert.xbert : build bert with cross_module: ca
2024-05-28T02:01:47 | INFO | models.criterions : Norm type: l2
2024-05-28T02:01:47 | INFO | models.criterions : Loss type: l2
2024-05-28T02:01:47 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-05-28T02:01:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.lora_r: wd: 0, lr: 1e-05
2024-05-28T02:01:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T02:01:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T02:01:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T02:01:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T02:01:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T02:01:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.lora_r: wd: 0, lr: 1e-05
2024-05-28T02:01:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T02:01:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T02:01:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T02:01:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T02:01:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T02:01:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.lora_r: wd: 0, lr: 1e-05
2024-05-28T02:01:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T02:01:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T02:01:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T02:01:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T02:01:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T02:01:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.lora_r: wd: 0, lr: 1e-05
2024-05-28T02:01:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T02:01:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T02:01:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T02:01:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T02:01:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T02:01:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.lora_r: wd: 0, lr: 1e-05
2024-05-28T02:01:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T02:01:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T02:01:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T02:01:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T02:01:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T02:01:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.lora_r: wd: 0, lr: 1e-05
2024-05-28T02:01:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T02:01:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T02:01:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T02:01:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T02:01:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T02:01:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.lora_r: wd: 0, lr: 1e-05
2024-05-28T02:01:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T02:01:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T02:01:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T02:01:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T02:01:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T02:01:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.lora_r: wd: 0, lr: 1e-05
2024-05-28T02:01:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T02:01:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T02:01:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T02:01:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T02:01:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T02:01:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.lora_r: wd: 0, lr: 1e-05
2024-05-28T02:01:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T02:01:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T02:01:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T02:01:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T02:01:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T02:01:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.lora_r: wd: 0, lr: 1e-05
2024-05-28T02:01:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T02:01:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T02:01:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T02:01:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T02:01:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T02:01:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.lora_r: wd: 0, lr: 1e-05
2024-05-28T02:01:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T02:01:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T02:01:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T02:01:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T02:01:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T02:01:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.lora_r: wd: 0, lr: 1e-05
2024-05-28T02:01:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T02:01:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T02:01:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T02:01:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T02:01:47 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T02:01:47 | INFO | utils.optimizer : param module.vision_proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T02:01:47 | INFO | utils.optimizer : param module.vision_proj.bias: wd: 0, lr: 1e-05
2024-05-28T02:01:47 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0 len(p)=49
2024-05-28T02:01:47 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0.02 len(p)=25
2024-05-28T02:01:47 | INFO | tasks.shared_utils : Auto resuming
2024-05-28T02:01:47 | INFO | tasks.shared_utils : Not found checkpoint in exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
2024-05-28T02:01:48 | INFO | tasks.shared_utils : _IncompatibleKeys(missing_keys=['vision_encoder.encoder.blocks.0.lora_r', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.1.lora_r', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.2.lora_r', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.3.lora_r', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.4.lora_r', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.5.lora_r', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.6.lora_r', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.7.lora_r', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.8.lora_r', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.9.lora_r', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.10.lora_r', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.11.lora_r', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.bias'], unexpected_keys=['clip_teacher.class_embedding', 'clip_teacher.positional_embedding', 'clip_teacher.proj', 'clip_teacher.conv1.weight', 'clip_teacher.ln_pre.weight', 'clip_teacher.ln_pre.bias', 'clip_teacher.transformer.resblocks.0.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.0.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.0.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.0.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.0.ln_1.weight', 'clip_teacher.transformer.resblocks.0.ln_1.bias', 'clip_teacher.transformer.resblocks.0.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.0.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.0.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.0.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.0.ln_2.weight', 'clip_teacher.transformer.resblocks.0.ln_2.bias', 'clip_teacher.transformer.resblocks.1.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.1.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.1.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.1.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.1.ln_1.weight', 'clip_teacher.transformer.resblocks.1.ln_1.bias', 'clip_teacher.transformer.resblocks.1.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.1.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.1.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.1.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.1.ln_2.weight', 'clip_teacher.transformer.resblocks.1.ln_2.bias', 'clip_teacher.transformer.resblocks.2.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.2.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.2.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.2.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.2.ln_1.weight', 'clip_teacher.transformer.resblocks.2.ln_1.bias', 'clip_teacher.transformer.resblocks.2.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.2.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.2.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.2.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.2.ln_2.weight', 'clip_teacher.transformer.resblocks.2.ln_2.bias', 'clip_teacher.transformer.resblocks.3.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.3.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.3.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.3.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.3.ln_1.weight', 'clip_teacher.transformer.resblocks.3.ln_1.bias', 'clip_teacher.transformer.resblocks.3.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.3.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.3.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.3.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.3.ln_2.weight', 'clip_teacher.transformer.resblocks.3.ln_2.bias', 'clip_teacher.transformer.resblocks.4.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.4.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.4.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.4.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.4.ln_1.weight', 'clip_teacher.transformer.resblocks.4.ln_1.bias', 'clip_teacher.transformer.resblocks.4.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.4.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.4.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.4.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.4.ln_2.weight', 'clip_teacher.transformer.resblocks.4.ln_2.bias', 'clip_teacher.transformer.resblocks.5.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.5.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.5.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.5.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.5.ln_1.weight', 'clip_teacher.transformer.resblocks.5.ln_1.bias', 'clip_teacher.transformer.resblocks.5.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.5.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.5.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.5.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.5.ln_2.weight', 'clip_teacher.transformer.resblocks.5.ln_2.bias', 'clip_teacher.transformer.resblocks.6.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.6.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.6.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.6.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.6.ln_1.weight', 'clip_teacher.transformer.resblocks.6.ln_1.bias', 'clip_teacher.transformer.resblocks.6.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.6.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.6.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.6.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.6.ln_2.weight', 'clip_teacher.transformer.resblocks.6.ln_2.bias', 'clip_teacher.transformer.resblocks.7.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.7.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.7.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.7.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.7.ln_1.weight', 'clip_teacher.transformer.resblocks.7.ln_1.bias', 'clip_teacher.transformer.resblocks.7.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.7.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.7.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.7.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.7.ln_2.weight', 'clip_teacher.transformer.resblocks.7.ln_2.bias', 'clip_teacher.transformer.resblocks.8.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.8.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.8.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.8.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.8.ln_1.weight', 'clip_teacher.transformer.resblocks.8.ln_1.bias', 'clip_teacher.transformer.resblocks.8.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.8.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.8.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.8.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.8.ln_2.weight', 'clip_teacher.transformer.resblocks.8.ln_2.bias', 'clip_teacher.transformer.resblocks.9.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.9.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.9.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.9.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.9.ln_1.weight', 'clip_teacher.transformer.resblocks.9.ln_1.bias', 'clip_teacher.transformer.resblocks.9.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.9.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.9.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.9.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.9.ln_2.weight', 'clip_teacher.transformer.resblocks.9.ln_2.bias', 'clip_teacher.transformer.resblocks.10.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.10.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.10.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.10.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.10.ln_1.weight', 'clip_teacher.transformer.resblocks.10.ln_1.bias', 'clip_teacher.transformer.resblocks.10.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.10.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.10.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.10.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.10.ln_2.weight', 'clip_teacher.transformer.resblocks.10.ln_2.bias', 'clip_teacher.transformer.resblocks.11.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.11.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.11.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.11.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.11.ln_1.weight', 'clip_teacher.transformer.resblocks.11.ln_1.bias', 'clip_teacher.transformer.resblocks.11.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.11.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.11.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.11.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.11.ln_2.weight', 'clip_teacher.transformer.resblocks.11.ln_2.bias', 'clip_teacher.ln_post.weight', 'clip_teacher.ln_post.bias', 'vision_encoder.clip_decoder.0.head.weight', 'vision_encoder.clip_decoder.0.head.bias', 'vision_encoder.clip_decoder.0.norm.weight', 'vision_encoder.clip_decoder.0.norm.bias', 'vision_encoder.clip_decoder.1.head.weight', 'vision_encoder.clip_decoder.1.head.bias', 'vision_encoder.clip_decoder.1.norm.weight', 'vision_encoder.clip_decoder.1.norm.bias', 'vision_encoder.clip_decoder.2.head.weight', 'vision_encoder.clip_decoder.2.head.bias', 'vision_encoder.clip_decoder.2.norm.weight', 'vision_encoder.clip_decoder.2.norm.bias', 'vision_encoder.clip_decoder.3.head.weight', 'vision_encoder.clip_decoder.3.head.bias', 'vision_encoder.clip_decoder.3.norm.weight', 'vision_encoder.clip_decoder.3.norm.bias', 'vision_encoder.clip_decoder.4.head.weight', 'vision_encoder.clip_decoder.4.head.bias', 'vision_encoder.clip_decoder.4.norm.weight', 'vision_encoder.clip_decoder.4.norm.bias', 'vision_encoder.clip_decoder.5.head.weight', 'vision_encoder.clip_decoder.5.head.bias', 'vision_encoder.clip_decoder.5.norm.weight', 'vision_encoder.clip_decoder.5.norm.bias', 'text_encoder.cls.predictions.bias', 'text_encoder.cls.predictions.transform.dense.weight', 'text_encoder.cls.predictions.transform.dense.bias', 'text_encoder.cls.predictions.transform.LayerNorm.weight', 'text_encoder.cls.predictions.transform.LayerNorm.bias', 'text_encoder.cls.predictions.decoder.weight', 'text_encoder.cls.predictions.decoder.bias'])
2024-05-28T02:01:48 | INFO | tasks.shared_utils : Loaded checkpoint from /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
2024-05-28T02:01:48 | INFO | __main__ : training
2024-05-28T02:01:48 | INFO | tasks.retrieval_utils : Start evaluation for media_type=video
2024-05-28T02:01:48 | INFO | tasks.retrieval_utils : Computing dual encoder features...
2024-05-28T02:01:49 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T02:01:49 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T02:01:49 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T02:01:49 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T02:01:50 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T02:01:50 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T02:01:50 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T02:01:50 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T02:01:50 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T02:01:50 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T02:01:50 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T02:01:50 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T02:02:05 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  builtin_warn(*args, **kwargs)

2024-05-28T02:02:05 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  builtin_warn(*args, **kwargs)

2024-05-28T02:02:05 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-05-28T02:02:05 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-05-28T02:02:07 | INFO | utils.basic_utils : extracting image feats  [ 0/32]  eta: 0:09:44    time: 18.2557  data: 15.8197  max mem: 14911 res mem: 23234
2024-05-28T02:03:23 | INFO | utils.basic_utils : extracting image feats  [31/32]  eta: 0:00:02    time: 2.4518  data: 0.5320  max mem: 15136 res mem: 23234
2024-05-28T02:03:23 | INFO | utils.basic_utils : extracting image feats Total time: 0:01:33 (2.9353 s / it)
2024-05-28T02:03:32 | INFO | tasks.retrieval_utils : Finished feature extraction
2024-05-28T02:03:32 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product]
2024-05-28T02:03:32 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product], done!
2024-05-28T02:03:32 | INFO | tasks.retrieval_utils : Rerank dual-encoder results with cross-encoder...
2024-05-28T02:03:32 | INFO | tasks.retrieval_utils : i2t_scores.shape torch.Size([1000, 1000])
2024-05-28T02:03:32 | INFO | tasks.retrieval_utils : n_clip_per_video=1, with eval_frame_ensemble=concat
2024-05-28T02:03:33 | INFO | utils.basic_utils : Evaluation:  [   0/1000]  eta: 0:02:12    time: 0.1320  data: 0.0009  max mem: 15136 res mem: 23234
2024-05-28T02:03:41 | INFO | utils.basic_utils : Evaluation:  [ 100/1000]  eta: 0:01:16    time: 0.0852  data: 0.0000  max mem: 15136 res mem: 23234
2024-05-28T02:03:50 | INFO | utils.basic_utils : Evaluation:  [ 200/1000]  eta: 0:01:08    time: 0.0854  data: 0.0000  max mem: 15136 res mem: 23234
2024-05-28T02:03:58 | INFO | utils.basic_utils : Evaluation:  [ 300/1000]  eta: 0:00:59    time: 0.0856  data: 0.0000  max mem: 15136 res mem: 23234
2024-05-28T02:04:07 | INFO | utils.basic_utils : Evaluation:  [ 400/1000]  eta: 0:00:51    time: 0.0857  data: 0.0000  max mem: 15136 res mem: 23234
2024-05-28T02:04:15 | INFO | utils.basic_utils : Evaluation:  [ 500/1000]  eta: 0:00:42    time: 0.0858  data: 0.0000  max mem: 15136 res mem: 23234
2024-05-28T02:04:24 | INFO | utils.basic_utils : Evaluation:  [ 600/1000]  eta: 0:00:34    time: 0.0859  data: 0.0000  max mem: 15136 res mem: 23234
2024-05-28T02:04:32 | INFO | utils.basic_utils : Evaluation:  [ 700/1000]  eta: 0:00:25    time: 0.0861  data: 0.0000  max mem: 15136 res mem: 23234
2024-05-28T02:04:41 | INFO | utils.basic_utils : Evaluation:  [ 800/1000]  eta: 0:00:17    time: 0.0861  data: 0.0000  max mem: 15136 res mem: 23234
2024-05-28T02:04:50 | INFO | utils.basic_utils : Evaluation:  [ 900/1000]  eta: 0:00:08    time: 0.0861  data: 0.0000  max mem: 15136 res mem: 23234
2024-05-28T02:04:58 | INFO | utils.basic_utils : Evaluation:  [ 999/1000]  eta: 0:00:00    time: 0.0862  data: 0.0000  max mem: 15136 res mem: 23234
2024-05-28T02:04:58 | INFO | utils.basic_utils : Evaluation: Total time: 0:01:25 (0.0858 s / it)
2024-05-28T02:04:58 | INFO | tasks.retrieval_utils : t2i_scores.shape torch.Size([1000, 1000])
2024-05-28T02:04:59 | INFO | utils.basic_utils : Evaluation:  [   0/1000]  eta: 0:13:01    time: 0.7811  data: 0.0009  max mem: 15136 res mem: 23234
2024-05-28T02:06:01 | INFO | utils.basic_utils : Evaluation:  [ 100/1000]  eta: 0:09:18    time: 0.6182  data: 0.0000  max mem: 15136 res mem: 23234
2024-05-28T02:07:01 | INFO | utils.basic_utils : Evaluation:  [ 200/1000]  eta: 0:08:07    time: 0.6062  data: 0.0000  max mem: 15136 res mem: 23234
2024-05-28T02:08:01 | INFO | utils.basic_utils : Evaluation:  [ 300/1000]  eta: 0:07:05    time: 0.6161  data: 0.0000  max mem: 15136 res mem: 23234
2024-05-28T02:09:01 | INFO | utils.basic_utils : Evaluation:  [ 400/1000]  eta: 0:06:03    time: 0.6129  data: 0.0000  max mem: 15136 res mem: 23234
2024-05-28T02:10:02 | INFO | utils.basic_utils : Evaluation:  [ 500/1000]  eta: 0:05:03    time: 0.5950  data: 0.0000  max mem: 15136 res mem: 23234
2024-05-28T02:11:02 | INFO | utils.basic_utils : Evaluation:  [ 600/1000]  eta: 0:04:02    time: 0.6089  data: 0.0000  max mem: 15136 res mem: 23234
2024-05-28T02:12:05 | INFO | utils.basic_utils : Evaluation:  [ 700/1000]  eta: 0:03:02    time: 0.5972  data: 0.0000  max mem: 15136 res mem: 23234
2024-05-28T02:13:05 | INFO | utils.basic_utils : Evaluation:  [ 800/1000]  eta: 0:02:01    time: 0.6012  data: 0.0000  max mem: 15136 res mem: 23234
2024-05-28T02:14:07 | INFO | utils.basic_utils : Evaluation:  [ 900/1000]  eta: 0:01:00    time: 0.6228  data: 0.0000  max mem: 15136 res mem: 23234
2024-05-28T02:15:08 | INFO | utils.basic_utils : Evaluation:  [ 999/1000]  eta: 0:00:00    time: 0.6340  data: 0.0000  max mem: 15136 res mem: 23234
2024-05-28T02:15:08 | INFO | utils.basic_utils : Evaluation: Total time: 0:10:10 (0.6102 s / it)
2024-05-28T02:15:08 | INFO | tasks.retrieval_utils : Evaluation time 0:13:20
2024-05-28T02:15:09 | INFO | __main__ : Epoch 0
2024-05-28T02:15:09 | INFO | __main__ : 
           txt_r1  txt_r5  txt_r10  txt_r_mean  img_r1  img_r5  img_r10  img_r_mean  r_mean  txt_acc  img_acc
test/        58.1    83.7     88.5       76.77    64.1    85.7     90.8        80.2   78.48     97.2     97.6
test_emb/    37.8    68.7     78.5       61.67    47.9    74.9     83.3        68.7   65.18     98.4     98.8
2024-05-28T02:15:10 | INFO | tasks.retrieval_utils : Start evaluation for media_type=video
2024-05-28T02:15:10 | INFO | tasks.retrieval_utils : Computing dual encoder features...
2024-05-28T02:15:26 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  builtin_warn(*args, **kwargs)

2024-05-28T02:15:26 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  builtin_warn(*args, **kwargs)

2024-05-28T02:15:26 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-05-28T02:15:26 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-05-28T02:15:28 | INFO | utils.basic_utils : extracting image feats  [ 0/32]  eta: 0:09:04    time: 17.0264  data: 15.1344  max mem: 15136 res mem: 23234
2024-05-28T02:16:50 | INFO | umt : Logging to: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2/train.log
2024-05-28T02:16:50 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
  test_file: {
      test: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test2k.json', '/data2/dy/temporal_video/dataset', 'video'] }
  test_types: ['test']
  num_workers: 6
  rtime: False
  pos_num: 1
  neg_num: 10
  stop_key: test/
  is_paragraph_retrieval: False
  is_pretrain: False
  num_frames: 12
  num_frames_test: 12
  batch_size: 32
  max_txt_l: 50
  evaluate: False
  train_shuffle: False
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 12
          sample_type: rand
          num_frames_test: 12
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 50
          video: 50 }
      batch_size: {
          image: 32
          video: 32 }
      batch_size_test: {
          image: 32
          video: 32 } }
  text_enc: bert
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_b16
          img_size: 224
          patch_size: 16
          d_model: 768
          encoder_embed_dim: 768
          encoder_depth: 12
          encoder_num_heads: 12
          drop_path_rate: 0.2
          num_frames: 12
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 12
          clip_decoder_embed_dim: 768
          clip_output_dim: 512
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 224
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      multimodal: {
          enable: True }
      embed_dim: 512
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 1e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 5
      min_lr_multi: 0.01
      warmup_epochs: 1 }
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: user
      project: umt_ret }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
  resume: False
  debug: False
  log_freq: 100
  seed: 3407
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
  rank: 0
  world_size: 4
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-05-28T02:16:50 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video'], 'test_file': {'test': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test2k.json', '/data2/dy/temporal_video/dataset', 'video']}, 'test_types': ['test'], 'num_workers': 6, 'rtime': False, 'pos_num': 1, 'neg_num': 10, 'stop_key': 'test/', 'is_paragraph_retrieval': False, 'is_pretrain': False, 'num_frames': 12, 'num_frames_test': 12, 'batch_size': 32, 'max_txt_l': 50, 'evaluate': False, 'train_shuffle': False, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 12, 'sample_type': 'rand', 'num_frames_test': 12, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 50, 'video': 50}, 'batch_size': {'image': 32, 'video': 32}, 'batch_size_test': {'image': 32, 'video': 32}}, 'text_enc': 'bert', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_b16', 'img_size': 224, 'patch_size': 16, 'd_model': 768, 'encoder_embed_dim': 768, 'encoder_depth': 12, 'encoder_num_heads': 12, 'drop_path_rate': 0.2, 'num_frames': 12, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 12, 'clip_decoder_embed_dim': 768, 'clip_output_dim': 512, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 224, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'multimodal': {'enable': True}, 'embed_dim': 512, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 1e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 5, 'min_lr_multi': 0.01, 'warmup_epochs': 1}, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': False, 'entity': 'user', 'project': 'umt_ret'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': 'exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 3407, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth', 'rank': 0, 'world_size': 4, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2024-05-28T02:16:50 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
2024-05-28T02:16:50 | INFO | tasks.pretrain : Creating dataset for ret
2024-05-28T02:16:50 | INFO | tasks.shared_utils : Creating model
2024-05-28T02:17:01 | INFO | models.umt : Build vision_encoder: vit_b16
2024-05-28T02:17:01 | INFO | models.backbones.vit.vit : Num of patches: 2352
2024-05-28T02:17:01 | INFO | models.backbones.vit.vit : Use checkpoint: True
2024-05-28T02:17:01 | INFO | models.backbones.vit.vit : Checkpoint number: 12
2024-05-28T02:17:01 | INFO | models.backbones.vit.vit : Student return index: []
2024-05-28T02:17:11 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
2024-05-28T02:17:11 | INFO | models.umt : Build text_encoder bert_base
2024-05-28T02:17:12 | INFO | models.backbones.bert.xbert : build bert with cross_module: ca
2024-05-28T02:17:13 | INFO | models.criterions : Norm type: l2
2024-05-28T02:17:13 | INFO | models.criterions : Loss type: l2
2024-05-28T02:17:13 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-05-28T02:17:13 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.lora_r: wd: 0, lr: 1e-05
2024-05-28T02:17:13 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T02:17:13 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T02:17:13 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T02:17:13 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T02:17:13 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T02:17:13 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.lora_r: wd: 0, lr: 1e-05
2024-05-28T02:17:13 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T02:17:13 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T02:17:13 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T02:17:13 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T02:17:13 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T02:17:13 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.lora_r: wd: 0, lr: 1e-05
2024-05-28T02:17:13 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T02:17:13 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T02:17:13 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T02:17:13 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T02:17:13 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T02:17:13 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.lora_r: wd: 0, lr: 1e-05
2024-05-28T02:17:13 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T02:17:13 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T02:17:13 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T02:17:13 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T02:17:13 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T02:17:13 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.lora_r: wd: 0, lr: 1e-05
2024-05-28T02:17:13 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T02:17:13 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T02:17:13 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T02:17:13 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T02:17:13 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T02:17:13 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.lora_r: wd: 0, lr: 1e-05
2024-05-28T02:17:13 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T02:17:13 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T02:17:13 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T02:17:13 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T02:17:13 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T02:17:13 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.lora_r: wd: 0, lr: 1e-05
2024-05-28T02:17:13 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T02:17:13 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T02:17:13 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T02:17:13 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T02:17:13 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T02:17:13 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.lora_r: wd: 0, lr: 1e-05
2024-05-28T02:17:13 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T02:17:13 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T02:17:13 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T02:17:13 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T02:17:13 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T02:17:13 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.lora_r: wd: 0, lr: 1e-05
2024-05-28T02:17:13 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T02:17:13 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T02:17:13 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T02:17:13 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T02:17:13 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T02:17:13 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.lora_r: wd: 0, lr: 1e-05
2024-05-28T02:17:13 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T02:17:13 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T02:17:13 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T02:17:13 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T02:17:13 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T02:17:13 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.lora_r: wd: 0, lr: 1e-05
2024-05-28T02:17:13 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T02:17:13 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T02:17:13 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T02:17:13 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T02:17:13 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T02:17:13 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.lora_r: wd: 0, lr: 1e-05
2024-05-28T02:17:13 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T02:17:13 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T02:17:13 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T02:17:13 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T02:17:13 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T02:17:13 | INFO | utils.optimizer : param module.vision_proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T02:17:13 | INFO | utils.optimizer : param module.vision_proj.bias: wd: 0, lr: 1e-05
2024-05-28T02:17:13 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0 len(p)=49
2024-05-28T02:17:13 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0.02 len(p)=25
2024-05-28T02:17:13 | INFO | tasks.shared_utils : Auto resuming
2024-05-28T02:17:14 | INFO | tasks.shared_utils : <All keys matched successfully>
2024-05-28T02:17:14 | INFO | tasks.shared_utils : Loaded checkpoint from exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2/ckpt_best.pth
2024-05-28T02:17:14 | INFO | __main__ : training
2024-05-28T02:17:14 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 1448 batches in total
dataloader index=0 name=video, batch-size=32 length(#batches)=1448 
2024-05-28T02:17:15 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T02:17:15 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T02:17:15 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T02:17:15 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T02:17:15 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T02:17:15 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T02:17:15 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T02:17:15 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T02:17:15 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T02:17:15 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T02:17:15 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T02:17:15 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T02:17:33 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  builtin_warn(*args, **kwargs)

2024-05-28T02:17:33 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  builtin_warn(*args, **kwargs)

2024-05-28T02:17:33 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-05-28T02:17:33 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-05-28T02:17:35 | INFO | utils.basic_utils : Train Epoch: [1]  [   0/1448]  eta: 8:21:16  lr: 0.000000  temperature: 0.0112  video-loss_vtc: 2.5536  video-loss_vtm: 0.5447  time: 20.7714  data: 17.6624  max mem: 14768 res mem: 22898
2024-05-28T02:18:09 | INFO | umt : Logging to: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2/train.log
2024-05-28T02:18:09 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
  test_file: {
      test: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test2k.json', '/data2/dy/temporal_video/dataset', 'video'] }
  test_types: ['test']
  num_workers: 6
  rtime: False
  pos_num: 1
  neg_num: 10
  stop_key: test/
  is_paragraph_retrieval: False
  is_pretrain: False
  num_frames: 12
  num_frames_test: 12
  batch_size: 32
  max_txt_l: 50
  evaluate: False
  train_shuffle: False
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 12
          sample_type: rand
          num_frames_test: 12
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 50
          video: 50 }
      batch_size: {
          image: 32
          video: 32 }
      batch_size_test: {
          image: 32
          video: 32 } }
  text_enc: bert
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_b16
          img_size: 224
          patch_size: 16
          d_model: 768
          encoder_embed_dim: 768
          encoder_depth: 12
          encoder_num_heads: 12
          drop_path_rate: 0.2
          num_frames: 12
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 12
          clip_decoder_embed_dim: 768
          clip_output_dim: 512
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 224
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      multimodal: {
          enable: True }
      embed_dim: 512
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 1e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 5
      min_lr_multi: 0.01
      warmup_epochs: 1 }
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: user
      project: umt_ret }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
  resume: False
  debug: False
  log_freq: 100
  seed: 3407
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
  rank: 0
  world_size: 4
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-05-28T02:18:09 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video'], 'test_file': {'test': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test2k.json', '/data2/dy/temporal_video/dataset', 'video']}, 'test_types': ['test'], 'num_workers': 6, 'rtime': False, 'pos_num': 1, 'neg_num': 10, 'stop_key': 'test/', 'is_paragraph_retrieval': False, 'is_pretrain': False, 'num_frames': 12, 'num_frames_test': 12, 'batch_size': 32, 'max_txt_l': 50, 'evaluate': False, 'train_shuffle': False, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 12, 'sample_type': 'rand', 'num_frames_test': 12, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 50, 'video': 50}, 'batch_size': {'image': 32, 'video': 32}, 'batch_size_test': {'image': 32, 'video': 32}}, 'text_enc': 'bert', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_b16', 'img_size': 224, 'patch_size': 16, 'd_model': 768, 'encoder_embed_dim': 768, 'encoder_depth': 12, 'encoder_num_heads': 12, 'drop_path_rate': 0.2, 'num_frames': 12, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 12, 'clip_decoder_embed_dim': 768, 'clip_output_dim': 512, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 224, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'multimodal': {'enable': True}, 'embed_dim': 512, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 1e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 5, 'min_lr_multi': 0.01, 'warmup_epochs': 1}, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': False, 'entity': 'user', 'project': 'umt_ret'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': 'exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 3407, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth', 'rank': 0, 'world_size': 4, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2024-05-28T02:18:09 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
2024-05-28T02:18:09 | INFO | tasks.pretrain : Creating dataset for ret
2024-05-28T02:18:10 | INFO | tasks.shared_utils : Creating model
2024-05-28T02:18:20 | INFO | models.umt : Build vision_encoder: vit_b16
2024-05-28T02:18:20 | INFO | models.backbones.vit.vit : Num of patches: 2352
2024-05-28T02:18:20 | INFO | models.backbones.vit.vit : Use checkpoint: True
2024-05-28T02:18:20 | INFO | models.backbones.vit.vit : Checkpoint number: 12
2024-05-28T02:18:20 | INFO | models.backbones.vit.vit : Student return index: []
2024-05-28T02:18:28 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
2024-05-28T02:18:28 | INFO | models.umt : Build text_encoder bert_base
2024-05-28T02:18:29 | INFO | models.backbones.bert.xbert : build bert with cross_module: ca
2024-05-28T02:18:30 | INFO | models.criterions : Norm type: l2
2024-05-28T02:18:30 | INFO | models.criterions : Loss type: l2
2024-05-28T02:18:30 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-05-28T02:18:30 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.lora_r: wd: 0, lr: 1e-05
2024-05-28T02:18:30 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T02:18:30 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T02:18:30 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T02:18:30 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T02:18:30 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T02:18:30 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.lora_r: wd: 0, lr: 1e-05
2024-05-28T02:18:30 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T02:18:30 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T02:18:30 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T02:18:30 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T02:18:30 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T02:18:30 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.lora_r: wd: 0, lr: 1e-05
2024-05-28T02:18:30 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T02:18:30 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T02:18:30 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T02:18:30 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T02:18:30 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T02:18:30 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.lora_r: wd: 0, lr: 1e-05
2024-05-28T02:18:30 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T02:18:30 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T02:18:30 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T02:18:30 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T02:18:30 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T02:18:30 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.lora_r: wd: 0, lr: 1e-05
2024-05-28T02:18:30 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T02:18:30 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T02:18:30 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T02:18:30 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T02:18:30 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T02:18:30 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.lora_r: wd: 0, lr: 1e-05
2024-05-28T02:18:30 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T02:18:30 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T02:18:30 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T02:18:30 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T02:18:30 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T02:18:30 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.lora_r: wd: 0, lr: 1e-05
2024-05-28T02:18:30 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T02:18:30 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T02:18:30 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T02:18:30 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T02:18:30 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T02:18:30 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.lora_r: wd: 0, lr: 1e-05
2024-05-28T02:18:30 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T02:18:30 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T02:18:30 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T02:18:30 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T02:18:30 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T02:18:30 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.lora_r: wd: 0, lr: 1e-05
2024-05-28T02:18:30 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T02:18:30 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T02:18:30 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T02:18:30 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T02:18:30 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T02:18:30 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.lora_r: wd: 0, lr: 1e-05
2024-05-28T02:18:30 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T02:18:30 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T02:18:30 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T02:18:30 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T02:18:30 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T02:18:30 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.lora_r: wd: 0, lr: 1e-05
2024-05-28T02:18:30 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T02:18:30 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T02:18:30 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T02:18:30 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T02:18:30 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T02:18:30 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.lora_r: wd: 0, lr: 1e-05
2024-05-28T02:18:30 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T02:18:30 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T02:18:30 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T02:18:30 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T02:18:30 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T02:18:30 | INFO | utils.optimizer : param module.vision_proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T02:18:30 | INFO | utils.optimizer : param module.vision_proj.bias: wd: 0, lr: 1e-05
2024-05-28T02:18:30 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0 len(p)=49
2024-05-28T02:18:30 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0.02 len(p)=25
2024-05-28T02:18:30 | INFO | tasks.shared_utils : Auto resuming
2024-05-28T02:18:30 | INFO | tasks.shared_utils : Not found checkpoint in exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
2024-05-28T02:18:31 | INFO | tasks.shared_utils : _IncompatibleKeys(missing_keys=['vision_encoder.encoder.blocks.0.lora_r', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.1.lora_r', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.2.lora_r', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.3.lora_r', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.4.lora_r', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.5.lora_r', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.6.lora_r', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.7.lora_r', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.8.lora_r', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.9.lora_r', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.10.lora_r', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.bias', 'vision_encoder.encoder.blocks.11.lora_r', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.q_bias', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.v_bias', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.qkv.weight', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.weight', 'vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.bias'], unexpected_keys=['clip_teacher.class_embedding', 'clip_teacher.positional_embedding', 'clip_teacher.proj', 'clip_teacher.conv1.weight', 'clip_teacher.ln_pre.weight', 'clip_teacher.ln_pre.bias', 'clip_teacher.transformer.resblocks.0.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.0.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.0.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.0.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.0.ln_1.weight', 'clip_teacher.transformer.resblocks.0.ln_1.bias', 'clip_teacher.transformer.resblocks.0.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.0.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.0.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.0.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.0.ln_2.weight', 'clip_teacher.transformer.resblocks.0.ln_2.bias', 'clip_teacher.transformer.resblocks.1.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.1.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.1.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.1.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.1.ln_1.weight', 'clip_teacher.transformer.resblocks.1.ln_1.bias', 'clip_teacher.transformer.resblocks.1.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.1.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.1.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.1.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.1.ln_2.weight', 'clip_teacher.transformer.resblocks.1.ln_2.bias', 'clip_teacher.transformer.resblocks.2.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.2.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.2.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.2.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.2.ln_1.weight', 'clip_teacher.transformer.resblocks.2.ln_1.bias', 'clip_teacher.transformer.resblocks.2.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.2.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.2.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.2.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.2.ln_2.weight', 'clip_teacher.transformer.resblocks.2.ln_2.bias', 'clip_teacher.transformer.resblocks.3.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.3.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.3.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.3.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.3.ln_1.weight', 'clip_teacher.transformer.resblocks.3.ln_1.bias', 'clip_teacher.transformer.resblocks.3.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.3.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.3.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.3.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.3.ln_2.weight', 'clip_teacher.transformer.resblocks.3.ln_2.bias', 'clip_teacher.transformer.resblocks.4.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.4.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.4.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.4.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.4.ln_1.weight', 'clip_teacher.transformer.resblocks.4.ln_1.bias', 'clip_teacher.transformer.resblocks.4.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.4.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.4.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.4.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.4.ln_2.weight', 'clip_teacher.transformer.resblocks.4.ln_2.bias', 'clip_teacher.transformer.resblocks.5.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.5.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.5.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.5.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.5.ln_1.weight', 'clip_teacher.transformer.resblocks.5.ln_1.bias', 'clip_teacher.transformer.resblocks.5.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.5.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.5.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.5.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.5.ln_2.weight', 'clip_teacher.transformer.resblocks.5.ln_2.bias', 'clip_teacher.transformer.resblocks.6.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.6.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.6.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.6.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.6.ln_1.weight', 'clip_teacher.transformer.resblocks.6.ln_1.bias', 'clip_teacher.transformer.resblocks.6.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.6.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.6.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.6.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.6.ln_2.weight', 'clip_teacher.transformer.resblocks.6.ln_2.bias', 'clip_teacher.transformer.resblocks.7.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.7.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.7.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.7.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.7.ln_1.weight', 'clip_teacher.transformer.resblocks.7.ln_1.bias', 'clip_teacher.transformer.resblocks.7.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.7.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.7.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.7.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.7.ln_2.weight', 'clip_teacher.transformer.resblocks.7.ln_2.bias', 'clip_teacher.transformer.resblocks.8.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.8.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.8.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.8.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.8.ln_1.weight', 'clip_teacher.transformer.resblocks.8.ln_1.bias', 'clip_teacher.transformer.resblocks.8.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.8.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.8.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.8.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.8.ln_2.weight', 'clip_teacher.transformer.resblocks.8.ln_2.bias', 'clip_teacher.transformer.resblocks.9.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.9.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.9.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.9.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.9.ln_1.weight', 'clip_teacher.transformer.resblocks.9.ln_1.bias', 'clip_teacher.transformer.resblocks.9.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.9.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.9.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.9.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.9.ln_2.weight', 'clip_teacher.transformer.resblocks.9.ln_2.bias', 'clip_teacher.transformer.resblocks.10.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.10.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.10.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.10.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.10.ln_1.weight', 'clip_teacher.transformer.resblocks.10.ln_1.bias', 'clip_teacher.transformer.resblocks.10.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.10.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.10.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.10.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.10.ln_2.weight', 'clip_teacher.transformer.resblocks.10.ln_2.bias', 'clip_teacher.transformer.resblocks.11.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.11.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.11.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.11.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.11.ln_1.weight', 'clip_teacher.transformer.resblocks.11.ln_1.bias', 'clip_teacher.transformer.resblocks.11.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.11.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.11.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.11.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.11.ln_2.weight', 'clip_teacher.transformer.resblocks.11.ln_2.bias', 'clip_teacher.ln_post.weight', 'clip_teacher.ln_post.bias', 'vision_encoder.clip_decoder.0.head.weight', 'vision_encoder.clip_decoder.0.head.bias', 'vision_encoder.clip_decoder.0.norm.weight', 'vision_encoder.clip_decoder.0.norm.bias', 'vision_encoder.clip_decoder.1.head.weight', 'vision_encoder.clip_decoder.1.head.bias', 'vision_encoder.clip_decoder.1.norm.weight', 'vision_encoder.clip_decoder.1.norm.bias', 'vision_encoder.clip_decoder.2.head.weight', 'vision_encoder.clip_decoder.2.head.bias', 'vision_encoder.clip_decoder.2.norm.weight', 'vision_encoder.clip_decoder.2.norm.bias', 'vision_encoder.clip_decoder.3.head.weight', 'vision_encoder.clip_decoder.3.head.bias', 'vision_encoder.clip_decoder.3.norm.weight', 'vision_encoder.clip_decoder.3.norm.bias', 'vision_encoder.clip_decoder.4.head.weight', 'vision_encoder.clip_decoder.4.head.bias', 'vision_encoder.clip_decoder.4.norm.weight', 'vision_encoder.clip_decoder.4.norm.bias', 'vision_encoder.clip_decoder.5.head.weight', 'vision_encoder.clip_decoder.5.head.bias', 'vision_encoder.clip_decoder.5.norm.weight', 'vision_encoder.clip_decoder.5.norm.bias', 'text_encoder.cls.predictions.bias', 'text_encoder.cls.predictions.transform.dense.weight', 'text_encoder.cls.predictions.transform.dense.bias', 'text_encoder.cls.predictions.transform.LayerNorm.weight', 'text_encoder.cls.predictions.transform.LayerNorm.bias', 'text_encoder.cls.predictions.decoder.weight', 'text_encoder.cls.predictions.decoder.bias'])
2024-05-28T02:18:31 | INFO | tasks.shared_utils : Loaded checkpoint from /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
2024-05-28T02:18:31 | INFO | __main__ : training
2024-05-28T02:18:32 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 1448 batches in total
dataloader index=0 name=video, batch-size=32 length(#batches)=1448 
2024-05-28T02:18:32 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T02:18:32 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T02:18:32 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T02:18:32 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T02:18:32 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T02:18:32 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T02:18:32 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T02:18:32 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T02:18:32 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T02:18:32 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T02:18:33 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T02:18:33 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T02:18:48 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  builtin_warn(*args, **kwargs)

2024-05-28T02:18:48 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  builtin_warn(*args, **kwargs)

2024-05-28T02:18:48 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-05-28T02:18:48 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-05-28T02:18:52 | INFO | utils.basic_utils : Train Epoch: [0]  [   0/1448]  eta: 8:22:53  lr: 0.000000  temperature: 0.0112  video-loss_vtc: 2.5536  video-loss_vtm: 0.5447  time: 20.8378  data: 15.5314  max mem: 14768 res mem: 22898
2024-05-28T02:24:20 | INFO | utils.basic_utils : Train Epoch: [0]  [ 100/1448]  eta: 1:17:36  lr: 0.000001  temperature: 0.0112  video-loss_vtc: 2.6353  video-loss_vtm: 0.6143  time: 3.1422  data: 0.0020  max mem: 14783 res mem: 22900
2024-05-28T02:29:06 | INFO | utils.basic_utils : Train Epoch: [0]  [ 200/1448]  eta: 1:05:40  lr: 0.000001  temperature: 0.0112  video-loss_vtc: 2.7845  video-loss_vtm: 0.7969  time: 2.6901  data: 0.0022  max mem: 14783 res mem: 22900
2024-05-28T02:33:29 | INFO | utils.basic_utils : Train Epoch: [0]  [ 300/1448]  eta: 0:57:01  lr: 0.000002  temperature: 0.0112  video-loss_vtc: 2.0444  video-loss_vtm: 0.2924  time: 2.6716  data: 0.0022  max mem: 14783 res mem: 22900
2024-05-28T02:37:37 | INFO | utils.basic_utils : Train Epoch: [0]  [ 400/1448]  eta: 0:49:54  lr: 0.000003  temperature: 0.0112  video-loss_vtc: 2.5409  video-loss_vtm: 0.5999  time: 2.5503  data: 0.0016  max mem: 14783 res mem: 22900
2024-05-28T02:41:55 | INFO | utils.basic_utils : Train Epoch: [0]  [ 500/1448]  eta: 0:44:15  lr: 0.000003  temperature: 0.0112  video-loss_vtc: 2.6473  video-loss_vtm: 0.6523  time: 2.6429  data: 0.1187  max mem: 14783 res mem: 22900
2024-05-28T02:46:12 | INFO | utils.basic_utils : Train Epoch: [0]  [ 600/1448]  eta: 0:39:02  lr: 0.000004  temperature: 0.0112  video-loss_vtc: 2.4108  video-loss_vtm: 0.5087  time: 2.3605  data: 0.0017  max mem: 14783 res mem: 22900
2024-05-28T02:50:32 | INFO | utils.basic_utils : Train Epoch: [0]  [ 700/1448]  eta: 0:34:09  lr: 0.000005  temperature: 0.0112  video-loss_vtc: 2.6092  video-loss_vtm: 0.5732  time: 2.6766  data: 0.0020  max mem: 14783 res mem: 22900
2024-05-28T02:54:48 | INFO | utils.basic_utils : Train Epoch: [0]  [ 800/1448]  eta: 0:29:20  lr: 0.000006  temperature: 0.0112  video-loss_vtc: 2.1121  video-loss_vtm: 0.6493  time: 2.6200  data: 0.0016  max mem: 14783 res mem: 22900
2024-05-28T02:59:02 | INFO | utils.basic_utils : Train Epoch: [0]  [ 900/1448]  eta: 0:24:38  lr: 0.000006  temperature: 0.0112  video-loss_vtc: 1.8767  video-loss_vtm: 0.4761  time: 2.5263  data: 0.0018  max mem: 14783 res mem: 22900
2024-05-28T03:03:19 | INFO | utils.basic_utils : Train Epoch: [0]  [1000/1448]  eta: 0:20:02  lr: 0.000007  temperature: 0.0112  video-loss_vtc: 2.3285  video-loss_vtm: 0.8198  time: 2.4379  data: 0.0020  max mem: 14783 res mem: 22900
2024-05-28T03:07:38 | INFO | utils.basic_utils : Train Epoch: [0]  [1100/1448]  eta: 0:15:31  lr: 0.000008  temperature: 0.0112  video-loss_vtc: 2.4236  video-loss_vtm: 0.5128  time: 2.4961  data: 0.0017  max mem: 14783 res mem: 22900
2024-05-28T03:11:57 | INFO | utils.basic_utils : Train Epoch: [0]  [1200/1448]  eta: 0:11:01  lr: 0.000008  temperature: 0.0112  video-loss_vtc: 2.0469  video-loss_vtm: 0.7175  time: 2.6743  data: 0.0020  max mem: 14783 res mem: 22900
2024-05-28T03:16:16 | INFO | utils.basic_utils : Train Epoch: [0]  [1300/1448]  eta: 0:06:34  lr: 0.000009  temperature: 0.0112  video-loss_vtc: 2.1237  video-loss_vtm: 0.4691  time: 2.6404  data: 0.0018  max mem: 14783 res mem: 22900
2024-05-28T03:20:31 | INFO | utils.basic_utils : Train Epoch: [0]  [1400/1448]  eta: 0:02:07  lr: 0.000010  temperature: 0.0112  video-loss_vtc: 2.2197  video-loss_vtm: 0.7498  time: 2.6433  data: 0.0021  max mem: 14783 res mem: 22900
2024-05-28T03:22:31 | INFO | utils.basic_utils : Train Epoch: [0]  [1447/1448]  eta: 0:00:02  lr: 0.000010  temperature: 0.0112  video-loss_vtc: 1.8155  video-loss_vtm: 0.4899  time: 2.4934  data: 0.0022  max mem: 14783 res mem: 22900
2024-05-28T03:22:31 | INFO | utils.basic_utils : Train Epoch: [0] Total time: 1:03:59 (2.6516 s / it)
2024-05-28T03:22:31 | INFO | __main__ : Averaged train stats: lr: 0.0000  temperature: 0.0112  video-loss_vtc: 2.2684  video-loss_vtm: 0.5406
2024-05-28T03:22:31 | INFO | tasks.retrieval_utils : Start evaluation for media_type=video
2024-05-28T03:22:31 | INFO | tasks.retrieval_utils : Computing dual encoder features...
2024-05-28T03:22:33 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T03:22:33 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T03:22:33 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T03:22:33 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T03:22:33 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T03:22:33 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T03:22:33 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T03:22:33 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T03:22:33 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T03:22:33 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T03:22:33 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T03:22:33 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T03:22:50 | INFO | utils.basic_utils : extracting image feats  [ 0/63]  eta: 0:18:30    time: 17.6303  data: 15.6634  max mem: 15078 res mem: 22900
2024-05-28T03:25:22 | INFO | utils.basic_utils : extracting image feats  [62/63]  eta: 0:00:02    time: 2.3330  data: 0.3790  max mem: 15302 res mem: 22900
2024-05-28T03:25:22 | INFO | utils.basic_utils : extracting image feats Total time: 0:02:49 (2.6919 s / it)
2024-05-28T03:25:33 | INFO | tasks.retrieval_utils : Finished feature extraction
2024-05-28T03:25:33 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product]
2024-05-28T03:25:33 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product], done!
2024-05-28T03:25:33 | INFO | tasks.retrieval_utils : Rerank dual-encoder results with cross-encoder...
2024-05-28T03:25:33 | INFO | tasks.retrieval_utils : i2t_scores.shape torch.Size([501, 2000])
2024-05-28T03:25:33 | INFO | tasks.retrieval_utils : n_clip_per_video=1, with eval_frame_ensemble=concat
2024-05-28T03:25:34 | INFO | utils.basic_utils : Evaluation:  [  0/501]  eta: 0:00:22    time: 0.0441  data: 0.0005  max mem: 15302 res mem: 22900
2024-05-28T03:25:42 | INFO | utils.basic_utils : Evaluation:  [100/501]  eta: 0:00:33    time: 0.0850  data: 0.0000  max mem: 15302 res mem: 22900
2024-05-28T03:25:51 | INFO | utils.basic_utils : Evaluation:  [200/501]  eta: 0:00:25    time: 0.0863  data: 0.0000  max mem: 15302 res mem: 22900
2024-05-28T03:25:59 | INFO | utils.basic_utils : Evaluation:  [300/501]  eta: 0:00:17    time: 0.0865  data: 0.0000  max mem: 15302 res mem: 22900
2024-05-28T03:26:08 | INFO | utils.basic_utils : Evaluation:  [400/501]  eta: 0:00:08    time: 0.0867  data: 0.0000  max mem: 15302 res mem: 22900
2024-05-28T03:26:17 | INFO | utils.basic_utils : Evaluation:  [500/501]  eta: 0:00:00    time: 0.0868  data: 0.0000  max mem: 15302 res mem: 22900
2024-05-28T03:26:17 | INFO | utils.basic_utils : Evaluation: Total time: 0:00:43 (0.0860 s / it)
2024-05-28T03:26:17 | INFO | tasks.retrieval_utils : t2i_scores.shape torch.Size([501, 2000])
2024-05-28T03:26:17 | INFO | utils.basic_utils : Evaluation:  [  0/501]  eta: 0:05:17    time: 0.6332  data: 0.0004  max mem: 15302 res mem: 22900
2024-05-28T03:27:28 | INFO | utils.basic_utils : Evaluation:  [100/501]  eta: 0:04:41    time: 0.7056  data: 0.0000  max mem: 15302 res mem: 22900
2024-05-28T03:28:39 | INFO | utils.basic_utils : Evaluation:  [200/501]  eta: 0:03:33    time: 0.6914  data: 0.0000  max mem: 15302 res mem: 22900
2024-05-28T03:29:52 | INFO | utils.basic_utils : Evaluation:  [300/501]  eta: 0:02:24    time: 0.7347  data: 0.0000  max mem: 15302 res mem: 22900
2024-05-28T03:31:04 | INFO | utils.basic_utils : Evaluation:  [400/501]  eta: 0:01:12    time: 0.7642  data: 0.0000  max mem: 15302 res mem: 22900
2024-05-28T03:32:17 | INFO | utils.basic_utils : Evaluation:  [500/501]  eta: 0:00:00    time: 0.7267  data: 0.0000  max mem: 15302 res mem: 22900
2024-05-28T03:32:17 | INFO | utils.basic_utils : Evaluation: Total time: 0:06:00 (0.7202 s / it)
2024-05-28T03:34:50 | INFO | tasks.retrieval_utils : Evaluation time 0:12:18
2024-05-28T03:34:51 | INFO | __main__ : Epoch 0
2024-05-28T03:34:51 | INFO | __main__ : 
           txt_r1  txt_r5  txt_r10  txt_r_mean  img_r1  img_r5  img_r10  img_r_mean  r_mean  txt_acc  img_acc
test/       31.00   74.25    84.10       63.12   32.50   76.90    85.15       64.85   63.98     50.0    49.55
test_emb/   26.35   67.30    78.45       57.37   28.15   68.45    79.60       58.73   58.05     49.3    49.35
2024-05-28T03:34:52 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 1448 batches in total
dataloader index=0 name=video, batch-size=32 length(#batches)=1448 
2024-05-28T03:35:07 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  builtin_warn(*args, **kwargs)

2024-05-28T03:35:07 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  builtin_warn(*args, **kwargs)

2024-05-28T03:35:07 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-05-28T03:35:07 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-05-28T03:35:09 | INFO | utils.basic_utils : Train Epoch: [1]  [   0/1448]  eta: 6:58:27  lr: 0.000010  temperature: 0.0112  video-loss_vtc: 2.0427  video-loss_vtm: 0.4707  time: 17.3392  data: 15.3265  max mem: 15302 res mem: 22900
2024-05-28T03:39:32 | INFO | utils.basic_utils : Train Epoch: [1]  [ 100/1448]  eta: 1:02:10  lr: 0.000010  temperature: 0.0112  video-loss_vtc: 2.0508  video-loss_vtm: 0.6128  time: 2.5084  data: 0.3780  max mem: 15302 res mem: 22900
2024-05-28T03:43:48 | INFO | utils.basic_utils : Train Epoch: [1]  [ 200/1448]  eta: 0:55:29  lr: 0.000010  temperature: 0.0112  video-loss_vtc: 1.8208  video-loss_vtm: 0.7822  time: 2.6945  data: 0.0856  max mem: 15302 res mem: 22900
2024-05-28T03:48:05 | INFO | utils.basic_utils : Train Epoch: [1]  [ 300/1448]  eta: 0:50:22  lr: 0.000010  temperature: 0.0112  video-loss_vtc: 1.5407  video-loss_vtm: 0.4023  time: 2.6717  data: 0.0172  max mem: 15302 res mem: 22900
2024-05-28T03:52:27 | INFO | utils.basic_utils : Train Epoch: [1]  [ 400/1448]  eta: 0:45:56  lr: 0.000010  temperature: 0.0112  video-loss_vtc: 1.6566  video-loss_vtm: 0.7113  time: 2.6721  data: 0.0485  max mem: 15302 res mem: 22900
2024-05-28T03:56:46 | INFO | utils.basic_utils : Train Epoch: [1]  [ 500/1448]  eta: 0:41:27  lr: 0.000010  temperature: 0.0112  video-loss_vtc: 1.8332  video-loss_vtm: 0.6889  time: 2.6882  data: 0.0017  max mem: 15302 res mem: 22900
2024-05-28T04:01:06 | INFO | utils.basic_utils : Train Epoch: [1]  [ 600/1448]  eta: 0:37:00  lr: 0.000010  temperature: 0.0112  video-loss_vtc: 1.9180  video-loss_vtm: 0.5003  time: 2.6281  data: 0.0018  max mem: 15302 res mem: 22900
2024-05-28T04:05:29 | INFO | utils.basic_utils : Train Epoch: [1]  [ 700/1448]  eta: 0:32:40  lr: 0.000010  temperature: 0.0112  video-loss_vtc: 1.9814  video-loss_vtm: 0.5156  time: 2.5580  data: 0.0022  max mem: 15302 res mem: 22900
2024-05-28T04:09:44 | INFO | utils.basic_utils : Train Epoch: [1]  [ 800/1448]  eta: 0:28:12  lr: 0.000010  temperature: 0.0112  video-loss_vtc: 1.8873  video-loss_vtm: 0.5584  time: 2.6046  data: 0.0016  max mem: 15302 res mem: 22900
2024-05-28T04:14:00 | INFO | utils.basic_utils : Train Epoch: [1]  [ 900/1448]  eta: 0:23:48  lr: 0.000009  temperature: 0.0112  video-loss_vtc: 1.6691  video-loss_vtm: 0.5979  time: 2.5066  data: 0.0018  max mem: 15302 res mem: 22900
2024-05-28T04:18:16 | INFO | utils.basic_utils : Train Epoch: [1]  [1000/1448]  eta: 0:19:25  lr: 0.000009  temperature: 0.0112  video-loss_vtc: 1.9941  video-loss_vtm: 0.8366  time: 2.4319  data: 0.0017  max mem: 15302 res mem: 22900
2024-05-28T04:22:38 | INFO | utils.basic_utils : Train Epoch: [1]  [1100/1448]  eta: 0:15:05  lr: 0.000009  temperature: 0.0112  video-loss_vtc: 2.0319  video-loss_vtm: 0.6681  time: 2.6963  data: 0.0017  max mem: 15302 res mem: 22900
2024-05-28T04:26:55 | INFO | utils.basic_utils : Train Epoch: [1]  [1200/1448]  eta: 0:10:44  lr: 0.000009  temperature: 0.0112  video-loss_vtc: 1.7974  video-loss_vtm: 0.6224  time: 2.5766  data: 0.0018  max mem: 15302 res mem: 22900
2024-05-28T04:31:12 | INFO | utils.basic_utils : Train Epoch: [1]  [1300/1448]  eta: 0:06:24  lr: 0.000009  temperature: 0.0112  video-loss_vtc: 2.0019  video-loss_vtm: 0.5554  time: 2.5485  data: 0.0017  max mem: 15302 res mem: 22900
2024-05-28T04:35:34 | INFO | utils.basic_utils : Train Epoch: [1]  [1400/1448]  eta: 0:02:04  lr: 0.000009  temperature: 0.0112  video-loss_vtc: 1.9730  video-loss_vtm: 0.6550  time: 2.7733  data: 0.0018  max mem: 15302 res mem: 22900
2024-05-28T04:37:31 | INFO | utils.basic_utils : Train Epoch: [1]  [1447/1448]  eta: 0:00:02  lr: 0.000009  temperature: 0.0112  video-loss_vtc: 1.8284  video-loss_vtm: 0.7967  time: 2.5018  data: 0.0021  max mem: 15302 res mem: 22900
2024-05-28T04:37:31 | INFO | utils.basic_utils : Train Epoch: [1] Total time: 1:02:38 (2.5958 s / it)
2024-05-28T04:37:31 | INFO | __main__ : Averaged train stats: lr: 0.0000  temperature: 0.0112  video-loss_vtc: 1.8284  video-loss_vtm: 0.5356
2024-05-28T04:37:31 | INFO | tasks.retrieval_utils : Start evaluation for media_type=video
2024-05-28T04:37:31 | INFO | tasks.retrieval_utils : Computing dual encoder features...
2024-05-28T04:37:49 | INFO | utils.basic_utils : extracting image feats  [ 0/63]  eta: 0:18:04    time: 17.2077  data: 15.2478  max mem: 15302 res mem: 22900
2024-05-28T04:40:22 | INFO | utils.basic_utils : extracting image feats  [62/63]  eta: 0:00:02    time: 2.3397  data: 0.3968  max mem: 15302 res mem: 22900
2024-05-28T04:40:22 | INFO | utils.basic_utils : extracting image feats Total time: 0:02:50 (2.7029 s / it)
2024-05-28T04:40:34 | INFO | tasks.retrieval_utils : Finished feature extraction
2024-05-28T04:40:34 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product]
2024-05-28T04:40:34 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product], done!
2024-05-28T04:40:34 | INFO | tasks.retrieval_utils : Rerank dual-encoder results with cross-encoder...
2024-05-28T04:40:34 | INFO | tasks.retrieval_utils : i2t_scores.shape torch.Size([501, 2000])
2024-05-28T04:40:34 | INFO | tasks.retrieval_utils : n_clip_per_video=1, with eval_frame_ensemble=concat
2024-05-28T04:40:34 | INFO | utils.basic_utils : Evaluation:  [  0/501]  eta: 0:00:11    time: 0.0220  data: 0.0005  max mem: 15302 res mem: 22900
2024-05-28T04:40:43 | INFO | utils.basic_utils : Evaluation:  [100/501]  eta: 0:00:33    time: 0.0851  data: 0.0000  max mem: 15302 res mem: 22900
2024-05-28T04:40:51 | INFO | utils.basic_utils : Evaluation:  [200/501]  eta: 0:00:25    time: 0.0864  data: 0.0000  max mem: 15302 res mem: 22900
2024-05-28T04:41:00 | INFO | utils.basic_utils : Evaluation:  [300/501]  eta: 0:00:17    time: 0.0866  data: 0.0000  max mem: 15302 res mem: 22900
2024-05-28T04:41:09 | INFO | utils.basic_utils : Evaluation:  [400/501]  eta: 0:00:08    time: 0.0867  data: 0.0000  max mem: 15302 res mem: 22900
2024-05-28T04:41:17 | INFO | utils.basic_utils : Evaluation:  [500/501]  eta: 0:00:00    time: 0.0869  data: 0.0000  max mem: 15302 res mem: 22900
2024-05-28T04:41:17 | INFO | utils.basic_utils : Evaluation: Total time: 0:00:43 (0.0859 s / it)
2024-05-28T04:41:17 | INFO | tasks.retrieval_utils : t2i_scores.shape torch.Size([501, 2000])
2024-05-28T04:41:18 | INFO | utils.basic_utils : Evaluation:  [  0/501]  eta: 0:06:07    time: 0.7333  data: 0.0005  max mem: 15302 res mem: 22900
2024-05-28T04:42:34 | INFO | utils.basic_utils : Evaluation:  [100/501]  eta: 0:05:03    time: 0.7420  data: 0.0000  max mem: 15302 res mem: 22900
2024-05-28T04:43:49 | INFO | utils.basic_utils : Evaluation:  [200/501]  eta: 0:03:46    time: 0.7213  data: 0.0000  max mem: 15302 res mem: 22900
2024-05-28T04:45:05 | INFO | utils.basic_utils : Evaluation:  [300/501]  eta: 0:02:31    time: 0.7212  data: 0.0000  max mem: 15302 res mem: 22900
2024-05-28T04:46:19 | INFO | utils.basic_utils : Evaluation:  [400/501]  eta: 0:01:16    time: 0.7539  data: 0.0000  max mem: 15302 res mem: 22900
2024-05-28T04:47:34 | INFO | utils.basic_utils : Evaluation:  [500/501]  eta: 0:00:00    time: 0.7354  data: 0.0000  max mem: 15302 res mem: 22900
2024-05-28T04:47:34 | INFO | utils.basic_utils : Evaluation: Total time: 0:06:16 (0.7517 s / it)
2024-05-28T04:49:49 | INFO | tasks.retrieval_utils : Evaluation time 0:12:17
2024-05-28T04:49:50 | INFO | __main__ : Epoch 1
2024-05-28T04:49:50 | INFO | __main__ : 
           txt_r1  txt_r5  txt_r10  txt_r_mean  img_r1  img_r5  img_r10  img_r_mean  r_mean  txt_acc  img_acc
test/       31.20    74.9    84.35       63.48    32.3   76.75     85.3       64.78   64.13    50.05    49.65
test_emb/   28.05    70.7    80.85       59.87    29.1   70.00     81.4       60.17   60.02    49.00    49.75
2024-05-28T04:49:56 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 1448 batches in total
dataloader index=0 name=video, batch-size=32 length(#batches)=1448 
2024-05-28T04:50:11 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  builtin_warn(*args, **kwargs)

2024-05-28T04:50:11 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  builtin_warn(*args, **kwargs)

2024-05-28T04:50:11 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-05-28T04:50:11 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-05-28T04:50:13 | INFO | utils.basic_utils : Train Epoch: [2]  [   0/1448]  eta: 7:02:10  lr: 0.000009  temperature: 0.0112  video-loss_vtc: 1.7967  video-loss_vtm: 0.5835  time: 17.4937  data: 15.4887  max mem: 15302 res mem: 22900
2024-05-28T04:54:40 | INFO | utils.basic_utils : Train Epoch: [2]  [ 100/1448]  eta: 1:03:19  lr: 0.000008  temperature: 0.0112  video-loss_vtc: 1.8143  video-loss_vtm: 0.5738  time: 2.5370  data: 0.3913  max mem: 15302 res mem: 22900
2024-05-28T04:58:57 | INFO | utils.basic_utils : Train Epoch: [2]  [ 200/1448]  eta: 0:55:59  lr: 0.000008  temperature: 0.0112  video-loss_vtc: 1.7342  video-loss_vtm: 0.7199  time: 2.5878  data: 0.0209  max mem: 15302 res mem: 22900
2024-05-28T05:03:21 | INFO | utils.basic_utils : Train Epoch: [2]  [ 300/1448]  eta: 0:51:10  lr: 0.000008  temperature: 0.0112  video-loss_vtc: 1.4278  video-loss_vtm: 0.3518  time: 2.7618  data: 0.0018  max mem: 15302 res mem: 22900
2024-05-28T05:07:37 | INFO | utils.basic_utils : Train Epoch: [2]  [ 400/1448]  eta: 0:46:13  lr: 0.000008  temperature: 0.0112  video-loss_vtc: 1.3652  video-loss_vtm: 0.5105  time: 2.5798  data: 0.2537  max mem: 15302 res mem: 22900
2024-05-28T05:11:59 | INFO | utils.basic_utils : Train Epoch: [2]  [ 500/1448]  eta: 0:41:43  lr: 0.000007  temperature: 0.0112  video-loss_vtc: 1.7193  video-loss_vtm: 0.5593  time: 2.6365  data: 0.0015  max mem: 15302 res mem: 22900
2024-05-28T05:16:19 | INFO | utils.basic_utils : Train Epoch: [2]  [ 600/1448]  eta: 0:37:13  lr: 0.000007  temperature: 0.0112  video-loss_vtc: 1.7880  video-loss_vtm: 0.5361  time: 2.6195  data: 0.0018  max mem: 15302 res mem: 22900
2024-05-28T05:20:42 | INFO | utils.basic_utils : Train Epoch: [2]  [ 700/1448]  eta: 0:32:50  lr: 0.000007  temperature: 0.0112  video-loss_vtc: 1.8247  video-loss_vtm: 0.3764  time: 2.5897  data: 0.0020  max mem: 15302 res mem: 22900
2024-05-28T05:24:56 | INFO | utils.basic_utils : Train Epoch: [2]  [ 800/1448]  eta: 0:28:19  lr: 0.000007  temperature: 0.0112  video-loss_vtc: 1.5997  video-loss_vtm: 0.5774  time: 2.5822  data: 0.0019  max mem: 15302 res mem: 22900
2024-05-28T05:29:23 | INFO | utils.basic_utils : Train Epoch: [2]  [ 900/1448]  eta: 0:23:59  lr: 0.000006  temperature: 0.0112  video-loss_vtc: 1.4524  video-loss_vtm: 0.5943  time: 3.0015  data: 0.0021  max mem: 15302 res mem: 22900
2024-05-28T05:41:35 | INFO | utils.basic_utils : Train Epoch: [2]  [1000/1448]  eta: 0:23:06  lr: 0.000006  temperature: 0.0112  video-loss_vtc: 1.9434  video-loss_vtm: 0.6598  time: 7.5990  data: 0.0051  max mem: 15302 res mem: 22900
2024-05-28T05:51:44 | INFO | utils.basic_utils : Train Epoch: [2]  [1100/1448]  eta: 0:19:32  lr: 0.000006  temperature: 0.0112  video-loss_vtc: 1.8039  video-loss_vtm: 0.5797  time: 6.2497  data: 0.0075  max mem: 15302 res mem: 22900
2024-05-28T06:02:44 | INFO | utils.basic_utils : Train Epoch: [2]  [1200/1448]  eta: 0:15:02  lr: 0.000006  temperature: 0.0112  video-loss_vtc: 1.7012  video-loss_vtm: 0.6629  time: 6.4656  data: 0.0067  max mem: 15302 res mem: 22900
2024-05-28T06:13:14 | INFO | utils.basic_utils : Train Epoch: [2]  [1300/1448]  eta: 0:09:28  lr: 0.000005  temperature: 0.0112  video-loss_vtc: 1.9324  video-loss_vtm: 0.5389  time: 6.4759  data: 0.0040  max mem: 15302 res mem: 22900
2024-05-28T06:24:02 | INFO | utils.basic_utils : Train Epoch: [2]  [1400/1448]  eta: 0:03:13  lr: 0.000005  temperature: 0.0112  video-loss_vtc: 1.8791  video-loss_vtm: 0.7718  time: 6.4057  data: 0.0045  max mem: 15302 res mem: 22900
2024-05-28T06:29:09 | INFO | utils.basic_utils : Train Epoch: [2]  [1447/1448]  eta: 0:00:04  lr: 0.000005  temperature: 0.0112  video-loss_vtc: 1.6999  video-loss_vtm: 0.5469  time: 7.0753  data: 0.0033  max mem: 15302 res mem: 22900
2024-05-28T06:29:09 | INFO | utils.basic_utils : Train Epoch: [2] Total time: 1:39:13 (4.1113 s / it)
2024-05-28T06:29:09 | INFO | __main__ : Averaged train stats: lr: 0.0000  temperature: 0.0112  video-loss_vtc: 1.7131  video-loss_vtm: 0.5367
2024-05-28T06:29:09 | INFO | tasks.retrieval_utils : Start evaluation for media_type=video
2024-05-28T06:29:09 | INFO | tasks.retrieval_utils : Computing dual encoder features...
2024-05-28T06:29:42 | INFO | utils.basic_utils : extracting image feats  [ 0/63]  eta: 0:32:44    time: 31.1884  data: 25.4425  max mem: 15302 res mem: 22900
2024-05-28T06:36:07 | INFO | utils.basic_utils : extracting image feats  [62/63]  eta: 0:00:06    time: 7.1439  data: 0.0483  max mem: 15302 res mem: 22900
2024-05-28T06:36:07 | INFO | utils.basic_utils : extracting image feats Total time: 0:06:56 (6.6056 s / it)
2024-05-28T06:36:23 | INFO | tasks.retrieval_utils : Finished feature extraction
2024-05-28T06:36:23 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product]
2024-05-28T06:36:23 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product], done!
2024-05-28T06:36:23 | INFO | tasks.retrieval_utils : Rerank dual-encoder results with cross-encoder...
2024-05-28T06:36:23 | INFO | tasks.retrieval_utils : i2t_scores.shape torch.Size([501, 2000])
2024-05-28T06:36:23 | INFO | tasks.retrieval_utils : n_clip_per_video=1, with eval_frame_ensemble=concat
2024-05-28T06:36:23 | INFO | utils.basic_utils : Evaluation:  [  0/501]  eta: 0:00:21    time: 0.0419  data: 0.0008  max mem: 15302 res mem: 22900
2024-05-28T06:36:57 | INFO | utils.basic_utils : Evaluation:  [100/501]  eta: 0:02:17    time: 0.3528  data: 0.0000  max mem: 15302 res mem: 22900
2024-05-28T06:37:32 | INFO | utils.basic_utils : Evaluation:  [200/501]  eta: 0:01:43    time: 0.3583  data: 0.0000  max mem: 15302 res mem: 22900
2024-05-28T06:38:06 | INFO | utils.basic_utils : Evaluation:  [300/501]  eta: 0:01:09    time: 0.3564  data: 0.0000  max mem: 15302 res mem: 22900
2024-05-28T06:38:40 | INFO | utils.basic_utils : Evaluation:  [400/501]  eta: 0:00:34    time: 0.3458  data: 0.0000  max mem: 15302 res mem: 22900
2024-05-28T06:39:15 | INFO | utils.basic_utils : Evaluation:  [500/501]  eta: 0:00:00    time: 0.3447  data: 0.0000  max mem: 15302 res mem: 22900
2024-05-28T06:39:15 | INFO | utils.basic_utils : Evaluation: Total time: 0:02:52 (0.3442 s / it)
2024-05-28T06:39:15 | INFO | tasks.retrieval_utils : t2i_scores.shape torch.Size([501, 2000])
2024-05-28T06:39:17 | INFO | utils.basic_utils : Evaluation:  [  0/501]  eta: 0:09:15    time: 1.1094  data: 0.0009  max mem: 15302 res mem: 22900
2024-05-28T06:41:01 | INFO | utils.basic_utils : Evaluation:  [100/501]  eta: 0:06:57    time: 0.9945  data: 0.0000  max mem: 15302 res mem: 22900
2024-05-28T06:42:44 | INFO | utils.basic_utils : Evaluation:  [200/501]  eta: 0:05:12    time: 1.0728  data: 0.0000  max mem: 15302 res mem: 22900
2024-05-28T06:44:26 | INFO | utils.basic_utils : Evaluation:  [300/501]  eta: 0:03:27    time: 0.9643  data: 0.0000  max mem: 15302 res mem: 22900
2024-05-28T06:46:02 | INFO | utils.basic_utils : Evaluation:  [400/501]  eta: 0:01:42    time: 0.9278  data: 0.0000  max mem: 15302 res mem: 22900
2024-05-28T06:47:36 | INFO | utils.basic_utils : Evaluation:  [500/501]  eta: 0:00:00    time: 0.9066  data: 0.0000  max mem: 15302 res mem: 22900
2024-05-28T06:47:36 | INFO | utils.basic_utils : Evaluation: Total time: 0:08:20 (0.9993 s / it)
2024-05-28T06:47:36 | INFO | tasks.retrieval_utils : Evaluation time 0:18:27
2024-05-28T06:47:38 | INFO | __main__ : Epoch 2
2024-05-28T06:47:38 | INFO | __main__ : 
           txt_r1  txt_r5  txt_r10  txt_r_mean  img_r1  img_r5  img_r10  img_r_mean  r_mean  txt_acc  img_acc
test/       31.25   74.75    84.45       63.48   32.25    76.7    85.25       64.73   64.11    50.05    49.80
test_emb/   28.70   71.60    81.95       60.75   28.70    71.1    82.10       60.63   60.69    48.80    49.45
2024-05-28T06:47:38 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 1448 batches in total
dataloader index=0 name=video, batch-size=32 length(#batches)=1448 
2024-05-28T06:48:02 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  builtin_warn(*args, **kwargs)

2024-05-28T06:48:02 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  builtin_warn(*args, **kwargs)

2024-05-28T06:48:02 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-05-28T06:48:02 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-05-28T06:48:08 | INFO | utils.basic_utils : Train Epoch: [3]  [   0/1448]  eta: 11:57:28  lr: 0.000005  temperature: 0.0112  video-loss_vtc: 1.5801  video-loss_vtm: 0.4277  time: 29.7298  data: 23.9723  max mem: 15302 res mem: 22900
2024-05-28T06:58:51 | INFO | utils.basic_utils : Train Epoch: [3]  [ 100/1448]  eta: 2:29:42  lr: 0.000005  temperature: 0.0112  video-loss_vtc: 1.7414  video-loss_vtm: 0.4922  time: 6.3857  data: 0.0052  max mem: 15302 res mem: 22900
2024-05-28T07:09:52 | INFO | utils.basic_utils : Train Epoch: [3]  [ 200/1448]  eta: 2:18:01  lr: 0.000004  temperature: 0.0112  video-loss_vtc: 1.6518  video-loss_vtm: 0.7116  time: 6.6116  data: 0.0055  max mem: 15302 res mem: 22900
2024-05-28T07:21:01 | INFO | utils.basic_utils : Train Epoch: [3]  [ 300/1448]  eta: 2:07:18  lr: 0.000004  temperature: 0.0112  video-loss_vtc: 1.3154  video-loss_vtm: 0.4766  time: 6.5675  data: 0.0058  max mem: 15302 res mem: 22900
2024-05-28T07:32:38 | INFO | utils.basic_utils : Train Epoch: [3]  [ 400/1448]  eta: 1:57:36  lr: 0.000004  temperature: 0.0112  video-loss_vtc: 1.4802  video-loss_vtm: 0.5094  time: 7.0448  data: 0.0078  max mem: 15302 res mem: 22900
2024-05-28T07:44:18 | INFO | utils.basic_utils : Train Epoch: [3]  [ 500/1448]  eta: 1:47:13  lr: 0.000004  temperature: 0.0112  video-loss_vtc: 1.6395  video-loss_vtm: 0.6685  time: 7.2396  data: 0.0036  max mem: 15302 res mem: 22900
2024-05-28T07:53:59 | INFO | utils.basic_utils : Train Epoch: [3]  [ 600/1448]  eta: 1:33:37  lr: 0.000003  temperature: 0.0112  video-loss_vtc: 1.8293  video-loss_vtm: 0.5807  time: 5.6277  data: 0.0050  max mem: 15302 res mem: 22900
2024-05-28T08:02:27 | INFO | utils.basic_utils : Train Epoch: [3]  [ 700/1448]  eta: 1:19:50  lr: 0.000003  temperature: 0.0112  video-loss_vtc: 1.7165  video-loss_vtm: 0.4795  time: 5.0033  data: 0.0100  max mem: 15302 res mem: 22900
2024-05-28T08:10:33 | INFO | utils.basic_utils : Train Epoch: [3]  [ 800/1448]  eta: 1:07:04  lr: 0.000003  temperature: 0.0112  video-loss_vtc: 1.6459  video-loss_vtm: 0.6197  time: 4.8546  data: 0.0111  max mem: 15302 res mem: 22900
2024-05-28T08:18:20 | INFO | utils.basic_utils : Train Epoch: [3]  [ 900/1448]  eta: 0:55:10  lr: 0.000003  temperature: 0.0112  video-loss_vtc: 1.3865  video-loss_vtm: 0.4851  time: 4.6336  data: 0.0082  max mem: 15302 res mem: 22900
2024-05-28T08:26:06 | INFO | utils.basic_utils : Train Epoch: [3]  [1000/1448]  eta: 0:44:03  lr: 0.000002  temperature: 0.0112  video-loss_vtc: 1.9774  video-loss_vtm: 0.7192  time: 4.5005  data: 0.0097  max mem: 15302 res mem: 22900
2024-05-28T08:34:04 | INFO | utils.basic_utils : Train Epoch: [3]  [1100/1448]  eta: 0:33:38  lr: 0.000002  temperature: 0.0112  video-loss_vtc: 1.8435  video-loss_vtm: 0.4741  time: 4.7447  data: 0.0076  max mem: 15302 res mem: 22900
2024-05-28T08:42:00 | INFO | utils.basic_utils : Train Epoch: [3]  [1200/1448]  eta: 0:23:36  lr: 0.000002  temperature: 0.0112  video-loss_vtc: 1.5839  video-loss_vtm: 0.5707  time: 4.7749  data: 0.0054  max mem: 15302 res mem: 22900
2024-05-28T08:49:59 | INFO | utils.basic_utils : Train Epoch: [3]  [1300/1448]  eta: 0:13:55  lr: 0.000002  temperature: 0.0112  video-loss_vtc: 1.7726  video-loss_vtm: 0.3677  time: 4.8605  data: 0.0081  max mem: 15302 res mem: 22900
2024-05-28T08:57:54 | INFO | utils.basic_utils : Train Epoch: [3]  [1400/1448]  eta: 0:04:27  lr: 0.000002  temperature: 0.0112  video-loss_vtc: 1.8584  video-loss_vtm: 0.7461  time: 4.8548  data: 0.0092  max mem: 15302 res mem: 22900
2024-05-28T09:01:50 | INFO | utils.basic_utils : Train Epoch: [3]  [1447/1448]  eta: 0:00:05  lr: 0.000001  temperature: 0.0112  video-loss_vtc: 1.5702  video-loss_vtm: 0.5592  time: 5.1949  data: 0.0081  max mem: 15302 res mem: 22900
2024-05-28T09:01:50 | INFO | utils.basic_utils : Train Epoch: [3] Total time: 2:14:11 (5.5606 s / it)
2024-05-28T09:01:50 | INFO | __main__ : Averaged train stats: lr: 0.0000  temperature: 0.0112  video-loss_vtc: 1.6727  video-loss_vtm: 0.5364
2024-05-28T09:01:50 | INFO | tasks.retrieval_utils : Start evaluation for media_type=video
2024-05-28T09:01:50 | INFO | tasks.retrieval_utils : Computing dual encoder features...
2024-05-28T09:02:20 | INFO | utils.basic_utils : extracting image feats  [ 0/63]  eta: 0:29:35    time: 28.1853  data: 23.6810  max mem: 15302 res mem: 22900
2024-05-28T09:07:09 | INFO | utils.basic_utils : extracting image feats  [62/63]  eta: 0:00:05    time: 5.0108  data: 0.0484  max mem: 15302 res mem: 22900
2024-05-28T09:07:09 | INFO | utils.basic_utils : extracting image feats Total time: 0:05:18 (5.0481 s / it)
2024-05-28T09:07:24 | INFO | tasks.retrieval_utils : Finished feature extraction
2024-05-28T09:07:24 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product]
2024-05-28T09:07:24 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product], done!
2024-05-28T09:07:24 | INFO | tasks.retrieval_utils : Rerank dual-encoder results with cross-encoder...
2024-05-28T09:07:24 | INFO | tasks.retrieval_utils : i2t_scores.shape torch.Size([501, 2000])
2024-05-28T09:07:24 | INFO | tasks.retrieval_utils : n_clip_per_video=1, with eval_frame_ensemble=concat
2024-05-28T09:07:24 | INFO | utils.basic_utils : Evaluation:  [  0/501]  eta: 0:00:16    time: 0.0337  data: 0.0008  max mem: 15302 res mem: 22900
2024-05-28T09:07:51 | INFO | utils.basic_utils : Evaluation:  [100/501]  eta: 0:01:45    time: 0.2811  data: 0.0000  max mem: 15302 res mem: 22900
2024-05-28T09:08:17 | INFO | utils.basic_utils : Evaluation:  [200/501]  eta: 0:01:18    time: 0.2495  data: 0.0000  max mem: 15302 res mem: 22900
2024-05-28T09:08:44 | INFO | utils.basic_utils : Evaluation:  [300/501]  eta: 0:00:53    time: 0.2611  data: 0.0000  max mem: 15302 res mem: 22900
2024-05-28T09:09:10 | INFO | utils.basic_utils : Evaluation:  [400/501]  eta: 0:00:26    time: 0.2531  data: 0.0000  max mem: 15302 res mem: 22900
2024-05-28T09:09:36 | INFO | utils.basic_utils : Evaluation:  [500/501]  eta: 0:00:00    time: 0.2667  data: 0.0000  max mem: 15302 res mem: 22900
2024-05-28T09:09:36 | INFO | utils.basic_utils : Evaluation: Total time: 0:02:12 (0.2636 s / it)
2024-05-28T09:09:36 | INFO | tasks.retrieval_utils : t2i_scores.shape torch.Size([501, 2000])
2024-05-28T09:09:37 | INFO | utils.basic_utils : Evaluation:  [  0/501]  eta: 0:08:08    time: 0.9743  data: 0.0008  max mem: 15302 res mem: 22900
2024-05-28T09:11:12 | INFO | utils.basic_utils : Evaluation:  [100/501]  eta: 0:06:19    time: 0.9513  data: 0.0000  max mem: 15302 res mem: 22900
2024-05-28T09:12:47 | INFO | utils.basic_utils : Evaluation:  [200/501]  eta: 0:04:45    time: 0.9577  data: 0.0000  max mem: 15302 res mem: 22900
2024-05-28T09:14:18 | INFO | utils.basic_utils : Evaluation:  [300/501]  eta: 0:03:08    time: 0.9527  data: 0.0000  max mem: 15302 res mem: 22900
2024-05-28T09:15:49 | INFO | utils.basic_utils : Evaluation:  [400/501]  eta: 0:01:33    time: 0.8651  data: 0.0000  max mem: 15302 res mem: 22900
2024-05-28T09:17:19 | INFO | utils.basic_utils : Evaluation:  [500/501]  eta: 0:00:00    time: 0.8739  data: 0.0000  max mem: 15302 res mem: 22900
2024-05-28T09:17:19 | INFO | utils.basic_utils : Evaluation: Total time: 0:07:42 (0.9227 s / it)
2024-05-28T09:17:19 | INFO | tasks.retrieval_utils : Evaluation time 0:15:28
2024-05-28T09:17:21 | INFO | __main__ : Epoch 3
2024-05-28T09:17:21 | INFO | __main__ : 
           txt_r1  txt_r5  txt_r10  txt_r_mean  img_r1  img_r5  img_r10  img_r_mean  r_mean  txt_acc  img_acc
test/       31.55    74.8    84.55       63.63    32.3   76.75    85.25       64.77   64.20    50.10     49.8
test_emb/   28.60    72.2    82.15       60.98    28.6   72.00    82.50       61.03   61.01    48.85     48.9
2024-05-28T09:17:27 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 1448 batches in total
dataloader index=0 name=video, batch-size=32 length(#batches)=1448 
2024-05-28T09:17:52 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  builtin_warn(*args, **kwargs)

2024-05-28T09:17:52 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  builtin_warn(*args, **kwargs)

2024-05-28T09:17:52 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-05-28T09:17:52 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-05-28T09:17:56 | INFO | utils.basic_utils : Train Epoch: [4]  [   0/1448]  eta: 11:46:53  lr: 0.000001  temperature: 0.0112  video-loss_vtc: 1.7077  video-loss_vtm: 0.5535  time: 29.2909  data: 24.7291  max mem: 15302 res mem: 22900
2024-05-28T09:25:53 | INFO | utils.basic_utils : Train Epoch: [4]  [ 100/1448]  eta: 1:52:42  lr: 0.000001  temperature: 0.0112  video-loss_vtc: 1.6006  video-loss_vtm: 0.5717  time: 4.9199  data: 0.0070  max mem: 15302 res mem: 22900
2024-05-28T09:34:13 | INFO | utils.basic_utils : Train Epoch: [4]  [ 200/1448]  eta: 1:44:05  lr: 0.000001  temperature: 0.0112  video-loss_vtc: 1.6667  video-loss_vtm: 0.6927  time: 4.9940  data: 0.0066  max mem: 15302 res mem: 22900
2024-05-28T09:42:28 | INFO | utils.basic_utils : Train Epoch: [4]  [ 300/1448]  eta: 1:35:26  lr: 0.000001  temperature: 0.0112  video-loss_vtc: 1.3039  video-loss_vtm: 0.3002  time: 4.9281  data: 0.0080  max mem: 15302 res mem: 22900
2024-05-28T09:50:34 | INFO | utils.basic_utils : Train Epoch: [4]  [ 400/1448]  eta: 1:26:34  lr: 0.000001  temperature: 0.0112  video-loss_vtc: 1.4302  video-loss_vtm: 0.6025  time: 4.6535  data: 0.0104  max mem: 15302 res mem: 22900
2024-05-28T09:58:29 | INFO | utils.basic_utils : Train Epoch: [4]  [ 500/1448]  eta: 1:17:38  lr: 0.000001  temperature: 0.0112  video-loss_vtc: 1.8415  video-loss_vtm: 0.6709  time: 4.7411  data: 0.0078  max mem: 15302 res mem: 22900
2024-05-28T10:06:49 | INFO | utils.basic_utils : Train Epoch: [4]  [ 600/1448]  eta: 1:09:39  lr: 0.000001  temperature: 0.0112  video-loss_vtc: 1.8278  video-loss_vtm: 0.4463  time: 5.1743  data: 0.0072  max mem: 15302 res mem: 22900
2024-05-28T10:15:01 | INFO | utils.basic_utils : Train Epoch: [4]  [ 700/1448]  eta: 1:01:26  lr: 0.000000  temperature: 0.0112  video-loss_vtc: 1.7822  video-loss_vtm: 0.4744  time: 4.8937  data: 0.0069  max mem: 15302 res mem: 22900
2024-05-28T10:23:03 | INFO | utils.basic_utils : Train Epoch: [4]  [ 800/1448]  eta: 0:53:04  lr: 0.000000  temperature: 0.0112  video-loss_vtc: 1.6495  video-loss_vtm: 0.5519  time: 4.8485  data: 0.0073  max mem: 15302 res mem: 22900
2024-05-28T10:30:54 | INFO | utils.basic_utils : Train Epoch: [4]  [ 900/1448]  eta: 0:44:40  lr: 0.000000  temperature: 0.0112  video-loss_vtc: 1.4915  video-loss_vtm: 0.4623  time: 4.6486  data: 0.0063  max mem: 15302 res mem: 22900
2024-05-28T10:38:42 | INFO | utils.basic_utils : Train Epoch: [4]  [1000/1448]  eta: 0:36:21  lr: 0.000000  temperature: 0.0112  video-loss_vtc: 1.7546  video-loss_vtm: 0.6181  time: 4.6907  data: 0.0074  max mem: 15302 res mem: 22900
2024-05-28T10:46:43 | INFO | utils.basic_utils : Train Epoch: [4]  [1100/1448]  eta: 0:28:13  lr: 0.000000  temperature: 0.0112  video-loss_vtc: 1.9046  video-loss_vtm: 0.5466  time: 4.8070  data: 0.0082  max mem: 15302 res mem: 22900
2024-05-28T10:55:28 | INFO | utils.basic_utils : Train Epoch: [4]  [1200/1448]  eta: 0:20:14  lr: 0.000000  temperature: 0.0112  video-loss_vtc: 1.6557  video-loss_vtm: 0.6554  time: 5.4786  data: 0.0050  max mem: 15302 res mem: 22900
2024-05-28T11:04:30 | INFO | utils.basic_utils : Train Epoch: [4]  [1300/1448]  eta: 0:12:10  lr: 0.000000  temperature: 0.0112  video-loss_vtc: 1.7614  video-loss_vtm: 0.6373  time: 5.3233  data: 0.0068  max mem: 15302 res mem: 22900
2024-05-28T11:13:27 | INFO | utils.basic_utils : Train Epoch: [4]  [1400/1448]  eta: 0:03:58  lr: 0.000000  temperature: 0.0112  video-loss_vtc: 1.8844  video-loss_vtm: 0.8658  time: 5.3599  data: 0.0040  max mem: 15302 res mem: 22900
2024-05-28T11:17:42 | INFO | utils.basic_utils : Train Epoch: [4]  [1447/1448]  eta: 0:00:04  lr: 0.000000  temperature: 0.0112  video-loss_vtc: 1.6221  video-loss_vtm: 0.6539  time: 5.6096  data: 0.0054  max mem: 15302 res mem: 22900
2024-05-28T11:17:42 | INFO | utils.basic_utils : Train Epoch: [4] Total time: 2:00:14 (4.9826 s / it)
2024-05-28T11:17:42 | INFO | __main__ : Averaged train stats: lr: 0.0000  temperature: 0.0112  video-loss_vtc: 1.6601  video-loss_vtm: 0.5365
2024-05-28T11:17:42 | INFO | tasks.retrieval_utils : Start evaluation for media_type=video
2024-05-28T11:17:42 | INFO | tasks.retrieval_utils : Computing dual encoder features...
2024-05-28T11:18:12 | INFO | utils.basic_utils : extracting image feats  [ 0/63]  eta: 0:30:58    time: 29.4971  data: 24.8177  max mem: 15302 res mem: 22900
2024-05-28T11:23:23 | INFO | utils.basic_utils : extracting image feats  [62/63]  eta: 0:00:05    time: 5.4488  data: 0.0465  max mem: 15302 res mem: 22900
2024-05-28T11:23:23 | INFO | utils.basic_utils : extracting image feats Total time: 0:05:39 (5.3941 s / it)
2024-05-28T11:23:38 | INFO | tasks.retrieval_utils : Finished feature extraction
2024-05-28T11:23:38 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product]
2024-05-28T11:23:38 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product], done!
2024-05-28T11:23:38 | INFO | tasks.retrieval_utils : Rerank dual-encoder results with cross-encoder...
2024-05-28T11:23:38 | INFO | tasks.retrieval_utils : i2t_scores.shape torch.Size([501, 2000])
2024-05-28T11:23:38 | INFO | tasks.retrieval_utils : n_clip_per_video=1, with eval_frame_ensemble=concat
2024-05-28T11:23:39 | INFO | utils.basic_utils : Evaluation:  [  0/501]  eta: 0:00:19    time: 0.0398  data: 0.0008  max mem: 15302 res mem: 22900
2024-05-28T11:24:06 | INFO | utils.basic_utils : Evaluation:  [100/501]  eta: 0:01:50    time: 0.2848  data: 0.0000  max mem: 15302 res mem: 22900
2024-05-28T11:24:35 | INFO | utils.basic_utils : Evaluation:  [200/501]  eta: 0:01:24    time: 0.2754  data: 0.0000  max mem: 15302 res mem: 22900
2024-05-28T11:25:02 | INFO | utils.basic_utils : Evaluation:  [300/501]  eta: 0:00:55    time: 0.2632  data: 0.0000  max mem: 15302 res mem: 22900
2024-05-28T11:25:29 | INFO | utils.basic_utils : Evaluation:  [400/501]  eta: 0:00:27    time: 0.2774  data: 0.0000  max mem: 15302 res mem: 22900
2024-05-28T11:25:57 | INFO | utils.basic_utils : Evaluation:  [500/501]  eta: 0:00:00    time: 0.2851  data: 0.0000  max mem: 15302 res mem: 22900
2024-05-28T11:25:57 | INFO | utils.basic_utils : Evaluation: Total time: 0:02:18 (0.2772 s / it)
2024-05-28T11:25:58 | INFO | tasks.retrieval_utils : t2i_scores.shape torch.Size([501, 2000])
2024-05-28T11:25:59 | INFO | utils.basic_utils : Evaluation:  [  0/501]  eta: 0:07:58    time: 0.9541  data: 0.0007  max mem: 15302 res mem: 22900
2024-05-28T11:27:36 | INFO | utils.basic_utils : Evaluation:  [100/501]  eta: 0:06:31    time: 0.9590  data: 0.0000  max mem: 15302 res mem: 22900
2024-05-28T11:29:11 | INFO | utils.basic_utils : Evaluation:  [200/501]  eta: 0:04:49    time: 0.9656  data: 0.0000  max mem: 15302 res mem: 22900
2024-05-28T11:30:46 | INFO | utils.basic_utils : Evaluation:  [300/501]  eta: 0:03:12    time: 0.9284  data: 0.0000  max mem: 15302 res mem: 22900
2024-05-28T11:32:23 | INFO | utils.basic_utils : Evaluation:  [400/501]  eta: 0:01:37    time: 0.9179  data: 0.0000  max mem: 15302 res mem: 22900
2024-05-28T11:33:53 | INFO | utils.basic_utils : Evaluation:  [500/501]  eta: 0:00:00    time: 0.8649  data: 0.0000  max mem: 15302 res mem: 22900
2024-05-28T11:33:53 | INFO | utils.basic_utils : Evaluation: Total time: 0:07:54 (0.9481 s / it)
2024-05-28T11:34:18 | INFO | tasks.retrieval_utils : Evaluation time 0:16:36
2024-05-28T11:34:20 | INFO | __main__ : Epoch 4
2024-05-28T11:34:20 | INFO | __main__ : 
           txt_r1  txt_r5  txt_r10  txt_r_mean  img_r1  img_r5  img_r10  img_r_mean  r_mean  txt_acc  img_acc
test/       31.55    74.8     84.5       63.62    32.3   76.75    85.25       64.77   64.19    50.10    49.80
test_emb/   28.60    72.3     82.3       61.07    28.5   72.00    82.60       61.03   61.05    48.85    49.05
2024-05-28T11:34:21 | INFO | __main__ : Training time 9:15:49
2024-05-28T11:34:21 | INFO | __main__ : best epoch 3 [config.stop_key test/]
2024-05-28T11:34:21 | INFO | __main__ : Checkpoints and Logs saved at exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2
2024-05-28T11:34:22 | INFO | __main__ : ===========> START eval_after_training [['test']]
2024-05-28T11:34:22 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video'], 'test_file': {'test': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/test2k.json', '/data2/dy/temporal_video/dataset', 'video']}, 'test_types': ['test'], 'num_workers': 6, 'rtime': False, 'pos_num': 1, 'neg_num': 10, 'stop_key': 'test/', 'is_paragraph_retrieval': False, 'is_pretrain': False, 'num_frames': 12, 'num_frames_test': 12, 'batch_size': 32, 'max_txt_l': 50, 'evaluate': True, 'train_shuffle': False, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 12, 'sample_type': 'rand', 'num_frames_test': 12, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 50, 'video': 50}, 'batch_size': {'image': 32, 'video': 32}, 'batch_size_test': {'image': 32, 'video': 32}}, 'text_enc': 'bert', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_b16', 'img_size': 224, 'patch_size': 16, 'd_model': 768, 'encoder_embed_dim': 768, 'encoder_depth': 12, 'encoder_num_heads': 12, 'drop_path_rate': 0.2, 'num_frames': 12, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 12, 'clip_decoder_embed_dim': 768, 'clip_output_dim': 512, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 224, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'multimodal': {'enable': True}, 'embed_dim': 512, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 1e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 5, 'min_lr_multi': 0.01, 'warmup_epochs': 1, 'num_training_steps': 7240, 'num_warmup_steps': 1448}, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': False, 'entity': 'user', 'project': 'umt_ret'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': 'exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2/eval_after_training', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 3407, 'save_latest': True, 'auto_resume': True, 'pretrained_path': 'exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2/ckpt_best.pth', 'rank': 0, 'world_size': 4, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl', 'result_dir': 'exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2/eval_after_training'}
2024-05-28T11:34:22 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/reversed_in_time/shuffle/train_reverse_rewrite_shuffle.json', '/data2/dy/temporal_video/dataset', 'video']
2024-05-28T11:34:22 | INFO | tasks.pretrain : Creating dataset for ret
2024-05-28T11:34:22 | INFO | tasks.shared_utils : Creating model
2024-05-28T11:34:32 | INFO | models.umt : Build vision_encoder: vit_b16
2024-05-28T11:34:32 | INFO | models.backbones.vit.vit : Num of patches: 2352
2024-05-28T11:34:32 | INFO | models.backbones.vit.vit : Use checkpoint: True
2024-05-28T11:34:32 | INFO | models.backbones.vit.vit : Checkpoint number: 12
2024-05-28T11:34:32 | INFO | models.backbones.vit.vit : Student return index: []
2024-05-28T11:34:44 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
2024-05-28T11:34:44 | INFO | models.umt : Build text_encoder bert_base
2024-05-28T11:34:46 | INFO | models.backbones.bert.xbert : build bert with cross_module: ca
2024-05-28T11:34:46 | INFO | models.criterions : Norm type: l2
2024-05-28T11:34:46 | INFO | models.criterions : Loss type: l2
2024-05-28T11:34:51 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-05-28T11:34:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.lora_r: wd: 0, lr: 1e-05
2024-05-28T11:34:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T11:34:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T11:34:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T11:34:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T11:34:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T11:34:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.lora_r: wd: 0, lr: 1e-05
2024-05-28T11:34:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T11:34:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T11:34:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T11:34:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T11:34:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T11:34:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.lora_r: wd: 0, lr: 1e-05
2024-05-28T11:34:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T11:34:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T11:34:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T11:34:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T11:34:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T11:34:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.lora_r: wd: 0, lr: 1e-05
2024-05-28T11:34:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T11:34:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T11:34:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T11:34:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T11:34:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T11:34:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.lora_r: wd: 0, lr: 1e-05
2024-05-28T11:34:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T11:34:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T11:34:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T11:34:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T11:34:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T11:34:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.lora_r: wd: 0, lr: 1e-05
2024-05-28T11:34:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T11:34:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T11:34:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T11:34:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T11:34:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T11:34:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.lora_r: wd: 0, lr: 1e-05
2024-05-28T11:34:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T11:34:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T11:34:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T11:34:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T11:34:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T11:34:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.lora_r: wd: 0, lr: 1e-05
2024-05-28T11:34:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T11:34:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T11:34:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T11:34:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T11:34:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T11:34:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.lora_r: wd: 0, lr: 1e-05
2024-05-28T11:34:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T11:34:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T11:34:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T11:34:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T11:34:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T11:34:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.lora_r: wd: 0, lr: 1e-05
2024-05-28T11:34:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T11:34:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T11:34:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T11:34:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T11:34:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T11:34:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.lora_r: wd: 0, lr: 1e-05
2024-05-28T11:34:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T11:34:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T11:34:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T11:34:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T11:34:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T11:34:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.lora_r: wd: 0, lr: 1e-05
2024-05-28T11:34:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.q_bias: wd: 0, lr: 1e-05
2024-05-28T11:34:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.v_bias: wd: 0, lr: 1e-05
2024-05-28T11:34:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.qkv.weight: wd: 0.02, lr: 1e-05
2024-05-28T11:34:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T11:34:51 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn_temporal_mask.proj.bias: wd: 0, lr: 1e-05
2024-05-28T11:34:51 | INFO | utils.optimizer : param module.vision_proj.weight: wd: 0.02, lr: 1e-05
2024-05-28T11:34:51 | INFO | utils.optimizer : param module.vision_proj.bias: wd: 0, lr: 1e-05
2024-05-28T11:34:51 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0 len(p)=49
2024-05-28T11:34:51 | INFO | utils.optimizer : optimizer -- lr=1e-05 wd=0.02 len(p)=25
2024-05-28T11:34:51 | INFO | tasks.shared_utils : Auto resuming
2024-05-28T11:34:51 | INFO | tasks.shared_utils : Not found checkpoint in exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2/eval_after_training
2024-05-28T11:34:54 | INFO | tasks.shared_utils : <All keys matched successfully>
2024-05-28T11:34:54 | INFO | tasks.shared_utils : Loaded checkpoint from exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2/ckpt_best.pth
2024-05-28T11:34:54 | INFO | __main__ : Start evaluation
2024-05-28T11:34:54 | INFO | tasks.retrieval_utils : Start evaluation for media_type=video
2024-05-28T11:34:54 | INFO | tasks.retrieval_utils : Computing dual encoder features...
2024-05-28T11:34:56 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T11:34:56 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T11:34:56 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T11:34:56 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T11:34:57 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T11:34:57 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T11:34:57 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T11:34:57 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T11:34:57 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T11:34:57 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T11:34:57 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T11:34:57 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-05-28T11:35:22 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  builtin_warn(*args, **kwargs)

2024-05-28T11:35:22 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  builtin_warn(*args, **kwargs)

2024-05-28T11:35:22 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-05-28T11:35:22 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2024-05-28T11:35:29 | INFO | utils.basic_utils : extracting image feats  [ 0/63]  eta: 0:34:55    time: 33.2647  data: 26.3868  max mem: 15302 res mem: 22900
2024-05-28T11:40:32 | INFO | utils.basic_utils : extracting image feats  [62/63]  eta: 0:00:05    time: 4.5864  data: 0.0526  max mem: 15302 res mem: 22900
2024-05-28T11:40:32 | INFO | utils.basic_utils : extracting image feats Total time: 0:05:36 (5.3471 s / it)
2024-05-28T11:40:48 | INFO | tasks.retrieval_utils : Finished feature extraction
2024-05-28T11:40:48 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product]
2024-05-28T11:40:48 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product], done!
2024-05-28T11:40:48 | INFO | tasks.retrieval_utils : Rerank dual-encoder results with cross-encoder...
2024-05-28T11:40:48 | INFO | tasks.retrieval_utils : i2t_scores.shape torch.Size([501, 2000])
2024-05-28T11:40:48 | INFO | tasks.retrieval_utils : n_clip_per_video=1, with eval_frame_ensemble=concat
2024-05-28T11:40:48 | INFO | utils.basic_utils : Evaluation:  [  0/501]  eta: 0:00:21    time: 0.0422  data: 0.0013  max mem: 15302 res mem: 22900
2024-05-28T11:41:10 | INFO | utils.basic_utils : Evaluation:  [100/501]  eta: 0:01:26    time: 0.1743  data: 0.0000  max mem: 15302 res mem: 22900
2024-05-28T11:41:32 | INFO | utils.basic_utils : Evaluation:  [200/501]  eta: 0:01:04    time: 0.2200  data: 0.0000  max mem: 15302 res mem: 22900
2024-05-28T11:41:54 | INFO | utils.basic_utils : Evaluation:  [300/501]  eta: 0:00:43    time: 0.2305  data: 0.0000  max mem: 15302 res mem: 22900
2024-05-28T11:42:16 | INFO | utils.basic_utils : Evaluation:  [400/501]  eta: 0:00:22    time: 0.2272  data: 0.0000  max mem: 15302 res mem: 22900
2024-05-28T11:42:38 | INFO | utils.basic_utils : Evaluation:  [500/501]  eta: 0:00:00    time: 0.2162  data: 0.0000  max mem: 15302 res mem: 22900
2024-05-28T11:42:38 | INFO | utils.basic_utils : Evaluation: Total time: 0:01:50 (0.2200 s / it)
2024-05-28T11:42:39 | INFO | tasks.retrieval_utils : t2i_scores.shape torch.Size([501, 2000])
2024-05-28T11:42:39 | INFO | utils.basic_utils : Evaluation:  [  0/501]  eta: 0:06:49    time: 0.8177  data: 0.0009  max mem: 15302 res mem: 22900
2024-05-28T11:43:57 | INFO | utils.basic_utils : Evaluation:  [100/501]  eta: 0:05:10    time: 0.8039  data: 0.0000  max mem: 15302 res mem: 22900
2024-05-28T11:45:10 | INFO | utils.basic_utils : Evaluation:  [200/501]  eta: 0:03:46    time: 0.7157  data: 0.0000  max mem: 15302 res mem: 22900
2024-05-28T11:46:26 | INFO | utils.basic_utils : Evaluation:  [300/501]  eta: 0:02:31    time: 0.8003  data: 0.0000  max mem: 15302 res mem: 22900
2024-05-28T11:47:42 | INFO | utils.basic_utils : Evaluation:  [400/501]  eta: 0:01:16    time: 0.7420  data: 0.0000  max mem: 15302 res mem: 22900
2024-05-28T11:48:51 | INFO | utils.basic_utils : Evaluation:  [500/501]  eta: 0:00:00    time: 0.6909  data: 0.0000  max mem: 15302 res mem: 22900
2024-05-28T11:48:51 | INFO | utils.basic_utils : Evaluation: Total time: 0:06:12 (0.7437 s / it)
2024-05-28T11:49:15 | INFO | tasks.retrieval_utils : Evaluation time 0:14:21
2024-05-28T11:49:18 | INFO | __main__ : Epoch 0
2024-05-28T11:49:18 | INFO | __main__ : 
           txt_r1  txt_r5  txt_r10  txt_r_mean  img_r1  img_r5  img_r10  img_r_mean  r_mean  txt_acc  img_acc
test/       31.55    74.8    84.55       63.63    32.3   76.75    85.25       64.77   64.20    50.10     49.8
test_emb/   28.60    72.2    82.15       60.98    28.6   72.00    82.50       61.03   61.01    48.85     48.9
2024-05-28T11:49:18 | INFO | __main__ : Training time 0:14:24
2024-05-28T11:49:18 | INFO | __main__ : best epoch 0 [config.stop_key test/]
2024-05-28T11:49:18 | INFO | __main__ : Checkpoints and Logs saved at exp/finetuning/ret_rtime_vlp/without_rewrite_vlm2/eval_after_training
