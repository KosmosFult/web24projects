2023-12-30T15:33:32 | INFO | umt : Logging to: exp/finetuning/ret_ssv2_label/b16_25m/train.log
2023-12-30T15:33:32 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  your_ssv2_path: /datassd2/DATASET/something-something-v2/rawvideo/20bn-something-something-v2
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/ssv2_ret_label_train.json', '/datassd2/DATASET/something-something-v2/rawvideo/20bn-something-something-v2', 'video']
  test_file: {
      val: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/ssv2_ret_label_val_small.json', '/datassd2/DATASET/something-something-v2/rawvideo/20bn-something-something-v2', 'video'] }
  test_types: ['val']
  num_workers: 6
  stop_key: val/
  is_paragraph_retrieval: False
  has_multi_vision_gt: True
  num_frames: 12
  num_frames_test: 12
  batch_size: 32
  max_txt_l: 25
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 12
          sample_type: rand
          num_frames_test: 12
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 25
          video: 25 }
      batch_size: {
          image: 32
          video: 32 }
      batch_size_test: {
          image: 32
          video: 32 } }
  text_enc: bert
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_b16
          img_size: 224
          patch_size: 16
          d_model: 768
          encoder_embed_dim: 768
          encoder_depth: 12
          encoder_num_heads: 12
          drop_path_rate: 0.1
          num_frames: 12
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 12
          clip_decoder_embed_dim: 768
          clip_output_dim: 512
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 224
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      multimodal: {
          enable: True }
      embed_dim: 512
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 5e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 0
      min_lr_multi: 0.01
      warmup_epochs: 0 }
  evaluate: False
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: True
      entity: user
      project: umt_ret_ssv2 }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/finetuning/ret_ssv2_label/b16_25m
  resume: False
  debug: False
  log_freq: 100
  seed: 42
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
  rank: 0
  world_size: 1
  gpu: 0
  distributed: True
  dist_backend: nccl }
2023-12-30T15:33:40 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'your_ssv2_path': '/datassd2/DATASET/something-something-v2/rawvideo/20bn-something-something-v2', 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/ssv2_ret_label_train.json', '/datassd2/DATASET/something-something-v2/rawvideo/20bn-something-something-v2', 'video'], 'test_file': {'val': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/ssv2_ret_label_val_small.json', '/datassd2/DATASET/something-something-v2/rawvideo/20bn-something-something-v2', 'video']}, 'test_types': ['val'], 'num_workers': 6, 'stop_key': 'val/', 'is_paragraph_retrieval': False, 'has_multi_vision_gt': True, 'num_frames': 12, 'num_frames_test': 12, 'batch_size': 32, 'max_txt_l': 25, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 12, 'sample_type': 'rand', 'num_frames_test': 12, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 25, 'video': 25}, 'batch_size': {'image': 32, 'video': 32}, 'batch_size_test': {'image': 32, 'video': 32}}, 'text_enc': 'bert', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_b16', 'img_size': 224, 'patch_size': 16, 'd_model': 768, 'encoder_embed_dim': 768, 'encoder_depth': 12, 'encoder_num_heads': 12, 'drop_path_rate': 0.1, 'num_frames': 12, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 12, 'clip_decoder_embed_dim': 768, 'clip_output_dim': 512, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 224, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'multimodal': {'enable': True}, 'embed_dim': 512, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 5e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 0, 'min_lr_multi': 0.01, 'warmup_epochs': 0}, 'evaluate': False, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': True, 'entity': 'user', 'project': 'umt_ret_ssv2'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': 'exp/finetuning/ret_ssv2_label/b16_25m', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 42, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth', 'rank': 0, 'world_size': 1, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2023-12-30T15:33:40 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/ssv2_ret_label_train.json', '/datassd2/DATASET/something-something-v2/rawvideo/20bn-something-something-v2', 'video']
2023-12-30T15:33:40 | INFO | tasks.pretrain : Creating dataset for ret
2023-12-30T15:33:41 | INFO | tasks.shared_utils : Creating model
2023-12-30T15:33:54 | INFO | models.umt : Build vision_encoder: vit_b16
2023-12-30T15:33:54 | INFO | models.backbones.vit.vit : Num of patches: 2352
2023-12-30T15:33:54 | INFO | models.backbones.vit.vit : Use checkpoint: True
2023-12-30T15:33:54 | INFO | models.backbones.vit.vit : Checkpoint number: 12
2023-12-30T15:33:54 | INFO | models.backbones.vit.vit : Student return index: []
2023-12-30T15:34:03 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
2023-12-30T15:34:03 | INFO | models.umt : Build text_encoder bert_base
2023-12-30T15:34:05 | INFO | models.backbones.bert.xbert : build bert with cross_module: ca
2023-12-30T15:34:06 | INFO | models.criterions : Norm type: l2
2023-12-30T15:34:06 | INFO | models.criterions : Loss type: l2
2023-12-30T15:34:06 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.temp: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.q_bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.v_bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.qkv.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.q_bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.v_bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.qkv.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.q_bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.v_bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.qkv.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.q_bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.v_bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.qkv.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.q_bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.v_bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.qkv.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.q_bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.v_bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.qkv.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.q_bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.v_bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.qkv.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.q_bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.v_bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.qkv.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.q_bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.v_bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.qkv.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.q_bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.v_bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.qkv.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.q_bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.v_bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.qkv.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.q_bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.v_bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.qkv.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.embeddings.word_embeddings.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.embeddings.position_embeddings.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.embeddings.token_type_embeddings.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_proj.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.vision_proj.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_proj.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.text_proj.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.itm_head.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : param module.itm_head.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:06 | INFO | utils.optimizer : optimizer -- lr=5e-05 wd=0.02 len(p)=140
2023-12-30T15:34:06 | INFO | utils.optimizer : optimizer -- lr=5e-05 wd=0 len(p)=256
2023-12-30T15:34:06 | INFO | tasks.shared_utils : Auto resuming
2023-12-30T15:34:06 | INFO | tasks.shared_utils : Not found checkpoint in exp/finetuning/ret_ssv2_label/b16_25m
2023-12-30T15:34:09 | INFO | tasks.shared_utils : _IncompatibleKeys(missing_keys=[], unexpected_keys=['clip_teacher.class_embedding', 'clip_teacher.positional_embedding', 'clip_teacher.proj', 'clip_teacher.conv1.weight', 'clip_teacher.ln_pre.weight', 'clip_teacher.ln_pre.bias', 'clip_teacher.transformer.resblocks.0.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.0.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.0.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.0.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.0.ln_1.weight', 'clip_teacher.transformer.resblocks.0.ln_1.bias', 'clip_teacher.transformer.resblocks.0.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.0.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.0.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.0.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.0.ln_2.weight', 'clip_teacher.transformer.resblocks.0.ln_2.bias', 'clip_teacher.transformer.resblocks.1.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.1.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.1.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.1.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.1.ln_1.weight', 'clip_teacher.transformer.resblocks.1.ln_1.bias', 'clip_teacher.transformer.resblocks.1.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.1.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.1.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.1.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.1.ln_2.weight', 'clip_teacher.transformer.resblocks.1.ln_2.bias', 'clip_teacher.transformer.resblocks.2.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.2.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.2.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.2.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.2.ln_1.weight', 'clip_teacher.transformer.resblocks.2.ln_1.bias', 'clip_teacher.transformer.resblocks.2.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.2.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.2.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.2.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.2.ln_2.weight', 'clip_teacher.transformer.resblocks.2.ln_2.bias', 'clip_teacher.transformer.resblocks.3.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.3.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.3.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.3.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.3.ln_1.weight', 'clip_teacher.transformer.resblocks.3.ln_1.bias', 'clip_teacher.transformer.resblocks.3.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.3.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.3.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.3.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.3.ln_2.weight', 'clip_teacher.transformer.resblocks.3.ln_2.bias', 'clip_teacher.transformer.resblocks.4.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.4.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.4.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.4.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.4.ln_1.weight', 'clip_teacher.transformer.resblocks.4.ln_1.bias', 'clip_teacher.transformer.resblocks.4.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.4.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.4.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.4.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.4.ln_2.weight', 'clip_teacher.transformer.resblocks.4.ln_2.bias', 'clip_teacher.transformer.resblocks.5.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.5.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.5.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.5.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.5.ln_1.weight', 'clip_teacher.transformer.resblocks.5.ln_1.bias', 'clip_teacher.transformer.resblocks.5.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.5.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.5.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.5.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.5.ln_2.weight', 'clip_teacher.transformer.resblocks.5.ln_2.bias', 'clip_teacher.transformer.resblocks.6.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.6.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.6.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.6.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.6.ln_1.weight', 'clip_teacher.transformer.resblocks.6.ln_1.bias', 'clip_teacher.transformer.resblocks.6.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.6.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.6.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.6.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.6.ln_2.weight', 'clip_teacher.transformer.resblocks.6.ln_2.bias', 'clip_teacher.transformer.resblocks.7.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.7.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.7.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.7.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.7.ln_1.weight', 'clip_teacher.transformer.resblocks.7.ln_1.bias', 'clip_teacher.transformer.resblocks.7.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.7.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.7.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.7.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.7.ln_2.weight', 'clip_teacher.transformer.resblocks.7.ln_2.bias', 'clip_teacher.transformer.resblocks.8.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.8.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.8.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.8.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.8.ln_1.weight', 'clip_teacher.transformer.resblocks.8.ln_1.bias', 'clip_teacher.transformer.resblocks.8.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.8.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.8.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.8.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.8.ln_2.weight', 'clip_teacher.transformer.resblocks.8.ln_2.bias', 'clip_teacher.transformer.resblocks.9.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.9.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.9.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.9.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.9.ln_1.weight', 'clip_teacher.transformer.resblocks.9.ln_1.bias', 'clip_teacher.transformer.resblocks.9.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.9.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.9.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.9.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.9.ln_2.weight', 'clip_teacher.transformer.resblocks.9.ln_2.bias', 'clip_teacher.transformer.resblocks.10.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.10.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.10.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.10.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.10.ln_1.weight', 'clip_teacher.transformer.resblocks.10.ln_1.bias', 'clip_teacher.transformer.resblocks.10.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.10.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.10.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.10.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.10.ln_2.weight', 'clip_teacher.transformer.resblocks.10.ln_2.bias', 'clip_teacher.transformer.resblocks.11.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.11.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.11.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.11.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.11.ln_1.weight', 'clip_teacher.transformer.resblocks.11.ln_1.bias', 'clip_teacher.transformer.resblocks.11.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.11.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.11.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.11.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.11.ln_2.weight', 'clip_teacher.transformer.resblocks.11.ln_2.bias', 'clip_teacher.ln_post.weight', 'clip_teacher.ln_post.bias', 'vision_encoder.clip_decoder.0.head.weight', 'vision_encoder.clip_decoder.0.head.bias', 'vision_encoder.clip_decoder.0.norm.weight', 'vision_encoder.clip_decoder.0.norm.bias', 'vision_encoder.clip_decoder.1.head.weight', 'vision_encoder.clip_decoder.1.head.bias', 'vision_encoder.clip_decoder.1.norm.weight', 'vision_encoder.clip_decoder.1.norm.bias', 'vision_encoder.clip_decoder.2.head.weight', 'vision_encoder.clip_decoder.2.head.bias', 'vision_encoder.clip_decoder.2.norm.weight', 'vision_encoder.clip_decoder.2.norm.bias', 'vision_encoder.clip_decoder.3.head.weight', 'vision_encoder.clip_decoder.3.head.bias', 'vision_encoder.clip_decoder.3.norm.weight', 'vision_encoder.clip_decoder.3.norm.bias', 'vision_encoder.clip_decoder.4.head.weight', 'vision_encoder.clip_decoder.4.head.bias', 'vision_encoder.clip_decoder.4.norm.weight', 'vision_encoder.clip_decoder.4.norm.bias', 'vision_encoder.clip_decoder.5.head.weight', 'vision_encoder.clip_decoder.5.head.bias', 'vision_encoder.clip_decoder.5.norm.weight', 'vision_encoder.clip_decoder.5.norm.bias', 'text_encoder.cls.predictions.bias', 'text_encoder.cls.predictions.transform.dense.weight', 'text_encoder.cls.predictions.transform.dense.bias', 'text_encoder.cls.predictions.transform.LayerNorm.weight', 'text_encoder.cls.predictions.transform.LayerNorm.bias', 'text_encoder.cls.predictions.decoder.weight', 'text_encoder.cls.predictions.decoder.bias'])
2023-12-30T15:34:09 | INFO | tasks.shared_utils : Loaded checkpoint from /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
2023-12-30T15:34:09 | INFO | __main__ : training
2023-12-30T15:34:09 | INFO | __main__ : Training time 0:00:00
2023-12-30T15:34:09 | INFO | __main__ : best epoch 0 [config.stop_key val/]
2023-12-30T15:34:09 | INFO | __main__ : Checkpoints and Logs saved at exp/finetuning/ret_ssv2_label/b16_25m
2023-12-30T15:34:11 | INFO | __main__ : ===========> START eval_after_training [['val']]
2023-12-30T15:34:11 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'your_ssv2_path': '/datassd2/DATASET/something-something-v2/rawvideo/20bn-something-something-v2', 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/ssv2_ret_label_train.json', '/datassd2/DATASET/something-something-v2/rawvideo/20bn-something-something-v2', 'video'], 'test_file': {'val': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/ssv2_ret_label_val_small.json', '/datassd2/DATASET/something-something-v2/rawvideo/20bn-something-something-v2', 'video']}, 'test_types': ['val'], 'num_workers': 6, 'stop_key': 'val/', 'is_paragraph_retrieval': False, 'has_multi_vision_gt': True, 'num_frames': 12, 'num_frames_test': 12, 'batch_size': 32, 'max_txt_l': 25, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 12, 'sample_type': 'rand', 'num_frames_test': 12, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 25, 'video': 25}, 'batch_size': {'image': 32, 'video': 32}, 'batch_size_test': {'image': 32, 'video': 32}}, 'text_enc': 'bert', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_b16', 'img_size': 224, 'patch_size': 16, 'd_model': 768, 'encoder_embed_dim': 768, 'encoder_depth': 12, 'encoder_num_heads': 12, 'drop_path_rate': 0.1, 'num_frames': 12, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 12, 'clip_decoder_embed_dim': 768, 'clip_output_dim': 512, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 224, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'multimodal': {'enable': True}, 'embed_dim': 512, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 5e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 0, 'min_lr_multi': 0.01, 'warmup_epochs': 0, 'num_training_steps': 0, 'num_warmup_steps': 0}, 'evaluate': True, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': False, 'entity': 'user', 'project': 'umt_ret_ssv2'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': 'exp/finetuning/ret_ssv2_label/b16_25m/eval_after_training', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 42, 'save_latest': True, 'auto_resume': True, 'pretrained_path': 'exp/finetuning/ret_ssv2_label/b16_25m/ckpt_best.pth', 'rank': 0, 'world_size': 1, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl', 'result_dir': 'exp/finetuning/ret_ssv2_label/b16_25m/eval_after_training'}
2023-12-30T15:34:11 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/ssv2_ret_label_train.json', '/datassd2/DATASET/something-something-v2/rawvideo/20bn-something-something-v2', 'video']
2023-12-30T15:34:11 | INFO | tasks.pretrain : Creating dataset for ret
2023-12-30T15:34:11 | INFO | tasks.shared_utils : Creating model
2023-12-30T15:34:24 | INFO | models.umt : Build vision_encoder: vit_b16
2023-12-30T15:34:24 | INFO | models.backbones.vit.vit : Num of patches: 2352
2023-12-30T15:34:24 | INFO | models.backbones.vit.vit : Use checkpoint: True
2023-12-30T15:34:24 | INFO | models.backbones.vit.vit : Checkpoint number: 12
2023-12-30T15:34:24 | INFO | models.backbones.vit.vit : Student return index: []
2023-12-30T15:34:34 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
2023-12-30T15:34:34 | INFO | models.umt : Build text_encoder bert_base
2023-12-30T15:34:36 | INFO | models.backbones.bert.xbert : build bert with cross_module: ca
2023-12-30T15:34:36 | INFO | models.criterions : Norm type: l2
2023-12-30T15:34:36 | INFO | models.criterions : Loss type: l2
2023-12-30T15:34:37 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.temp: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.q_bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.v_bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.qkv.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.q_bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.v_bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.qkv.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.q_bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.v_bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.qkv.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.q_bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.v_bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.qkv.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.q_bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.v_bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.qkv.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.q_bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.v_bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.qkv.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.q_bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.v_bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.qkv.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.q_bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.v_bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.qkv.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.q_bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.v_bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.qkv.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.q_bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.v_bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.qkv.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.q_bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.v_bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.qkv.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.q_bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.v_bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.qkv.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.embeddings.word_embeddings.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.embeddings.position_embeddings.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.embeddings.token_type_embeddings.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_proj.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.vision_proj.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_proj.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.text_proj.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.itm_head.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : param module.itm_head.bias: wd: 0, lr: 5e-05
2023-12-30T15:34:37 | INFO | utils.optimizer : optimizer -- lr=5e-05 wd=0.02 len(p)=140
2023-12-30T15:34:37 | INFO | utils.optimizer : optimizer -- lr=5e-05 wd=0 len(p)=256
2023-12-30T15:34:37 | INFO | tasks.shared_utils : Auto resuming
2023-12-30T15:34:37 | INFO | tasks.shared_utils : Not found checkpoint in exp/finetuning/ret_ssv2_label/b16_25m/eval_after_training
2023-12-30T15:34:37 | WARNING | tasks.shared_utils : No pretrained checkpoint provided, training from scratch
2023-12-30T15:34:37 | INFO | __main__ : Start evaluation
2023-12-30T15:34:37 | INFO | __main__ : Training time 0:00:00
2023-12-30T15:34:37 | INFO | __main__ : best epoch 0 [config.stop_key val/]
2023-12-30T15:34:37 | INFO | __main__ : Checkpoints and Logs saved at exp/finetuning/ret_ssv2_label/b16_25m/eval_after_training
2023-12-30T15:37:08 | INFO | umt : Logging to: exp/finetuning/ret_ssv2_label/b16_25m/train.log
2023-12-30T15:37:08 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  your_ssv2_path: /datassd2/DATASET/something-something-v2/rawvideo/20bn-something-something-v2
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/ssv2_ret_label_train.json', '/datassd2/DATASET/something-something-v2/rawvideo/20bn-something-something-v2', 'video']
  test_file: {
      val: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/ssv2_ret_label_val_small.json', '/datassd2/DATASET/something-something-v2/rawvideo/20bn-something-something-v2', 'video'] }
  test_types: ['val']
  num_workers: 6
  stop_key: val/
  is_paragraph_retrieval: False
  has_multi_vision_gt: True
  num_frames: 12
  num_frames_test: 12
  batch_size: 32
  max_txt_l: 25
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 12
          sample_type: rand
          num_frames_test: 12
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 25
          video: 25 }
      batch_size: {
          image: 32
          video: 32 }
      batch_size_test: {
          image: 32
          video: 32 } }
  text_enc: bert
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_b16
          img_size: 224
          patch_size: 16
          d_model: 768
          encoder_embed_dim: 768
          encoder_depth: 12
          encoder_num_heads: 12
          drop_path_rate: 0.1
          num_frames: 12
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 12
          clip_decoder_embed_dim: 768
          clip_output_dim: 512
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 224
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      multimodal: {
          enable: True }
      embed_dim: 512
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 5e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 0
      min_lr_multi: 0.01
      warmup_epochs: 0 }
  evaluate: False
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: True
      entity: user
      project: umt_ret_ssv2 }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/finetuning/ret_ssv2_label/b16_25m
  resume: False
  debug: False
  log_freq: 100
  seed: 42
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
  rank: 0
  world_size: 1
  gpu: 0
  distributed: True
  dist_backend: nccl }
2023-12-30T15:39:01 | INFO | umt : Logging to: exp/finetuning/ret_ssv2_label/b16_25m/train.log
2023-12-30T15:39:01 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  your_ssv2_path: /datassd2/DATASET/something-something-v2/rawvideo/20bn-something-something-v2
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/ssv2_ret_label_train.json', '/datassd2/DATASET/something-something-v2/rawvideo/20bn-something-something-v2', 'video']
  test_file: {
      val: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/ssv2_ret_label_val_small.json', '/datassd2/DATASET/something-something-v2/rawvideo/20bn-something-something-v2', 'video'] }
  test_types: ['val']
  num_workers: 6
  stop_key: val/
  is_paragraph_retrieval: False
  has_multi_vision_gt: True
  num_frames: 12
  num_frames_test: 12
  batch_size: 32
  max_txt_l: 25
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 12
          sample_type: rand
          num_frames_test: 12
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 25
          video: 25 }
      batch_size: {
          image: 32
          video: 32 }
      batch_size_test: {
          image: 32
          video: 32 } }
  text_enc: bert
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_b16
          img_size: 224
          patch_size: 16
          d_model: 768
          encoder_embed_dim: 768
          encoder_depth: 12
          encoder_num_heads: 12
          drop_path_rate: 0.1
          num_frames: 12
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 12
          clip_decoder_embed_dim: 768
          clip_output_dim: 512
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 224
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      multimodal: {
          enable: True }
      embed_dim: 512
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 5e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 0
      min_lr_multi: 0.01
      warmup_epochs: 0 }
  evaluate: True
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: user
      project: umt_ret_ssv2 }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/finetuning/ret_ssv2_label/b16_25m
  resume: False
  debug: False
  log_freq: 100
  seed: 42
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
  rank: 0
  world_size: 1
  gpu: 0
  distributed: True
  dist_backend: nccl }
2023-12-30T15:39:01 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'your_ssv2_path': '/datassd2/DATASET/something-something-v2/rawvideo/20bn-something-something-v2', 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/ssv2_ret_label_train.json', '/datassd2/DATASET/something-something-v2/rawvideo/20bn-something-something-v2', 'video'], 'test_file': {'val': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/ssv2_ret_label_val_small.json', '/datassd2/DATASET/something-something-v2/rawvideo/20bn-something-something-v2', 'video']}, 'test_types': ['val'], 'num_workers': 6, 'stop_key': 'val/', 'is_paragraph_retrieval': False, 'has_multi_vision_gt': True, 'num_frames': 12, 'num_frames_test': 12, 'batch_size': 32, 'max_txt_l': 25, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 12, 'sample_type': 'rand', 'num_frames_test': 12, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 25, 'video': 25}, 'batch_size': {'image': 32, 'video': 32}, 'batch_size_test': {'image': 32, 'video': 32}}, 'text_enc': 'bert', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_b16', 'img_size': 224, 'patch_size': 16, 'd_model': 768, 'encoder_embed_dim': 768, 'encoder_depth': 12, 'encoder_num_heads': 12, 'drop_path_rate': 0.1, 'num_frames': 12, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 12, 'clip_decoder_embed_dim': 768, 'clip_output_dim': 512, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 224, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'multimodal': {'enable': True}, 'embed_dim': 512, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 5e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 0, 'min_lr_multi': 0.01, 'warmup_epochs': 0}, 'evaluate': True, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': False, 'entity': 'user', 'project': 'umt_ret_ssv2'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': 'exp/finetuning/ret_ssv2_label/b16_25m', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 42, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth', 'rank': 0, 'world_size': 1, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2023-12-30T15:39:01 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/ssv2_ret_label_train.json', '/datassd2/DATASET/something-something-v2/rawvideo/20bn-something-something-v2', 'video']
2023-12-30T15:39:01 | INFO | tasks.pretrain : Creating dataset for ret
2023-12-30T15:39:02 | INFO | tasks.shared_utils : Creating model
2023-12-30T15:39:15 | INFO | models.umt : Build vision_encoder: vit_b16
2023-12-30T15:39:15 | INFO | models.backbones.vit.vit : Num of patches: 2352
2023-12-30T15:39:15 | INFO | models.backbones.vit.vit : Use checkpoint: True
2023-12-30T15:39:15 | INFO | models.backbones.vit.vit : Checkpoint number: 12
2023-12-30T15:39:15 | INFO | models.backbones.vit.vit : Student return index: []
2023-12-30T15:39:23 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
2023-12-30T15:39:23 | INFO | models.umt : Build text_encoder bert_base
2023-12-30T15:39:25 | INFO | models.backbones.bert.xbert : build bert with cross_module: ca
2023-12-30T15:39:26 | INFO | models.criterions : Norm type: l2
2023-12-30T15:39:26 | INFO | models.criterions : Loss type: l2
2023-12-30T15:39:26 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.temp: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.weight: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.q_bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.v_bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.qkv.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.weight: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.weight: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.q_bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.v_bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.qkv.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.weight: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.weight: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.q_bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.v_bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.qkv.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.weight: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.weight: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.q_bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.v_bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.qkv.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.weight: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.weight: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.q_bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.v_bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.qkv.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.weight: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.weight: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.q_bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.v_bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.qkv.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.weight: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.weight: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.q_bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.v_bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.qkv.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.weight: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.weight: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.q_bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.v_bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.qkv.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.weight: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.weight: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.q_bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.v_bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.qkv.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.weight: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.weight: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.q_bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.v_bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.qkv.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.weight: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.weight: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.q_bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.v_bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.qkv.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.weight: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.weight: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.q_bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.v_bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.qkv.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.weight: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.weight: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.weight: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.embeddings.word_embeddings.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.embeddings.position_embeddings.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.embeddings.token_type_embeddings.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_proj.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.vision_proj.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_proj.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.text_proj.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.itm_head.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : param module.itm_head.bias: wd: 0, lr: 5e-05
2023-12-30T15:39:26 | INFO | utils.optimizer : optimizer -- lr=5e-05 wd=0.02 len(p)=140
2023-12-30T15:39:26 | INFO | utils.optimizer : optimizer -- lr=5e-05 wd=0 len(p)=256
2023-12-30T15:39:26 | INFO | tasks.shared_utils : Auto resuming
2023-12-30T15:39:26 | INFO | tasks.shared_utils : Not found checkpoint in exp/finetuning/ret_ssv2_label/b16_25m
2023-12-30T15:39:27 | INFO | tasks.shared_utils : _IncompatibleKeys(missing_keys=['text_encoder.embeddings.position_ids', 'text_encoder.embeddings.word_embeddings.weight', 'text_encoder.embeddings.position_embeddings.weight', 'text_encoder.embeddings.token_type_embeddings.weight', 'text_encoder.embeddings.LayerNorm.weight', 'text_encoder.embeddings.LayerNorm.bias', 'text_encoder.encoder.layer.0.attention.self.query.weight', 'text_encoder.encoder.layer.0.attention.self.query.bias', 'text_encoder.encoder.layer.0.attention.self.key.weight', 'text_encoder.encoder.layer.0.attention.self.key.bias', 'text_encoder.encoder.layer.0.attention.self.value.weight', 'text_encoder.encoder.layer.0.attention.self.value.bias', 'text_encoder.encoder.layer.0.attention.output.dense.weight', 'text_encoder.encoder.layer.0.attention.output.dense.bias', 'text_encoder.encoder.layer.0.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.0.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.0.intermediate.dense.weight', 'text_encoder.encoder.layer.0.intermediate.dense.bias', 'text_encoder.encoder.layer.0.output.dense.weight', 'text_encoder.encoder.layer.0.output.dense.bias', 'text_encoder.encoder.layer.0.output.LayerNorm.weight', 'text_encoder.encoder.layer.0.output.LayerNorm.bias', 'text_encoder.encoder.layer.1.attention.self.query.weight', 'text_encoder.encoder.layer.1.attention.self.query.bias', 'text_encoder.encoder.layer.1.attention.self.key.weight', 'text_encoder.encoder.layer.1.attention.self.key.bias', 'text_encoder.encoder.layer.1.attention.self.value.weight', 'text_encoder.encoder.layer.1.attention.self.value.bias', 'text_encoder.encoder.layer.1.attention.output.dense.weight', 'text_encoder.encoder.layer.1.attention.output.dense.bias', 'text_encoder.encoder.layer.1.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.1.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.1.intermediate.dense.weight', 'text_encoder.encoder.layer.1.intermediate.dense.bias', 'text_encoder.encoder.layer.1.output.dense.weight', 'text_encoder.encoder.layer.1.output.dense.bias', 'text_encoder.encoder.layer.1.output.LayerNorm.weight', 'text_encoder.encoder.layer.1.output.LayerNorm.bias', 'text_encoder.encoder.layer.2.attention.self.query.weight', 'text_encoder.encoder.layer.2.attention.self.query.bias', 'text_encoder.encoder.layer.2.attention.self.key.weight', 'text_encoder.encoder.layer.2.attention.self.key.bias', 'text_encoder.encoder.layer.2.attention.self.value.weight', 'text_encoder.encoder.layer.2.attention.self.value.bias', 'text_encoder.encoder.layer.2.attention.output.dense.weight', 'text_encoder.encoder.layer.2.attention.output.dense.bias', 'text_encoder.encoder.layer.2.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.2.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.2.intermediate.dense.weight', 'text_encoder.encoder.layer.2.intermediate.dense.bias', 'text_encoder.encoder.layer.2.output.dense.weight', 'text_encoder.encoder.layer.2.output.dense.bias', 'text_encoder.encoder.layer.2.output.LayerNorm.weight', 'text_encoder.encoder.layer.2.output.LayerNorm.bias', 'text_encoder.encoder.layer.3.attention.self.query.weight', 'text_encoder.encoder.layer.3.attention.self.query.bias', 'text_encoder.encoder.layer.3.attention.self.key.weight', 'text_encoder.encoder.layer.3.attention.self.key.bias', 'text_encoder.encoder.layer.3.attention.self.value.weight', 'text_encoder.encoder.layer.3.attention.self.value.bias', 'text_encoder.encoder.layer.3.attention.output.dense.weight', 'text_encoder.encoder.layer.3.attention.output.dense.bias', 'text_encoder.encoder.layer.3.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.3.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.3.intermediate.dense.weight', 'text_encoder.encoder.layer.3.intermediate.dense.bias', 'text_encoder.encoder.layer.3.output.dense.weight', 'text_encoder.encoder.layer.3.output.dense.bias', 'text_encoder.encoder.layer.3.output.LayerNorm.weight', 'text_encoder.encoder.layer.3.output.LayerNorm.bias', 'text_encoder.encoder.layer.4.attention.self.query.weight', 'text_encoder.encoder.layer.4.attention.self.query.bias', 'text_encoder.encoder.layer.4.attention.self.key.weight', 'text_encoder.encoder.layer.4.attention.self.key.bias', 'text_encoder.encoder.layer.4.attention.self.value.weight', 'text_encoder.encoder.layer.4.attention.self.value.bias', 'text_encoder.encoder.layer.4.attention.output.dense.weight', 'text_encoder.encoder.layer.4.attention.output.dense.bias', 'text_encoder.encoder.layer.4.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.4.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.4.intermediate.dense.weight', 'text_encoder.encoder.layer.4.intermediate.dense.bias', 'text_encoder.encoder.layer.4.output.dense.weight', 'text_encoder.encoder.layer.4.output.dense.bias', 'text_encoder.encoder.layer.4.output.LayerNorm.weight', 'text_encoder.encoder.layer.4.output.LayerNorm.bias', 'text_encoder.encoder.layer.5.attention.self.query.weight', 'text_encoder.encoder.layer.5.attention.self.query.bias', 'text_encoder.encoder.layer.5.attention.self.key.weight', 'text_encoder.encoder.layer.5.attention.self.key.bias', 'text_encoder.encoder.layer.5.attention.self.value.weight', 'text_encoder.encoder.layer.5.attention.self.value.bias', 'text_encoder.encoder.layer.5.attention.output.dense.weight', 'text_encoder.encoder.layer.5.attention.output.dense.bias', 'text_encoder.encoder.layer.5.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.5.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.5.intermediate.dense.weight', 'text_encoder.encoder.layer.5.intermediate.dense.bias', 'text_encoder.encoder.layer.5.output.dense.weight', 'text_encoder.encoder.layer.5.output.dense.bias', 'text_encoder.encoder.layer.5.output.LayerNorm.weight', 'text_encoder.encoder.layer.5.output.LayerNorm.bias', 'text_encoder.encoder.layer.6.attention.self.query.weight', 'text_encoder.encoder.layer.6.attention.self.query.bias', 'text_encoder.encoder.layer.6.attention.self.key.weight', 'text_encoder.encoder.layer.6.attention.self.key.bias', 'text_encoder.encoder.layer.6.attention.self.value.weight', 'text_encoder.encoder.layer.6.attention.self.value.bias', 'text_encoder.encoder.layer.6.attention.output.dense.weight', 'text_encoder.encoder.layer.6.attention.output.dense.bias', 'text_encoder.encoder.layer.6.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.6.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.6.intermediate.dense.weight', 'text_encoder.encoder.layer.6.intermediate.dense.bias', 'text_encoder.encoder.layer.6.output.dense.weight', 'text_encoder.encoder.layer.6.output.dense.bias', 'text_encoder.encoder.layer.6.output.LayerNorm.weight', 'text_encoder.encoder.layer.6.output.LayerNorm.bias', 'text_encoder.encoder.layer.7.attention.self.query.weight', 'text_encoder.encoder.layer.7.attention.self.query.bias', 'text_encoder.encoder.layer.7.attention.self.key.weight', 'text_encoder.encoder.layer.7.attention.self.key.bias', 'text_encoder.encoder.layer.7.attention.self.value.weight', 'text_encoder.encoder.layer.7.attention.self.value.bias', 'text_encoder.encoder.layer.7.attention.output.dense.weight', 'text_encoder.encoder.layer.7.attention.output.dense.bias', 'text_encoder.encoder.layer.7.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.7.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.7.intermediate.dense.weight', 'text_encoder.encoder.layer.7.intermediate.dense.bias', 'text_encoder.encoder.layer.7.output.dense.weight', 'text_encoder.encoder.layer.7.output.dense.bias', 'text_encoder.encoder.layer.7.output.LayerNorm.weight', 'text_encoder.encoder.layer.7.output.LayerNorm.bias', 'text_encoder.encoder.layer.8.attention.self.query.weight', 'text_encoder.encoder.layer.8.attention.self.query.bias', 'text_encoder.encoder.layer.8.attention.self.key.weight', 'text_encoder.encoder.layer.8.attention.self.key.bias', 'text_encoder.encoder.layer.8.attention.self.value.weight', 'text_encoder.encoder.layer.8.attention.self.value.bias', 'text_encoder.encoder.layer.8.attention.output.dense.weight', 'text_encoder.encoder.layer.8.attention.output.dense.bias', 'text_encoder.encoder.layer.8.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.8.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.8.intermediate.dense.weight', 'text_encoder.encoder.layer.8.intermediate.dense.bias', 'text_encoder.encoder.layer.8.output.dense.weight', 'text_encoder.encoder.layer.8.output.dense.bias', 'text_encoder.encoder.layer.8.output.LayerNorm.weight', 'text_encoder.encoder.layer.8.output.LayerNorm.bias', 'text_encoder.encoder.layer.9.attention.self.query.weight', 'text_encoder.encoder.layer.9.attention.self.query.bias', 'text_encoder.encoder.layer.9.attention.self.key.weight', 'text_encoder.encoder.layer.9.attention.self.key.bias', 'text_encoder.encoder.layer.9.attention.self.value.weight', 'text_encoder.encoder.layer.9.attention.self.value.bias', 'text_encoder.encoder.layer.9.attention.output.dense.weight', 'text_encoder.encoder.layer.9.attention.output.dense.bias', 'text_encoder.encoder.layer.9.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.9.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.9.crossattention.self.query.weight', 'text_encoder.encoder.layer.9.crossattention.self.query.bias', 'text_encoder.encoder.layer.9.crossattention.self.key.weight', 'text_encoder.encoder.layer.9.crossattention.self.key.bias', 'text_encoder.encoder.layer.9.crossattention.self.value.weight', 'text_encoder.encoder.layer.9.crossattention.self.value.bias', 'text_encoder.encoder.layer.9.crossattention.output.dense.weight', 'text_encoder.encoder.layer.9.crossattention.output.dense.bias', 'text_encoder.encoder.layer.9.crossattention.output.LayerNorm.weight', 'text_encoder.encoder.layer.9.crossattention.output.LayerNorm.bias', 'text_encoder.encoder.layer.9.intermediate.dense.weight', 'text_encoder.encoder.layer.9.intermediate.dense.bias', 'text_encoder.encoder.layer.9.output.dense.weight', 'text_encoder.encoder.layer.9.output.dense.bias', 'text_encoder.encoder.layer.9.output.LayerNorm.weight', 'text_encoder.encoder.layer.9.output.LayerNorm.bias', 'text_encoder.encoder.layer.10.attention.self.query.weight', 'text_encoder.encoder.layer.10.attention.self.query.bias', 'text_encoder.encoder.layer.10.attention.self.key.weight', 'text_encoder.encoder.layer.10.attention.self.key.bias', 'text_encoder.encoder.layer.10.attention.self.value.weight', 'text_encoder.encoder.layer.10.attention.self.value.bias', 'text_encoder.encoder.layer.10.attention.output.dense.weight', 'text_encoder.encoder.layer.10.attention.output.dense.bias', 'text_encoder.encoder.layer.10.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.10.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.10.crossattention.self.query.weight', 'text_encoder.encoder.layer.10.crossattention.self.query.bias', 'text_encoder.encoder.layer.10.crossattention.self.key.weight', 'text_encoder.encoder.layer.10.crossattention.self.key.bias', 'text_encoder.encoder.layer.10.crossattention.self.value.weight', 'text_encoder.encoder.layer.10.crossattention.self.value.bias', 'text_encoder.encoder.layer.10.crossattention.output.dense.weight', 'text_encoder.encoder.layer.10.crossattention.output.dense.bias', 'text_encoder.encoder.layer.10.crossattention.output.LayerNorm.weight', 'text_encoder.encoder.layer.10.crossattention.output.LayerNorm.bias', 'text_encoder.encoder.layer.10.intermediate.dense.weight', 'text_encoder.encoder.layer.10.intermediate.dense.bias', 'text_encoder.encoder.layer.10.output.dense.weight', 'text_encoder.encoder.layer.10.output.dense.bias', 'text_encoder.encoder.layer.10.output.LayerNorm.weight', 'text_encoder.encoder.layer.10.output.LayerNorm.bias', 'text_encoder.encoder.layer.11.attention.self.query.weight', 'text_encoder.encoder.layer.11.attention.self.query.bias', 'text_encoder.encoder.layer.11.attention.self.key.weight', 'text_encoder.encoder.layer.11.attention.self.key.bias', 'text_encoder.encoder.layer.11.attention.self.value.weight', 'text_encoder.encoder.layer.11.attention.self.value.bias', 'text_encoder.encoder.layer.11.attention.output.dense.weight', 'text_encoder.encoder.layer.11.attention.output.dense.bias', 'text_encoder.encoder.layer.11.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.11.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.11.crossattention.self.query.weight', 'text_encoder.encoder.layer.11.crossattention.self.query.bias', 'text_encoder.encoder.layer.11.crossattention.self.key.weight', 'text_encoder.encoder.layer.11.crossattention.self.key.bias', 'text_encoder.encoder.layer.11.crossattention.self.value.weight', 'text_encoder.encoder.layer.11.crossattention.self.value.bias', 'text_encoder.encoder.layer.11.crossattention.output.dense.weight', 'text_encoder.encoder.layer.11.crossattention.output.dense.bias', 'text_encoder.encoder.layer.11.crossattention.output.LayerNorm.weight', 'text_encoder.encoder.layer.11.crossattention.output.LayerNorm.bias', 'text_encoder.encoder.layer.11.intermediate.dense.weight', 'text_encoder.encoder.layer.11.intermediate.dense.bias', 'text_encoder.encoder.layer.11.output.dense.weight', 'text_encoder.encoder.layer.11.output.dense.bias', 'text_encoder.encoder.layer.11.output.LayerNorm.weight', 'text_encoder.encoder.layer.11.output.LayerNorm.bias'], unexpected_keys=['clip_teacher.class_embedding', 'clip_teacher.positional_embedding', 'clip_teacher.proj', 'clip_teacher.conv1.weight', 'clip_teacher.ln_pre.weight', 'clip_teacher.ln_pre.bias', 'clip_teacher.transformer.resblocks.0.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.0.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.0.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.0.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.0.ln_1.weight', 'clip_teacher.transformer.resblocks.0.ln_1.bias', 'clip_teacher.transformer.resblocks.0.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.0.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.0.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.0.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.0.ln_2.weight', 'clip_teacher.transformer.resblocks.0.ln_2.bias', 'clip_teacher.transformer.resblocks.1.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.1.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.1.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.1.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.1.ln_1.weight', 'clip_teacher.transformer.resblocks.1.ln_1.bias', 'clip_teacher.transformer.resblocks.1.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.1.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.1.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.1.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.1.ln_2.weight', 'clip_teacher.transformer.resblocks.1.ln_2.bias', 'clip_teacher.transformer.resblocks.2.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.2.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.2.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.2.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.2.ln_1.weight', 'clip_teacher.transformer.resblocks.2.ln_1.bias', 'clip_teacher.transformer.resblocks.2.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.2.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.2.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.2.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.2.ln_2.weight', 'clip_teacher.transformer.resblocks.2.ln_2.bias', 'clip_teacher.transformer.resblocks.3.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.3.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.3.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.3.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.3.ln_1.weight', 'clip_teacher.transformer.resblocks.3.ln_1.bias', 'clip_teacher.transformer.resblocks.3.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.3.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.3.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.3.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.3.ln_2.weight', 'clip_teacher.transformer.resblocks.3.ln_2.bias', 'clip_teacher.transformer.resblocks.4.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.4.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.4.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.4.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.4.ln_1.weight', 'clip_teacher.transformer.resblocks.4.ln_1.bias', 'clip_teacher.transformer.resblocks.4.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.4.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.4.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.4.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.4.ln_2.weight', 'clip_teacher.transformer.resblocks.4.ln_2.bias', 'clip_teacher.transformer.resblocks.5.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.5.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.5.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.5.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.5.ln_1.weight', 'clip_teacher.transformer.resblocks.5.ln_1.bias', 'clip_teacher.transformer.resblocks.5.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.5.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.5.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.5.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.5.ln_2.weight', 'clip_teacher.transformer.resblocks.5.ln_2.bias', 'clip_teacher.transformer.resblocks.6.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.6.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.6.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.6.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.6.ln_1.weight', 'clip_teacher.transformer.resblocks.6.ln_1.bias', 'clip_teacher.transformer.resblocks.6.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.6.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.6.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.6.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.6.ln_2.weight', 'clip_teacher.transformer.resblocks.6.ln_2.bias', 'clip_teacher.transformer.resblocks.7.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.7.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.7.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.7.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.7.ln_1.weight', 'clip_teacher.transformer.resblocks.7.ln_1.bias', 'clip_teacher.transformer.resblocks.7.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.7.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.7.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.7.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.7.ln_2.weight', 'clip_teacher.transformer.resblocks.7.ln_2.bias', 'clip_teacher.transformer.resblocks.8.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.8.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.8.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.8.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.8.ln_1.weight', 'clip_teacher.transformer.resblocks.8.ln_1.bias', 'clip_teacher.transformer.resblocks.8.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.8.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.8.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.8.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.8.ln_2.weight', 'clip_teacher.transformer.resblocks.8.ln_2.bias', 'clip_teacher.transformer.resblocks.9.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.9.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.9.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.9.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.9.ln_1.weight', 'clip_teacher.transformer.resblocks.9.ln_1.bias', 'clip_teacher.transformer.resblocks.9.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.9.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.9.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.9.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.9.ln_2.weight', 'clip_teacher.transformer.resblocks.9.ln_2.bias', 'clip_teacher.transformer.resblocks.10.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.10.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.10.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.10.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.10.ln_1.weight', 'clip_teacher.transformer.resblocks.10.ln_1.bias', 'clip_teacher.transformer.resblocks.10.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.10.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.10.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.10.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.10.ln_2.weight', 'clip_teacher.transformer.resblocks.10.ln_2.bias', 'clip_teacher.transformer.resblocks.11.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.11.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.11.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.11.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.11.ln_1.weight', 'clip_teacher.transformer.resblocks.11.ln_1.bias', 'clip_teacher.transformer.resblocks.11.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.11.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.11.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.11.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.11.ln_2.weight', 'clip_teacher.transformer.resblocks.11.ln_2.bias', 'clip_teacher.ln_post.weight', 'clip_teacher.ln_post.bias', 'vision_encoder.clip_decoder.0.head.weight', 'vision_encoder.clip_decoder.0.head.bias', 'vision_encoder.clip_decoder.0.norm.weight', 'vision_encoder.clip_decoder.0.norm.bias', 'vision_encoder.clip_decoder.1.head.weight', 'vision_encoder.clip_decoder.1.head.bias', 'vision_encoder.clip_decoder.1.norm.weight', 'vision_encoder.clip_decoder.1.norm.bias', 'vision_encoder.clip_decoder.2.head.weight', 'vision_encoder.clip_decoder.2.head.bias', 'vision_encoder.clip_decoder.2.norm.weight', 'vision_encoder.clip_decoder.2.norm.bias', 'vision_encoder.clip_decoder.3.head.weight', 'vision_encoder.clip_decoder.3.head.bias', 'vision_encoder.clip_decoder.3.norm.weight', 'vision_encoder.clip_decoder.3.norm.bias', 'vision_encoder.clip_decoder.4.head.weight', 'vision_encoder.clip_decoder.4.head.bias', 'vision_encoder.clip_decoder.4.norm.weight', 'vision_encoder.clip_decoder.4.norm.bias', 'vision_encoder.clip_decoder.5.head.weight', 'vision_encoder.clip_decoder.5.head.bias', 'vision_encoder.clip_decoder.5.norm.weight', 'vision_encoder.clip_decoder.5.norm.bias', 'text_encoder.bert.embeddings.position_ids', 'text_encoder.bert.embeddings.word_embeddings.weight', 'text_encoder.bert.embeddings.position_embeddings.weight', 'text_encoder.bert.embeddings.token_type_embeddings.weight', 'text_encoder.bert.embeddings.LayerNorm.weight', 'text_encoder.bert.embeddings.LayerNorm.bias', 'text_encoder.bert.encoder.layer.0.attention.self.query.weight', 'text_encoder.bert.encoder.layer.0.attention.self.query.bias', 'text_encoder.bert.encoder.layer.0.attention.self.key.weight', 'text_encoder.bert.encoder.layer.0.attention.self.key.bias', 'text_encoder.bert.encoder.layer.0.attention.self.value.weight', 'text_encoder.bert.encoder.layer.0.attention.self.value.bias', 'text_encoder.bert.encoder.layer.0.attention.output.dense.weight', 'text_encoder.bert.encoder.layer.0.attention.output.dense.bias', 'text_encoder.bert.encoder.layer.0.attention.output.LayerNorm.weight', 'text_encoder.bert.encoder.layer.0.attention.output.LayerNorm.bias', 'text_encoder.bert.encoder.layer.0.intermediate.dense.weight', 'text_encoder.bert.encoder.layer.0.intermediate.dense.bias', 'text_encoder.bert.encoder.layer.0.output.dense.weight', 'text_encoder.bert.encoder.layer.0.output.dense.bias', 'text_encoder.bert.encoder.layer.0.output.LayerNorm.weight', 'text_encoder.bert.encoder.layer.0.output.LayerNorm.bias', 'text_encoder.bert.encoder.layer.1.attention.self.query.weight', 'text_encoder.bert.encoder.layer.1.attention.self.query.bias', 'text_encoder.bert.encoder.layer.1.attention.self.key.weight', 'text_encoder.bert.encoder.layer.1.attention.self.key.bias', 'text_encoder.bert.encoder.layer.1.attention.self.value.weight', 'text_encoder.bert.encoder.layer.1.attention.self.value.bias', 'text_encoder.bert.encoder.layer.1.attention.output.dense.weight', 'text_encoder.bert.encoder.layer.1.attention.output.dense.bias', 'text_encoder.bert.encoder.layer.1.attention.output.LayerNorm.weight', 'text_encoder.bert.encoder.layer.1.attention.output.LayerNorm.bias', 'text_encoder.bert.encoder.layer.1.intermediate.dense.weight', 'text_encoder.bert.encoder.layer.1.intermediate.dense.bias', 'text_encoder.bert.encoder.layer.1.output.dense.weight', 'text_encoder.bert.encoder.layer.1.output.dense.bias', 'text_encoder.bert.encoder.layer.1.output.LayerNorm.weight', 'text_encoder.bert.encoder.layer.1.output.LayerNorm.bias', 'text_encoder.bert.encoder.layer.2.attention.self.query.weight', 'text_encoder.bert.encoder.layer.2.attention.self.query.bias', 'text_encoder.bert.encoder.layer.2.attention.self.key.weight', 'text_encoder.bert.encoder.layer.2.attention.self.key.bias', 'text_encoder.bert.encoder.layer.2.attention.self.value.weight', 'text_encoder.bert.encoder.layer.2.attention.self.value.bias', 'text_encoder.bert.encoder.layer.2.attention.output.dense.weight', 'text_encoder.bert.encoder.layer.2.attention.output.dense.bias', 'text_encoder.bert.encoder.layer.2.attention.output.LayerNorm.weight', 'text_encoder.bert.encoder.layer.2.attention.output.LayerNorm.bias', 'text_encoder.bert.encoder.layer.2.intermediate.dense.weight', 'text_encoder.bert.encoder.layer.2.intermediate.dense.bias', 'text_encoder.bert.encoder.layer.2.output.dense.weight', 'text_encoder.bert.encoder.layer.2.output.dense.bias', 'text_encoder.bert.encoder.layer.2.output.LayerNorm.weight', 'text_encoder.bert.encoder.layer.2.output.LayerNorm.bias', 'text_encoder.bert.encoder.layer.3.attention.self.query.weight', 'text_encoder.bert.encoder.layer.3.attention.self.query.bias', 'text_encoder.bert.encoder.layer.3.attention.self.key.weight', 'text_encoder.bert.encoder.layer.3.attention.self.key.bias', 'text_encoder.bert.encoder.layer.3.attention.self.value.weight', 'text_encoder.bert.encoder.layer.3.attention.self.value.bias', 'text_encoder.bert.encoder.layer.3.attention.output.dense.weight', 'text_encoder.bert.encoder.layer.3.attention.output.dense.bias', 'text_encoder.bert.encoder.layer.3.attention.output.LayerNorm.weight', 'text_encoder.bert.encoder.layer.3.attention.output.LayerNorm.bias', 'text_encoder.bert.encoder.layer.3.intermediate.dense.weight', 'text_encoder.bert.encoder.layer.3.intermediate.dense.bias', 'text_encoder.bert.encoder.layer.3.output.dense.weight', 'text_encoder.bert.encoder.layer.3.output.dense.bias', 'text_encoder.bert.encoder.layer.3.output.LayerNorm.weight', 'text_encoder.bert.encoder.layer.3.output.LayerNorm.bias', 'text_encoder.bert.encoder.layer.4.attention.self.query.weight', 'text_encoder.bert.encoder.layer.4.attention.self.query.bias', 'text_encoder.bert.encoder.layer.4.attention.self.key.weight', 'text_encoder.bert.encoder.layer.4.attention.self.key.bias', 'text_encoder.bert.encoder.layer.4.attention.self.value.weight', 'text_encoder.bert.encoder.layer.4.attention.self.value.bias', 'text_encoder.bert.encoder.layer.4.attention.output.dense.weight', 'text_encoder.bert.encoder.layer.4.attention.output.dense.bias', 'text_encoder.bert.encoder.layer.4.attention.output.LayerNorm.weight', 'text_encoder.bert.encoder.layer.4.attention.output.LayerNorm.bias', 'text_encoder.bert.encoder.layer.4.intermediate.dense.weight', 'text_encoder.bert.encoder.layer.4.intermediate.dense.bias', 'text_encoder.bert.encoder.layer.4.output.dense.weight', 'text_encoder.bert.encoder.layer.4.output.dense.bias', 'text_encoder.bert.encoder.layer.4.output.LayerNorm.weight', 'text_encoder.bert.encoder.layer.4.output.LayerNorm.bias', 'text_encoder.bert.encoder.layer.5.attention.self.query.weight', 'text_encoder.bert.encoder.layer.5.attention.self.query.bias', 'text_encoder.bert.encoder.layer.5.attention.self.key.weight', 'text_encoder.bert.encoder.layer.5.attention.self.key.bias', 'text_encoder.bert.encoder.layer.5.attention.self.value.weight', 'text_encoder.bert.encoder.layer.5.attention.self.value.bias', 'text_encoder.bert.encoder.layer.5.attention.output.dense.weight', 'text_encoder.bert.encoder.layer.5.attention.output.dense.bias', 'text_encoder.bert.encoder.layer.5.attention.output.LayerNorm.weight', 'text_encoder.bert.encoder.layer.5.attention.output.LayerNorm.bias', 'text_encoder.bert.encoder.layer.5.intermediate.dense.weight', 'text_encoder.bert.encoder.layer.5.intermediate.dense.bias', 'text_encoder.bert.encoder.layer.5.output.dense.weight', 'text_encoder.bert.encoder.layer.5.output.dense.bias', 'text_encoder.bert.encoder.layer.5.output.LayerNorm.weight', 'text_encoder.bert.encoder.layer.5.output.LayerNorm.bias', 'text_encoder.bert.encoder.layer.6.attention.self.query.weight', 'text_encoder.bert.encoder.layer.6.attention.self.query.bias', 'text_encoder.bert.encoder.layer.6.attention.self.key.weight', 'text_encoder.bert.encoder.layer.6.attention.self.key.bias', 'text_encoder.bert.encoder.layer.6.attention.self.value.weight', 'text_encoder.bert.encoder.layer.6.attention.self.value.bias', 'text_encoder.bert.encoder.layer.6.attention.output.dense.weight', 'text_encoder.bert.encoder.layer.6.attention.output.dense.bias', 'text_encoder.bert.encoder.layer.6.attention.output.LayerNorm.weight', 'text_encoder.bert.encoder.layer.6.attention.output.LayerNorm.bias', 'text_encoder.bert.encoder.layer.6.intermediate.dense.weight', 'text_encoder.bert.encoder.layer.6.intermediate.dense.bias', 'text_encoder.bert.encoder.layer.6.output.dense.weight', 'text_encoder.bert.encoder.layer.6.output.dense.bias', 'text_encoder.bert.encoder.layer.6.output.LayerNorm.weight', 'text_encoder.bert.encoder.layer.6.output.LayerNorm.bias', 'text_encoder.bert.encoder.layer.7.attention.self.query.weight', 'text_encoder.bert.encoder.layer.7.attention.self.query.bias', 'text_encoder.bert.encoder.layer.7.attention.self.key.weight', 'text_encoder.bert.encoder.layer.7.attention.self.key.bias', 'text_encoder.bert.encoder.layer.7.attention.self.value.weight', 'text_encoder.bert.encoder.layer.7.attention.self.value.bias', 'text_encoder.bert.encoder.layer.7.attention.output.dense.weight', 'text_encoder.bert.encoder.layer.7.attention.output.dense.bias', 'text_encoder.bert.encoder.layer.7.attention.output.LayerNorm.weight', 'text_encoder.bert.encoder.layer.7.attention.output.LayerNorm.bias', 'text_encoder.bert.encoder.layer.7.intermediate.dense.weight', 'text_encoder.bert.encoder.layer.7.intermediate.dense.bias', 'text_encoder.bert.encoder.layer.7.output.dense.weight', 'text_encoder.bert.encoder.layer.7.output.dense.bias', 'text_encoder.bert.encoder.layer.7.output.LayerNorm.weight', 'text_encoder.bert.encoder.layer.7.output.LayerNorm.bias', 'text_encoder.bert.encoder.layer.8.attention.self.query.weight', 'text_encoder.bert.encoder.layer.8.attention.self.query.bias', 'text_encoder.bert.encoder.layer.8.attention.self.key.weight', 'text_encoder.bert.encoder.layer.8.attention.self.key.bias', 'text_encoder.bert.encoder.layer.8.attention.self.value.weight', 'text_encoder.bert.encoder.layer.8.attention.self.value.bias', 'text_encoder.bert.encoder.layer.8.attention.output.dense.weight', 'text_encoder.bert.encoder.layer.8.attention.output.dense.bias', 'text_encoder.bert.encoder.layer.8.attention.output.LayerNorm.weight', 'text_encoder.bert.encoder.layer.8.attention.output.LayerNorm.bias', 'text_encoder.bert.encoder.layer.8.intermediate.dense.weight', 'text_encoder.bert.encoder.layer.8.intermediate.dense.bias', 'text_encoder.bert.encoder.layer.8.output.dense.weight', 'text_encoder.bert.encoder.layer.8.output.dense.bias', 'text_encoder.bert.encoder.layer.8.output.LayerNorm.weight', 'text_encoder.bert.encoder.layer.8.output.LayerNorm.bias', 'text_encoder.bert.encoder.layer.9.attention.self.query.weight', 'text_encoder.bert.encoder.layer.9.attention.self.query.bias', 'text_encoder.bert.encoder.layer.9.attention.self.key.weight', 'text_encoder.bert.encoder.layer.9.attention.self.key.bias', 'text_encoder.bert.encoder.layer.9.attention.self.value.weight', 'text_encoder.bert.encoder.layer.9.attention.self.value.bias', 'text_encoder.bert.encoder.layer.9.attention.output.dense.weight', 'text_encoder.bert.encoder.layer.9.attention.output.dense.bias', 'text_encoder.bert.encoder.layer.9.attention.output.LayerNorm.weight', 'text_encoder.bert.encoder.layer.9.attention.output.LayerNorm.bias', 'text_encoder.bert.encoder.layer.9.crossattention.self.query.weight', 'text_encoder.bert.encoder.layer.9.crossattention.self.query.bias', 'text_encoder.bert.encoder.layer.9.crossattention.self.key.weight', 'text_encoder.bert.encoder.layer.9.crossattention.self.key.bias', 'text_encoder.bert.encoder.layer.9.crossattention.self.value.weight', 'text_encoder.bert.encoder.layer.9.crossattention.self.value.bias', 'text_encoder.bert.encoder.layer.9.crossattention.output.dense.weight', 'text_encoder.bert.encoder.layer.9.crossattention.output.dense.bias', 'text_encoder.bert.encoder.layer.9.crossattention.output.LayerNorm.weight', 'text_encoder.bert.encoder.layer.9.crossattention.output.LayerNorm.bias', 'text_encoder.bert.encoder.layer.9.intermediate.dense.weight', 'text_encoder.bert.encoder.layer.9.intermediate.dense.bias', 'text_encoder.bert.encoder.layer.9.output.dense.weight', 'text_encoder.bert.encoder.layer.9.output.dense.bias', 'text_encoder.bert.encoder.layer.9.output.LayerNorm.weight', 'text_encoder.bert.encoder.layer.9.output.LayerNorm.bias', 'text_encoder.bert.encoder.layer.10.attention.self.query.weight', 'text_encoder.bert.encoder.layer.10.attention.self.query.bias', 'text_encoder.bert.encoder.layer.10.attention.self.key.weight', 'text_encoder.bert.encoder.layer.10.attention.self.key.bias', 'text_encoder.bert.encoder.layer.10.attention.self.value.weight', 'text_encoder.bert.encoder.layer.10.attention.self.value.bias', 'text_encoder.bert.encoder.layer.10.attention.output.dense.weight', 'text_encoder.bert.encoder.layer.10.attention.output.dense.bias', 'text_encoder.bert.encoder.layer.10.attention.output.LayerNorm.weight', 'text_encoder.bert.encoder.layer.10.attention.output.LayerNorm.bias', 'text_encoder.bert.encoder.layer.10.crossattention.self.query.weight', 'text_encoder.bert.encoder.layer.10.crossattention.self.query.bias', 'text_encoder.bert.encoder.layer.10.crossattention.self.key.weight', 'text_encoder.bert.encoder.layer.10.crossattention.self.key.bias', 'text_encoder.bert.encoder.layer.10.crossattention.self.value.weight', 'text_encoder.bert.encoder.layer.10.crossattention.self.value.bias', 'text_encoder.bert.encoder.layer.10.crossattention.output.dense.weight', 'text_encoder.bert.encoder.layer.10.crossattention.output.dense.bias', 'text_encoder.bert.encoder.layer.10.crossattention.output.LayerNorm.weight', 'text_encoder.bert.encoder.layer.10.crossattention.output.LayerNorm.bias', 'text_encoder.bert.encoder.layer.10.intermediate.dense.weight', 'text_encoder.bert.encoder.layer.10.intermediate.dense.bias', 'text_encoder.bert.encoder.layer.10.output.dense.weight', 'text_encoder.bert.encoder.layer.10.output.dense.bias', 'text_encoder.bert.encoder.layer.10.output.LayerNorm.weight', 'text_encoder.bert.encoder.layer.10.output.LayerNorm.bias', 'text_encoder.bert.encoder.layer.11.attention.self.query.weight', 'text_encoder.bert.encoder.layer.11.attention.self.query.bias', 'text_encoder.bert.encoder.layer.11.attention.self.key.weight', 'text_encoder.bert.encoder.layer.11.attention.self.key.bias', 'text_encoder.bert.encoder.layer.11.attention.self.value.weight', 'text_encoder.bert.encoder.layer.11.attention.self.value.bias', 'text_encoder.bert.encoder.layer.11.attention.output.dense.weight', 'text_encoder.bert.encoder.layer.11.attention.output.dense.bias', 'text_encoder.bert.encoder.layer.11.attention.output.LayerNorm.weight', 'text_encoder.bert.encoder.layer.11.attention.output.LayerNorm.bias', 'text_encoder.bert.encoder.layer.11.crossattention.self.query.weight', 'text_encoder.bert.encoder.layer.11.crossattention.self.query.bias', 'text_encoder.bert.encoder.layer.11.crossattention.self.key.weight', 'text_encoder.bert.encoder.layer.11.crossattention.self.key.bias', 'text_encoder.bert.encoder.layer.11.crossattention.self.value.weight', 'text_encoder.bert.encoder.layer.11.crossattention.self.value.bias', 'text_encoder.bert.encoder.layer.11.crossattention.output.dense.weight', 'text_encoder.bert.encoder.layer.11.crossattention.output.dense.bias', 'text_encoder.bert.encoder.layer.11.crossattention.output.LayerNorm.weight', 'text_encoder.bert.encoder.layer.11.crossattention.output.LayerNorm.bias', 'text_encoder.bert.encoder.layer.11.intermediate.dense.weight', 'text_encoder.bert.encoder.layer.11.intermediate.dense.bias', 'text_encoder.bert.encoder.layer.11.output.dense.weight', 'text_encoder.bert.encoder.layer.11.output.dense.bias', 'text_encoder.bert.encoder.layer.11.output.LayerNorm.weight', 'text_encoder.bert.encoder.layer.11.output.LayerNorm.bias', 'text_encoder.cls.predictions.bias', 'text_encoder.cls.predictions.transform.dense.weight', 'text_encoder.cls.predictions.transform.dense.bias', 'text_encoder.cls.predictions.transform.LayerNorm.weight', 'text_encoder.cls.predictions.transform.LayerNorm.bias', 'text_encoder.cls.predictions.decoder.weight', 'text_encoder.cls.predictions.decoder.bias'])
2023-12-30T15:39:27 | INFO | tasks.shared_utils : Loaded checkpoint from /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
2023-12-30T15:39:27 | INFO | __main__ : Start evaluation
2023-12-30T15:39:27 | INFO | __main__ : Training time 0:00:00
2023-12-30T15:39:27 | INFO | __main__ : best epoch 0 [config.stop_key val/]
2023-12-30T15:39:27 | INFO | __main__ : Checkpoints and Logs saved at exp/finetuning/ret_ssv2_label/b16_25m
2023-12-30T15:42:58 | INFO | umt : Logging to: exp/finetuning/ret_ssv2_label/b16_25m/train.log
2023-12-30T15:42:58 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  your_ssv2_path: /datassd2/DATASET/something-something-v2/rawvideo/20bn-something-something-v2
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/ssv2_ret_label_train.json', '/datassd2/DATASET/something-something-v2/rawvideo/20bn-something-something-v2', 'video']
  test_file: {
      val: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/ssv2_ret_label_val_small.json', '/datassd2/DATASET/something-something-v2/rawvideo/20bn-something-something-v2', 'video'] }
  test_types: ['val']
  num_workers: 6
  stop_key: val/
  is_paragraph_retrieval: False
  has_multi_vision_gt: True
  num_frames: 12
  num_frames_test: 12
  batch_size: 32
  max_txt_l: 25
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 12
          sample_type: rand
          num_frames_test: 12
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 25
          video: 25 }
      batch_size: {
          image: 32
          video: 32 }
      batch_size_test: {
          image: 32
          video: 32 } }
  text_enc: bert
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_b16
          img_size: 224
          patch_size: 16
          d_model: 768
          encoder_embed_dim: 768
          encoder_depth: 12
          encoder_num_heads: 12
          drop_path_rate: 0.1
          num_frames: 12
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 12
          clip_decoder_embed_dim: 768
          clip_output_dim: 512
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 224
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      multimodal: {
          enable: True }
      embed_dim: 512
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 5e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 10
      min_lr_multi: 0.01
      warmup_epochs: 0 }
  evaluate: True
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: user
      project: umt_ret_ssv2 }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/finetuning/ret_ssv2_label/b16_25m
  resume: False
  debug: False
  log_freq: 100
  seed: 42
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
  rank: 0
  world_size: 1
  gpu: 0
  distributed: True
  dist_backend: nccl }
2023-12-30T15:42:58 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'your_ssv2_path': '/datassd2/DATASET/something-something-v2/rawvideo/20bn-something-something-v2', 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/ssv2_ret_label_train.json', '/datassd2/DATASET/something-something-v2/rawvideo/20bn-something-something-v2', 'video'], 'test_file': {'val': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/ssv2_ret_label_val_small.json', '/datassd2/DATASET/something-something-v2/rawvideo/20bn-something-something-v2', 'video']}, 'test_types': ['val'], 'num_workers': 6, 'stop_key': 'val/', 'is_paragraph_retrieval': False, 'has_multi_vision_gt': True, 'num_frames': 12, 'num_frames_test': 12, 'batch_size': 32, 'max_txt_l': 25, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 12, 'sample_type': 'rand', 'num_frames_test': 12, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 25, 'video': 25}, 'batch_size': {'image': 32, 'video': 32}, 'batch_size_test': {'image': 32, 'video': 32}}, 'text_enc': 'bert', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_b16', 'img_size': 224, 'patch_size': 16, 'd_model': 768, 'encoder_embed_dim': 768, 'encoder_depth': 12, 'encoder_num_heads': 12, 'drop_path_rate': 0.1, 'num_frames': 12, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 12, 'clip_decoder_embed_dim': 768, 'clip_output_dim': 512, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 224, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'multimodal': {'enable': True}, 'embed_dim': 512, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 5e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 10, 'min_lr_multi': 0.01, 'warmup_epochs': 0}, 'evaluate': True, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': False, 'entity': 'user', 'project': 'umt_ret_ssv2'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': 'exp/finetuning/ret_ssv2_label/b16_25m', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 42, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth', 'rank': 0, 'world_size': 1, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2023-12-30T15:42:58 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/ssv2_ret_label_train.json', '/datassd2/DATASET/something-something-v2/rawvideo/20bn-something-something-v2', 'video']
2023-12-30T15:42:58 | INFO | tasks.pretrain : Creating dataset for ret
2023-12-30T15:42:58 | INFO | tasks.shared_utils : Creating model
2023-12-30T15:43:11 | INFO | models.umt : Build vision_encoder: vit_b16
2023-12-30T15:43:11 | INFO | models.backbones.vit.vit : Num of patches: 2352
2023-12-30T15:43:11 | INFO | models.backbones.vit.vit : Use checkpoint: True
2023-12-30T15:43:11 | INFO | models.backbones.vit.vit : Checkpoint number: 12
2023-12-30T15:43:11 | INFO | models.backbones.vit.vit : Student return index: []
2023-12-30T15:43:21 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
2023-12-30T15:43:21 | INFO | models.umt : Build text_encoder bert_base
2023-12-30T15:43:23 | INFO | models.backbones.bert.xbert : build bert with cross_module: ca
2023-12-30T15:43:23 | INFO | models.criterions : Norm type: l2
2023-12-30T15:43:23 | INFO | models.criterions : Loss type: l2
2023-12-30T15:43:24 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.temp: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.weight: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.q_bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.v_bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.qkv.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.weight: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.weight: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.q_bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.v_bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.qkv.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.weight: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.weight: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.q_bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.v_bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.qkv.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.weight: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.weight: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.q_bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.v_bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.qkv.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.weight: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.weight: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.q_bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.v_bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.qkv.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.weight: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.weight: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.q_bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.v_bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.qkv.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.weight: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.weight: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.q_bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.v_bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.qkv.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.weight: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.weight: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.q_bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.v_bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.qkv.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.weight: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.weight: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.q_bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.v_bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.qkv.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.weight: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.weight: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.q_bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.v_bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.qkv.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.weight: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.weight: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.q_bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.v_bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.qkv.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.weight: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.weight: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.q_bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.v_bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.qkv.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.weight: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.weight: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.weight: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.embeddings.word_embeddings.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.embeddings.position_embeddings.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.embeddings.token_type_embeddings.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_proj.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.vision_proj.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_proj.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.text_proj.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.itm_head.weight: wd: 0.02, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : param module.itm_head.bias: wd: 0, lr: 5e-05
2023-12-30T15:43:24 | INFO | utils.optimizer : optimizer -- lr=5e-05 wd=0.02 len(p)=140
2023-12-30T15:43:24 | INFO | utils.optimizer : optimizer -- lr=5e-05 wd=0 len(p)=256
2023-12-30T15:43:24 | INFO | tasks.shared_utils : Auto resuming
2023-12-30T15:43:24 | INFO | tasks.shared_utils : Not found checkpoint in exp/finetuning/ret_ssv2_label/b16_25m
2023-12-30T15:43:24 | INFO | tasks.shared_utils : _IncompatibleKeys(missing_keys=['text_encoder.embeddings.position_ids', 'text_encoder.embeddings.word_embeddings.weight', 'text_encoder.embeddings.position_embeddings.weight', 'text_encoder.embeddings.token_type_embeddings.weight', 'text_encoder.embeddings.LayerNorm.weight', 'text_encoder.embeddings.LayerNorm.bias', 'text_encoder.encoder.layer.0.attention.self.query.weight', 'text_encoder.encoder.layer.0.attention.self.query.bias', 'text_encoder.encoder.layer.0.attention.self.key.weight', 'text_encoder.encoder.layer.0.attention.self.key.bias', 'text_encoder.encoder.layer.0.attention.self.value.weight', 'text_encoder.encoder.layer.0.attention.self.value.bias', 'text_encoder.encoder.layer.0.attention.output.dense.weight', 'text_encoder.encoder.layer.0.attention.output.dense.bias', 'text_encoder.encoder.layer.0.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.0.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.0.intermediate.dense.weight', 'text_encoder.encoder.layer.0.intermediate.dense.bias', 'text_encoder.encoder.layer.0.output.dense.weight', 'text_encoder.encoder.layer.0.output.dense.bias', 'text_encoder.encoder.layer.0.output.LayerNorm.weight', 'text_encoder.encoder.layer.0.output.LayerNorm.bias', 'text_encoder.encoder.layer.1.attention.self.query.weight', 'text_encoder.encoder.layer.1.attention.self.query.bias', 'text_encoder.encoder.layer.1.attention.self.key.weight', 'text_encoder.encoder.layer.1.attention.self.key.bias', 'text_encoder.encoder.layer.1.attention.self.value.weight', 'text_encoder.encoder.layer.1.attention.self.value.bias', 'text_encoder.encoder.layer.1.attention.output.dense.weight', 'text_encoder.encoder.layer.1.attention.output.dense.bias', 'text_encoder.encoder.layer.1.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.1.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.1.intermediate.dense.weight', 'text_encoder.encoder.layer.1.intermediate.dense.bias', 'text_encoder.encoder.layer.1.output.dense.weight', 'text_encoder.encoder.layer.1.output.dense.bias', 'text_encoder.encoder.layer.1.output.LayerNorm.weight', 'text_encoder.encoder.layer.1.output.LayerNorm.bias', 'text_encoder.encoder.layer.2.attention.self.query.weight', 'text_encoder.encoder.layer.2.attention.self.query.bias', 'text_encoder.encoder.layer.2.attention.self.key.weight', 'text_encoder.encoder.layer.2.attention.self.key.bias', 'text_encoder.encoder.layer.2.attention.self.value.weight', 'text_encoder.encoder.layer.2.attention.self.value.bias', 'text_encoder.encoder.layer.2.attention.output.dense.weight', 'text_encoder.encoder.layer.2.attention.output.dense.bias', 'text_encoder.encoder.layer.2.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.2.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.2.intermediate.dense.weight', 'text_encoder.encoder.layer.2.intermediate.dense.bias', 'text_encoder.encoder.layer.2.output.dense.weight', 'text_encoder.encoder.layer.2.output.dense.bias', 'text_encoder.encoder.layer.2.output.LayerNorm.weight', 'text_encoder.encoder.layer.2.output.LayerNorm.bias', 'text_encoder.encoder.layer.3.attention.self.query.weight', 'text_encoder.encoder.layer.3.attention.self.query.bias', 'text_encoder.encoder.layer.3.attention.self.key.weight', 'text_encoder.encoder.layer.3.attention.self.key.bias', 'text_encoder.encoder.layer.3.attention.self.value.weight', 'text_encoder.encoder.layer.3.attention.self.value.bias', 'text_encoder.encoder.layer.3.attention.output.dense.weight', 'text_encoder.encoder.layer.3.attention.output.dense.bias', 'text_encoder.encoder.layer.3.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.3.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.3.intermediate.dense.weight', 'text_encoder.encoder.layer.3.intermediate.dense.bias', 'text_encoder.encoder.layer.3.output.dense.weight', 'text_encoder.encoder.layer.3.output.dense.bias', 'text_encoder.encoder.layer.3.output.LayerNorm.weight', 'text_encoder.encoder.layer.3.output.LayerNorm.bias', 'text_encoder.encoder.layer.4.attention.self.query.weight', 'text_encoder.encoder.layer.4.attention.self.query.bias', 'text_encoder.encoder.layer.4.attention.self.key.weight', 'text_encoder.encoder.layer.4.attention.self.key.bias', 'text_encoder.encoder.layer.4.attention.self.value.weight', 'text_encoder.encoder.layer.4.attention.self.value.bias', 'text_encoder.encoder.layer.4.attention.output.dense.weight', 'text_encoder.encoder.layer.4.attention.output.dense.bias', 'text_encoder.encoder.layer.4.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.4.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.4.intermediate.dense.weight', 'text_encoder.encoder.layer.4.intermediate.dense.bias', 'text_encoder.encoder.layer.4.output.dense.weight', 'text_encoder.encoder.layer.4.output.dense.bias', 'text_encoder.encoder.layer.4.output.LayerNorm.weight', 'text_encoder.encoder.layer.4.output.LayerNorm.bias', 'text_encoder.encoder.layer.5.attention.self.query.weight', 'text_encoder.encoder.layer.5.attention.self.query.bias', 'text_encoder.encoder.layer.5.attention.self.key.weight', 'text_encoder.encoder.layer.5.attention.self.key.bias', 'text_encoder.encoder.layer.5.attention.self.value.weight', 'text_encoder.encoder.layer.5.attention.self.value.bias', 'text_encoder.encoder.layer.5.attention.output.dense.weight', 'text_encoder.encoder.layer.5.attention.output.dense.bias', 'text_encoder.encoder.layer.5.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.5.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.5.intermediate.dense.weight', 'text_encoder.encoder.layer.5.intermediate.dense.bias', 'text_encoder.encoder.layer.5.output.dense.weight', 'text_encoder.encoder.layer.5.output.dense.bias', 'text_encoder.encoder.layer.5.output.LayerNorm.weight', 'text_encoder.encoder.layer.5.output.LayerNorm.bias', 'text_encoder.encoder.layer.6.attention.self.query.weight', 'text_encoder.encoder.layer.6.attention.self.query.bias', 'text_encoder.encoder.layer.6.attention.self.key.weight', 'text_encoder.encoder.layer.6.attention.self.key.bias', 'text_encoder.encoder.layer.6.attention.self.value.weight', 'text_encoder.encoder.layer.6.attention.self.value.bias', 'text_encoder.encoder.layer.6.attention.output.dense.weight', 'text_encoder.encoder.layer.6.attention.output.dense.bias', 'text_encoder.encoder.layer.6.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.6.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.6.intermediate.dense.weight', 'text_encoder.encoder.layer.6.intermediate.dense.bias', 'text_encoder.encoder.layer.6.output.dense.weight', 'text_encoder.encoder.layer.6.output.dense.bias', 'text_encoder.encoder.layer.6.output.LayerNorm.weight', 'text_encoder.encoder.layer.6.output.LayerNorm.bias', 'text_encoder.encoder.layer.7.attention.self.query.weight', 'text_encoder.encoder.layer.7.attention.self.query.bias', 'text_encoder.encoder.layer.7.attention.self.key.weight', 'text_encoder.encoder.layer.7.attention.self.key.bias', 'text_encoder.encoder.layer.7.attention.self.value.weight', 'text_encoder.encoder.layer.7.attention.self.value.bias', 'text_encoder.encoder.layer.7.attention.output.dense.weight', 'text_encoder.encoder.layer.7.attention.output.dense.bias', 'text_encoder.encoder.layer.7.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.7.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.7.intermediate.dense.weight', 'text_encoder.encoder.layer.7.intermediate.dense.bias', 'text_encoder.encoder.layer.7.output.dense.weight', 'text_encoder.encoder.layer.7.output.dense.bias', 'text_encoder.encoder.layer.7.output.LayerNorm.weight', 'text_encoder.encoder.layer.7.output.LayerNorm.bias', 'text_encoder.encoder.layer.8.attention.self.query.weight', 'text_encoder.encoder.layer.8.attention.self.query.bias', 'text_encoder.encoder.layer.8.attention.self.key.weight', 'text_encoder.encoder.layer.8.attention.self.key.bias', 'text_encoder.encoder.layer.8.attention.self.value.weight', 'text_encoder.encoder.layer.8.attention.self.value.bias', 'text_encoder.encoder.layer.8.attention.output.dense.weight', 'text_encoder.encoder.layer.8.attention.output.dense.bias', 'text_encoder.encoder.layer.8.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.8.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.8.intermediate.dense.weight', 'text_encoder.encoder.layer.8.intermediate.dense.bias', 'text_encoder.encoder.layer.8.output.dense.weight', 'text_encoder.encoder.layer.8.output.dense.bias', 'text_encoder.encoder.layer.8.output.LayerNorm.weight', 'text_encoder.encoder.layer.8.output.LayerNorm.bias', 'text_encoder.encoder.layer.9.attention.self.query.weight', 'text_encoder.encoder.layer.9.attention.self.query.bias', 'text_encoder.encoder.layer.9.attention.self.key.weight', 'text_encoder.encoder.layer.9.attention.self.key.bias', 'text_encoder.encoder.layer.9.attention.self.value.weight', 'text_encoder.encoder.layer.9.attention.self.value.bias', 'text_encoder.encoder.layer.9.attention.output.dense.weight', 'text_encoder.encoder.layer.9.attention.output.dense.bias', 'text_encoder.encoder.layer.9.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.9.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.9.crossattention.self.query.weight', 'text_encoder.encoder.layer.9.crossattention.self.query.bias', 'text_encoder.encoder.layer.9.crossattention.self.key.weight', 'text_encoder.encoder.layer.9.crossattention.self.key.bias', 'text_encoder.encoder.layer.9.crossattention.self.value.weight', 'text_encoder.encoder.layer.9.crossattention.self.value.bias', 'text_encoder.encoder.layer.9.crossattention.output.dense.weight', 'text_encoder.encoder.layer.9.crossattention.output.dense.bias', 'text_encoder.encoder.layer.9.crossattention.output.LayerNorm.weight', 'text_encoder.encoder.layer.9.crossattention.output.LayerNorm.bias', 'text_encoder.encoder.layer.9.intermediate.dense.weight', 'text_encoder.encoder.layer.9.intermediate.dense.bias', 'text_encoder.encoder.layer.9.output.dense.weight', 'text_encoder.encoder.layer.9.output.dense.bias', 'text_encoder.encoder.layer.9.output.LayerNorm.weight', 'text_encoder.encoder.layer.9.output.LayerNorm.bias', 'text_encoder.encoder.layer.10.attention.self.query.weight', 'text_encoder.encoder.layer.10.attention.self.query.bias', 'text_encoder.encoder.layer.10.attention.self.key.weight', 'text_encoder.encoder.layer.10.attention.self.key.bias', 'text_encoder.encoder.layer.10.attention.self.value.weight', 'text_encoder.encoder.layer.10.attention.self.value.bias', 'text_encoder.encoder.layer.10.attention.output.dense.weight', 'text_encoder.encoder.layer.10.attention.output.dense.bias', 'text_encoder.encoder.layer.10.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.10.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.10.crossattention.self.query.weight', 'text_encoder.encoder.layer.10.crossattention.self.query.bias', 'text_encoder.encoder.layer.10.crossattention.self.key.weight', 'text_encoder.encoder.layer.10.crossattention.self.key.bias', 'text_encoder.encoder.layer.10.crossattention.self.value.weight', 'text_encoder.encoder.layer.10.crossattention.self.value.bias', 'text_encoder.encoder.layer.10.crossattention.output.dense.weight', 'text_encoder.encoder.layer.10.crossattention.output.dense.bias', 'text_encoder.encoder.layer.10.crossattention.output.LayerNorm.weight', 'text_encoder.encoder.layer.10.crossattention.output.LayerNorm.bias', 'text_encoder.encoder.layer.10.intermediate.dense.weight', 'text_encoder.encoder.layer.10.intermediate.dense.bias', 'text_encoder.encoder.layer.10.output.dense.weight', 'text_encoder.encoder.layer.10.output.dense.bias', 'text_encoder.encoder.layer.10.output.LayerNorm.weight', 'text_encoder.encoder.layer.10.output.LayerNorm.bias', 'text_encoder.encoder.layer.11.attention.self.query.weight', 'text_encoder.encoder.layer.11.attention.self.query.bias', 'text_encoder.encoder.layer.11.attention.self.key.weight', 'text_encoder.encoder.layer.11.attention.self.key.bias', 'text_encoder.encoder.layer.11.attention.self.value.weight', 'text_encoder.encoder.layer.11.attention.self.value.bias', 'text_encoder.encoder.layer.11.attention.output.dense.weight', 'text_encoder.encoder.layer.11.attention.output.dense.bias', 'text_encoder.encoder.layer.11.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.11.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.11.crossattention.self.query.weight', 'text_encoder.encoder.layer.11.crossattention.self.query.bias', 'text_encoder.encoder.layer.11.crossattention.self.key.weight', 'text_encoder.encoder.layer.11.crossattention.self.key.bias', 'text_encoder.encoder.layer.11.crossattention.self.value.weight', 'text_encoder.encoder.layer.11.crossattention.self.value.bias', 'text_encoder.encoder.layer.11.crossattention.output.dense.weight', 'text_encoder.encoder.layer.11.crossattention.output.dense.bias', 'text_encoder.encoder.layer.11.crossattention.output.LayerNorm.weight', 'text_encoder.encoder.layer.11.crossattention.output.LayerNorm.bias', 'text_encoder.encoder.layer.11.intermediate.dense.weight', 'text_encoder.encoder.layer.11.intermediate.dense.bias', 'text_encoder.encoder.layer.11.output.dense.weight', 'text_encoder.encoder.layer.11.output.dense.bias', 'text_encoder.encoder.layer.11.output.LayerNorm.weight', 'text_encoder.encoder.layer.11.output.LayerNorm.bias'], unexpected_keys=['clip_teacher.class_embedding', 'clip_teacher.positional_embedding', 'clip_teacher.proj', 'clip_teacher.conv1.weight', 'clip_teacher.ln_pre.weight', 'clip_teacher.ln_pre.bias', 'clip_teacher.transformer.resblocks.0.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.0.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.0.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.0.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.0.ln_1.weight', 'clip_teacher.transformer.resblocks.0.ln_1.bias', 'clip_teacher.transformer.resblocks.0.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.0.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.0.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.0.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.0.ln_2.weight', 'clip_teacher.transformer.resblocks.0.ln_2.bias', 'clip_teacher.transformer.resblocks.1.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.1.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.1.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.1.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.1.ln_1.weight', 'clip_teacher.transformer.resblocks.1.ln_1.bias', 'clip_teacher.transformer.resblocks.1.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.1.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.1.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.1.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.1.ln_2.weight', 'clip_teacher.transformer.resblocks.1.ln_2.bias', 'clip_teacher.transformer.resblocks.2.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.2.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.2.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.2.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.2.ln_1.weight', 'clip_teacher.transformer.resblocks.2.ln_1.bias', 'clip_teacher.transformer.resblocks.2.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.2.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.2.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.2.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.2.ln_2.weight', 'clip_teacher.transformer.resblocks.2.ln_2.bias', 'clip_teacher.transformer.resblocks.3.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.3.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.3.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.3.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.3.ln_1.weight', 'clip_teacher.transformer.resblocks.3.ln_1.bias', 'clip_teacher.transformer.resblocks.3.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.3.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.3.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.3.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.3.ln_2.weight', 'clip_teacher.transformer.resblocks.3.ln_2.bias', 'clip_teacher.transformer.resblocks.4.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.4.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.4.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.4.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.4.ln_1.weight', 'clip_teacher.transformer.resblocks.4.ln_1.bias', 'clip_teacher.transformer.resblocks.4.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.4.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.4.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.4.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.4.ln_2.weight', 'clip_teacher.transformer.resblocks.4.ln_2.bias', 'clip_teacher.transformer.resblocks.5.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.5.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.5.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.5.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.5.ln_1.weight', 'clip_teacher.transformer.resblocks.5.ln_1.bias', 'clip_teacher.transformer.resblocks.5.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.5.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.5.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.5.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.5.ln_2.weight', 'clip_teacher.transformer.resblocks.5.ln_2.bias', 'clip_teacher.transformer.resblocks.6.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.6.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.6.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.6.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.6.ln_1.weight', 'clip_teacher.transformer.resblocks.6.ln_1.bias', 'clip_teacher.transformer.resblocks.6.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.6.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.6.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.6.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.6.ln_2.weight', 'clip_teacher.transformer.resblocks.6.ln_2.bias', 'clip_teacher.transformer.resblocks.7.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.7.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.7.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.7.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.7.ln_1.weight', 'clip_teacher.transformer.resblocks.7.ln_1.bias', 'clip_teacher.transformer.resblocks.7.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.7.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.7.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.7.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.7.ln_2.weight', 'clip_teacher.transformer.resblocks.7.ln_2.bias', 'clip_teacher.transformer.resblocks.8.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.8.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.8.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.8.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.8.ln_1.weight', 'clip_teacher.transformer.resblocks.8.ln_1.bias', 'clip_teacher.transformer.resblocks.8.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.8.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.8.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.8.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.8.ln_2.weight', 'clip_teacher.transformer.resblocks.8.ln_2.bias', 'clip_teacher.transformer.resblocks.9.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.9.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.9.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.9.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.9.ln_1.weight', 'clip_teacher.transformer.resblocks.9.ln_1.bias', 'clip_teacher.transformer.resblocks.9.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.9.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.9.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.9.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.9.ln_2.weight', 'clip_teacher.transformer.resblocks.9.ln_2.bias', 'clip_teacher.transformer.resblocks.10.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.10.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.10.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.10.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.10.ln_1.weight', 'clip_teacher.transformer.resblocks.10.ln_1.bias', 'clip_teacher.transformer.resblocks.10.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.10.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.10.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.10.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.10.ln_2.weight', 'clip_teacher.transformer.resblocks.10.ln_2.bias', 'clip_teacher.transformer.resblocks.11.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.11.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.11.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.11.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.11.ln_1.weight', 'clip_teacher.transformer.resblocks.11.ln_1.bias', 'clip_teacher.transformer.resblocks.11.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.11.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.11.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.11.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.11.ln_2.weight', 'clip_teacher.transformer.resblocks.11.ln_2.bias', 'clip_teacher.ln_post.weight', 'clip_teacher.ln_post.bias', 'vision_encoder.clip_decoder.0.head.weight', 'vision_encoder.clip_decoder.0.head.bias', 'vision_encoder.clip_decoder.0.norm.weight', 'vision_encoder.clip_decoder.0.norm.bias', 'vision_encoder.clip_decoder.1.head.weight', 'vision_encoder.clip_decoder.1.head.bias', 'vision_encoder.clip_decoder.1.norm.weight', 'vision_encoder.clip_decoder.1.norm.bias', 'vision_encoder.clip_decoder.2.head.weight', 'vision_encoder.clip_decoder.2.head.bias', 'vision_encoder.clip_decoder.2.norm.weight', 'vision_encoder.clip_decoder.2.norm.bias', 'vision_encoder.clip_decoder.3.head.weight', 'vision_encoder.clip_decoder.3.head.bias', 'vision_encoder.clip_decoder.3.norm.weight', 'vision_encoder.clip_decoder.3.norm.bias', 'vision_encoder.clip_decoder.4.head.weight', 'vision_encoder.clip_decoder.4.head.bias', 'vision_encoder.clip_decoder.4.norm.weight', 'vision_encoder.clip_decoder.4.norm.bias', 'vision_encoder.clip_decoder.5.head.weight', 'vision_encoder.clip_decoder.5.head.bias', 'vision_encoder.clip_decoder.5.norm.weight', 'vision_encoder.clip_decoder.5.norm.bias', 'text_encoder.bert.embeddings.position_ids', 'text_encoder.bert.embeddings.word_embeddings.weight', 'text_encoder.bert.embeddings.position_embeddings.weight', 'text_encoder.bert.embeddings.token_type_embeddings.weight', 'text_encoder.bert.embeddings.LayerNorm.weight', 'text_encoder.bert.embeddings.LayerNorm.bias', 'text_encoder.bert.encoder.layer.0.attention.self.query.weight', 'text_encoder.bert.encoder.layer.0.attention.self.query.bias', 'text_encoder.bert.encoder.layer.0.attention.self.key.weight', 'text_encoder.bert.encoder.layer.0.attention.self.key.bias', 'text_encoder.bert.encoder.layer.0.attention.self.value.weight', 'text_encoder.bert.encoder.layer.0.attention.self.value.bias', 'text_encoder.bert.encoder.layer.0.attention.output.dense.weight', 'text_encoder.bert.encoder.layer.0.attention.output.dense.bias', 'text_encoder.bert.encoder.layer.0.attention.output.LayerNorm.weight', 'text_encoder.bert.encoder.layer.0.attention.output.LayerNorm.bias', 'text_encoder.bert.encoder.layer.0.intermediate.dense.weight', 'text_encoder.bert.encoder.layer.0.intermediate.dense.bias', 'text_encoder.bert.encoder.layer.0.output.dense.weight', 'text_encoder.bert.encoder.layer.0.output.dense.bias', 'text_encoder.bert.encoder.layer.0.output.LayerNorm.weight', 'text_encoder.bert.encoder.layer.0.output.LayerNorm.bias', 'text_encoder.bert.encoder.layer.1.attention.self.query.weight', 'text_encoder.bert.encoder.layer.1.attention.self.query.bias', 'text_encoder.bert.encoder.layer.1.attention.self.key.weight', 'text_encoder.bert.encoder.layer.1.attention.self.key.bias', 'text_encoder.bert.encoder.layer.1.attention.self.value.weight', 'text_encoder.bert.encoder.layer.1.attention.self.value.bias', 'text_encoder.bert.encoder.layer.1.attention.output.dense.weight', 'text_encoder.bert.encoder.layer.1.attention.output.dense.bias', 'text_encoder.bert.encoder.layer.1.attention.output.LayerNorm.weight', 'text_encoder.bert.encoder.layer.1.attention.output.LayerNorm.bias', 'text_encoder.bert.encoder.layer.1.intermediate.dense.weight', 'text_encoder.bert.encoder.layer.1.intermediate.dense.bias', 'text_encoder.bert.encoder.layer.1.output.dense.weight', 'text_encoder.bert.encoder.layer.1.output.dense.bias', 'text_encoder.bert.encoder.layer.1.output.LayerNorm.weight', 'text_encoder.bert.encoder.layer.1.output.LayerNorm.bias', 'text_encoder.bert.encoder.layer.2.attention.self.query.weight', 'text_encoder.bert.encoder.layer.2.attention.self.query.bias', 'text_encoder.bert.encoder.layer.2.attention.self.key.weight', 'text_encoder.bert.encoder.layer.2.attention.self.key.bias', 'text_encoder.bert.encoder.layer.2.attention.self.value.weight', 'text_encoder.bert.encoder.layer.2.attention.self.value.bias', 'text_encoder.bert.encoder.layer.2.attention.output.dense.weight', 'text_encoder.bert.encoder.layer.2.attention.output.dense.bias', 'text_encoder.bert.encoder.layer.2.attention.output.LayerNorm.weight', 'text_encoder.bert.encoder.layer.2.attention.output.LayerNorm.bias', 'text_encoder.bert.encoder.layer.2.intermediate.dense.weight', 'text_encoder.bert.encoder.layer.2.intermediate.dense.bias', 'text_encoder.bert.encoder.layer.2.output.dense.weight', 'text_encoder.bert.encoder.layer.2.output.dense.bias', 'text_encoder.bert.encoder.layer.2.output.LayerNorm.weight', 'text_encoder.bert.encoder.layer.2.output.LayerNorm.bias', 'text_encoder.bert.encoder.layer.3.attention.self.query.weight', 'text_encoder.bert.encoder.layer.3.attention.self.query.bias', 'text_encoder.bert.encoder.layer.3.attention.self.key.weight', 'text_encoder.bert.encoder.layer.3.attention.self.key.bias', 'text_encoder.bert.encoder.layer.3.attention.self.value.weight', 'text_encoder.bert.encoder.layer.3.attention.self.value.bias', 'text_encoder.bert.encoder.layer.3.attention.output.dense.weight', 'text_encoder.bert.encoder.layer.3.attention.output.dense.bias', 'text_encoder.bert.encoder.layer.3.attention.output.LayerNorm.weight', 'text_encoder.bert.encoder.layer.3.attention.output.LayerNorm.bias', 'text_encoder.bert.encoder.layer.3.intermediate.dense.weight', 'text_encoder.bert.encoder.layer.3.intermediate.dense.bias', 'text_encoder.bert.encoder.layer.3.output.dense.weight', 'text_encoder.bert.encoder.layer.3.output.dense.bias', 'text_encoder.bert.encoder.layer.3.output.LayerNorm.weight', 'text_encoder.bert.encoder.layer.3.output.LayerNorm.bias', 'text_encoder.bert.encoder.layer.4.attention.self.query.weight', 'text_encoder.bert.encoder.layer.4.attention.self.query.bias', 'text_encoder.bert.encoder.layer.4.attention.self.key.weight', 'text_encoder.bert.encoder.layer.4.attention.self.key.bias', 'text_encoder.bert.encoder.layer.4.attention.self.value.weight', 'text_encoder.bert.encoder.layer.4.attention.self.value.bias', 'text_encoder.bert.encoder.layer.4.attention.output.dense.weight', 'text_encoder.bert.encoder.layer.4.attention.output.dense.bias', 'text_encoder.bert.encoder.layer.4.attention.output.LayerNorm.weight', 'text_encoder.bert.encoder.layer.4.attention.output.LayerNorm.bias', 'text_encoder.bert.encoder.layer.4.intermediate.dense.weight', 'text_encoder.bert.encoder.layer.4.intermediate.dense.bias', 'text_encoder.bert.encoder.layer.4.output.dense.weight', 'text_encoder.bert.encoder.layer.4.output.dense.bias', 'text_encoder.bert.encoder.layer.4.output.LayerNorm.weight', 'text_encoder.bert.encoder.layer.4.output.LayerNorm.bias', 'text_encoder.bert.encoder.layer.5.attention.self.query.weight', 'text_encoder.bert.encoder.layer.5.attention.self.query.bias', 'text_encoder.bert.encoder.layer.5.attention.self.key.weight', 'text_encoder.bert.encoder.layer.5.attention.self.key.bias', 'text_encoder.bert.encoder.layer.5.attention.self.value.weight', 'text_encoder.bert.encoder.layer.5.attention.self.value.bias', 'text_encoder.bert.encoder.layer.5.attention.output.dense.weight', 'text_encoder.bert.encoder.layer.5.attention.output.dense.bias', 'text_encoder.bert.encoder.layer.5.attention.output.LayerNorm.weight', 'text_encoder.bert.encoder.layer.5.attention.output.LayerNorm.bias', 'text_encoder.bert.encoder.layer.5.intermediate.dense.weight', 'text_encoder.bert.encoder.layer.5.intermediate.dense.bias', 'text_encoder.bert.encoder.layer.5.output.dense.weight', 'text_encoder.bert.encoder.layer.5.output.dense.bias', 'text_encoder.bert.encoder.layer.5.output.LayerNorm.weight', 'text_encoder.bert.encoder.layer.5.output.LayerNorm.bias', 'text_encoder.bert.encoder.layer.6.attention.self.query.weight', 'text_encoder.bert.encoder.layer.6.attention.self.query.bias', 'text_encoder.bert.encoder.layer.6.attention.self.key.weight', 'text_encoder.bert.encoder.layer.6.attention.self.key.bias', 'text_encoder.bert.encoder.layer.6.attention.self.value.weight', 'text_encoder.bert.encoder.layer.6.attention.self.value.bias', 'text_encoder.bert.encoder.layer.6.attention.output.dense.weight', 'text_encoder.bert.encoder.layer.6.attention.output.dense.bias', 'text_encoder.bert.encoder.layer.6.attention.output.LayerNorm.weight', 'text_encoder.bert.encoder.layer.6.attention.output.LayerNorm.bias', 'text_encoder.bert.encoder.layer.6.intermediate.dense.weight', 'text_encoder.bert.encoder.layer.6.intermediate.dense.bias', 'text_encoder.bert.encoder.layer.6.output.dense.weight', 'text_encoder.bert.encoder.layer.6.output.dense.bias', 'text_encoder.bert.encoder.layer.6.output.LayerNorm.weight', 'text_encoder.bert.encoder.layer.6.output.LayerNorm.bias', 'text_encoder.bert.encoder.layer.7.attention.self.query.weight', 'text_encoder.bert.encoder.layer.7.attention.self.query.bias', 'text_encoder.bert.encoder.layer.7.attention.self.key.weight', 'text_encoder.bert.encoder.layer.7.attention.self.key.bias', 'text_encoder.bert.encoder.layer.7.attention.self.value.weight', 'text_encoder.bert.encoder.layer.7.attention.self.value.bias', 'text_encoder.bert.encoder.layer.7.attention.output.dense.weight', 'text_encoder.bert.encoder.layer.7.attention.output.dense.bias', 'text_encoder.bert.encoder.layer.7.attention.output.LayerNorm.weight', 'text_encoder.bert.encoder.layer.7.attention.output.LayerNorm.bias', 'text_encoder.bert.encoder.layer.7.intermediate.dense.weight', 'text_encoder.bert.encoder.layer.7.intermediate.dense.bias', 'text_encoder.bert.encoder.layer.7.output.dense.weight', 'text_encoder.bert.encoder.layer.7.output.dense.bias', 'text_encoder.bert.encoder.layer.7.output.LayerNorm.weight', 'text_encoder.bert.encoder.layer.7.output.LayerNorm.bias', 'text_encoder.bert.encoder.layer.8.attention.self.query.weight', 'text_encoder.bert.encoder.layer.8.attention.self.query.bias', 'text_encoder.bert.encoder.layer.8.attention.self.key.weight', 'text_encoder.bert.encoder.layer.8.attention.self.key.bias', 'text_encoder.bert.encoder.layer.8.attention.self.value.weight', 'text_encoder.bert.encoder.layer.8.attention.self.value.bias', 'text_encoder.bert.encoder.layer.8.attention.output.dense.weight', 'text_encoder.bert.encoder.layer.8.attention.output.dense.bias', 'text_encoder.bert.encoder.layer.8.attention.output.LayerNorm.weight', 'text_encoder.bert.encoder.layer.8.attention.output.LayerNorm.bias', 'text_encoder.bert.encoder.layer.8.intermediate.dense.weight', 'text_encoder.bert.encoder.layer.8.intermediate.dense.bias', 'text_encoder.bert.encoder.layer.8.output.dense.weight', 'text_encoder.bert.encoder.layer.8.output.dense.bias', 'text_encoder.bert.encoder.layer.8.output.LayerNorm.weight', 'text_encoder.bert.encoder.layer.8.output.LayerNorm.bias', 'text_encoder.bert.encoder.layer.9.attention.self.query.weight', 'text_encoder.bert.encoder.layer.9.attention.self.query.bias', 'text_encoder.bert.encoder.layer.9.attention.self.key.weight', 'text_encoder.bert.encoder.layer.9.attention.self.key.bias', 'text_encoder.bert.encoder.layer.9.attention.self.value.weight', 'text_encoder.bert.encoder.layer.9.attention.self.value.bias', 'text_encoder.bert.encoder.layer.9.attention.output.dense.weight', 'text_encoder.bert.encoder.layer.9.attention.output.dense.bias', 'text_encoder.bert.encoder.layer.9.attention.output.LayerNorm.weight', 'text_encoder.bert.encoder.layer.9.attention.output.LayerNorm.bias', 'text_encoder.bert.encoder.layer.9.crossattention.self.query.weight', 'text_encoder.bert.encoder.layer.9.crossattention.self.query.bias', 'text_encoder.bert.encoder.layer.9.crossattention.self.key.weight', 'text_encoder.bert.encoder.layer.9.crossattention.self.key.bias', 'text_encoder.bert.encoder.layer.9.crossattention.self.value.weight', 'text_encoder.bert.encoder.layer.9.crossattention.self.value.bias', 'text_encoder.bert.encoder.layer.9.crossattention.output.dense.weight', 'text_encoder.bert.encoder.layer.9.crossattention.output.dense.bias', 'text_encoder.bert.encoder.layer.9.crossattention.output.LayerNorm.weight', 'text_encoder.bert.encoder.layer.9.crossattention.output.LayerNorm.bias', 'text_encoder.bert.encoder.layer.9.intermediate.dense.weight', 'text_encoder.bert.encoder.layer.9.intermediate.dense.bias', 'text_encoder.bert.encoder.layer.9.output.dense.weight', 'text_encoder.bert.encoder.layer.9.output.dense.bias', 'text_encoder.bert.encoder.layer.9.output.LayerNorm.weight', 'text_encoder.bert.encoder.layer.9.output.LayerNorm.bias', 'text_encoder.bert.encoder.layer.10.attention.self.query.weight', 'text_encoder.bert.encoder.layer.10.attention.self.query.bias', 'text_encoder.bert.encoder.layer.10.attention.self.key.weight', 'text_encoder.bert.encoder.layer.10.attention.self.key.bias', 'text_encoder.bert.encoder.layer.10.attention.self.value.weight', 'text_encoder.bert.encoder.layer.10.attention.self.value.bias', 'text_encoder.bert.encoder.layer.10.attention.output.dense.weight', 'text_encoder.bert.encoder.layer.10.attention.output.dense.bias', 'text_encoder.bert.encoder.layer.10.attention.output.LayerNorm.weight', 'text_encoder.bert.encoder.layer.10.attention.output.LayerNorm.bias', 'text_encoder.bert.encoder.layer.10.crossattention.self.query.weight', 'text_encoder.bert.encoder.layer.10.crossattention.self.query.bias', 'text_encoder.bert.encoder.layer.10.crossattention.self.key.weight', 'text_encoder.bert.encoder.layer.10.crossattention.self.key.bias', 'text_encoder.bert.encoder.layer.10.crossattention.self.value.weight', 'text_encoder.bert.encoder.layer.10.crossattention.self.value.bias', 'text_encoder.bert.encoder.layer.10.crossattention.output.dense.weight', 'text_encoder.bert.encoder.layer.10.crossattention.output.dense.bias', 'text_encoder.bert.encoder.layer.10.crossattention.output.LayerNorm.weight', 'text_encoder.bert.encoder.layer.10.crossattention.output.LayerNorm.bias', 'text_encoder.bert.encoder.layer.10.intermediate.dense.weight', 'text_encoder.bert.encoder.layer.10.intermediate.dense.bias', 'text_encoder.bert.encoder.layer.10.output.dense.weight', 'text_encoder.bert.encoder.layer.10.output.dense.bias', 'text_encoder.bert.encoder.layer.10.output.LayerNorm.weight', 'text_encoder.bert.encoder.layer.10.output.LayerNorm.bias', 'text_encoder.bert.encoder.layer.11.attention.self.query.weight', 'text_encoder.bert.encoder.layer.11.attention.self.query.bias', 'text_encoder.bert.encoder.layer.11.attention.self.key.weight', 'text_encoder.bert.encoder.layer.11.attention.self.key.bias', 'text_encoder.bert.encoder.layer.11.attention.self.value.weight', 'text_encoder.bert.encoder.layer.11.attention.self.value.bias', 'text_encoder.bert.encoder.layer.11.attention.output.dense.weight', 'text_encoder.bert.encoder.layer.11.attention.output.dense.bias', 'text_encoder.bert.encoder.layer.11.attention.output.LayerNorm.weight', 'text_encoder.bert.encoder.layer.11.attention.output.LayerNorm.bias', 'text_encoder.bert.encoder.layer.11.crossattention.self.query.weight', 'text_encoder.bert.encoder.layer.11.crossattention.self.query.bias', 'text_encoder.bert.encoder.layer.11.crossattention.self.key.weight', 'text_encoder.bert.encoder.layer.11.crossattention.self.key.bias', 'text_encoder.bert.encoder.layer.11.crossattention.self.value.weight', 'text_encoder.bert.encoder.layer.11.crossattention.self.value.bias', 'text_encoder.bert.encoder.layer.11.crossattention.output.dense.weight', 'text_encoder.bert.encoder.layer.11.crossattention.output.dense.bias', 'text_encoder.bert.encoder.layer.11.crossattention.output.LayerNorm.weight', 'text_encoder.bert.encoder.layer.11.crossattention.output.LayerNorm.bias', 'text_encoder.bert.encoder.layer.11.intermediate.dense.weight', 'text_encoder.bert.encoder.layer.11.intermediate.dense.bias', 'text_encoder.bert.encoder.layer.11.output.dense.weight', 'text_encoder.bert.encoder.layer.11.output.dense.bias', 'text_encoder.bert.encoder.layer.11.output.LayerNorm.weight', 'text_encoder.bert.encoder.layer.11.output.LayerNorm.bias', 'text_encoder.cls.predictions.bias', 'text_encoder.cls.predictions.transform.dense.weight', 'text_encoder.cls.predictions.transform.dense.bias', 'text_encoder.cls.predictions.transform.LayerNorm.weight', 'text_encoder.cls.predictions.transform.LayerNorm.bias', 'text_encoder.cls.predictions.decoder.weight', 'text_encoder.cls.predictions.decoder.bias'])
2023-12-30T15:43:24 | INFO | tasks.shared_utils : Loaded checkpoint from /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_25m.pth
2023-12-30T15:43:24 | INFO | __main__ : Start evaluation
2023-12-30T15:43:24 | INFO | tasks.retrieval_utils : Start evaluation for media_type=video
2023-12-30T15:43:24 | INFO | tasks.retrieval_utils : Computing dual encoder features...
2023-12-30T15:43:31 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2023-12-30T15:43:31 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2023-12-30T15:43:32 | INFO | utils.basic_utils : extracting image feats  [ 0/66]  eta: 0:07:07    time: 6.4733  data: 3.2466  max mem: 15484 res mem: 23840
2023-12-30T15:44:44 | INFO | utils.basic_utils : extracting image feats  [65/66]  eta: 0:00:01    time: 1.0742  data: 0.0345  max mem: 15717 res mem: 23840
2023-12-30T15:44:44 | INFO | utils.basic_utils : extracting image feats Total time: 0:01:18 (1.1855 s / it)
2023-12-30T15:44:54 | INFO | tasks.retrieval_utils : Finished feature extraction
2023-12-30T15:44:54 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product]
2023-12-30T15:44:54 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product], done!
2023-12-30T15:44:54 | INFO | tasks.retrieval_utils : Rerank dual-encoder results with cross-encoder...
2023-12-30T15:44:54 | INFO | tasks.retrieval_utils : i2t_scores.shape torch.Size([2088, 1989])
2023-12-30T15:44:54 | INFO | tasks.retrieval_utils : n_clip_per_video=1, with eval_frame_ensemble=concat
2023-12-30T15:44:54 | INFO | utils.basic_utils : Evaluation:  [   0/2088]  eta: 0:00:48    time: 0.0233  data: 0.0015  max mem: 15717 res mem: 23840
2023-12-30T15:45:01 | INFO | utils.basic_utils : Evaluation:  [ 100/2088]  eta: 0:02:16    time: 0.0694  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T15:45:08 | INFO | utils.basic_utils : Evaluation:  [ 200/2088]  eta: 0:02:10    time: 0.0686  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T15:45:15 | INFO | utils.basic_utils : Evaluation:  [ 300/2088]  eta: 0:02:03    time: 0.0695  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T15:45:22 | INFO | utils.basic_utils : Evaluation:  [ 400/2088]  eta: 0:01:57    time: 0.0697  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T15:45:29 | INFO | utils.basic_utils : Evaluation:  [ 500/2088]  eta: 0:01:50    time: 0.0699  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T15:45:36 | INFO | utils.basic_utils : Evaluation:  [ 600/2088]  eta: 0:01:43    time: 0.0699  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T15:45:43 | INFO | utils.basic_utils : Evaluation:  [ 700/2088]  eta: 0:01:36    time: 0.0699  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T15:45:50 | INFO | utils.basic_utils : Evaluation:  [ 800/2088]  eta: 0:01:29    time: 0.0702  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T15:45:57 | INFO | utils.basic_utils : Evaluation:  [ 900/2088]  eta: 0:01:22    time: 0.0698  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T15:46:04 | INFO | utils.basic_utils : Evaluation:  [1000/2088]  eta: 0:01:15    time: 0.0700  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T15:46:11 | INFO | utils.basic_utils : Evaluation:  [1100/2088]  eta: 0:01:08    time: 0.0700  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T15:46:18 | INFO | utils.basic_utils : Evaluation:  [1200/2088]  eta: 0:01:01    time: 0.0703  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T15:46:25 | INFO | utils.basic_utils : Evaluation:  [1300/2088]  eta: 0:00:55    time: 0.0703  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T15:46:32 | INFO | utils.basic_utils : Evaluation:  [1400/2088]  eta: 0:00:48    time: 0.0704  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T15:46:39 | INFO | utils.basic_utils : Evaluation:  [1500/2088]  eta: 0:00:41    time: 0.0704  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T15:46:46 | INFO | utils.basic_utils : Evaluation:  [1600/2088]  eta: 0:00:34    time: 0.0707  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T15:46:53 | INFO | utils.basic_utils : Evaluation:  [1700/2088]  eta: 0:00:27    time: 0.0709  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T15:47:00 | INFO | utils.basic_utils : Evaluation:  [1800/2088]  eta: 0:00:20    time: 0.0706  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T15:47:07 | INFO | utils.basic_utils : Evaluation:  [1900/2088]  eta: 0:00:13    time: 0.0702  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T15:47:14 | INFO | utils.basic_utils : Evaluation:  [2000/2088]  eta: 0:00:06    time: 0.0706  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T15:47:21 | INFO | utils.basic_utils : Evaluation:  [2087/2088]  eta: 0:00:00    time: 0.0705  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T15:47:21 | INFO | utils.basic_utils : Evaluation: Total time: 0:02:26 (0.0701 s / it)
2023-12-30T15:47:21 | INFO | tasks.retrieval_utils : t2i_scores.shape torch.Size([1989, 2088])
2023-12-30T15:47:21 | INFO | utils.basic_utils : Evaluation:  [   0/1989]  eta: 0:30:57    time: 0.9338  data: 0.0019  max mem: 15717 res mem: 23840
2023-12-30T15:48:40 | INFO | utils.basic_utils : Evaluation:  [ 100/1989]  eta: 0:24:38    time: 0.7808  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T15:49:59 | INFO | utils.basic_utils : Evaluation:  [ 200/1989]  eta: 0:23:28    time: 0.7930  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T15:51:17 | INFO | utils.basic_utils : Evaluation:  [ 300/1989]  eta: 0:22:09    time: 0.7839  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T15:52:38 | INFO | utils.basic_utils : Evaluation:  [ 400/1989]  eta: 0:20:56    time: 0.8037  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T15:53:58 | INFO | utils.basic_utils : Evaluation:  [ 500/1989]  eta: 0:19:40    time: 0.7874  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T15:55:17 | INFO | utils.basic_utils : Evaluation:  [ 600/1989]  eta: 0:18:20    time: 0.7550  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T15:56:35 | INFO | utils.basic_utils : Evaluation:  [ 700/1989]  eta: 0:16:58    time: 0.7857  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T15:57:54 | INFO | utils.basic_utils : Evaluation:  [ 800/1989]  eta: 0:15:40    time: 0.7941  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T15:59:18 | INFO | utils.basic_utils : Evaluation:  [ 900/1989]  eta: 0:14:26    time: 0.8619  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T16:00:44 | INFO | utils.basic_utils : Evaluation:  [1000/1989]  eta: 0:13:13    time: 0.8495  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T16:02:08 | INFO | utils.basic_utils : Evaluation:  [1100/1989]  eta: 0:11:56    time: 0.8436  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T16:03:33 | INFO | utils.basic_utils : Evaluation:  [1200/1989]  eta: 0:10:38    time: 0.8451  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T16:04:57 | INFO | utils.basic_utils : Evaluation:  [1300/1989]  eta: 0:09:19    time: 0.8409  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T16:06:23 | INFO | utils.basic_utils : Evaluation:  [1400/1989]  eta: 0:08:00    time: 0.8767  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T16:07:49 | INFO | utils.basic_utils : Evaluation:  [1500/1989]  eta: 0:06:40    time: 0.8494  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T16:09:16 | INFO | utils.basic_utils : Evaluation:  [1600/1989]  eta: 0:05:19    time: 0.8537  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T16:10:43 | INFO | utils.basic_utils : Evaluation:  [1700/1989]  eta: 0:03:58    time: 0.8600  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T16:12:10 | INFO | utils.basic_utils : Evaluation:  [1800/1989]  eta: 0:02:36    time: 0.8700  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T16:13:38 | INFO | utils.basic_utils : Evaluation:  [1900/1989]  eta: 0:01:13    time: 0.8436  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T16:14:58 | INFO | utils.basic_utils : Evaluation:  [1988/1989]  eta: 0:00:00    time: 0.9096  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T16:14:58 | INFO | utils.basic_utils : Evaluation: Total time: 0:27:37 (0.8334 s / it)
2023-12-30T16:14:58 | INFO | tasks.retrieval_utils : Evaluation time 0:31:33
2023-12-30T16:15:00 | INFO | __main__ : Epoch 0
2023-12-30T16:15:00 | INFO | __main__ : 
          txt_r1  txt_r5  txt_r10  txt_r_mean  img_r1  img_r5  img_r10  img_r_mean  r_mean
val/        0.00    0.19     0.43        0.21    0.05    0.25      0.6        0.30    0.25
val_emb/    0.14    0.72     1.10        0.65    0.10    0.35      0.6        0.35    0.50
2023-12-30T16:15:00 | INFO | __main__ : Training time 0:31:36
2023-12-30T16:15:00 | INFO | __main__ : best epoch 0 [config.stop_key val/]
2023-12-30T16:15:00 | INFO | __main__ : Checkpoints and Logs saved at exp/finetuning/ret_ssv2_label/b16_25m
2023-12-30T16:30:02 | INFO | umt : Logging to: exp/finetuning/ret_ssv2_label/b16_25m/train.log
2023-12-30T16:30:02 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  your_ssv2_path: /datassd2/DATASET/something-something-v2/rawvideo/forward
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/ssv2_ret_label_train.json', '/datassd2/DATASET/something-something-v2/rawvideo/forward', 'video']
  test_file: {
      val: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/ssv2_ret_label_val_small.json', '/datassd2/DATASET/something-something-v2/rawvideo/forward', 'video'] }
  test_types: ['val']
  num_workers: 6
  stop_key: val/
  is_paragraph_retrieval: False
  has_multi_vision_gt: True
  num_frames: 12
  num_frames_test: 12
  batch_size: 32
  max_txt_l: 25
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 12
          sample_type: rand
          num_frames_test: 12
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 25
          video: 25 }
      batch_size: {
          image: 32
          video: 32 }
      batch_size_test: {
          image: 32
          video: 32 } }
  text_enc: bert
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_b16
          img_size: 224
          patch_size: 16
          d_model: 768
          encoder_embed_dim: 768
          encoder_depth: 12
          encoder_num_heads: 12
          drop_path_rate: 0.1
          num_frames: 12
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 12
          clip_decoder_embed_dim: 768
          clip_output_dim: 512
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 224
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      multimodal: {
          enable: True }
      embed_dim: 512
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 5e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 10
      min_lr_multi: 0.01
      warmup_epochs: 0 }
  evaluate: True
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: user
      project: umt_ret_ssv2 }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/finetuning/ret_ssv2_label/b16_25m
  resume: False
  debug: False
  log_freq: 100
  seed: 42
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_models/Unmasked_Teacher/multimodality/ret_ssv2_label_b16_25m.pth
  rank: 0
  world_size: 1
  gpu: 0
  distributed: True
  dist_backend: nccl }
2023-12-30T16:30:02 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'your_ssv2_path': '/datassd2/DATASET/something-something-v2/rawvideo/forward', 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/ssv2_ret_label_train.json', '/datassd2/DATASET/something-something-v2/rawvideo/forward', 'video'], 'test_file': {'val': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/ssv2_ret_label_val_small.json', '/datassd2/DATASET/something-something-v2/rawvideo/forward', 'video']}, 'test_types': ['val'], 'num_workers': 6, 'stop_key': 'val/', 'is_paragraph_retrieval': False, 'has_multi_vision_gt': True, 'num_frames': 12, 'num_frames_test': 12, 'batch_size': 32, 'max_txt_l': 25, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 12, 'sample_type': 'rand', 'num_frames_test': 12, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 25, 'video': 25}, 'batch_size': {'image': 32, 'video': 32}, 'batch_size_test': {'image': 32, 'video': 32}}, 'text_enc': 'bert', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_b16', 'img_size': 224, 'patch_size': 16, 'd_model': 768, 'encoder_embed_dim': 768, 'encoder_depth': 12, 'encoder_num_heads': 12, 'drop_path_rate': 0.1, 'num_frames': 12, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 12, 'clip_decoder_embed_dim': 768, 'clip_output_dim': 512, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 224, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'multimodal': {'enable': True}, 'embed_dim': 512, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 5e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 10, 'min_lr_multi': 0.01, 'warmup_epochs': 0}, 'evaluate': True, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': False, 'entity': 'user', 'project': 'umt_ret_ssv2'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': 'exp/finetuning/ret_ssv2_label/b16_25m', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 42, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_models/Unmasked_Teacher/multimodality/ret_ssv2_label_b16_25m.pth', 'rank': 0, 'world_size': 1, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2023-12-30T16:30:02 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/ssv2_ret_label_train.json', '/datassd2/DATASET/something-something-v2/rawvideo/forward', 'video']
2023-12-30T16:30:02 | INFO | tasks.pretrain : Creating dataset for ret
2023-12-30T16:30:03 | INFO | tasks.shared_utils : Creating model
2023-12-30T16:30:16 | INFO | models.umt : Build vision_encoder: vit_b16
2023-12-30T16:30:16 | INFO | models.backbones.vit.vit : Num of patches: 2352
2023-12-30T16:30:16 | INFO | models.backbones.vit.vit : Use checkpoint: True
2023-12-30T16:30:16 | INFO | models.backbones.vit.vit : Checkpoint number: 12
2023-12-30T16:30:16 | INFO | models.backbones.vit.vit : Student return index: []
2023-12-30T16:30:26 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
2023-12-30T16:30:26 | INFO | models.umt : Build text_encoder bert_base
2023-12-30T16:30:28 | INFO | models.backbones.bert.xbert : build bert with cross_module: ca
2023-12-30T16:30:28 | INFO | models.criterions : Norm type: l2
2023-12-30T16:30:28 | INFO | models.criterions : Loss type: l2
2023-12-30T16:30:29 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.temp: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.weight: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.q_bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.v_bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.qkv.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.weight: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.weight: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.q_bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.v_bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.qkv.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.weight: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.weight: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.q_bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.v_bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.qkv.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.weight: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.weight: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.q_bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.v_bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.qkv.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.weight: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.weight: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.q_bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.v_bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.qkv.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.weight: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.weight: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.q_bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.v_bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.qkv.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.weight: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.weight: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.q_bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.v_bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.qkv.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.weight: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.weight: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.q_bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.v_bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.qkv.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.weight: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.weight: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.q_bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.v_bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.qkv.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.weight: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.weight: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.q_bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.v_bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.qkv.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.weight: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.weight: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.q_bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.v_bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.qkv.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.weight: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.weight: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.q_bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.v_bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.qkv.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.weight: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.weight: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.weight: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.embeddings.word_embeddings.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.embeddings.position_embeddings.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.embeddings.token_type_embeddings.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_proj.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.vision_proj.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_proj.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.text_proj.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.itm_head.weight: wd: 0.02, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : param module.itm_head.bias: wd: 0, lr: 5e-05
2023-12-30T16:30:29 | INFO | utils.optimizer : optimizer -- lr=5e-05 wd=0.02 len(p)=140
2023-12-30T16:30:29 | INFO | utils.optimizer : optimizer -- lr=5e-05 wd=0 len(p)=256
2023-12-30T16:30:29 | INFO | tasks.shared_utils : Auto resuming
2023-12-30T16:30:29 | INFO | tasks.shared_utils : Not found checkpoint in exp/finetuning/ret_ssv2_label/b16_25m
2023-12-30T16:30:29 | INFO | tasks.shared_utils : <All keys matched successfully>
2023-12-30T16:30:29 | INFO | tasks.shared_utils : Loaded checkpoint from /datassd2/pretrained_models/Unmasked_Teacher/multimodality/ret_ssv2_label_b16_25m.pth
2023-12-30T16:30:29 | INFO | __main__ : Start evaluation
2023-12-30T16:30:29 | INFO | tasks.retrieval_utils : Start evaluation for media_type=video
2023-12-30T16:30:29 | INFO | tasks.retrieval_utils : Computing dual encoder features...
2023-12-30T16:30:37 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2023-12-30T16:30:37 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2023-12-30T16:30:38 | INFO | utils.basic_utils : extracting image feats  [ 0/66]  eta: 0:07:33    time: 6.8718  data: 3.5498  max mem: 15484 res mem: 23840
2023-12-30T16:31:51 | INFO | utils.basic_utils : extracting image feats  [65/66]  eta: 0:00:01    time: 1.0961  data: 0.0461  max mem: 15717 res mem: 23840
2023-12-30T16:31:51 | INFO | utils.basic_utils : extracting image feats Total time: 0:01:19 (1.2101 s / it)
2023-12-30T16:32:03 | INFO | tasks.retrieval_utils : Finished feature extraction
2023-12-30T16:32:03 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product]
2023-12-30T16:32:03 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product], done!
2023-12-30T16:32:03 | INFO | tasks.retrieval_utils : Rerank dual-encoder results with cross-encoder...
2023-12-30T16:32:03 | INFO | tasks.retrieval_utils : i2t_scores.shape torch.Size([2088, 1989])
2023-12-30T16:32:03 | INFO | tasks.retrieval_utils : n_clip_per_video=1, with eval_frame_ensemble=concat
2023-12-30T16:32:03 | INFO | utils.basic_utils : Evaluation:  [   0/2088]  eta: 0:01:30    time: 0.0432  data: 0.0026  max mem: 15717 res mem: 23840
2023-12-30T16:32:10 | INFO | utils.basic_utils : Evaluation:  [ 100/2088]  eta: 0:02:17    time: 0.0696  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T16:32:17 | INFO | utils.basic_utils : Evaluation:  [ 200/2088]  eta: 0:02:11    time: 0.0698  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T16:32:24 | INFO | utils.basic_utils : Evaluation:  [ 300/2088]  eta: 0:02:04    time: 0.0700  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T16:32:31 | INFO | utils.basic_utils : Evaluation:  [ 400/2088]  eta: 0:01:57    time: 0.0700  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T16:32:38 | INFO | utils.basic_utils : Evaluation:  [ 500/2088]  eta: 0:01:50    time: 0.0699  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T16:32:45 | INFO | utils.basic_utils : Evaluation:  [ 600/2088]  eta: 0:01:43    time: 0.0701  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T16:32:52 | INFO | utils.basic_utils : Evaluation:  [ 700/2088]  eta: 0:01:37    time: 0.0704  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T16:32:59 | INFO | utils.basic_utils : Evaluation:  [ 800/2088]  eta: 0:01:30    time: 0.0705  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T16:33:06 | INFO | utils.basic_utils : Evaluation:  [ 900/2088]  eta: 0:01:23    time: 0.0704  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T16:33:13 | INFO | utils.basic_utils : Evaluation:  [1000/2088]  eta: 0:01:16    time: 0.0707  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T16:33:20 | INFO | utils.basic_utils : Evaluation:  [1100/2088]  eta: 0:01:09    time: 0.0707  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T16:33:27 | INFO | utils.basic_utils : Evaluation:  [1200/2088]  eta: 0:01:02    time: 0.0710  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T16:33:34 | INFO | utils.basic_utils : Evaluation:  [1300/2088]  eta: 0:00:55    time: 0.0711  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T16:33:42 | INFO | utils.basic_utils : Evaluation:  [1400/2088]  eta: 0:00:48    time: 0.0710  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T16:33:49 | INFO | utils.basic_utils : Evaluation:  [1500/2088]  eta: 0:00:41    time: 0.0709  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T16:33:56 | INFO | utils.basic_utils : Evaluation:  [1600/2088]  eta: 0:00:34    time: 0.0718  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T16:34:03 | INFO | utils.basic_utils : Evaluation:  [1700/2088]  eta: 0:00:27    time: 0.0709  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T16:34:10 | INFO | utils.basic_utils : Evaluation:  [1800/2088]  eta: 0:00:20    time: 0.0707  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T16:34:17 | INFO | utils.basic_utils : Evaluation:  [1900/2088]  eta: 0:00:13    time: 0.0708  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T16:34:24 | INFO | utils.basic_utils : Evaluation:  [2000/2088]  eta: 0:00:06    time: 0.0711  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T16:34:30 | INFO | utils.basic_utils : Evaluation:  [2087/2088]  eta: 0:00:00    time: 0.0720  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T16:34:30 | INFO | utils.basic_utils : Evaluation: Total time: 0:02:27 (0.0706 s / it)
2023-12-30T16:34:30 | INFO | tasks.retrieval_utils : t2i_scores.shape torch.Size([1989, 2088])
2023-12-30T16:34:32 | INFO | utils.basic_utils : Evaluation:  [   0/1989]  eta: 0:38:28    time: 1.1605  data: 0.0025  max mem: 15717 res mem: 23840
2023-12-30T16:35:58 | INFO | utils.basic_utils : Evaluation:  [ 100/1989]  eta: 0:27:11    time: 0.8593  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T16:37:21 | INFO | utils.basic_utils : Evaluation:  [ 200/1989]  eta: 0:25:21    time: 0.8528  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T16:38:48 | INFO | utils.basic_utils : Evaluation:  [ 300/1989]  eta: 0:24:03    time: 0.8300  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T16:40:16 | INFO | utils.basic_utils : Evaluation:  [ 400/1989]  eta: 0:22:50    time: 0.8887  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T16:41:47 | INFO | utils.basic_utils : Evaluation:  [ 500/1989]  eta: 0:21:37    time: 0.8894  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T16:43:24 | INFO | utils.basic_utils : Evaluation:  [ 600/1989]  eta: 0:20:32    time: 0.9735  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T16:44:54 | INFO | utils.basic_utils : Evaluation:  [ 700/1989]  eta: 0:19:06    time: 0.8569  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T16:46:25 | INFO | utils.basic_utils : Evaluation:  [ 800/1989]  eta: 0:17:40    time: 0.8767  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T16:47:58 | INFO | utils.basic_utils : Evaluation:  [ 900/1989]  eta: 0:16:15    time: 0.8929  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T16:49:27 | INFO | utils.basic_utils : Evaluation:  [1000/1989]  eta: 0:14:46    time: 0.8920  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T16:51:00 | INFO | utils.basic_utils : Evaluation:  [1100/1989]  eta: 0:13:19    time: 0.9176  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T16:52:32 | INFO | utils.basic_utils : Evaluation:  [1200/1989]  eta: 0:11:50    time: 0.9555  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T16:54:08 | INFO | utils.basic_utils : Evaluation:  [1300/1989]  eta: 0:10:23    time: 1.0360  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T16:55:43 | INFO | utils.basic_utils : Evaluation:  [1400/1989]  eta: 0:08:55    time: 0.9581  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T16:57:15 | INFO | utils.basic_utils : Evaluation:  [1500/1989]  eta: 0:07:24    time: 0.8507  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T16:58:44 | INFO | utils.basic_utils : Evaluation:  [1600/1989]  eta: 0:05:53    time: 0.9040  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T17:00:16 | INFO | utils.basic_utils : Evaluation:  [1700/1989]  eta: 0:04:22    time: 0.9291  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T17:01:48 | INFO | utils.basic_utils : Evaluation:  [1800/1989]  eta: 0:02:51    time: 0.9302  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T17:03:14 | INFO | utils.basic_utils : Evaluation:  [1900/1989]  eta: 0:01:20    time: 0.8935  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T17:04:30 | INFO | utils.basic_utils : Evaluation:  [1988/1989]  eta: 0:00:00    time: 0.9163  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-30T17:04:30 | INFO | utils.basic_utils : Evaluation: Total time: 0:29:59 (0.9049 s / it)
2023-12-30T17:04:30 | INFO | tasks.retrieval_utils : Evaluation time 0:34:00
2023-12-30T17:04:33 | INFO | __main__ : Epoch 0
2023-12-30T17:04:33 | INFO | __main__ : 
          txt_r1  txt_r5  txt_r10  txt_r_mean  img_r1  img_r5  img_r10  img_r_mean  r_mean
val/       63.84   88.31    93.15       81.77   64.15   88.24    92.71       81.70   81.73
val_emb/   56.70   85.39    91.76       77.95   58.17   85.22    91.40       78.26   78.11
2023-12-30T17:04:33 | INFO | __main__ : Training time 0:34:03
2023-12-30T17:04:33 | INFO | __main__ : best epoch 0 [config.stop_key val/]
2023-12-30T17:04:33 | INFO | __main__ : Checkpoints and Logs saved at exp/finetuning/ret_ssv2_label/b16_25m
2023-12-31T07:39:41 | INFO | umt : Logging to: exp/finetuning/ret_ssv2_label/b16_25m/train.log
2023-12-31T07:39:41 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  your_ssv2_path: /datassd2/DATASET/something-something-v2/rawvideo/reverse
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/ssv2_ret_label_train.json', '/datassd2/DATASET/something-something-v2/rawvideo/reverse', 'video']
  test_file: {
      val: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/ssv2_ret_label_val_small.json', '/datassd2/DATASET/something-something-v2/rawvideo/reverse', 'video'] }
  test_types: ['val']
  num_workers: 6
  stop_key: val/
  is_paragraph_retrieval: False
  has_multi_vision_gt: True
  num_frames: 12
  num_frames_test: 12
  batch_size: 32
  max_txt_l: 25
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 12
          sample_type: rand
          num_frames_test: 12
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 25
          video: 25 }
      batch_size: {
          image: 32
          video: 32 }
      batch_size_test: {
          image: 32
          video: 32 } }
  text_enc: bert
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_b16
          img_size: 224
          patch_size: 16
          d_model: 768
          encoder_embed_dim: 768
          encoder_depth: 12
          encoder_num_heads: 12
          drop_path_rate: 0.1
          num_frames: 12
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 12
          clip_decoder_embed_dim: 768
          clip_output_dim: 512
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 224
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      multimodal: {
          enable: True }
      embed_dim: 512
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 5e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 10
      min_lr_multi: 0.01
      warmup_epochs: 0 }
  evaluate: True
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: user
      project: umt_ret_ssv2 }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/finetuning/ret_ssv2_label/b16_25m
  resume: False
  debug: False
  log_freq: 100
  seed: 42
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_models/Unmasked_Teacher/multimodality/ret_ssv2_label_b16_25m.pth
  rank: 0
  world_size: 1
  gpu: 0
  distributed: True
  dist_backend: nccl }
2023-12-31T07:39:41 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'your_ssv2_path': '/datassd2/DATASET/something-something-v2/rawvideo/reverse', 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/ssv2_ret_label_train.json', '/datassd2/DATASET/something-something-v2/rawvideo/reverse', 'video'], 'test_file': {'val': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/ssv2_ret_label_val_small.json', '/datassd2/DATASET/something-something-v2/rawvideo/reverse', 'video']}, 'test_types': ['val'], 'num_workers': 6, 'stop_key': 'val/', 'is_paragraph_retrieval': False, 'has_multi_vision_gt': True, 'num_frames': 12, 'num_frames_test': 12, 'batch_size': 32, 'max_txt_l': 25, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 12, 'sample_type': 'rand', 'num_frames_test': 12, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 25, 'video': 25}, 'batch_size': {'image': 32, 'video': 32}, 'batch_size_test': {'image': 32, 'video': 32}}, 'text_enc': 'bert', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_b16', 'img_size': 224, 'patch_size': 16, 'd_model': 768, 'encoder_embed_dim': 768, 'encoder_depth': 12, 'encoder_num_heads': 12, 'drop_path_rate': 0.1, 'num_frames': 12, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 12, 'clip_decoder_embed_dim': 768, 'clip_output_dim': 512, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 224, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'multimodal': {'enable': True}, 'embed_dim': 512, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 5e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 10, 'min_lr_multi': 0.01, 'warmup_epochs': 0}, 'evaluate': True, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': False, 'entity': 'user', 'project': 'umt_ret_ssv2'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': 'exp/finetuning/ret_ssv2_label/b16_25m', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 42, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_models/Unmasked_Teacher/multimodality/ret_ssv2_label_b16_25m.pth', 'rank': 0, 'world_size': 1, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2023-12-31T07:39:41 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/ssv2_ret_label_train.json', '/datassd2/DATASET/something-something-v2/rawvideo/reverse', 'video']
2023-12-31T07:39:41 | INFO | tasks.pretrain : Creating dataset for ret
2023-12-31T07:39:42 | INFO | tasks.shared_utils : Creating model
2023-12-31T07:39:54 | INFO | models.umt : Build vision_encoder: vit_b16
2023-12-31T07:39:54 | INFO | models.backbones.vit.vit : Num of patches: 2352
2023-12-31T07:39:54 | INFO | models.backbones.vit.vit : Use checkpoint: True
2023-12-31T07:39:54 | INFO | models.backbones.vit.vit : Checkpoint number: 12
2023-12-31T07:39:54 | INFO | models.backbones.vit.vit : Student return index: []
2023-12-31T07:40:02 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
2023-12-31T07:40:02 | INFO | models.umt : Build text_encoder bert_base
2023-12-31T07:40:04 | INFO | models.backbones.bert.xbert : build bert with cross_module: ca
2023-12-31T07:40:04 | INFO | models.criterions : Norm type: l2
2023-12-31T07:40:04 | INFO | models.criterions : Loss type: l2
2023-12-31T07:40:04 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.temp: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.weight: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.q_bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.v_bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.qkv.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.weight: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.weight: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.q_bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.v_bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.qkv.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.weight: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.weight: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.q_bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.v_bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.qkv.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.weight: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.weight: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.q_bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.v_bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.qkv.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.weight: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.weight: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.q_bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.v_bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.qkv.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.weight: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.weight: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.q_bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.v_bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.qkv.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.weight: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.weight: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.q_bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.v_bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.qkv.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.weight: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.weight: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.q_bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.v_bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.qkv.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.weight: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.weight: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.q_bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.v_bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.qkv.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.weight: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.weight: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.q_bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.v_bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.qkv.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.weight: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.weight: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.q_bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.v_bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.qkv.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.weight: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.weight: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.q_bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.v_bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.qkv.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.weight: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.weight: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.weight: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.embeddings.word_embeddings.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.embeddings.position_embeddings.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.embeddings.token_type_embeddings.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.weight: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_proj.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.vision_proj.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_proj.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.text_proj.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.itm_head.weight: wd: 0.02, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : param module.itm_head.bias: wd: 0, lr: 5e-05
2023-12-31T07:40:04 | INFO | utils.optimizer : optimizer -- lr=5e-05 wd=0.02 len(p)=140
2023-12-31T07:40:04 | INFO | utils.optimizer : optimizer -- lr=5e-05 wd=0 len(p)=256
2023-12-31T07:40:04 | INFO | tasks.shared_utils : Auto resuming
2023-12-31T07:40:04 | INFO | tasks.shared_utils : Not found checkpoint in exp/finetuning/ret_ssv2_label/b16_25m
2023-12-31T07:40:05 | INFO | tasks.shared_utils : <All keys matched successfully>
2023-12-31T07:40:05 | INFO | tasks.shared_utils : Loaded checkpoint from /datassd2/pretrained_models/Unmasked_Teacher/multimodality/ret_ssv2_label_b16_25m.pth
2023-12-31T07:40:05 | INFO | __main__ : Start evaluation
2023-12-31T07:40:05 | INFO | tasks.retrieval_utils : Start evaluation for media_type=video
2023-12-31T07:40:05 | INFO | tasks.retrieval_utils : Computing dual encoder features...
2023-12-31T07:40:11 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2023-12-31T07:40:11 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2023-12-31T07:40:12 | INFO | utils.basic_utils : extracting image feats  [ 0/66]  eta: 0:07:05    time: 6.4395  data: 3.5915  max mem: 15484 res mem: 23840
2023-12-31T07:41:23 | INFO | utils.basic_utils : extracting image feats  [65/66]  eta: 0:00:01    time: 1.0575  data: 0.0302  max mem: 15717 res mem: 23840
2023-12-31T07:41:23 | INFO | utils.basic_utils : extracting image feats Total time: 0:01:16 (1.1633 s / it)
2023-12-31T07:41:31 | INFO | tasks.retrieval_utils : Finished feature extraction
2023-12-31T07:41:31 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product]
2023-12-31T07:41:31 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product], done!
2023-12-31T07:41:31 | INFO | tasks.retrieval_utils : Rerank dual-encoder results with cross-encoder...
2023-12-31T07:41:31 | INFO | tasks.retrieval_utils : i2t_scores.shape torch.Size([2088, 1989])
2023-12-31T07:41:31 | INFO | tasks.retrieval_utils : n_clip_per_video=1, with eval_frame_ensemble=concat
2023-12-31T07:41:31 | INFO | utils.basic_utils : Evaluation:  [   0/2088]  eta: 0:00:43    time: 0.0209  data: 0.0013  max mem: 15717 res mem: 23840
2023-12-31T07:41:38 | INFO | utils.basic_utils : Evaluation:  [ 100/2088]  eta: 0:02:14    time: 0.0686  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-31T07:41:45 | INFO | utils.basic_utils : Evaluation:  [ 200/2088]  eta: 0:02:08    time: 0.0688  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-31T07:41:52 | INFO | utils.basic_utils : Evaluation:  [ 300/2088]  eta: 0:02:02    time: 0.0690  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-31T07:41:59 | INFO | utils.basic_utils : Evaluation:  [ 400/2088]  eta: 0:01:55    time: 0.0690  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-31T07:42:06 | INFO | utils.basic_utils : Evaluation:  [ 500/2088]  eta: 0:01:49    time: 0.0690  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-31T07:42:13 | INFO | utils.basic_utils : Evaluation:  [ 600/2088]  eta: 0:01:42    time: 0.0692  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-31T07:42:20 | INFO | utils.basic_utils : Evaluation:  [ 700/2088]  eta: 0:01:35    time: 0.0693  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-31T07:42:26 | INFO | utils.basic_utils : Evaluation:  [ 800/2088]  eta: 0:01:28    time: 0.0694  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-31T07:42:33 | INFO | utils.basic_utils : Evaluation:  [ 900/2088]  eta: 0:01:21    time: 0.0695  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-31T07:42:40 | INFO | utils.basic_utils : Evaluation:  [1000/2088]  eta: 0:01:15    time: 0.0695  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-31T07:42:47 | INFO | utils.basic_utils : Evaluation:  [1100/2088]  eta: 0:01:08    time: 0.0695  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-31T07:42:54 | INFO | utils.basic_utils : Evaluation:  [1200/2088]  eta: 0:01:01    time: 0.0696  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-31T07:43:01 | INFO | utils.basic_utils : Evaluation:  [1300/2088]  eta: 0:00:54    time: 0.0697  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-31T07:43:08 | INFO | utils.basic_utils : Evaluation:  [1400/2088]  eta: 0:00:47    time: 0.0697  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-31T07:43:15 | INFO | utils.basic_utils : Evaluation:  [1500/2088]  eta: 0:00:40    time: 0.0698  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-31T07:43:22 | INFO | utils.basic_utils : Evaluation:  [1600/2088]  eta: 0:00:33    time: 0.0700  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-31T07:43:29 | INFO | utils.basic_utils : Evaluation:  [1700/2088]  eta: 0:00:26    time: 0.0699  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-31T07:43:36 | INFO | utils.basic_utils : Evaluation:  [1800/2088]  eta: 0:00:19    time: 0.0698  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-31T07:43:43 | INFO | utils.basic_utils : Evaluation:  [1900/2088]  eta: 0:00:13    time: 0.0700  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-31T07:43:50 | INFO | utils.basic_utils : Evaluation:  [2000/2088]  eta: 0:00:06    time: 0.0698  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-31T07:43:56 | INFO | utils.basic_utils : Evaluation:  [2087/2088]  eta: 0:00:00    time: 0.0699  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-31T07:43:56 | INFO | utils.basic_utils : Evaluation: Total time: 0:02:24 (0.0694 s / it)
2023-12-31T07:43:56 | INFO | tasks.retrieval_utils : t2i_scores.shape torch.Size([1989, 2088])
2023-12-31T07:43:57 | INFO | utils.basic_utils : Evaluation:  [   0/1989]  eta: 0:27:39    time: 0.8342  data: 0.0013  max mem: 15717 res mem: 23840
2023-12-31T07:45:09 | INFO | utils.basic_utils : Evaluation:  [ 100/1989]  eta: 0:22:48    time: 0.7175  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-31T07:46:21 | INFO | utils.basic_utils : Evaluation:  [ 200/1989]  eta: 0:21:27    time: 0.7078  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-31T07:47:33 | INFO | utils.basic_utils : Evaluation:  [ 300/1989]  eta: 0:20:13    time: 0.7183  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-31T07:48:44 | INFO | utils.basic_utils : Evaluation:  [ 400/1989]  eta: 0:19:00    time: 0.7231  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-31T07:49:56 | INFO | utils.basic_utils : Evaluation:  [ 500/1989]  eta: 0:17:48    time: 0.7230  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-31T07:51:07 | INFO | utils.basic_utils : Evaluation:  [ 600/1989]  eta: 0:16:36    time: 0.7224  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-31T07:52:19 | INFO | utils.basic_utils : Evaluation:  [ 700/1989]  eta: 0:15:23    time: 0.7112  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-31T07:53:30 | INFO | utils.basic_utils : Evaluation:  [ 800/1989]  eta: 0:14:11    time: 0.7088  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-31T07:54:42 | INFO | utils.basic_utils : Evaluation:  [ 900/1989]  eta: 0:13:00    time: 0.7139  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-31T07:55:53 | INFO | utils.basic_utils : Evaluation:  [1000/1989]  eta: 0:11:48    time: 0.7141  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-31T07:57:05 | INFO | utils.basic_utils : Evaluation:  [1100/1989]  eta: 0:10:36    time: 0.7185  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-31T07:58:16 | INFO | utils.basic_utils : Evaluation:  [1200/1989]  eta: 0:09:24    time: 0.7049  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-31T07:59:27 | INFO | utils.basic_utils : Evaluation:  [1300/1989]  eta: 0:08:13    time: 0.7057  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-31T08:00:39 | INFO | utils.basic_utils : Evaluation:  [1400/1989]  eta: 0:07:01    time: 0.7177  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-31T08:01:50 | INFO | utils.basic_utils : Evaluation:  [1500/1989]  eta: 0:05:49    time: 0.7125  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-31T08:03:01 | INFO | utils.basic_utils : Evaluation:  [1600/1989]  eta: 0:04:38    time: 0.7154  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-31T08:04:12 | INFO | utils.basic_utils : Evaluation:  [1700/1989]  eta: 0:03:26    time: 0.7182  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-31T08:05:23 | INFO | utils.basic_utils : Evaluation:  [1800/1989]  eta: 0:02:15    time: 0.7031  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-31T08:06:34 | INFO | utils.basic_utils : Evaluation:  [1900/1989]  eta: 0:01:03    time: 0.7077  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-31T08:07:36 | INFO | utils.basic_utils : Evaluation:  [1988/1989]  eta: 0:00:00    time: 0.7070  data: 0.0000  max mem: 15717 res mem: 23840
2023-12-31T08:07:36 | INFO | utils.basic_utils : Evaluation: Total time: 0:23:40 (0.7140 s / it)
2023-12-31T08:07:36 | INFO | tasks.retrieval_utils : Evaluation time 0:27:31
2023-12-31T08:07:38 | INFO | __main__ : Epoch 0
2023-12-31T08:07:38 | INFO | __main__ : 
          txt_r1  txt_r5  txt_r10  txt_r_mean  img_r1  img_r5  img_r10  img_r_mean  r_mean
val/       53.21   80.36    87.50       73.69   53.04   80.79    86.22       73.35   73.52
val_emb/   48.08   77.63    86.16       70.63   47.66   77.02    85.12       69.93   70.28
2023-12-31T08:07:38 | INFO | __main__ : Training time 0:27:33
2023-12-31T08:07:38 | INFO | __main__ : best epoch 0 [config.stop_key val/]
2023-12-31T08:07:38 | INFO | __main__ : Checkpoints and Logs saved at exp/finetuning/ret_ssv2_label/b16_25m
