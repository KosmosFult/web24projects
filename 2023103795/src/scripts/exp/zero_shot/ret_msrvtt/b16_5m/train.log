2023-12-30T13:32:51 | INFO | umt : Logging to: exp/zero_shot/ret_msrvtt/b16_5m/train.log
2023-12-30T13:32:51 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  your_msrvtt_path: /data1/DATASET/MSRVTT/videos
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_train9k.json', '/data1/DATASET/MSRVTT/videos', 'video']
  test_file: {
      test: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_test1k.json', '/data1/DATASET/MSRVTT/videos', 'video'] }
  test_types: ['test']
  num_workers: 6
  stop_key: test/
  is_paragraph_retrieval: False
  num_frames: 4
  num_frames_test: 4
  batch_size: 32
  max_txt_l: 32
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 4
          sample_type: rand
          num_frames_test: 4
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 32
          video: 32 }
      batch_size: {
          image: 32
          video: 32 }
      batch_size_test: {
          image: 32
          video: 32 } }
  text_enc: bert
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_b16
          img_size: 224
          patch_size: 16
          d_model: 768
          encoder_embed_dim: 768
          encoder_depth: 12
          encoder_num_heads: 12
          drop_path_rate: 0.2
          num_frames: 4
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 12
          clip_decoder_embed_dim: 768
          clip_output_dim: 512
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_model/Unmasked_Teacher/b16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 224
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      multimodal: {
          enable: True }
      embed_dim: 512
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 2e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 7
      min_lr_multi: 0.01
      warmup_epochs: 1 }
  evaluate: True
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: user
      project: umt }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/zero_shot/ret_msrvtt/b16_5m
  resume: False
  debug: False
  log_freq: 100
  seed: 42
  zero_shot: True
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_model/Unmasked_Teacher/multimodality/b16_5m.pth
  rank: 0
  world_size: 1
  gpu: 0
  distributed: True
  dist_backend: nccl }
2023-12-30T13:32:51 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'your_msrvtt_path': '/data1/DATASET/MSRVTT/videos', 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_train9k.json', '/data1/DATASET/MSRVTT/videos', 'video'], 'test_file': {'test': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_test1k.json', '/data1/DATASET/MSRVTT/videos', 'video']}, 'test_types': ['test'], 'num_workers': 6, 'stop_key': 'test/', 'is_paragraph_retrieval': False, 'num_frames': 4, 'num_frames_test': 4, 'batch_size': 32, 'max_txt_l': 32, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 4, 'sample_type': 'rand', 'num_frames_test': 4, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 32, 'video': 32}, 'batch_size': {'image': 32, 'video': 32}, 'batch_size_test': {'image': 32, 'video': 32}}, 'text_enc': 'bert', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_b16', 'img_size': 224, 'patch_size': 16, 'd_model': 768, 'encoder_embed_dim': 768, 'encoder_depth': 12, 'encoder_num_heads': 12, 'drop_path_rate': 0.2, 'num_frames': 4, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 12, 'clip_decoder_embed_dim': 768, 'clip_output_dim': 512, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_model/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 224, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'multimodal': {'enable': True}, 'embed_dim': 512, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 2e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 7, 'min_lr_multi': 0.01, 'warmup_epochs': 1}, 'evaluate': True, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': False, 'entity': 'user', 'project': 'umt'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': 'exp/zero_shot/ret_msrvtt/b16_5m', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 42, 'zero_shot': True, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_model/Unmasked_Teacher/multimodality/b16_5m.pth', 'rank': 0, 'world_size': 1, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2023-12-30T13:32:51 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_train9k.json', '/data1/DATASET/MSRVTT/videos', 'video']
2023-12-30T13:32:51 | INFO | tasks.pretrain : Creating dataset for ret
2023-12-30T13:32:52 | INFO | tasks.shared_utils : Creating model
2023-12-30T13:32:55 | INFO | models.umt : Build vision_encoder: vit_b16
2023-12-30T13:32:55 | INFO | models.backbones.vit.vit : Num of patches: 784
2023-12-30T13:32:55 | INFO | models.backbones.vit.vit : Use checkpoint: True
2023-12-30T13:32:55 | INFO | models.backbones.vit.vit : Checkpoint number: 12
2023-12-30T13:32:55 | INFO | models.backbones.vit.vit : Student return index: []
2023-12-30T13:33:00 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_model/Unmasked_Teacher/b16_ptk710_f8_res224.pth
2023-12-30T13:33:24 | INFO | umt : Logging to: exp/zero_shot/ret_msrvtt/b16_5m/train.log
2023-12-30T13:33:24 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  your_msrvtt_path: /data1/DATASET/MSRVTT/videos
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_train9k.json', '/data1/DATASET/MSRVTT/videos', 'video']
  test_file: {
      test: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_test1k.json', '/data1/DATASET/MSRVTT/videos', 'video'] }
  test_types: ['test']
  num_workers: 6
  stop_key: test/
  is_paragraph_retrieval: False
  num_frames: 4
  num_frames_test: 4
  batch_size: 32
  max_txt_l: 32
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 4
          sample_type: rand
          num_frames_test: 4
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 32
          video: 32 }
      batch_size: {
          image: 32
          video: 32 }
      batch_size_test: {
          image: 32
          video: 32 } }
  text_enc: bert
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_b16
          img_size: 224
          patch_size: 16
          d_model: 768
          encoder_embed_dim: 768
          encoder_depth: 12
          encoder_num_heads: 12
          drop_path_rate: 0.2
          num_frames: 4
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 12
          clip_decoder_embed_dim: 768
          clip_output_dim: 512
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 224
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      multimodal: {
          enable: True }
      embed_dim: 512
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 2e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 7
      min_lr_multi: 0.01
      warmup_epochs: 1 }
  evaluate: True
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: user
      project: umt }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/zero_shot/ret_msrvtt/b16_5m
  resume: False
  debug: False
  log_freq: 100
  seed: 42
  zero_shot: True
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_model/Unmasked_Teacher/multimodality/b16_5m.pth
  rank: 0
  world_size: 1
  gpu: 0
  distributed: True
  dist_backend: nccl }
2023-12-30T13:33:24 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'your_msrvtt_path': '/data1/DATASET/MSRVTT/videos', 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_train9k.json', '/data1/DATASET/MSRVTT/videos', 'video'], 'test_file': {'test': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_test1k.json', '/data1/DATASET/MSRVTT/videos', 'video']}, 'test_types': ['test'], 'num_workers': 6, 'stop_key': 'test/', 'is_paragraph_retrieval': False, 'num_frames': 4, 'num_frames_test': 4, 'batch_size': 32, 'max_txt_l': 32, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 4, 'sample_type': 'rand', 'num_frames_test': 4, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 32, 'video': 32}, 'batch_size': {'image': 32, 'video': 32}, 'batch_size_test': {'image': 32, 'video': 32}}, 'text_enc': 'bert', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_b16', 'img_size': 224, 'patch_size': 16, 'd_model': 768, 'encoder_embed_dim': 768, 'encoder_depth': 12, 'encoder_num_heads': 12, 'drop_path_rate': 0.2, 'num_frames': 4, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 12, 'clip_decoder_embed_dim': 768, 'clip_output_dim': 512, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 224, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'multimodal': {'enable': True}, 'embed_dim': 512, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 2e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 7, 'min_lr_multi': 0.01, 'warmup_epochs': 1}, 'evaluate': True, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': False, 'entity': 'user', 'project': 'umt'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': 'exp/zero_shot/ret_msrvtt/b16_5m', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 42, 'zero_shot': True, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_model/Unmasked_Teacher/multimodality/b16_5m.pth', 'rank': 0, 'world_size': 1, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2023-12-30T13:33:24 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_train9k.json', '/data1/DATASET/MSRVTT/videos', 'video']
2023-12-30T13:33:24 | INFO | tasks.pretrain : Creating dataset for ret
2023-12-30T13:33:25 | INFO | tasks.shared_utils : Creating model
2023-12-30T13:33:28 | INFO | models.umt : Build vision_encoder: vit_b16
2023-12-30T13:33:28 | INFO | models.backbones.vit.vit : Num of patches: 784
2023-12-30T13:33:28 | INFO | models.backbones.vit.vit : Use checkpoint: True
2023-12-30T13:33:28 | INFO | models.backbones.vit.vit : Checkpoint number: 12
2023-12-30T13:33:28 | INFO | models.backbones.vit.vit : Student return index: []
2023-12-30T13:33:33 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
2023-12-30T13:33:33 | INFO | models.umt : Build text_encoder bert_base
2023-12-30T13:33:35 | INFO | models.backbones.bert.xbert : build bert with cross_module: ca
2023-12-30T13:33:35 | INFO | models.criterions : Norm type: l2
2023-12-30T13:33:35 | INFO | models.criterions : Loss type: l2
2023-12-30T13:33:36 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.temp: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.weight: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.weight: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.embeddings.word_embeddings.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.embeddings.position_embeddings.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.embeddings.token_type_embeddings.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.vision_proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.text_proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.itm_head.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : param module.itm_head.bias: wd: 0, lr: 2e-05
2023-12-30T13:33:36 | INFO | utils.optimizer : optimizer -- lr=2e-05 wd=0.02 len(p)=140
2023-12-30T13:33:36 | INFO | utils.optimizer : optimizer -- lr=2e-05 wd=0 len(p)=256
2023-12-30T13:33:36 | INFO | tasks.shared_utils : Auto resuming
2023-12-30T13:33:36 | INFO | tasks.shared_utils : Not found checkpoint in exp/zero_shot/ret_msrvtt/b16_5m
2023-12-30T13:33:36 | WARNING | tasks.shared_utils : No pretrained checkpoint provided, training from scratch
2023-12-30T13:33:36 | INFO | __main__ : Start evaluation
2023-12-30T13:33:36 | INFO | tasks.retrieval_utils : Start evaluation for media_type=video
2023-12-30T13:33:36 | INFO | tasks.retrieval_utils : Computing dual encoder features...
2023-12-30T13:35:14 | INFO | umt : Logging to: exp/zero_shot/ret_msrvtt/b16_5m/train.log
2023-12-30T13:35:14 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  your_msrvtt_path: /data1/DATASET/MSRVTT/videos
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_train9k.json', '/data1/DATASET/MSRVTT/videos', 'video']
  test_file: {
      test: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_test1k.json', '/data1/DATASET/MSRVTT/videos', 'video'] }
  test_types: ['test']
  num_workers: 6
  stop_key: test/
  is_paragraph_retrieval: False
  num_frames: 4
  num_frames_test: 4
  batch_size: 32
  max_txt_l: 32
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 4
          sample_type: rand
          num_frames_test: 4
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 32
          video: 32 }
      batch_size: {
          image: 32
          video: 32 }
      batch_size_test: {
          image: 32
          video: 32 } }
  text_enc: bert
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_b16
          img_size: 224
          patch_size: 16
          d_model: 768
          encoder_embed_dim: 768
          encoder_depth: 12
          encoder_num_heads: 12
          drop_path_rate: 0.2
          num_frames: 4
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 12
          clip_decoder_embed_dim: 768
          clip_output_dim: 512
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 224
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      multimodal: {
          enable: True }
      embed_dim: 512
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 2e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 7
      min_lr_multi: 0.01
      warmup_epochs: 1 }
  evaluate: True
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: user
      project: umt }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/zero_shot/ret_msrvtt/b16_5m
  resume: False
  debug: False
  log_freq: 100
  seed: 42
  zero_shot: True
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_model/Unmasked_Teacher/multimodality/b16_5m.pth
  rank: 0
  world_size: 1
  gpu: 0
  distributed: True
  dist_backend: nccl }
2023-12-30T13:35:14 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'your_msrvtt_path': '/data1/DATASET/MSRVTT/videos', 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_train9k.json', '/data1/DATASET/MSRVTT/videos', 'video'], 'test_file': {'test': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_test1k.json', '/data1/DATASET/MSRVTT/videos', 'video']}, 'test_types': ['test'], 'num_workers': 6, 'stop_key': 'test/', 'is_paragraph_retrieval': False, 'num_frames': 4, 'num_frames_test': 4, 'batch_size': 32, 'max_txt_l': 32, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 4, 'sample_type': 'rand', 'num_frames_test': 4, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 32, 'video': 32}, 'batch_size': {'image': 32, 'video': 32}, 'batch_size_test': {'image': 32, 'video': 32}}, 'text_enc': 'bert', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_b16', 'img_size': 224, 'patch_size': 16, 'd_model': 768, 'encoder_embed_dim': 768, 'encoder_depth': 12, 'encoder_num_heads': 12, 'drop_path_rate': 0.2, 'num_frames': 4, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 12, 'clip_decoder_embed_dim': 768, 'clip_output_dim': 512, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 224, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'multimodal': {'enable': True}, 'embed_dim': 512, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 2e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 7, 'min_lr_multi': 0.01, 'warmup_epochs': 1}, 'evaluate': True, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': False, 'entity': 'user', 'project': 'umt'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': 'exp/zero_shot/ret_msrvtt/b16_5m', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 42, 'zero_shot': True, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_model/Unmasked_Teacher/multimodality/b16_5m.pth', 'rank': 0, 'world_size': 1, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2023-12-30T13:35:14 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_train9k.json', '/data1/DATASET/MSRVTT/videos', 'video']
2023-12-30T13:35:14 | INFO | tasks.pretrain : Creating dataset for ret
2023-12-30T13:35:15 | INFO | tasks.shared_utils : Creating model
2023-12-30T13:35:18 | INFO | models.umt : Build vision_encoder: vit_b16
2023-12-30T13:35:18 | INFO | models.backbones.vit.vit : Num of patches: 784
2023-12-30T13:35:18 | INFO | models.backbones.vit.vit : Use checkpoint: True
2023-12-30T13:35:18 | INFO | models.backbones.vit.vit : Checkpoint number: 12
2023-12-30T13:35:18 | INFO | models.backbones.vit.vit : Student return index: []
2023-12-30T13:35:23 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
2023-12-30T13:35:24 | INFO | models.umt : Build text_encoder bert_base
2023-12-30T13:35:26 | INFO | models.backbones.bert.xbert : build bert with cross_module: ca
2023-12-30T13:35:26 | INFO | models.criterions : Norm type: l2
2023-12-30T13:35:26 | INFO | models.criterions : Loss type: l2
2023-12-30T13:35:26 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.temp: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.weight: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.weight: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.embeddings.word_embeddings.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.embeddings.position_embeddings.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.embeddings.token_type_embeddings.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.vision_proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.text_proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.itm_head.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : param module.itm_head.bias: wd: 0, lr: 2e-05
2023-12-30T13:35:26 | INFO | utils.optimizer : optimizer -- lr=2e-05 wd=0.02 len(p)=140
2023-12-30T13:35:26 | INFO | utils.optimizer : optimizer -- lr=2e-05 wd=0 len(p)=256
2023-12-30T13:35:26 | INFO | tasks.shared_utils : Auto resuming
2023-12-30T13:35:26 | INFO | tasks.shared_utils : Not found checkpoint in exp/zero_shot/ret_msrvtt/b16_5m
2023-12-30T13:35:26 | WARNING | tasks.shared_utils : No pretrained checkpoint provided, training from scratch
2023-12-30T13:35:26 | INFO | __main__ : Start evaluation
2023-12-30T13:35:26 | INFO | tasks.retrieval_utils : Start evaluation for media_type=video
2023-12-30T13:35:26 | INFO | tasks.retrieval_utils : Computing dual encoder features...
2023-12-30T13:35:34 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2023-12-30T13:35:34 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2023-12-30T13:35:34 | INFO | utils.basic_utils : extracting image feats  [ 0/32]  eta: 0:03:38    time: 6.8404  data: 4.7350  max mem: 3743 res mem: 4648
2023-12-30T13:35:54 | INFO | utils.basic_utils : extracting image feats  [31/32]  eta: 0:00:00    time: 0.7382  data: 0.5191  max mem: 3826 res mem: 4650
2023-12-30T13:35:54 | INFO | utils.basic_utils : extracting image feats Total time: 0:00:26 (0.8370 s / it)
2023-12-30T13:35:56 | INFO | tasks.retrieval_utils : Finished feature extraction
2023-12-30T13:35:56 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product]
2023-12-30T13:35:56 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product], done!
2023-12-30T13:35:56 | INFO | tasks.retrieval_utils : Rerank dual-encoder results with cross-encoder...
2023-12-30T13:35:56 | INFO | tasks.retrieval_utils : i2t_scores.shape torch.Size([1000, 1000])
2023-12-30T13:35:56 | INFO | tasks.retrieval_utils : n_clip_per_video=1, with eval_frame_ensemble=concat
2023-12-30T13:35:56 | INFO | utils.basic_utils : Evaluation:  [   0/1000]  eta: 0:00:27    time: 0.0278  data: 0.0007  max mem: 3826 res mem: 4650
2023-12-30T13:35:59 | INFO | utils.basic_utils : Evaluation:  [ 100/1000]  eta: 0:00:25    time: 0.0280  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T13:36:01 | INFO | utils.basic_utils : Evaluation:  [ 200/1000]  eta: 0:00:22    time: 0.0281  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T13:36:04 | INFO | utils.basic_utils : Evaluation:  [ 300/1000]  eta: 0:00:19    time: 0.0284  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T13:36:07 | INFO | utils.basic_utils : Evaluation:  [ 400/1000]  eta: 0:00:16    time: 0.0284  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T13:36:10 | INFO | utils.basic_utils : Evaluation:  [ 500/1000]  eta: 0:00:14    time: 0.0283  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T13:36:13 | INFO | utils.basic_utils : Evaluation:  [ 600/1000]  eta: 0:00:11    time: 0.0281  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T13:36:16 | INFO | utils.basic_utils : Evaluation:  [ 700/1000]  eta: 0:00:08    time: 0.0284  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T13:36:18 | INFO | utils.basic_utils : Evaluation:  [ 800/1000]  eta: 0:00:05    time: 0.0285  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T13:36:21 | INFO | utils.basic_utils : Evaluation:  [ 900/1000]  eta: 0:00:02    time: 0.0285  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T13:36:24 | INFO | utils.basic_utils : Evaluation:  [ 999/1000]  eta: 0:00:00    time: 0.0283  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T13:36:24 | INFO | utils.basic_utils : Evaluation: Total time: 0:00:28 (0.0283 s / it)
2023-12-30T13:36:24 | INFO | tasks.retrieval_utils : t2i_scores.shape torch.Size([1000, 1000])
2023-12-30T13:38:31 | INFO | umt : Logging to: exp/zero_shot/ret_msrvtt/b16_5m/train.log
2023-12-30T13:38:31 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  your_msrvtt_path: /data1/DATASET/MSRVTT/videos
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_train9k.json', '/data1/DATASET/MSRVTT/videos', 'video']
  test_file: {
      test: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_test1k.json', '/data1/DATASET/MSRVTT/videos', 'video'] }
  test_types: ['test']
  num_workers: 6
  stop_key: test/
  is_paragraph_retrieval: False
  num_frames: 4
  num_frames_test: 4
  batch_size: 32
  max_txt_l: 32
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 4
          sample_type: rand
          num_frames_test: 4
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 32
          video: 32 }
      batch_size: {
          image: 32
          video: 32 }
      batch_size_test: {
          image: 32
          video: 32 } }
  text_enc: bert
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_b16
          img_size: 224
          patch_size: 16
          d_model: 768
          encoder_embed_dim: 768
          encoder_depth: 12
          encoder_num_heads: 12
          drop_path_rate: 0.2
          num_frames: 4
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 12
          clip_decoder_embed_dim: 768
          clip_output_dim: 512
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 224
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      multimodal: {
          enable: True }
      embed_dim: 512
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 2e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 7
      min_lr_multi: 0.01
      warmup_epochs: 1 }
  evaluate: True
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: user
      project: umt }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/zero_shot/ret_msrvtt/b16_5m
  resume: False
  debug: False
  log_freq: 100
  seed: 42
  zero_shot: True
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_model/Unmasked_Teacher/multimodality/b16_5m.pth
  rank: 0
  world_size: 1
  gpu: 0
  distributed: True
  dist_backend: nccl }
2023-12-30T13:38:31 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'your_msrvtt_path': '/data1/DATASET/MSRVTT/videos', 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_train9k.json', '/data1/DATASET/MSRVTT/videos', 'video'], 'test_file': {'test': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_test1k.json', '/data1/DATASET/MSRVTT/videos', 'video']}, 'test_types': ['test'], 'num_workers': 6, 'stop_key': 'test/', 'is_paragraph_retrieval': False, 'num_frames': 4, 'num_frames_test': 4, 'batch_size': 32, 'max_txt_l': 32, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 4, 'sample_type': 'rand', 'num_frames_test': 4, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 32, 'video': 32}, 'batch_size': {'image': 32, 'video': 32}, 'batch_size_test': {'image': 32, 'video': 32}}, 'text_enc': 'bert', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_b16', 'img_size': 224, 'patch_size': 16, 'd_model': 768, 'encoder_embed_dim': 768, 'encoder_depth': 12, 'encoder_num_heads': 12, 'drop_path_rate': 0.2, 'num_frames': 4, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 12, 'clip_decoder_embed_dim': 768, 'clip_output_dim': 512, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 224, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'multimodal': {'enable': True}, 'embed_dim': 512, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 2e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 7, 'min_lr_multi': 0.01, 'warmup_epochs': 1}, 'evaluate': True, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': False, 'entity': 'user', 'project': 'umt'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': 'exp/zero_shot/ret_msrvtt/b16_5m', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 42, 'zero_shot': True, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_model/Unmasked_Teacher/multimodality/b16_5m.pth', 'rank': 0, 'world_size': 1, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2023-12-30T13:38:31 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_train9k.json', '/data1/DATASET/MSRVTT/videos', 'video']
2023-12-30T13:38:31 | INFO | tasks.pretrain : Creating dataset for ret
2023-12-30T13:38:32 | INFO | tasks.shared_utils : Creating model
2023-12-30T13:38:36 | INFO | models.umt : Build vision_encoder: vit_b16
2023-12-30T13:38:36 | INFO | models.backbones.vit.vit : Num of patches: 784
2023-12-30T13:38:36 | INFO | models.backbones.vit.vit : Use checkpoint: True
2023-12-30T13:38:36 | INFO | models.backbones.vit.vit : Checkpoint number: 12
2023-12-30T13:38:36 | INFO | models.backbones.vit.vit : Student return index: []
2023-12-30T13:38:40 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
2023-12-30T13:38:40 | INFO | models.umt : Build text_encoder bert_base
2023-12-30T13:38:43 | INFO | models.backbones.bert.xbert : build bert with cross_module: ca
2023-12-30T13:38:43 | INFO | models.criterions : Norm type: l2
2023-12-30T13:38:43 | INFO | models.criterions : Loss type: l2
2023-12-30T13:38:44 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.temp: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.weight: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.weight: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.embeddings.word_embeddings.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.embeddings.position_embeddings.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.embeddings.token_type_embeddings.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.vision_proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.text_proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.itm_head.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : param module.itm_head.bias: wd: 0, lr: 2e-05
2023-12-30T13:38:44 | INFO | utils.optimizer : optimizer -- lr=2e-05 wd=0.02 len(p)=140
2023-12-30T13:38:44 | INFO | utils.optimizer : optimizer -- lr=2e-05 wd=0 len(p)=256
2023-12-30T13:38:44 | INFO | tasks.shared_utils : Auto resuming
2023-12-30T13:38:44 | INFO | tasks.shared_utils : Not found checkpoint in exp/zero_shot/ret_msrvtt/b16_5m
2023-12-30T13:38:44 | WARNING | tasks.shared_utils : No pretrained checkpoint provided, training from scratch
2023-12-30T13:38:44 | INFO | __main__ : Start evaluation
2023-12-30T13:38:44 | INFO | tasks.retrieval_utils : Start evaluation for media_type=video
2023-12-30T13:38:44 | INFO | tasks.retrieval_utils : Computing dual encoder features...
2023-12-30T13:38:51 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2023-12-30T13:38:51 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2023-12-30T13:38:51 | INFO | utils.basic_utils : extracting image feats  [ 0/32]  eta: 0:03:18    time: 6.1949  data: 4.1853  max mem: 3743 res mem: 4648
2023-12-30T13:39:09 | INFO | utils.basic_utils : extracting image feats  [31/32]  eta: 0:00:00    time: 0.6723  data: 0.4507  max mem: 3826 res mem: 4650
2023-12-30T13:39:09 | INFO | utils.basic_utils : extracting image feats Total time: 0:00:24 (0.7519 s / it)
2023-12-30T13:39:11 | INFO | tasks.retrieval_utils : Finished feature extraction
2023-12-30T13:39:11 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product]
2023-12-30T13:39:11 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product], done!
2023-12-30T13:39:11 | INFO | tasks.retrieval_utils : Rerank dual-encoder results with cross-encoder...
2023-12-30T13:39:11 | INFO | tasks.retrieval_utils : i2t_scores.shape torch.Size([1000, 1000])
2023-12-30T13:39:11 | INFO | tasks.retrieval_utils : n_clip_per_video=1, with eval_frame_ensemble=concat
2023-12-30T13:39:11 | INFO | utils.basic_utils : Evaluation:  [   0/1000]  eta: 0:00:27    time: 0.0276  data: 0.0008  max mem: 3826 res mem: 4650
2023-12-30T13:39:14 | INFO | utils.basic_utils : Evaluation:  [ 100/1000]  eta: 0:00:25    time: 0.0284  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T13:39:17 | INFO | utils.basic_utils : Evaluation:  [ 200/1000]  eta: 0:00:22    time: 0.0285  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T13:39:19 | INFO | utils.basic_utils : Evaluation:  [ 300/1000]  eta: 0:00:19    time: 0.0287  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T13:39:22 | INFO | utils.basic_utils : Evaluation:  [ 400/1000]  eta: 0:00:17    time: 0.0285  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T13:39:25 | INFO | utils.basic_utils : Evaluation:  [ 500/1000]  eta: 0:00:14    time: 0.0284  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T13:39:28 | INFO | utils.basic_utils : Evaluation:  [ 600/1000]  eta: 0:00:11    time: 0.0286  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T13:39:31 | INFO | utils.basic_utils : Evaluation:  [ 700/1000]  eta: 0:00:08    time: 0.0288  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T13:39:34 | INFO | utils.basic_utils : Evaluation:  [ 800/1000]  eta: 0:00:05    time: 0.0286  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T13:39:37 | INFO | utils.basic_utils : Evaluation:  [ 900/1000]  eta: 0:00:02    time: 0.0286  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T13:39:39 | INFO | utils.basic_utils : Evaluation:  [ 999/1000]  eta: 0:00:00    time: 0.0286  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T13:39:39 | INFO | utils.basic_utils : Evaluation: Total time: 0:00:28 (0.0286 s / it)
2023-12-30T13:39:39 | INFO | tasks.retrieval_utils : t2i_scores.shape torch.Size([1000, 1000])
2023-12-30T13:43:44 | INFO | umt : Logging to: exp/zero_shot/ret_msrvtt/b16_5m/train.log
2023-12-30T13:43:44 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  your_msrvtt_path: /data1/DATASET/MSRVTT/videos
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_train9k.json', '/data1/DATASET/MSRVTT/videos', 'video']
  test_file: {
      test: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_test1k.json', '/data1/DATASET/MSRVTT/videos', 'video'] }
  test_types: ['test']
  num_workers: 6
  stop_key: test/
  is_paragraph_retrieval: False
  num_frames: 4
  num_frames_test: 4
  batch_size: 32
  max_txt_l: 32
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 4
          sample_type: rand
          num_frames_test: 4
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 32
          video: 32 }
      batch_size: {
          image: 32
          video: 32 }
      batch_size_test: {
          image: 32
          video: 32 } }
  text_enc: bert
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_b16
          img_size: 224
          patch_size: 16
          d_model: 768
          encoder_embed_dim: 768
          encoder_depth: 12
          encoder_num_heads: 12
          drop_path_rate: 0.2
          num_frames: 4
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 12
          clip_decoder_embed_dim: 768
          clip_output_dim: 512
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 224
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      multimodal: {
          enable: True }
      embed_dim: 512
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 2e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 7
      min_lr_multi: 0.01
      warmup_epochs: 1 }
  evaluate: True
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: user
      project: umt }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/zero_shot/ret_msrvtt/b16_5m
  resume: False
  debug: False
  log_freq: 100
  seed: 42
  zero_shot: True
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_model/Unmasked_Teacher/multimodality/b16_5m.pth
  rank: 0
  world_size: 1
  gpu: 0
  distributed: True
  dist_backend: nccl }
2023-12-30T13:43:44 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'your_msrvtt_path': '/data1/DATASET/MSRVTT/videos', 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_train9k.json', '/data1/DATASET/MSRVTT/videos', 'video'], 'test_file': {'test': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_test1k.json', '/data1/DATASET/MSRVTT/videos', 'video']}, 'test_types': ['test'], 'num_workers': 6, 'stop_key': 'test/', 'is_paragraph_retrieval': False, 'num_frames': 4, 'num_frames_test': 4, 'batch_size': 32, 'max_txt_l': 32, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 4, 'sample_type': 'rand', 'num_frames_test': 4, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 32, 'video': 32}, 'batch_size': {'image': 32, 'video': 32}, 'batch_size_test': {'image': 32, 'video': 32}}, 'text_enc': 'bert', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_b16', 'img_size': 224, 'patch_size': 16, 'd_model': 768, 'encoder_embed_dim': 768, 'encoder_depth': 12, 'encoder_num_heads': 12, 'drop_path_rate': 0.2, 'num_frames': 4, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 12, 'clip_decoder_embed_dim': 768, 'clip_output_dim': 512, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 224, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'multimodal': {'enable': True}, 'embed_dim': 512, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 2e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 7, 'min_lr_multi': 0.01, 'warmup_epochs': 1}, 'evaluate': True, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': False, 'entity': 'user', 'project': 'umt'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': 'exp/zero_shot/ret_msrvtt/b16_5m', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 42, 'zero_shot': True, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_model/Unmasked_Teacher/multimodality/b16_5m.pth', 'rank': 0, 'world_size': 1, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2023-12-30T13:43:44 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_train9k.json', '/data1/DATASET/MSRVTT/videos', 'video']
2023-12-30T13:43:44 | INFO | tasks.pretrain : Creating dataset for ret
2023-12-30T13:43:45 | INFO | tasks.shared_utils : Creating model
2023-12-30T13:43:48 | INFO | models.umt : Build vision_encoder: vit_b16
2023-12-30T13:43:48 | INFO | models.backbones.vit.vit : Num of patches: 784
2023-12-30T13:43:48 | INFO | models.backbones.vit.vit : Use checkpoint: True
2023-12-30T13:43:48 | INFO | models.backbones.vit.vit : Checkpoint number: 12
2023-12-30T13:43:48 | INFO | models.backbones.vit.vit : Student return index: []
2023-12-30T13:43:53 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
2023-12-30T13:43:53 | INFO | models.umt : Build text_encoder bert_base
2023-12-30T13:43:55 | INFO | models.backbones.bert.xbert : build bert with cross_module: ca
2023-12-30T13:43:55 | INFO | models.criterions : Norm type: l2
2023-12-30T13:43:55 | INFO | models.criterions : Loss type: l2
2023-12-30T13:43:56 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.temp: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.weight: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.weight: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.embeddings.word_embeddings.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.embeddings.position_embeddings.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.embeddings.token_type_embeddings.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.vision_proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.text_proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.itm_head.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : param module.itm_head.bias: wd: 0, lr: 2e-05
2023-12-30T13:43:56 | INFO | utils.optimizer : optimizer -- lr=2e-05 wd=0.02 len(p)=140
2023-12-30T13:43:56 | INFO | utils.optimizer : optimizer -- lr=2e-05 wd=0 len(p)=256
2023-12-30T13:43:56 | INFO | tasks.shared_utils : Auto resuming
2023-12-30T13:43:56 | INFO | tasks.shared_utils : Not found checkpoint in exp/zero_shot/ret_msrvtt/b16_5m
2023-12-30T13:43:56 | WARNING | tasks.shared_utils : No pretrained checkpoint provided, training from scratch
2023-12-30T13:43:56 | INFO | __main__ : Start evaluation
2023-12-30T13:43:56 | INFO | tasks.retrieval_utils : Start evaluation for media_type=video
2023-12-30T13:43:56 | INFO | tasks.retrieval_utils : Computing dual encoder features...
2023-12-30T13:44:03 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2023-12-30T13:44:03 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2023-12-30T13:44:04 | INFO | utils.basic_utils : extracting image feats  [ 0/32]  eta: 0:03:34    time: 6.6916  data: 4.1505  max mem: 3743 res mem: 4648
2023-12-30T13:44:21 | INFO | utils.basic_utils : extracting image feats  [31/32]  eta: 0:00:00    time: 0.6895  data: 0.4700  max mem: 3826 res mem: 4650
2023-12-30T13:44:21 | INFO | utils.basic_utils : extracting image feats Total time: 0:00:23 (0.7401 s / it)
2023-12-30T13:44:22 | INFO | tasks.retrieval_utils : Finished feature extraction
2023-12-30T13:44:22 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product]
2023-12-30T13:44:22 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product], done!
2023-12-30T13:44:22 | INFO | tasks.retrieval_utils : Rerank dual-encoder results with cross-encoder...
2023-12-30T13:44:22 | INFO | tasks.retrieval_utils : i2t_scores.shape torch.Size([1000, 1000])
2023-12-30T13:44:22 | INFO | tasks.retrieval_utils : n_clip_per_video=1, with eval_frame_ensemble=concat
2023-12-30T13:44:22 | INFO | utils.basic_utils : Evaluation:  [   0/1000]  eta: 0:00:23    time: 0.0231  data: 0.0007  max mem: 3826 res mem: 4650
2023-12-30T13:44:25 | INFO | utils.basic_utils : Evaluation:  [ 100/1000]  eta: 0:00:25    time: 0.0280  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T13:44:28 | INFO | utils.basic_utils : Evaluation:  [ 200/1000]  eta: 0:00:22    time: 0.0281  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T13:44:30 | INFO | utils.basic_utils : Evaluation:  [ 300/1000]  eta: 0:00:19    time: 0.0282  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T13:44:33 | INFO | utils.basic_utils : Evaluation:  [ 400/1000]  eta: 0:00:16    time: 0.0283  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T13:44:36 | INFO | utils.basic_utils : Evaluation:  [ 500/1000]  eta: 0:00:14    time: 0.0282  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T13:44:39 | INFO | utils.basic_utils : Evaluation:  [ 600/1000]  eta: 0:00:11    time: 0.0281  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T13:44:42 | INFO | utils.basic_utils : Evaluation:  [ 700/1000]  eta: 0:00:08    time: 0.0284  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T13:44:44 | INFO | utils.basic_utils : Evaluation:  [ 800/1000]  eta: 0:00:05    time: 0.0285  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T13:44:47 | INFO | utils.basic_utils : Evaluation:  [ 900/1000]  eta: 0:00:02    time: 0.0284  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T13:44:50 | INFO | utils.basic_utils : Evaluation:  [ 999/1000]  eta: 0:00:00    time: 0.0283  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T13:44:50 | INFO | utils.basic_utils : Evaluation: Total time: 0:00:28 (0.0282 s / it)
2023-12-30T13:44:50 | INFO | tasks.retrieval_utils : t2i_scores.shape torch.Size([1000, 1000])
2023-12-30T13:45:34 | INFO | umt : Logging to: exp/zero_shot/ret_msrvtt/b16_5m/train.log
2023-12-30T13:45:34 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  your_msrvtt_path: /data1/DATASET/MSRVTT/videos
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_train9k.json', '/data1/DATASET/MSRVTT/videos', 'video']
  test_file: {
      test: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_test1k.json', '/data1/DATASET/MSRVTT/videos', 'video'] }
  test_types: ['test']
  num_workers: 6
  stop_key: test/
  is_paragraph_retrieval: False
  num_frames: 4
  num_frames_test: 4
  batch_size: 32
  max_txt_l: 32
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 4
          sample_type: rand
          num_frames_test: 4
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 32
          video: 32 }
      batch_size: {
          image: 32
          video: 32 }
      batch_size_test: {
          image: 32
          video: 32 } }
  text_enc: bert
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_b16
          img_size: 224
          patch_size: 16
          d_model: 768
          encoder_embed_dim: 768
          encoder_depth: 12
          encoder_num_heads: 12
          drop_path_rate: 0.2
          num_frames: 4
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 12
          clip_decoder_embed_dim: 768
          clip_output_dim: 512
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 224
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      multimodal: {
          enable: True }
      embed_dim: 512
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 2e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 7
      min_lr_multi: 0.01
      warmup_epochs: 1 }
  evaluate: True
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: user
      project: umt }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/zero_shot/ret_msrvtt/b16_5m
  resume: False
  debug: False
  log_freq: 100
  seed: 42
  zero_shot: True
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_model/Unmasked_Teacher/multimodality/b16_5m.pth
  rank: 0
  world_size: 1
  gpu: 0
  distributed: True
  dist_backend: nccl }
2023-12-30T13:45:34 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'your_msrvtt_path': '/data1/DATASET/MSRVTT/videos', 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_train9k.json', '/data1/DATASET/MSRVTT/videos', 'video'], 'test_file': {'test': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_test1k.json', '/data1/DATASET/MSRVTT/videos', 'video']}, 'test_types': ['test'], 'num_workers': 6, 'stop_key': 'test/', 'is_paragraph_retrieval': False, 'num_frames': 4, 'num_frames_test': 4, 'batch_size': 32, 'max_txt_l': 32, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 4, 'sample_type': 'rand', 'num_frames_test': 4, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 32, 'video': 32}, 'batch_size': {'image': 32, 'video': 32}, 'batch_size_test': {'image': 32, 'video': 32}}, 'text_enc': 'bert', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_b16', 'img_size': 224, 'patch_size': 16, 'd_model': 768, 'encoder_embed_dim': 768, 'encoder_depth': 12, 'encoder_num_heads': 12, 'drop_path_rate': 0.2, 'num_frames': 4, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 12, 'clip_decoder_embed_dim': 768, 'clip_output_dim': 512, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 224, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'multimodal': {'enable': True}, 'embed_dim': 512, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 2e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 7, 'min_lr_multi': 0.01, 'warmup_epochs': 1}, 'evaluate': True, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': False, 'entity': 'user', 'project': 'umt'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': 'exp/zero_shot/ret_msrvtt/b16_5m', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 42, 'zero_shot': True, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_model/Unmasked_Teacher/multimodality/b16_5m.pth', 'rank': 0, 'world_size': 1, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2023-12-30T13:45:34 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_train9k.json', '/data1/DATASET/MSRVTT/videos', 'video']
2023-12-30T13:45:34 | INFO | tasks.pretrain : Creating dataset for ret
2023-12-30T13:45:34 | INFO | tasks.shared_utils : Creating model
2023-12-30T13:45:38 | INFO | models.umt : Build vision_encoder: vit_b16
2023-12-30T13:45:38 | INFO | models.backbones.vit.vit : Num of patches: 784
2023-12-30T13:45:38 | INFO | models.backbones.vit.vit : Use checkpoint: True
2023-12-30T13:45:38 | INFO | models.backbones.vit.vit : Checkpoint number: 12
2023-12-30T13:45:38 | INFO | models.backbones.vit.vit : Student return index: []
2023-12-30T13:45:42 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
2023-12-30T13:45:42 | INFO | models.umt : Build text_encoder bert_base
2023-12-30T13:45:44 | INFO | models.backbones.bert.xbert : build bert with cross_module: ca
2023-12-30T13:45:45 | INFO | models.criterions : Norm type: l2
2023-12-30T13:45:45 | INFO | models.criterions : Loss type: l2
2023-12-30T13:45:45 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.temp: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.weight: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.weight: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.embeddings.word_embeddings.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.embeddings.position_embeddings.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.embeddings.token_type_embeddings.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.vision_proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.text_proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.itm_head.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : param module.itm_head.bias: wd: 0, lr: 2e-05
2023-12-30T13:45:45 | INFO | utils.optimizer : optimizer -- lr=2e-05 wd=0.02 len(p)=140
2023-12-30T13:45:45 | INFO | utils.optimizer : optimizer -- lr=2e-05 wd=0 len(p)=256
2023-12-30T13:45:45 | INFO | tasks.shared_utils : Auto resuming
2023-12-30T13:45:45 | INFO | tasks.shared_utils : Not found checkpoint in exp/zero_shot/ret_msrvtt/b16_5m
2023-12-30T13:45:45 | WARNING | tasks.shared_utils : No pretrained checkpoint provided, training from scratch
2023-12-30T13:45:45 | INFO | __main__ : Start evaluation
2023-12-30T13:45:45 | INFO | tasks.retrieval_utils : Start evaluation for media_type=video
2023-12-30T13:45:45 | INFO | tasks.retrieval_utils : Computing dual encoder features...
2023-12-30T13:45:52 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2023-12-30T13:45:52 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2023-12-30T13:45:52 | INFO | utils.basic_utils : extracting image feats  [ 0/32]  eta: 0:03:26    time: 6.4413  data: 4.4172  max mem: 3743 res mem: 4648
2023-12-30T13:46:10 | INFO | utils.basic_utils : extracting image feats  [31/32]  eta: 0:00:00    time: 0.6784  data: 0.4587  max mem: 3826 res mem: 4650
2023-12-30T13:46:10 | INFO | utils.basic_utils : extracting image feats Total time: 0:00:24 (0.7568 s / it)
2023-12-30T13:46:12 | INFO | tasks.retrieval_utils : Finished feature extraction
2023-12-30T13:46:12 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product]
2023-12-30T13:46:12 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product], done!
2023-12-30T13:46:12 | INFO | tasks.retrieval_utils : Rerank dual-encoder results with cross-encoder...
2023-12-30T13:46:12 | INFO | tasks.retrieval_utils : i2t_scores.shape torch.Size([1000, 1000])
2023-12-30T13:46:12 | INFO | tasks.retrieval_utils : n_clip_per_video=1, with eval_frame_ensemble=concat
2023-12-30T13:46:12 | INFO | utils.basic_utils : Evaluation:  [   0/1000]  eta: 0:00:21    time: 0.0218  data: 0.0007  max mem: 3826 res mem: 4650
2023-12-30T13:46:15 | INFO | utils.basic_utils : Evaluation:  [ 100/1000]  eta: 0:00:25    time: 0.0283  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T13:46:17 | INFO | utils.basic_utils : Evaluation:  [ 200/1000]  eta: 0:00:22    time: 0.0283  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T13:46:20 | INFO | utils.basic_utils : Evaluation:  [ 300/1000]  eta: 0:00:19    time: 0.0284  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T13:46:23 | INFO | utils.basic_utils : Evaluation:  [ 400/1000]  eta: 0:00:16    time: 0.0283  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T13:46:26 | INFO | utils.basic_utils : Evaluation:  [ 500/1000]  eta: 0:00:14    time: 0.0286  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T13:46:29 | INFO | utils.basic_utils : Evaluation:  [ 600/1000]  eta: 0:00:11    time: 0.0286  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T13:46:32 | INFO | utils.basic_utils : Evaluation:  [ 700/1000]  eta: 0:00:08    time: 0.0286  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T13:46:35 | INFO | utils.basic_utils : Evaluation:  [ 800/1000]  eta: 0:00:05    time: 0.0285  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T13:46:37 | INFO | utils.basic_utils : Evaluation:  [ 900/1000]  eta: 0:00:02    time: 0.0284  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T13:46:40 | INFO | utils.basic_utils : Evaluation:  [ 999/1000]  eta: 0:00:00    time: 0.0285  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T13:46:40 | INFO | utils.basic_utils : Evaluation: Total time: 0:00:28 (0.0285 s / it)
2023-12-30T13:46:40 | INFO | tasks.retrieval_utils : t2i_scores.shape torch.Size([1000, 1000])
2023-12-30T13:47:07 | INFO | umt : Logging to: exp/zero_shot/ret_msrvtt/b16_5m/train.log
2023-12-30T13:47:07 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  your_msrvtt_path: /data1/DATASET/MSRVTT/videos
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_train9k.json', '/data1/DATASET/MSRVTT/videos', 'video']
  test_file: {
      test: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_test1k.json', '/data1/DATASET/MSRVTT/videos', 'video'] }
  test_types: ['test']
  num_workers: 6
  stop_key: test/
  is_paragraph_retrieval: False
  num_frames: 4
  num_frames_test: 4
  batch_size: 32
  max_txt_l: 32
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 4
          sample_type: rand
          num_frames_test: 4
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 32
          video: 32 }
      batch_size: {
          image: 32
          video: 32 }
      batch_size_test: {
          image: 32
          video: 32 } }
  text_enc: bert
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_b16
          img_size: 224
          patch_size: 16
          d_model: 768
          encoder_embed_dim: 768
          encoder_depth: 12
          encoder_num_heads: 12
          drop_path_rate: 0.2
          num_frames: 4
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 12
          clip_decoder_embed_dim: 768
          clip_output_dim: 512
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 224
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      multimodal: {
          enable: True }
      embed_dim: 512
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 2e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 7
      min_lr_multi: 0.01
      warmup_epochs: 1 }
  evaluate: True
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: user
      project: umt }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/zero_shot/ret_msrvtt/b16_5m
  resume: False
  debug: False
  log_freq: 100
  seed: 42
  zero_shot: True
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_model/Unmasked_Teacher/multimodality/b16_5m.pth
  rank: 0
  world_size: 1
  gpu: 0
  distributed: True
  dist_backend: nccl }
2023-12-30T13:47:07 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'your_msrvtt_path': '/data1/DATASET/MSRVTT/videos', 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_train9k.json', '/data1/DATASET/MSRVTT/videos', 'video'], 'test_file': {'test': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_test1k.json', '/data1/DATASET/MSRVTT/videos', 'video']}, 'test_types': ['test'], 'num_workers': 6, 'stop_key': 'test/', 'is_paragraph_retrieval': False, 'num_frames': 4, 'num_frames_test': 4, 'batch_size': 32, 'max_txt_l': 32, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 4, 'sample_type': 'rand', 'num_frames_test': 4, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 32, 'video': 32}, 'batch_size': {'image': 32, 'video': 32}, 'batch_size_test': {'image': 32, 'video': 32}}, 'text_enc': 'bert', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_b16', 'img_size': 224, 'patch_size': 16, 'd_model': 768, 'encoder_embed_dim': 768, 'encoder_depth': 12, 'encoder_num_heads': 12, 'drop_path_rate': 0.2, 'num_frames': 4, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 12, 'clip_decoder_embed_dim': 768, 'clip_output_dim': 512, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 224, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'multimodal': {'enable': True}, 'embed_dim': 512, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 2e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 7, 'min_lr_multi': 0.01, 'warmup_epochs': 1}, 'evaluate': True, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': False, 'entity': 'user', 'project': 'umt'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': 'exp/zero_shot/ret_msrvtt/b16_5m', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 42, 'zero_shot': True, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_model/Unmasked_Teacher/multimodality/b16_5m.pth', 'rank': 0, 'world_size': 1, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2023-12-30T13:47:07 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_train9k.json', '/data1/DATASET/MSRVTT/videos', 'video']
2023-12-30T13:47:07 | INFO | tasks.pretrain : Creating dataset for ret
2023-12-30T13:47:07 | INFO | tasks.shared_utils : Creating model
2023-12-30T13:47:12 | INFO | models.umt : Build vision_encoder: vit_b16
2023-12-30T13:47:12 | INFO | models.backbones.vit.vit : Num of patches: 784
2023-12-30T13:47:12 | INFO | models.backbones.vit.vit : Use checkpoint: True
2023-12-30T13:47:12 | INFO | models.backbones.vit.vit : Checkpoint number: 12
2023-12-30T13:47:12 | INFO | models.backbones.vit.vit : Student return index: []
2023-12-30T13:47:17 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
2023-12-30T13:47:17 | INFO | models.umt : Build text_encoder bert_base
2023-12-30T13:47:19 | INFO | models.backbones.bert.xbert : build bert with cross_module: ca
2023-12-30T13:47:19 | INFO | models.criterions : Norm type: l2
2023-12-30T13:47:19 | INFO | models.criterions : Loss type: l2
2023-12-30T13:47:19 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.temp: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.weight: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.weight: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.embeddings.word_embeddings.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.embeddings.position_embeddings.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.embeddings.token_type_embeddings.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:19 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.vision_proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.vision_proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.text_proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.itm_head.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : param module.itm_head.bias: wd: 0, lr: 2e-05
2023-12-30T13:47:20 | INFO | utils.optimizer : optimizer -- lr=2e-05 wd=0.02 len(p)=140
2023-12-30T13:47:20 | INFO | utils.optimizer : optimizer -- lr=2e-05 wd=0 len(p)=256
2023-12-30T13:47:20 | INFO | tasks.shared_utils : Auto resuming
2023-12-30T13:47:20 | INFO | tasks.shared_utils : Not found checkpoint in exp/zero_shot/ret_msrvtt/b16_5m
2023-12-30T13:47:20 | WARNING | tasks.shared_utils : No pretrained checkpoint provided, training from scratch
2023-12-30T13:47:20 | INFO | __main__ : Start evaluation
2023-12-30T13:47:20 | INFO | tasks.retrieval_utils : Start evaluation for media_type=video
2023-12-30T13:47:20 | INFO | tasks.retrieval_utils : Computing dual encoder features...
2023-12-30T13:47:27 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2023-12-30T13:47:27 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2023-12-30T13:47:28 | INFO | utils.basic_utils : extracting image feats  [ 0/32]  eta: 0:03:32    time: 6.6275  data: 4.5336  max mem: 3743 res mem: 4648
2023-12-30T13:47:45 | INFO | utils.basic_utils : extracting image feats  [31/32]  eta: 0:00:00    time: 0.6842  data: 0.4649  max mem: 3826 res mem: 4650
2023-12-30T13:47:45 | INFO | utils.basic_utils : extracting image feats Total time: 0:00:24 (0.7658 s / it)
2023-12-30T13:47:47 | INFO | tasks.retrieval_utils : Finished feature extraction
2023-12-30T13:47:47 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product]
2023-12-30T13:47:47 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product], done!
2023-12-30T13:47:47 | INFO | tasks.retrieval_utils : Rerank dual-encoder results with cross-encoder...
2023-12-30T13:47:47 | INFO | tasks.retrieval_utils : i2t_scores.shape torch.Size([1000, 1000])
2023-12-30T13:47:47 | INFO | tasks.retrieval_utils : n_clip_per_video=1, with eval_frame_ensemble=concat
2023-12-30T13:47:47 | INFO | utils.basic_utils : Evaluation:  [   0/1000]  eta: 0:00:23    time: 0.0239  data: 0.0008  max mem: 3826 res mem: 4650
2023-12-30T13:47:50 | INFO | utils.basic_utils : Evaluation:  [ 100/1000]  eta: 0:00:25    time: 0.0285  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T13:47:53 | INFO | utils.basic_utils : Evaluation:  [ 200/1000]  eta: 0:00:22    time: 0.0284  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T13:47:56 | INFO | utils.basic_utils : Evaluation:  [ 300/1000]  eta: 0:00:19    time: 0.0284  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T13:47:58 | INFO | utils.basic_utils : Evaluation:  [ 400/1000]  eta: 0:00:17    time: 0.0287  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T13:48:01 | INFO | utils.basic_utils : Evaluation:  [ 500/1000]  eta: 0:00:14    time: 0.0284  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T13:48:04 | INFO | utils.basic_utils : Evaluation:  [ 600/1000]  eta: 0:00:11    time: 0.0286  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T13:48:07 | INFO | utils.basic_utils : Evaluation:  [ 700/1000]  eta: 0:00:08    time: 0.0284  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T13:48:10 | INFO | utils.basic_utils : Evaluation:  [ 800/1000]  eta: 0:00:05    time: 0.0286  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T13:48:13 | INFO | utils.basic_utils : Evaluation:  [ 900/1000]  eta: 0:00:02    time: 0.0288  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T13:48:16 | INFO | utils.basic_utils : Evaluation:  [ 999/1000]  eta: 0:00:00    time: 0.0286  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T13:48:16 | INFO | utils.basic_utils : Evaluation: Total time: 0:00:28 (0.0285 s / it)
2023-12-30T13:48:16 | INFO | tasks.retrieval_utils : t2i_scores.shape torch.Size([1000, 1000])
2023-12-30T13:48:48 | INFO | umt : Logging to: exp/zero_shot/ret_msrvtt/b16_5m/train.log
2023-12-30T13:48:48 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  your_msrvtt_path: /data1/DATASET/MSRVTT/videos
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_train9k.json', '/data1/DATASET/MSRVTT/videos', 'video']
  test_file: {
      test: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_test1k.json', '/data1/DATASET/MSRVTT/videos', 'video'] }
  test_types: ['test']
  num_workers: 6
  stop_key: test/
  is_paragraph_retrieval: False
  num_frames: 4
  num_frames_test: 4
  batch_size: 32
  max_txt_l: 32
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 4
          sample_type: rand
          num_frames_test: 4
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 32
          video: 32 }
      batch_size: {
          image: 32
          video: 32 }
      batch_size_test: {
          image: 32
          video: 32 } }
  text_enc: bert
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_b16
          img_size: 224
          patch_size: 16
          d_model: 768
          encoder_embed_dim: 768
          encoder_depth: 12
          encoder_num_heads: 12
          drop_path_rate: 0.2
          num_frames: 4
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 12
          clip_decoder_embed_dim: 768
          clip_output_dim: 512
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 224
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      multimodal: {
          enable: True }
      embed_dim: 512
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 2e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 7
      min_lr_multi: 0.01
      warmup_epochs: 1 }
  evaluate: True
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: user
      project: umt }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/zero_shot/ret_msrvtt/b16_5m
  resume: False
  debug: False
  log_freq: 100
  seed: 42
  zero_shot: True
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_model/Unmasked_Teacher/multimodality/b16_5m.pth
  rank: 0
  world_size: 1
  gpu: 0
  distributed: True
  dist_backend: nccl }
2023-12-30T13:48:48 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'your_msrvtt_path': '/data1/DATASET/MSRVTT/videos', 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_train9k.json', '/data1/DATASET/MSRVTT/videos', 'video'], 'test_file': {'test': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_test1k.json', '/data1/DATASET/MSRVTT/videos', 'video']}, 'test_types': ['test'], 'num_workers': 6, 'stop_key': 'test/', 'is_paragraph_retrieval': False, 'num_frames': 4, 'num_frames_test': 4, 'batch_size': 32, 'max_txt_l': 32, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 4, 'sample_type': 'rand', 'num_frames_test': 4, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 32, 'video': 32}, 'batch_size': {'image': 32, 'video': 32}, 'batch_size_test': {'image': 32, 'video': 32}}, 'text_enc': 'bert', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_b16', 'img_size': 224, 'patch_size': 16, 'd_model': 768, 'encoder_embed_dim': 768, 'encoder_depth': 12, 'encoder_num_heads': 12, 'drop_path_rate': 0.2, 'num_frames': 4, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 12, 'clip_decoder_embed_dim': 768, 'clip_output_dim': 512, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 224, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'multimodal': {'enable': True}, 'embed_dim': 512, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 2e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 7, 'min_lr_multi': 0.01, 'warmup_epochs': 1}, 'evaluate': True, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': False, 'entity': 'user', 'project': 'umt'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': 'exp/zero_shot/ret_msrvtt/b16_5m', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 42, 'zero_shot': True, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_model/Unmasked_Teacher/multimodality/b16_5m.pth', 'rank': 0, 'world_size': 1, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2023-12-30T13:48:48 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_train9k.json', '/data1/DATASET/MSRVTT/videos', 'video']
2023-12-30T13:48:48 | INFO | tasks.pretrain : Creating dataset for ret
2023-12-30T13:48:49 | INFO | tasks.shared_utils : Creating model
2023-12-30T13:48:52 | INFO | models.umt : Build vision_encoder: vit_b16
2023-12-30T13:48:52 | INFO | models.backbones.vit.vit : Num of patches: 784
2023-12-30T13:48:52 | INFO | models.backbones.vit.vit : Use checkpoint: True
2023-12-30T13:48:52 | INFO | models.backbones.vit.vit : Checkpoint number: 12
2023-12-30T13:48:52 | INFO | models.backbones.vit.vit : Student return index: []
2023-12-30T13:48:57 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
2023-12-30T13:48:57 | INFO | models.umt : Build text_encoder bert_base
2023-12-30T13:48:59 | INFO | models.backbones.bert.xbert : build bert with cross_module: ca
2023-12-30T13:48:59 | INFO | models.criterions : Norm type: l2
2023-12-30T13:48:59 | INFO | models.criterions : Loss type: l2
2023-12-30T13:49:00 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.temp: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.weight: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.weight: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.embeddings.word_embeddings.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.embeddings.position_embeddings.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.embeddings.token_type_embeddings.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.vision_proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.text_proj.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.itm_head.weight: wd: 0.02, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : param module.itm_head.bias: wd: 0, lr: 2e-05
2023-12-30T13:49:00 | INFO | utils.optimizer : optimizer -- lr=2e-05 wd=0.02 len(p)=140
2023-12-30T13:49:00 | INFO | utils.optimizer : optimizer -- lr=2e-05 wd=0 len(p)=256
2023-12-30T13:49:00 | INFO | tasks.shared_utils : Auto resuming
2023-12-30T13:49:00 | INFO | tasks.shared_utils : Not found checkpoint in exp/zero_shot/ret_msrvtt/b16_5m
2023-12-30T13:49:00 | WARNING | tasks.shared_utils : No pretrained checkpoint provided, training from scratch
2023-12-30T13:49:00 | INFO | __main__ : Start evaluation
2023-12-30T13:49:00 | INFO | tasks.retrieval_utils : Start evaluation for media_type=video
2023-12-30T13:49:00 | INFO | tasks.retrieval_utils : Computing dual encoder features...
2023-12-30T13:49:08 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2023-12-30T13:49:08 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2023-12-30T13:49:08 | INFO | utils.basic_utils : extracting image feats  [ 0/32]  eta: 0:03:33    time: 6.6683  data: 4.5345  max mem: 3743 res mem: 4648
2023-12-30T13:49:27 | INFO | utils.basic_utils : extracting image feats  [31/32]  eta: 0:00:00    time: 0.7402  data: 0.5201  max mem: 3826 res mem: 4650
2023-12-30T13:49:27 | INFO | utils.basic_utils : extracting image feats Total time: 0:00:25 (0.7867 s / it)
2023-12-30T13:49:29 | INFO | tasks.retrieval_utils : Finished feature extraction
2023-12-30T13:49:29 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product]
2023-12-30T13:49:30 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product], done!
2023-12-30T13:49:30 | INFO | tasks.retrieval_utils : Rerank dual-encoder results with cross-encoder...
2023-12-30T13:49:30 | INFO | tasks.retrieval_utils : i2t_scores.shape torch.Size([1000, 1000])
2023-12-30T13:49:30 | INFO | tasks.retrieval_utils : n_clip_per_video=1, with eval_frame_ensemble=concat
2023-12-30T13:49:30 | INFO | utils.basic_utils : Evaluation:  [   0/1000]  eta: 0:00:20    time: 0.0201  data: 0.0008  max mem: 3826 res mem: 4650
2023-12-30T13:49:33 | INFO | utils.basic_utils : Evaluation:  [ 100/1000]  eta: 0:00:26    time: 0.0286  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T13:49:35 | INFO | utils.basic_utils : Evaluation:  [ 200/1000]  eta: 0:00:23    time: 0.0286  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T13:49:38 | INFO | utils.basic_utils : Evaluation:  [ 300/1000]  eta: 0:00:20    time: 0.0282  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T13:49:41 | INFO | utils.basic_utils : Evaluation:  [ 400/1000]  eta: 0:00:17    time: 0.0286  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T13:49:44 | INFO | utils.basic_utils : Evaluation:  [ 500/1000]  eta: 0:00:14    time: 0.0285  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T13:49:47 | INFO | utils.basic_utils : Evaluation:  [ 600/1000]  eta: 0:00:11    time: 0.0287  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T13:49:50 | INFO | utils.basic_utils : Evaluation:  [ 700/1000]  eta: 0:00:08    time: 0.0285  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T13:49:53 | INFO | utils.basic_utils : Evaluation:  [ 800/1000]  eta: 0:00:05    time: 0.0290  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T13:49:56 | INFO | utils.basic_utils : Evaluation:  [ 900/1000]  eta: 0:00:02    time: 0.0287  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T13:49:58 | INFO | utils.basic_utils : Evaluation:  [ 999/1000]  eta: 0:00:00    time: 0.0289  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T13:49:58 | INFO | utils.basic_utils : Evaluation: Total time: 0:00:28 (0.0287 s / it)
2023-12-30T13:49:58 | INFO | tasks.retrieval_utils : t2i_scores.shape torch.Size([1000, 1000])
2023-12-30T13:49:59 | INFO | utils.basic_utils : Evaluation:  [   0/1000]  eta: 0:06:11    time: 0.3714  data: 0.0009  max mem: 3826 res mem: 4650
2023-12-30T13:50:23 | INFO | utils.basic_utils : Evaluation:  [ 100/1000]  eta: 0:03:37    time: 0.2457  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T13:50:47 | INFO | utils.basic_utils : Evaluation:  [ 200/1000]  eta: 0:03:14    time: 0.2484  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T13:51:13 | INFO | utils.basic_utils : Evaluation:  [ 300/1000]  eta: 0:02:52    time: 0.2551  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T13:51:38 | INFO | utils.basic_utils : Evaluation:  [ 400/1000]  eta: 0:02:28    time: 0.2585  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T13:52:01 | INFO | utils.basic_utils : Evaluation:  [ 500/1000]  eta: 0:02:02    time: 0.2290  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T13:52:25 | INFO | utils.basic_utils : Evaluation:  [ 600/1000]  eta: 0:01:37    time: 0.2418  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T13:52:50 | INFO | utils.basic_utils : Evaluation:  [ 700/1000]  eta: 0:01:13    time: 0.2387  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T13:53:14 | INFO | utils.basic_utils : Evaluation:  [ 800/1000]  eta: 0:00:48    time: 0.2406  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T13:53:39 | INFO | utils.basic_utils : Evaluation:  [ 900/1000]  eta: 0:00:24    time: 0.2438  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T13:54:04 | INFO | utils.basic_utils : Evaluation:  [ 999/1000]  eta: 0:00:00    time: 0.2441  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T13:54:04 | INFO | utils.basic_utils : Evaluation: Total time: 0:04:05 (0.2460 s / it)
2023-12-30T13:54:04 | INFO | tasks.retrieval_utils : Evaluation time 0:05:04
2023-12-30T13:54:05 | INFO | __main__ : Epoch 0
2023-12-30T13:54:05 | INFO | __main__ : 
           txt_r1  txt_r5  txt_r10  txt_r_mean  img_r1  img_r5  img_r10  img_r_mean  r_mean
test/         0.0     0.3      0.7        0.33     0.2     0.7      0.9        0.60    0.47
test_emb/     0.2     0.9      1.5        0.87     0.2     0.4      0.8        0.47    0.67
2023-12-30T13:54:05 | INFO | __main__ : Training time 0:05:04
2023-12-30T13:54:05 | INFO | __main__ : best epoch 0 [config.stop_key test/]
2023-12-30T13:54:05 | INFO | __main__ : Checkpoints and Logs saved at exp/zero_shot/ret_msrvtt/b16_5m
2023-12-30T14:05:52 | INFO | umt : Logging to: exp/zero_shot/ret_msrvtt/b16_5m/train.log
2023-12-30T14:05:52 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_train9k.json', '/data1/DATASET/MSRVTT/videos', 'video']
  test_file: {
      test: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_test1k.json', '/data1/DATASET/MSRVTT/videos', 'video'] }
  test_types: ['test']
  num_workers: 6
  stop_key: test/
  is_paragraph_retrieval: False
  num_frames: 4
  num_frames_test: 4
  batch_size: 32
  max_txt_l: 32
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 4
          sample_type: rand
          num_frames_test: 4
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 32
          video: 32 }
      batch_size: {
          image: 32
          video: 32 }
      batch_size_test: {
          image: 32
          video: 32 } }
  text_enc: bert
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_b16
          img_size: 224
          patch_size: 16
          d_model: 768
          encoder_embed_dim: 768
          encoder_depth: 12
          encoder_num_heads: 12
          drop_path_rate: 0.2
          num_frames: 4
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 12
          clip_decoder_embed_dim: 768
          clip_output_dim: 512
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 224
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      multimodal: {
          enable: True }
      embed_dim: 512
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 2e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 7
      min_lr_multi: 0.01
      warmup_epochs: 1 }
  evaluate: True
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: user
      project: umt }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/zero_shot/ret_msrvtt/b16_5m
  resume: False
  debug: False
  log_freq: 100
  seed: 42
  zero_shot: True
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_models/Unmasked_Teacher/multimodality/l16_5m.pth
  rank: 0
  world_size: 1
  gpu: 0
  distributed: True
  dist_backend: nccl }
2023-12-30T14:05:52 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_train9k.json', '/data1/DATASET/MSRVTT/videos', 'video'], 'test_file': {'test': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_test1k.json', '/data1/DATASET/MSRVTT/videos', 'video']}, 'test_types': ['test'], 'num_workers': 6, 'stop_key': 'test/', 'is_paragraph_retrieval': False, 'num_frames': 4, 'num_frames_test': 4, 'batch_size': 32, 'max_txt_l': 32, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 4, 'sample_type': 'rand', 'num_frames_test': 4, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 32, 'video': 32}, 'batch_size': {'image': 32, 'video': 32}, 'batch_size_test': {'image': 32, 'video': 32}}, 'text_enc': 'bert', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_b16', 'img_size': 224, 'patch_size': 16, 'd_model': 768, 'encoder_embed_dim': 768, 'encoder_depth': 12, 'encoder_num_heads': 12, 'drop_path_rate': 0.2, 'num_frames': 4, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 12, 'clip_decoder_embed_dim': 768, 'clip_output_dim': 512, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 224, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'multimodal': {'enable': True}, 'embed_dim': 512, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 2e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 7, 'min_lr_multi': 0.01, 'warmup_epochs': 1}, 'evaluate': True, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': False, 'entity': 'user', 'project': 'umt'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': 'exp/zero_shot/ret_msrvtt/b16_5m', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 42, 'zero_shot': True, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_models/Unmasked_Teacher/multimodality/l16_5m.pth', 'rank': 0, 'world_size': 1, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2023-12-30T14:05:52 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_train9k.json', '/data1/DATASET/MSRVTT/videos', 'video']
2023-12-30T14:05:52 | INFO | tasks.pretrain : Creating dataset for ret
2023-12-30T14:05:52 | INFO | tasks.shared_utils : Creating model
2023-12-30T14:05:56 | INFO | models.umt : Build vision_encoder: vit_b16
2023-12-30T14:05:56 | INFO | models.backbones.vit.vit : Num of patches: 784
2023-12-30T14:05:56 | INFO | models.backbones.vit.vit : Use checkpoint: True
2023-12-30T14:05:56 | INFO | models.backbones.vit.vit : Checkpoint number: 12
2023-12-30T14:05:56 | INFO | models.backbones.vit.vit : Student return index: []
2023-12-30T14:06:00 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
2023-12-30T14:06:01 | INFO | models.umt : Build text_encoder bert_base
2023-12-30T14:06:03 | INFO | models.backbones.bert.xbert : build bert with cross_module: ca
2023-12-30T14:06:03 | INFO | models.criterions : Norm type: l2
2023-12-30T14:06:03 | INFO | models.criterions : Loss type: l2
2023-12-30T14:06:03 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.temp: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.weight: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.weight: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.embeddings.word_embeddings.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.embeddings.position_embeddings.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.embeddings.token_type_embeddings.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.vision_proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.text_proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.itm_head.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : param module.itm_head.bias: wd: 0, lr: 2e-05
2023-12-30T14:06:03 | INFO | utils.optimizer : optimizer -- lr=2e-05 wd=0.02 len(p)=140
2023-12-30T14:06:03 | INFO | utils.optimizer : optimizer -- lr=2e-05 wd=0 len(p)=256
2023-12-30T14:06:03 | INFO | tasks.shared_utils : Auto resuming
2023-12-30T14:06:03 | INFO | tasks.shared_utils : Not found checkpoint in exp/zero_shot/ret_msrvtt/b16_5m
2023-12-30T14:06:03 | WARNING | tasks.shared_utils : No pretrained checkpoint provided, training from scratch
2023-12-30T14:06:03 | INFO | __main__ : Start evaluation
2023-12-30T14:06:03 | INFO | tasks.retrieval_utils : Start evaluation for media_type=video
2023-12-30T14:06:03 | INFO | tasks.retrieval_utils : Computing dual encoder features...
2023-12-30T14:06:11 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2023-12-30T14:06:11 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2023-12-30T14:06:11 | INFO | utils.basic_utils : extracting image feats  [ 0/32]  eta: 0:03:22    time: 6.3250  data: 3.9990  max mem: 3743 res mem: 4648
2023-12-30T14:06:28 | INFO | utils.basic_utils : extracting image feats  [31/32]  eta: 0:00:00    time: 0.6890  data: 0.4676  max mem: 3826 res mem: 4650
2023-12-30T14:06:28 | INFO | utils.basic_utils : extracting image feats Total time: 0:00:23 (0.7405 s / it)
2023-12-30T14:06:30 | INFO | tasks.retrieval_utils : Finished feature extraction
2023-12-30T14:06:30 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product]
2023-12-30T14:06:30 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product], done!
2023-12-30T14:06:30 | INFO | tasks.retrieval_utils : Rerank dual-encoder results with cross-encoder...
2023-12-30T14:06:30 | INFO | tasks.retrieval_utils : i2t_scores.shape torch.Size([1000, 1000])
2023-12-30T14:06:30 | INFO | tasks.retrieval_utils : n_clip_per_video=1, with eval_frame_ensemble=concat
2023-12-30T14:06:30 | INFO | utils.basic_utils : Evaluation:  [   0/1000]  eta: 0:00:24    time: 0.0244  data: 0.0007  max mem: 3826 res mem: 4650
2023-12-30T14:06:33 | INFO | utils.basic_utils : Evaluation:  [ 100/1000]  eta: 0:00:25    time: 0.0279  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:06:36 | INFO | utils.basic_utils : Evaluation:  [ 200/1000]  eta: 0:00:22    time: 0.0282  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:06:38 | INFO | utils.basic_utils : Evaluation:  [ 300/1000]  eta: 0:00:19    time: 0.0281  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:06:41 | INFO | utils.basic_utils : Evaluation:  [ 400/1000]  eta: 0:00:16    time: 0.0280  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:06:44 | INFO | utils.basic_utils : Evaluation:  [ 500/1000]  eta: 0:00:14    time: 0.0283  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:06:47 | INFO | utils.basic_utils : Evaluation:  [ 600/1000]  eta: 0:00:11    time: 0.0283  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:06:50 | INFO | utils.basic_utils : Evaluation:  [ 700/1000]  eta: 0:00:08    time: 0.0285  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:06:53 | INFO | utils.basic_utils : Evaluation:  [ 800/1000]  eta: 0:00:05    time: 0.0280  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:06:55 | INFO | utils.basic_utils : Evaluation:  [ 900/1000]  eta: 0:00:02    time: 0.0286  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:06:58 | INFO | utils.basic_utils : Evaluation:  [ 999/1000]  eta: 0:00:00    time: 0.0284  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:06:58 | INFO | utils.basic_utils : Evaluation: Total time: 0:00:28 (0.0283 s / it)
2023-12-30T14:06:58 | INFO | tasks.retrieval_utils : t2i_scores.shape torch.Size([1000, 1000])
2023-12-30T14:06:59 | INFO | utils.basic_utils : Evaluation:  [   0/1000]  eta: 0:05:28    time: 0.3284  data: 0.0008  max mem: 3826 res mem: 4650
2023-12-30T14:07:26 | INFO | utils.basic_utils : Evaluation:  [ 100/1000]  eta: 0:04:09    time: 0.2849  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:07:54 | INFO | utils.basic_utils : Evaluation:  [ 200/1000]  eta: 0:03:41    time: 0.2645  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:08:21 | INFO | utils.basic_utils : Evaluation:  [ 300/1000]  eta: 0:03:11    time: 0.2730  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:08:48 | INFO | utils.basic_utils : Evaluation:  [ 400/1000]  eta: 0:02:43    time: 0.2740  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:09:15 | INFO | utils.basic_utils : Evaluation:  [ 500/1000]  eta: 0:02:16    time: 0.2678  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:09:42 | INFO | utils.basic_utils : Evaluation:  [ 600/1000]  eta: 0:01:48    time: 0.2832  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:10:09 | INFO | utils.basic_utils : Evaluation:  [ 700/1000]  eta: 0:01:21    time: 0.2658  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:10:36 | INFO | utils.basic_utils : Evaluation:  [ 800/1000]  eta: 0:00:54    time: 0.2645  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:11:04 | INFO | utils.basic_utils : Evaluation:  [ 900/1000]  eta: 0:00:27    time: 0.2835  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:11:31 | INFO | utils.basic_utils : Evaluation:  [ 999/1000]  eta: 0:00:00    time: 0.2632  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:11:31 | INFO | utils.basic_utils : Evaluation: Total time: 0:04:32 (0.2724 s / it)
2023-12-30T14:11:31 | INFO | tasks.retrieval_utils : Evaluation time 0:05:27
2023-12-30T14:11:31 | INFO | __main__ : Epoch 0
2023-12-30T14:11:31 | INFO | __main__ : 
           txt_r1  txt_r5  txt_r10  txt_r_mean  img_r1  img_r5  img_r10  img_r_mean  r_mean
test/         0.0     0.3      0.7        0.33     0.2     0.7      0.9        0.60    0.47
test_emb/     0.2     0.9      1.5        0.87     0.2     0.4      0.8        0.47    0.67
2023-12-30T14:11:31 | INFO | __main__ : Training time 0:05:27
2023-12-30T14:11:31 | INFO | __main__ : best epoch 0 [config.stop_key test/]
2023-12-30T14:11:31 | INFO | __main__ : Checkpoints and Logs saved at exp/zero_shot/ret_msrvtt/b16_5m
2023-12-30T14:17:44 | INFO | umt : Logging to: exp/zero_shot/ret_msrvtt/b16_5m/train.log
2023-12-30T14:17:44 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_train9k.json', '/data1/DATASET/MSRVTT/videos', 'video']
  test_file: {
      test: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_test1k.json', '/data1/DATASET/MSRVTT/videos', 'video'] }
  test_types: ['test']
  num_workers: 6
  stop_key: test/
  is_paragraph_retrieval: False
  num_frames: 4
  num_frames_test: 4
  batch_size: 32
  max_txt_l: 32
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 4
          sample_type: rand
          num_frames_test: 4
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 32
          video: 32 }
      batch_size: {
          image: 32
          video: 32 }
      batch_size_test: {
          image: 32
          video: 32 } }
  text_enc: bert
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_b16
          img_size: 224
          patch_size: 16
          d_model: 768
          encoder_embed_dim: 768
          encoder_depth: 12
          encoder_num_heads: 12
          drop_path_rate: 0.2
          num_frames: 4
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 12
          clip_decoder_embed_dim: 768
          clip_output_dim: 512
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 224
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      multimodal: {
          enable: True }
      embed_dim: 512
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 2e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 7
      min_lr_multi: 0.01
      warmup_epochs: 1 }
  evaluate: True
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: user
      project: umt }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/zero_shot/ret_msrvtt/b16_5m
  resume: False
  debug: False
  log_freq: 100
  seed: 42
  zero_shot: True
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_5m.pth
  rank: 0
  world_size: 1
  gpu: 0
  distributed: True
  dist_backend: nccl }
2023-12-30T14:17:44 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_train9k.json', '/data1/DATASET/MSRVTT/videos', 'video'], 'test_file': {'test': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_test1k.json', '/data1/DATASET/MSRVTT/videos', 'video']}, 'test_types': ['test'], 'num_workers': 6, 'stop_key': 'test/', 'is_paragraph_retrieval': False, 'num_frames': 4, 'num_frames_test': 4, 'batch_size': 32, 'max_txt_l': 32, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 4, 'sample_type': 'rand', 'num_frames_test': 4, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 32, 'video': 32}, 'batch_size': {'image': 32, 'video': 32}, 'batch_size_test': {'image': 32, 'video': 32}}, 'text_enc': 'bert', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_b16', 'img_size': 224, 'patch_size': 16, 'd_model': 768, 'encoder_embed_dim': 768, 'encoder_depth': 12, 'encoder_num_heads': 12, 'drop_path_rate': 0.2, 'num_frames': 4, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 12, 'clip_decoder_embed_dim': 768, 'clip_output_dim': 512, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 224, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'multimodal': {'enable': True}, 'embed_dim': 512, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 2e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 7, 'min_lr_multi': 0.01, 'warmup_epochs': 1}, 'evaluate': True, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': False, 'entity': 'user', 'project': 'umt'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': 'exp/zero_shot/ret_msrvtt/b16_5m', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 42, 'zero_shot': True, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_5m.pth', 'rank': 0, 'world_size': 1, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2023-12-30T14:17:44 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_train9k.json', '/data1/DATASET/MSRVTT/videos', 'video']
2023-12-30T14:17:44 | INFO | tasks.pretrain : Creating dataset for ret
2023-12-30T14:17:44 | INFO | tasks.shared_utils : Creating model
2023-12-30T14:17:48 | INFO | models.umt : Build vision_encoder: vit_b16
2023-12-30T14:17:48 | INFO | models.backbones.vit.vit : Num of patches: 784
2023-12-30T14:17:48 | INFO | models.backbones.vit.vit : Use checkpoint: True
2023-12-30T14:17:48 | INFO | models.backbones.vit.vit : Checkpoint number: 12
2023-12-30T14:17:48 | INFO | models.backbones.vit.vit : Student return index: []
2023-12-30T14:17:53 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
2023-12-30T14:17:53 | INFO | models.umt : Build text_encoder bert_base
2023-12-30T14:17:55 | INFO | models.backbones.bert.xbert : build bert with cross_module: ca
2023-12-30T14:17:55 | INFO | models.criterions : Norm type: l2
2023-12-30T14:17:55 | INFO | models.criterions : Loss type: l2
2023-12-30T14:17:56 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.temp: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.weight: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.weight: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.embeddings.word_embeddings.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.embeddings.position_embeddings.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.embeddings.token_type_embeddings.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.vision_proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.text_proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.itm_head.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : param module.itm_head.bias: wd: 0, lr: 2e-05
2023-12-30T14:17:56 | INFO | utils.optimizer : optimizer -- lr=2e-05 wd=0.02 len(p)=140
2023-12-30T14:17:56 | INFO | utils.optimizer : optimizer -- lr=2e-05 wd=0 len(p)=256
2023-12-30T14:17:56 | INFO | tasks.shared_utils : Auto resuming
2023-12-30T14:17:56 | INFO | tasks.shared_utils : Not found checkpoint in exp/zero_shot/ret_msrvtt/b16_5m
2023-12-30T14:17:58 | INFO | tasks.shared_utils : _IncompatibleKeys(missing_keys=[], unexpected_keys=['clip_teacher.class_embedding', 'clip_teacher.positional_embedding', 'clip_teacher.proj', 'clip_teacher.conv1.weight', 'clip_teacher.ln_pre.weight', 'clip_teacher.ln_pre.bias', 'clip_teacher.transformer.resblocks.0.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.0.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.0.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.0.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.0.ln_1.weight', 'clip_teacher.transformer.resblocks.0.ln_1.bias', 'clip_teacher.transformer.resblocks.0.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.0.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.0.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.0.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.0.ln_2.weight', 'clip_teacher.transformer.resblocks.0.ln_2.bias', 'clip_teacher.transformer.resblocks.1.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.1.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.1.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.1.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.1.ln_1.weight', 'clip_teacher.transformer.resblocks.1.ln_1.bias', 'clip_teacher.transformer.resblocks.1.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.1.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.1.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.1.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.1.ln_2.weight', 'clip_teacher.transformer.resblocks.1.ln_2.bias', 'clip_teacher.transformer.resblocks.2.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.2.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.2.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.2.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.2.ln_1.weight', 'clip_teacher.transformer.resblocks.2.ln_1.bias', 'clip_teacher.transformer.resblocks.2.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.2.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.2.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.2.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.2.ln_2.weight', 'clip_teacher.transformer.resblocks.2.ln_2.bias', 'clip_teacher.transformer.resblocks.3.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.3.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.3.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.3.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.3.ln_1.weight', 'clip_teacher.transformer.resblocks.3.ln_1.bias', 'clip_teacher.transformer.resblocks.3.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.3.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.3.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.3.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.3.ln_2.weight', 'clip_teacher.transformer.resblocks.3.ln_2.bias', 'clip_teacher.transformer.resblocks.4.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.4.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.4.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.4.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.4.ln_1.weight', 'clip_teacher.transformer.resblocks.4.ln_1.bias', 'clip_teacher.transformer.resblocks.4.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.4.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.4.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.4.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.4.ln_2.weight', 'clip_teacher.transformer.resblocks.4.ln_2.bias', 'clip_teacher.transformer.resblocks.5.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.5.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.5.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.5.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.5.ln_1.weight', 'clip_teacher.transformer.resblocks.5.ln_1.bias', 'clip_teacher.transformer.resblocks.5.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.5.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.5.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.5.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.5.ln_2.weight', 'clip_teacher.transformer.resblocks.5.ln_2.bias', 'clip_teacher.transformer.resblocks.6.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.6.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.6.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.6.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.6.ln_1.weight', 'clip_teacher.transformer.resblocks.6.ln_1.bias', 'clip_teacher.transformer.resblocks.6.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.6.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.6.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.6.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.6.ln_2.weight', 'clip_teacher.transformer.resblocks.6.ln_2.bias', 'clip_teacher.transformer.resblocks.7.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.7.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.7.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.7.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.7.ln_1.weight', 'clip_teacher.transformer.resblocks.7.ln_1.bias', 'clip_teacher.transformer.resblocks.7.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.7.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.7.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.7.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.7.ln_2.weight', 'clip_teacher.transformer.resblocks.7.ln_2.bias', 'clip_teacher.transformer.resblocks.8.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.8.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.8.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.8.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.8.ln_1.weight', 'clip_teacher.transformer.resblocks.8.ln_1.bias', 'clip_teacher.transformer.resblocks.8.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.8.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.8.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.8.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.8.ln_2.weight', 'clip_teacher.transformer.resblocks.8.ln_2.bias', 'clip_teacher.transformer.resblocks.9.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.9.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.9.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.9.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.9.ln_1.weight', 'clip_teacher.transformer.resblocks.9.ln_1.bias', 'clip_teacher.transformer.resblocks.9.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.9.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.9.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.9.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.9.ln_2.weight', 'clip_teacher.transformer.resblocks.9.ln_2.bias', 'clip_teacher.transformer.resblocks.10.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.10.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.10.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.10.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.10.ln_1.weight', 'clip_teacher.transformer.resblocks.10.ln_1.bias', 'clip_teacher.transformer.resblocks.10.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.10.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.10.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.10.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.10.ln_2.weight', 'clip_teacher.transformer.resblocks.10.ln_2.bias', 'clip_teacher.transformer.resblocks.11.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.11.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.11.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.11.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.11.ln_1.weight', 'clip_teacher.transformer.resblocks.11.ln_1.bias', 'clip_teacher.transformer.resblocks.11.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.11.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.11.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.11.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.11.ln_2.weight', 'clip_teacher.transformer.resblocks.11.ln_2.bias', 'clip_teacher.ln_post.weight', 'clip_teacher.ln_post.bias', 'vision_encoder.clip_decoder.0.head.weight', 'vision_encoder.clip_decoder.0.head.bias', 'vision_encoder.clip_decoder.0.norm.weight', 'vision_encoder.clip_decoder.0.norm.bias', 'vision_encoder.clip_decoder.1.head.weight', 'vision_encoder.clip_decoder.1.head.bias', 'vision_encoder.clip_decoder.1.norm.weight', 'vision_encoder.clip_decoder.1.norm.bias', 'vision_encoder.clip_decoder.2.head.weight', 'vision_encoder.clip_decoder.2.head.bias', 'vision_encoder.clip_decoder.2.norm.weight', 'vision_encoder.clip_decoder.2.norm.bias', 'vision_encoder.clip_decoder.3.head.weight', 'vision_encoder.clip_decoder.3.head.bias', 'vision_encoder.clip_decoder.3.norm.weight', 'vision_encoder.clip_decoder.3.norm.bias', 'vision_encoder.clip_decoder.4.head.weight', 'vision_encoder.clip_decoder.4.head.bias', 'vision_encoder.clip_decoder.4.norm.weight', 'vision_encoder.clip_decoder.4.norm.bias', 'vision_encoder.clip_decoder.5.head.weight', 'vision_encoder.clip_decoder.5.head.bias', 'vision_encoder.clip_decoder.5.norm.weight', 'vision_encoder.clip_decoder.5.norm.bias', 'text_encoder.cls.predictions.bias', 'text_encoder.cls.predictions.transform.dense.weight', 'text_encoder.cls.predictions.transform.dense.bias', 'text_encoder.cls.predictions.transform.LayerNorm.weight', 'text_encoder.cls.predictions.transform.LayerNorm.bias', 'text_encoder.cls.predictions.decoder.weight', 'text_encoder.cls.predictions.decoder.bias'])
2023-12-30T14:17:58 | INFO | tasks.shared_utils : Loaded checkpoint from /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_5m.pth
2023-12-30T14:17:58 | INFO | __main__ : Start evaluation
2023-12-30T14:17:58 | INFO | tasks.retrieval_utils : Start evaluation for media_type=video
2023-12-30T14:17:58 | INFO | tasks.retrieval_utils : Computing dual encoder features...
2023-12-30T14:18:06 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2023-12-30T14:18:06 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2023-12-30T14:18:06 | INFO | utils.basic_utils : extracting image feats  [ 0/32]  eta: 0:03:17    time: 6.1874  data: 4.0399  max mem: 3743 res mem: 4648
2023-12-30T14:18:24 | INFO | utils.basic_utils : extracting image feats  [31/32]  eta: 0:00:00    time: 0.7033  data: 0.4825  max mem: 3826 res mem: 4650
2023-12-30T14:18:24 | INFO | utils.basic_utils : extracting image feats Total time: 0:00:24 (0.7519 s / it)
2023-12-30T14:18:26 | INFO | tasks.retrieval_utils : Finished feature extraction
2023-12-30T14:18:26 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product]
2023-12-30T14:18:26 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product], done!
2023-12-30T14:18:26 | INFO | tasks.retrieval_utils : Rerank dual-encoder results with cross-encoder...
2023-12-30T14:18:26 | INFO | tasks.retrieval_utils : i2t_scores.shape torch.Size([1000, 1000])
2023-12-30T14:18:26 | INFO | tasks.retrieval_utils : n_clip_per_video=1, with eval_frame_ensemble=concat
2023-12-30T14:18:26 | INFO | utils.basic_utils : Evaluation:  [   0/1000]  eta: 0:00:22    time: 0.0224  data: 0.0010  max mem: 3826 res mem: 4650
2023-12-30T14:18:29 | INFO | utils.basic_utils : Evaluation:  [ 100/1000]  eta: 0:00:25    time: 0.0278  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:18:31 | INFO | utils.basic_utils : Evaluation:  [ 200/1000]  eta: 0:00:22    time: 0.0282  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:18:34 | INFO | utils.basic_utils : Evaluation:  [ 300/1000]  eta: 0:00:19    time: 0.0282  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:18:37 | INFO | utils.basic_utils : Evaluation:  [ 400/1000]  eta: 0:00:16    time: 0.0281  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:18:40 | INFO | utils.basic_utils : Evaluation:  [ 500/1000]  eta: 0:00:14    time: 0.0281  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:18:43 | INFO | utils.basic_utils : Evaluation:  [ 600/1000]  eta: 0:00:11    time: 0.0284  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:18:46 | INFO | utils.basic_utils : Evaluation:  [ 700/1000]  eta: 0:00:08    time: 0.0282  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:18:48 | INFO | utils.basic_utils : Evaluation:  [ 800/1000]  eta: 0:00:05    time: 0.0284  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:18:51 | INFO | utils.basic_utils : Evaluation:  [ 900/1000]  eta: 0:00:02    time: 0.0281  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:18:54 | INFO | utils.basic_utils : Evaluation:  [ 999/1000]  eta: 0:00:00    time: 0.0284  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:18:54 | INFO | utils.basic_utils : Evaluation: Total time: 0:00:28 (0.0282 s / it)
2023-12-30T14:18:54 | INFO | tasks.retrieval_utils : t2i_scores.shape torch.Size([1000, 1000])
2023-12-30T14:18:54 | INFO | utils.basic_utils : Evaluation:  [   0/1000]  eta: 0:05:15    time: 0.3159  data: 0.0008  max mem: 3826 res mem: 4650
2023-12-30T14:19:22 | INFO | utils.basic_utils : Evaluation:  [ 100/1000]  eta: 0:04:08    time: 0.2732  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:19:49 | INFO | utils.basic_utils : Evaluation:  [ 200/1000]  eta: 0:03:39    time: 0.2741  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:20:17 | INFO | utils.basic_utils : Evaluation:  [ 300/1000]  eta: 0:03:11    time: 0.2713  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:20:44 | INFO | utils.basic_utils : Evaluation:  [ 400/1000]  eta: 0:02:45    time: 0.2817  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:21:12 | INFO | utils.basic_utils : Evaluation:  [ 500/1000]  eta: 0:02:17    time: 0.2711  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:21:40 | INFO | utils.basic_utils : Evaluation:  [ 600/1000]  eta: 0:01:50    time: 0.2816  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:22:08 | INFO | utils.basic_utils : Evaluation:  [ 700/1000]  eta: 0:01:22    time: 0.2825  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:22:36 | INFO | utils.basic_utils : Evaluation:  [ 800/1000]  eta: 0:00:55    time: 0.2766  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:23:04 | INFO | utils.basic_utils : Evaluation:  [ 900/1000]  eta: 0:00:27    time: 0.2808  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:23:31 | INFO | utils.basic_utils : Evaluation:  [ 999/1000]  eta: 0:00:00    time: 0.2727  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:23:31 | INFO | utils.basic_utils : Evaluation: Total time: 0:04:37 (0.2770 s / it)
2023-12-30T14:23:31 | INFO | tasks.retrieval_utils : Evaluation time 0:05:32
2023-12-30T14:23:31 | INFO | __main__ : Epoch 0
2023-12-30T14:23:31 | INFO | __main__ : 
           txt_r1  txt_r5  txt_r10  txt_r_mean  img_r1  img_r5  img_r10  img_r_mean  r_mean
test/        26.4    46.7     54.9       42.67    29.6    53.0     61.9       48.17   45.42
test_emb/    20.9    41.7     51.3       37.97    23.5    46.9     56.3       42.23   40.10
2023-12-30T14:23:31 | INFO | __main__ : Training time 0:05:32
2023-12-30T14:23:31 | INFO | __main__ : best epoch 0 [config.stop_key test/]
2023-12-30T14:23:31 | INFO | __main__ : Checkpoints and Logs saved at exp/zero_shot/ret_msrvtt/b16_5m
2023-12-30T14:26:38 | INFO | umt : Logging to: exp/zero_shot/ret_msrvtt/b16_5m/train.log
2023-12-30T14:26:38 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_train9k.json', '/data1/DATASET/MSRVTT/videos', 'video']
  test_file: {
      test: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_test1k.json', '/data1/DATASET/MSRVTT/videos', 'video'] }
  test_types: ['test']
  num_workers: 6
  stop_key: test/
  is_paragraph_retrieval: False
  num_frames: 4
  num_frames_test: 4
  batch_size: 32
  max_txt_l: 32
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 4
          sample_type: rand
          num_frames_test: 4
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 32
          video: 32 }
      batch_size: {
          image: 32
          video: 32 }
      batch_size_test: {
          image: 32
          video: 32 } }
  text_enc: bert
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_b16
          img_size: 224
          patch_size: 16
          d_model: 768
          encoder_embed_dim: 768
          encoder_depth: 12
          encoder_num_heads: 12
          drop_path_rate: 0.2
          num_frames: 4
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 12
          clip_decoder_embed_dim: 768
          clip_output_dim: 512
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 224
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      multimodal: {
          enable: True }
      embed_dim: 512
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 2e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 7
      min_lr_multi: 0.01
      warmup_epochs: 1 }
  evaluate: True
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: user
      project: umt }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/zero_shot/ret_msrvtt/b16_5m
  resume: False
  debug: False
  log_freq: 100
  seed: 42
  zero_shot: True
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_models/Unmasked_Teacher/multimodality/l16_5m.pth
  rank: 0
  world_size: 1
  gpu: 0
  distributed: True
  dist_backend: nccl }
2023-12-30T14:26:38 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_train9k.json', '/data1/DATASET/MSRVTT/videos', 'video'], 'test_file': {'test': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_test1k.json', '/data1/DATASET/MSRVTT/videos', 'video']}, 'test_types': ['test'], 'num_workers': 6, 'stop_key': 'test/', 'is_paragraph_retrieval': False, 'num_frames': 4, 'num_frames_test': 4, 'batch_size': 32, 'max_txt_l': 32, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 4, 'sample_type': 'rand', 'num_frames_test': 4, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 32, 'video': 32}, 'batch_size': {'image': 32, 'video': 32}, 'batch_size_test': {'image': 32, 'video': 32}}, 'text_enc': 'bert', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_b16', 'img_size': 224, 'patch_size': 16, 'd_model': 768, 'encoder_embed_dim': 768, 'encoder_depth': 12, 'encoder_num_heads': 12, 'drop_path_rate': 0.2, 'num_frames': 4, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 12, 'clip_decoder_embed_dim': 768, 'clip_output_dim': 512, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 224, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'multimodal': {'enable': True}, 'embed_dim': 512, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 2e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 7, 'min_lr_multi': 0.01, 'warmup_epochs': 1}, 'evaluate': True, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': False, 'entity': 'user', 'project': 'umt'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': 'exp/zero_shot/ret_msrvtt/b16_5m', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 42, 'zero_shot': True, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_models/Unmasked_Teacher/multimodality/l16_5m.pth', 'rank': 0, 'world_size': 1, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2023-12-30T14:26:38 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_train9k.json', '/data1/DATASET/MSRVTT/videos', 'video']
2023-12-30T14:26:38 | INFO | tasks.pretrain : Creating dataset for ret
2023-12-30T14:26:38 | INFO | tasks.shared_utils : Creating model
2023-12-30T14:26:42 | INFO | models.umt : Build vision_encoder: vit_b16
2023-12-30T14:26:42 | INFO | models.backbones.vit.vit : Num of patches: 784
2023-12-30T14:26:42 | INFO | models.backbones.vit.vit : Use checkpoint: True
2023-12-30T14:26:42 | INFO | models.backbones.vit.vit : Checkpoint number: 12
2023-12-30T14:26:42 | INFO | models.backbones.vit.vit : Student return index: []
2023-12-30T14:26:46 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
2023-12-30T14:26:46 | INFO | models.umt : Build text_encoder bert_base
2023-12-30T14:26:48 | INFO | models.backbones.bert.xbert : build bert with cross_module: ca
2023-12-30T14:26:48 | INFO | models.criterions : Norm type: l2
2023-12-30T14:26:48 | INFO | models.criterions : Loss type: l2
2023-12-30T14:26:48 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.temp: wd: 0.02, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T14:26:48 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.weight: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.weight: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.embeddings.word_embeddings.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.embeddings.position_embeddings.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.embeddings.token_type_embeddings.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.vision_proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.text_proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.itm_head.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : param module.itm_head.bias: wd: 0, lr: 2e-05
2023-12-30T14:26:49 | INFO | utils.optimizer : optimizer -- lr=2e-05 wd=0.02 len(p)=140
2023-12-30T14:26:49 | INFO | utils.optimizer : optimizer -- lr=2e-05 wd=0 len(p)=256
2023-12-30T14:26:49 | INFO | tasks.shared_utils : Auto resuming
2023-12-30T14:26:49 | INFO | tasks.shared_utils : Not found checkpoint in exp/zero_shot/ret_msrvtt/b16_5m
2023-12-30T14:26:49 | WARNING | tasks.shared_utils : No pretrained checkpoint provided, training from scratch
2023-12-30T14:26:49 | INFO | __main__ : Start evaluation
2023-12-30T14:26:49 | INFO | tasks.retrieval_utils : Start evaluation for media_type=video
2023-12-30T14:26:49 | INFO | tasks.retrieval_utils : Computing dual encoder features...
2023-12-30T14:26:56 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2023-12-30T14:26:56 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2023-12-30T14:26:56 | INFO | utils.basic_utils : extracting image feats  [ 0/32]  eta: 0:03:35    time: 6.7217  data: 4.3472  max mem: 3743 res mem: 4648
2023-12-30T14:27:14 | INFO | utils.basic_utils : extracting image feats  [31/32]  eta: 0:00:00    time: 0.7000  data: 0.4807  max mem: 3826 res mem: 4650
2023-12-30T14:27:14 | INFO | utils.basic_utils : extracting image feats Total time: 0:00:24 (0.7556 s / it)
2023-12-30T14:27:16 | INFO | tasks.retrieval_utils : Finished feature extraction
2023-12-30T14:27:16 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product]
2023-12-30T14:27:16 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product], done!
2023-12-30T14:27:16 | INFO | tasks.retrieval_utils : Rerank dual-encoder results with cross-encoder...
2023-12-30T14:27:16 | INFO | tasks.retrieval_utils : i2t_scores.shape torch.Size([1000, 1000])
2023-12-30T14:27:16 | INFO | tasks.retrieval_utils : n_clip_per_video=1, with eval_frame_ensemble=concat
2023-12-30T14:27:16 | INFO | utils.basic_utils : Evaluation:  [   0/1000]  eta: 0:00:23    time: 0.0236  data: 0.0007  max mem: 3826 res mem: 4650
2023-12-30T14:27:19 | INFO | utils.basic_utils : Evaluation:  [ 100/1000]  eta: 0:00:25    time: 0.0281  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:27:21 | INFO | utils.basic_utils : Evaluation:  [ 200/1000]  eta: 0:00:22    time: 0.0283  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:27:24 | INFO | utils.basic_utils : Evaluation:  [ 300/1000]  eta: 0:00:19    time: 0.0279  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:27:27 | INFO | utils.basic_utils : Evaluation:  [ 400/1000]  eta: 0:00:16    time: 0.0283  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:27:30 | INFO | utils.basic_utils : Evaluation:  [ 500/1000]  eta: 0:00:14    time: 0.0282  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:27:33 | INFO | utils.basic_utils : Evaluation:  [ 600/1000]  eta: 0:00:11    time: 0.0282  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:27:35 | INFO | utils.basic_utils : Evaluation:  [ 700/1000]  eta: 0:00:08    time: 0.0285  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:27:38 | INFO | utils.basic_utils : Evaluation:  [ 800/1000]  eta: 0:00:05    time: 0.0283  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:27:41 | INFO | utils.basic_utils : Evaluation:  [ 900/1000]  eta: 0:00:02    time: 0.0282  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:27:44 | INFO | utils.basic_utils : Evaluation:  [ 999/1000]  eta: 0:00:00    time: 0.0286  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:27:44 | INFO | utils.basic_utils : Evaluation: Total time: 0:00:28 (0.0283 s / it)
2023-12-30T14:27:44 | INFO | tasks.retrieval_utils : t2i_scores.shape torch.Size([1000, 1000])
2023-12-30T14:27:44 | INFO | utils.basic_utils : Evaluation:  [   0/1000]  eta: 0:05:06    time: 0.3062  data: 0.0008  max mem: 3826 res mem: 4650
2023-12-30T14:28:11 | INFO | utils.basic_utils : Evaluation:  [ 100/1000]  eta: 0:03:56    time: 0.2650  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:28:37 | INFO | utils.basic_utils : Evaluation:  [ 200/1000]  eta: 0:03:32    time: 0.2687  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:29:04 | INFO | utils.basic_utils : Evaluation:  [ 300/1000]  eta: 0:03:06    time: 0.2633  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:29:32 | INFO | utils.basic_utils : Evaluation:  [ 400/1000]  eta: 0:02:41    time: 0.2800  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:29:59 | INFO | utils.basic_utils : Evaluation:  [ 500/1000]  eta: 0:02:15    time: 0.2687  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:30:27 | INFO | utils.basic_utils : Evaluation:  [ 600/1000]  eta: 0:01:48    time: 0.2726  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:30:54 | INFO | utils.basic_utils : Evaluation:  [ 700/1000]  eta: 0:01:21    time: 0.2711  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:31:21 | INFO | utils.basic_utils : Evaluation:  [ 800/1000]  eta: 0:00:54    time: 0.2613  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:31:48 | INFO | utils.basic_utils : Evaluation:  [ 900/1000]  eta: 0:00:27    time: 0.2714  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:32:15 | INFO | utils.basic_utils : Evaluation:  [ 999/1000]  eta: 0:00:00    time: 0.2809  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:32:15 | INFO | utils.basic_utils : Evaluation: Total time: 0:04:31 (0.2711 s / it)
2023-12-30T14:32:15 | INFO | tasks.retrieval_utils : Evaluation time 0:05:26
2023-12-30T14:32:15 | INFO | __main__ : Epoch 0
2023-12-30T14:32:15 | INFO | __main__ : 
           txt_r1  txt_r5  txt_r10  txt_r_mean  img_r1  img_r5  img_r10  img_r_mean  r_mean
test/         0.0     0.3      0.7        0.33     0.2     0.7      0.9        0.60    0.47
test_emb/     0.2     0.9      1.5        0.87     0.2     0.4      0.8        0.47    0.67
2023-12-30T14:32:15 | INFO | __main__ : Training time 0:05:26
2023-12-30T14:32:15 | INFO | __main__ : best epoch 0 [config.stop_key test/]
2023-12-30T14:32:15 | INFO | __main__ : Checkpoints and Logs saved at exp/zero_shot/ret_msrvtt/b16_5m
2023-12-30T14:36:19 | INFO | umt : Logging to: exp/zero_shot/ret_msrvtt/b16_5m/train.log
2023-12-30T14:36:19 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_train9k.json', '/data1/DATASET/MSRVTT/videos', 'video']
  test_file: {
      test: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_test1k.json', '/data1/DATASET/MSRVTT/videos', 'video'] }
  test_types: ['test']
  num_workers: 6
  stop_key: test/
  is_paragraph_retrieval: False
  num_frames: 4
  num_frames_test: 4
  batch_size: 32
  max_txt_l: 32
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 4
          sample_type: rand
          num_frames_test: 4
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 32
          video: 32 }
      batch_size: {
          image: 32
          video: 32 }
      batch_size_test: {
          image: 32
          video: 32 } }
  text_enc: bert
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_b16
          img_size: 224
          patch_size: 16
          d_model: 768
          encoder_embed_dim: 768
          encoder_depth: 12
          encoder_num_heads: 12
          drop_path_rate: 0.2
          num_frames: 4
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 12
          clip_decoder_embed_dim: 768
          clip_output_dim: 512
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 224
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      multimodal: {
          enable: True }
      embed_dim: 512
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 2e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 7
      min_lr_multi: 0.01
      warmup_epochs: 1 }
  evaluate: True
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: user
      project: umt }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/zero_shot/ret_msrvtt/b16_5m
  resume: False
  debug: False
  log_freq: 100
  seed: 42
  zero_shot: True
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_5m.pth
  rank: 0
  world_size: 1
  gpu: 0
  distributed: True
  dist_backend: nccl }
2023-12-30T14:36:19 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_train9k.json', '/data1/DATASET/MSRVTT/videos', 'video'], 'test_file': {'test': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_test1k.json', '/data1/DATASET/MSRVTT/videos', 'video']}, 'test_types': ['test'], 'num_workers': 6, 'stop_key': 'test/', 'is_paragraph_retrieval': False, 'num_frames': 4, 'num_frames_test': 4, 'batch_size': 32, 'max_txt_l': 32, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 4, 'sample_type': 'rand', 'num_frames_test': 4, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 32, 'video': 32}, 'batch_size': {'image': 32, 'video': 32}, 'batch_size_test': {'image': 32, 'video': 32}}, 'text_enc': 'bert', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_b16', 'img_size': 224, 'patch_size': 16, 'd_model': 768, 'encoder_embed_dim': 768, 'encoder_depth': 12, 'encoder_num_heads': 12, 'drop_path_rate': 0.2, 'num_frames': 4, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 12, 'clip_decoder_embed_dim': 768, 'clip_output_dim': 512, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 224, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'multimodal': {'enable': True}, 'embed_dim': 512, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 2e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 7, 'min_lr_multi': 0.01, 'warmup_epochs': 1}, 'evaluate': True, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': False, 'entity': 'user', 'project': 'umt'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': 'exp/zero_shot/ret_msrvtt/b16_5m', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 42, 'zero_shot': True, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_5m.pth', 'rank': 0, 'world_size': 1, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2023-12-30T14:36:19 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_train9k.json', '/data1/DATASET/MSRVTT/videos', 'video']
2023-12-30T14:36:19 | INFO | tasks.pretrain : Creating dataset for ret
2023-12-30T14:36:20 | INFO | tasks.shared_utils : Creating model
2023-12-30T14:36:23 | INFO | models.umt : Build vision_encoder: vit_b16
2023-12-30T14:36:23 | INFO | models.backbones.vit.vit : Num of patches: 784
2023-12-30T14:36:23 | INFO | models.backbones.vit.vit : Use checkpoint: True
2023-12-30T14:36:23 | INFO | models.backbones.vit.vit : Checkpoint number: 12
2023-12-30T14:36:23 | INFO | models.backbones.vit.vit : Student return index: []
2023-12-30T14:36:28 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
2023-12-30T14:36:28 | INFO | models.umt : Build text_encoder bert_base
2023-12-30T14:36:30 | INFO | models.backbones.bert.xbert : build bert with cross_module: ca
2023-12-30T14:36:30 | INFO | models.criterions : Norm type: l2
2023-12-30T14:36:30 | INFO | models.criterions : Loss type: l2
2023-12-30T14:36:31 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.temp: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.weight: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.weight: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.embeddings.word_embeddings.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.embeddings.position_embeddings.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.embeddings.token_type_embeddings.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.vision_proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.text_proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.itm_head.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : param module.itm_head.bias: wd: 0, lr: 2e-05
2023-12-30T14:36:31 | INFO | utils.optimizer : optimizer -- lr=2e-05 wd=0.02 len(p)=140
2023-12-30T14:36:31 | INFO | utils.optimizer : optimizer -- lr=2e-05 wd=0 len(p)=256
2023-12-30T14:36:31 | INFO | tasks.shared_utils : Auto resuming
2023-12-30T14:36:31 | INFO | tasks.shared_utils : Not found checkpoint in exp/zero_shot/ret_msrvtt/b16_5m
2023-12-30T14:36:31 | INFO | tasks.shared_utils : _IncompatibleKeys(missing_keys=[], unexpected_keys=['clip_teacher.class_embedding', 'clip_teacher.positional_embedding', 'clip_teacher.proj', 'clip_teacher.conv1.weight', 'clip_teacher.ln_pre.weight', 'clip_teacher.ln_pre.bias', 'clip_teacher.transformer.resblocks.0.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.0.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.0.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.0.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.0.ln_1.weight', 'clip_teacher.transformer.resblocks.0.ln_1.bias', 'clip_teacher.transformer.resblocks.0.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.0.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.0.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.0.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.0.ln_2.weight', 'clip_teacher.transformer.resblocks.0.ln_2.bias', 'clip_teacher.transformer.resblocks.1.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.1.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.1.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.1.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.1.ln_1.weight', 'clip_teacher.transformer.resblocks.1.ln_1.bias', 'clip_teacher.transformer.resblocks.1.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.1.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.1.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.1.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.1.ln_2.weight', 'clip_teacher.transformer.resblocks.1.ln_2.bias', 'clip_teacher.transformer.resblocks.2.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.2.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.2.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.2.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.2.ln_1.weight', 'clip_teacher.transformer.resblocks.2.ln_1.bias', 'clip_teacher.transformer.resblocks.2.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.2.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.2.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.2.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.2.ln_2.weight', 'clip_teacher.transformer.resblocks.2.ln_2.bias', 'clip_teacher.transformer.resblocks.3.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.3.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.3.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.3.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.3.ln_1.weight', 'clip_teacher.transformer.resblocks.3.ln_1.bias', 'clip_teacher.transformer.resblocks.3.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.3.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.3.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.3.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.3.ln_2.weight', 'clip_teacher.transformer.resblocks.3.ln_2.bias', 'clip_teacher.transformer.resblocks.4.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.4.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.4.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.4.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.4.ln_1.weight', 'clip_teacher.transformer.resblocks.4.ln_1.bias', 'clip_teacher.transformer.resblocks.4.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.4.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.4.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.4.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.4.ln_2.weight', 'clip_teacher.transformer.resblocks.4.ln_2.bias', 'clip_teacher.transformer.resblocks.5.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.5.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.5.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.5.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.5.ln_1.weight', 'clip_teacher.transformer.resblocks.5.ln_1.bias', 'clip_teacher.transformer.resblocks.5.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.5.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.5.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.5.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.5.ln_2.weight', 'clip_teacher.transformer.resblocks.5.ln_2.bias', 'clip_teacher.transformer.resblocks.6.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.6.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.6.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.6.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.6.ln_1.weight', 'clip_teacher.transformer.resblocks.6.ln_1.bias', 'clip_teacher.transformer.resblocks.6.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.6.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.6.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.6.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.6.ln_2.weight', 'clip_teacher.transformer.resblocks.6.ln_2.bias', 'clip_teacher.transformer.resblocks.7.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.7.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.7.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.7.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.7.ln_1.weight', 'clip_teacher.transformer.resblocks.7.ln_1.bias', 'clip_teacher.transformer.resblocks.7.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.7.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.7.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.7.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.7.ln_2.weight', 'clip_teacher.transformer.resblocks.7.ln_2.bias', 'clip_teacher.transformer.resblocks.8.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.8.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.8.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.8.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.8.ln_1.weight', 'clip_teacher.transformer.resblocks.8.ln_1.bias', 'clip_teacher.transformer.resblocks.8.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.8.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.8.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.8.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.8.ln_2.weight', 'clip_teacher.transformer.resblocks.8.ln_2.bias', 'clip_teacher.transformer.resblocks.9.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.9.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.9.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.9.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.9.ln_1.weight', 'clip_teacher.transformer.resblocks.9.ln_1.bias', 'clip_teacher.transformer.resblocks.9.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.9.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.9.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.9.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.9.ln_2.weight', 'clip_teacher.transformer.resblocks.9.ln_2.bias', 'clip_teacher.transformer.resblocks.10.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.10.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.10.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.10.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.10.ln_1.weight', 'clip_teacher.transformer.resblocks.10.ln_1.bias', 'clip_teacher.transformer.resblocks.10.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.10.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.10.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.10.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.10.ln_2.weight', 'clip_teacher.transformer.resblocks.10.ln_2.bias', 'clip_teacher.transformer.resblocks.11.attn.in_proj_weight', 'clip_teacher.transformer.resblocks.11.attn.in_proj_bias', 'clip_teacher.transformer.resblocks.11.attn.out_proj.weight', 'clip_teacher.transformer.resblocks.11.attn.out_proj.bias', 'clip_teacher.transformer.resblocks.11.ln_1.weight', 'clip_teacher.transformer.resblocks.11.ln_1.bias', 'clip_teacher.transformer.resblocks.11.mlp.c_fc.weight', 'clip_teacher.transformer.resblocks.11.mlp.c_fc.bias', 'clip_teacher.transformer.resblocks.11.mlp.c_proj.weight', 'clip_teacher.transformer.resblocks.11.mlp.c_proj.bias', 'clip_teacher.transformer.resblocks.11.ln_2.weight', 'clip_teacher.transformer.resblocks.11.ln_2.bias', 'clip_teacher.ln_post.weight', 'clip_teacher.ln_post.bias', 'vision_encoder.clip_decoder.0.head.weight', 'vision_encoder.clip_decoder.0.head.bias', 'vision_encoder.clip_decoder.0.norm.weight', 'vision_encoder.clip_decoder.0.norm.bias', 'vision_encoder.clip_decoder.1.head.weight', 'vision_encoder.clip_decoder.1.head.bias', 'vision_encoder.clip_decoder.1.norm.weight', 'vision_encoder.clip_decoder.1.norm.bias', 'vision_encoder.clip_decoder.2.head.weight', 'vision_encoder.clip_decoder.2.head.bias', 'vision_encoder.clip_decoder.2.norm.weight', 'vision_encoder.clip_decoder.2.norm.bias', 'vision_encoder.clip_decoder.3.head.weight', 'vision_encoder.clip_decoder.3.head.bias', 'vision_encoder.clip_decoder.3.norm.weight', 'vision_encoder.clip_decoder.3.norm.bias', 'vision_encoder.clip_decoder.4.head.weight', 'vision_encoder.clip_decoder.4.head.bias', 'vision_encoder.clip_decoder.4.norm.weight', 'vision_encoder.clip_decoder.4.norm.bias', 'vision_encoder.clip_decoder.5.head.weight', 'vision_encoder.clip_decoder.5.head.bias', 'vision_encoder.clip_decoder.5.norm.weight', 'vision_encoder.clip_decoder.5.norm.bias', 'text_encoder.cls.predictions.bias', 'text_encoder.cls.predictions.transform.dense.weight', 'text_encoder.cls.predictions.transform.dense.bias', 'text_encoder.cls.predictions.transform.LayerNorm.weight', 'text_encoder.cls.predictions.transform.LayerNorm.bias', 'text_encoder.cls.predictions.decoder.weight', 'text_encoder.cls.predictions.decoder.bias'])
2023-12-30T14:36:31 | INFO | tasks.shared_utils : Loaded checkpoint from /datassd2/pretrained_models/Unmasked_Teacher/multimodality/b16_5m.pth
2023-12-30T14:36:32 | INFO | __main__ : Start evaluation
2023-12-30T14:36:32 | INFO | tasks.retrieval_utils : Start evaluation for media_type=video
2023-12-30T14:36:32 | INFO | tasks.retrieval_utils : Computing dual encoder features...
2023-12-30T14:36:39 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2023-12-30T14:36:39 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2023-12-30T14:36:39 | INFO | utils.basic_utils : extracting image feats  [ 0/32]  eta: 0:03:21    time: 6.3113  data: 4.2579  max mem: 3743 res mem: 4648
2023-12-30T14:36:57 | INFO | utils.basic_utils : extracting image feats  [31/32]  eta: 0:00:00    time: 0.7179  data: 0.4978  max mem: 3826 res mem: 4650
2023-12-30T14:36:57 | INFO | utils.basic_utils : extracting image feats Total time: 0:00:24 (0.7536 s / it)
2023-12-30T14:36:58 | INFO | tasks.retrieval_utils : Finished feature extraction
2023-12-30T14:36:58 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product]
2023-12-30T14:36:58 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product], done!
2023-12-30T14:36:58 | INFO | tasks.retrieval_utils : Rerank dual-encoder results with cross-encoder...
2023-12-30T14:36:58 | INFO | tasks.retrieval_utils : i2t_scores.shape torch.Size([1000, 1000])
2023-12-30T14:36:58 | INFO | tasks.retrieval_utils : n_clip_per_video=1, with eval_frame_ensemble=concat
2023-12-30T14:36:58 | INFO | utils.basic_utils : Evaluation:  [   0/1000]  eta: 0:00:21    time: 0.0219  data: 0.0009  max mem: 3826 res mem: 4650
2023-12-30T14:37:01 | INFO | utils.basic_utils : Evaluation:  [ 100/1000]  eta: 0:00:25    time: 0.0281  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:37:04 | INFO | utils.basic_utils : Evaluation:  [ 200/1000]  eta: 0:00:22    time: 0.0287  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:37:07 | INFO | utils.basic_utils : Evaluation:  [ 300/1000]  eta: 0:00:19    time: 0.0284  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:37:10 | INFO | utils.basic_utils : Evaluation:  [ 400/1000]  eta: 0:00:16    time: 0.0281  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:37:13 | INFO | utils.basic_utils : Evaluation:  [ 500/1000]  eta: 0:00:14    time: 0.0282  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:37:15 | INFO | utils.basic_utils : Evaluation:  [ 600/1000]  eta: 0:00:11    time: 0.0286  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:37:18 | INFO | utils.basic_utils : Evaluation:  [ 700/1000]  eta: 0:00:08    time: 0.0283  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:37:21 | INFO | utils.basic_utils : Evaluation:  [ 800/1000]  eta: 0:00:05    time: 0.0285  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:37:24 | INFO | utils.basic_utils : Evaluation:  [ 900/1000]  eta: 0:00:02    time: 0.0282  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:37:27 | INFO | utils.basic_utils : Evaluation:  [ 999/1000]  eta: 0:00:00    time: 0.0283  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:37:27 | INFO | utils.basic_utils : Evaluation: Total time: 0:00:28 (0.0284 s / it)
2023-12-30T14:37:27 | INFO | tasks.retrieval_utils : t2i_scores.shape torch.Size([1000, 1000])
2023-12-30T14:37:27 | INFO | utils.basic_utils : Evaluation:  [   0/1000]  eta: 0:05:30    time: 0.3302  data: 0.0015  max mem: 3826 res mem: 4650
2023-12-30T14:37:55 | INFO | utils.basic_utils : Evaluation:  [ 100/1000]  eta: 0:04:13    time: 0.2906  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:38:23 | INFO | utils.basic_utils : Evaluation:  [ 200/1000]  eta: 0:03:44    time: 0.2771  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:38:51 | INFO | utils.basic_utils : Evaluation:  [ 300/1000]  eta: 0:03:15    time: 0.2831  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:39:17 | INFO | utils.basic_utils : Evaluation:  [ 400/1000]  eta: 0:02:45    time: 0.2676  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:39:45 | INFO | utils.basic_utils : Evaluation:  [ 500/1000]  eta: 0:02:18    time: 0.2794  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:40:14 | INFO | utils.basic_utils : Evaluation:  [ 600/1000]  eta: 0:01:51    time: 0.2829  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:40:42 | INFO | utils.basic_utils : Evaluation:  [ 700/1000]  eta: 0:01:23    time: 0.2824  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:41:10 | INFO | utils.basic_utils : Evaluation:  [ 800/1000]  eta: 0:00:55    time: 0.2846  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:41:38 | INFO | utils.basic_utils : Evaluation:  [ 900/1000]  eta: 0:00:27    time: 0.2769  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:42:06 | INFO | utils.basic_utils : Evaluation:  [ 999/1000]  eta: 0:00:00    time: 0.2861  data: 0.0000  max mem: 3826 res mem: 4650
2023-12-30T14:42:06 | INFO | utils.basic_utils : Evaluation: Total time: 0:04:38 (0.2790 s / it)
2023-12-30T14:42:06 | INFO | tasks.retrieval_utils : Evaluation time 0:05:34
2023-12-30T14:42:06 | INFO | __main__ : Epoch 0
2023-12-30T14:42:06 | INFO | __main__ : 
           txt_r1  txt_r5  txt_r10  txt_r_mean  img_r1  img_r5  img_r10  img_r_mean  r_mean
test/        26.4    46.7     54.9       42.67    29.6    53.0     61.9       48.17   45.42
test_emb/    20.9    41.7     51.3       37.97    23.5    46.9     56.3       42.23   40.10
2023-12-30T14:42:06 | INFO | __main__ : Training time 0:05:34
2023-12-30T14:42:06 | INFO | __main__ : best epoch 0 [config.stop_key test/]
2023-12-30T14:42:06 | INFO | __main__ : Checkpoints and Logs saved at exp/zero_shot/ret_msrvtt/b16_5m
2023-12-30T14:42:22 | INFO | umt : Logging to: exp/zero_shot/ret_msrvtt/b16_5m/train.log
2023-12-30T14:42:22 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_train9k.json', '/data1/DATASET/MSRVTT/videos', 'video']
  test_file: {
      test: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_test1k.json', '/data1/DATASET/MSRVTT/videos', 'video'] }
  test_types: ['test']
  num_workers: 6
  stop_key: test/
  is_paragraph_retrieval: False
  num_frames: 4
  num_frames_test: 4
  batch_size: 32
  max_txt_l: 32
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 4
          sample_type: rand
          num_frames_test: 4
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 32
          video: 32 }
      batch_size: {
          image: 32
          video: 32 }
      batch_size_test: {
          image: 32
          video: 32 } }
  text_enc: bert_large
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_l14
          img_size: 224
          patch_size: 16
          d_model: 1024
          encoder_embed_dim: 1024
          encoder_depth: 24
          encoder_num_heads: 16
          drop_path_rate: 0.3
          num_frames: 4
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 24
          clip_decoder_embed_dim: 1024
          clip_output_dim: 768
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_models/Unmasked_Teacher/l16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 196
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 }
      multimodal: {
          enable: True }
      embed_dim: 768
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 2e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 7
      min_lr_multi: 0.01
      warmup_epochs: 1 }
  evaluate: True
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: user
      project: umt }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/zero_shot/ret_msrvtt/b16_5m
  resume: False
  debug: False
  log_freq: 100
  seed: 42
  zero_shot: True
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_models/Unmasked_Teacher/multimodality/l16_5m.pth
  rank: 0
  world_size: 1
  gpu: 0
  distributed: True
  dist_backend: nccl }
2023-12-30T14:42:22 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_train9k.json', '/data1/DATASET/MSRVTT/videos', 'video'], 'test_file': {'test': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_test1k.json', '/data1/DATASET/MSRVTT/videos', 'video']}, 'test_types': ['test'], 'num_workers': 6, 'stop_key': 'test/', 'is_paragraph_retrieval': False, 'num_frames': 4, 'num_frames_test': 4, 'batch_size': 32, 'max_txt_l': 32, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 4, 'sample_type': 'rand', 'num_frames_test': 4, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 32, 'video': 32}, 'batch_size': {'image': 32, 'video': 32}, 'batch_size_test': {'image': 32, 'video': 32}}, 'text_enc': 'bert_large', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_l14', 'img_size': 224, 'patch_size': 16, 'd_model': 1024, 'encoder_embed_dim': 1024, 'encoder_depth': 24, 'encoder_num_heads': 16, 'drop_path_rate': 0.3, 'num_frames': 4, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 24, 'clip_decoder_embed_dim': 1024, 'clip_output_dim': 768, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_models/Unmasked_Teacher/l16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 196, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}, 'multimodal': {'enable': True}, 'embed_dim': 768, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 2e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 7, 'min_lr_multi': 0.01, 'warmup_epochs': 1}, 'evaluate': True, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': False, 'entity': 'user', 'project': 'umt'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': 'exp/zero_shot/ret_msrvtt/b16_5m', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 42, 'zero_shot': True, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_models/Unmasked_Teacher/multimodality/l16_5m.pth', 'rank': 0, 'world_size': 1, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2023-12-30T14:42:22 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_train9k.json', '/data1/DATASET/MSRVTT/videos', 'video']
2023-12-30T14:42:22 | INFO | tasks.pretrain : Creating dataset for ret
2023-12-30T14:42:22 | INFO | tasks.shared_utils : Creating model
2023-12-30T14:45:09 | INFO | umt : Logging to: exp/zero_shot/ret_msrvtt/b16_5m/train.log
2023-12-30T14:45:09 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_train9k.json', '/data1/DATASET/MSRVTT/videos', 'video']
  test_file: {
      test: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_test1k.json', '/data1/DATASET/MSRVTT/videos', 'video'] }
  test_types: ['test']
  num_workers: 6
  stop_key: test/
  is_paragraph_retrieval: False
  num_frames: 4
  num_frames_test: 4
  batch_size: 32
  max_txt_l: 32
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 4
          sample_type: rand
          num_frames_test: 4
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 32
          video: 32 }
      batch_size: {
          image: 32
          video: 32 }
      batch_size_test: {
          image: 32
          video: 32 } }
  text_enc: bert_large
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_l14
          img_size: 224
          patch_size: 16
          d_model: 1024
          encoder_embed_dim: 1024
          encoder_depth: 24
          encoder_num_heads: 16
          drop_path_rate: 0.3
          num_frames: 4
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 24
          clip_decoder_embed_dim: 1024
          clip_output_dim: 768
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_models/Unmasked_Teacher/l16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 196
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 }
      multimodal: {
          enable: True }
      embed_dim: 768
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 2e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 7
      min_lr_multi: 0.01
      warmup_epochs: 1 }
  evaluate: True
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: user
      project: umt }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/zero_shot/ret_msrvtt/b16_5m
  resume: False
  debug: False
  log_freq: 100
  seed: 42
  zero_shot: True
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_models/Unmasked_Teacher/multimodality/l16_5m.pth
  rank: 0
  world_size: 1
  gpu: 0
  distributed: True
  dist_backend: nccl }
2023-12-30T14:45:09 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_train9k.json', '/data1/DATASET/MSRVTT/videos', 'video'], 'test_file': {'test': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_test1k.json', '/data1/DATASET/MSRVTT/videos', 'video']}, 'test_types': ['test'], 'num_workers': 6, 'stop_key': 'test/', 'is_paragraph_retrieval': False, 'num_frames': 4, 'num_frames_test': 4, 'batch_size': 32, 'max_txt_l': 32, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 4, 'sample_type': 'rand', 'num_frames_test': 4, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 32, 'video': 32}, 'batch_size': {'image': 32, 'video': 32}, 'batch_size_test': {'image': 32, 'video': 32}}, 'text_enc': 'bert_large', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_l14', 'img_size': 224, 'patch_size': 16, 'd_model': 1024, 'encoder_embed_dim': 1024, 'encoder_depth': 24, 'encoder_num_heads': 16, 'drop_path_rate': 0.3, 'num_frames': 4, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 24, 'clip_decoder_embed_dim': 1024, 'clip_output_dim': 768, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_models/Unmasked_Teacher/l16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 196, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}, 'multimodal': {'enable': True}, 'embed_dim': 768, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 2e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 7, 'min_lr_multi': 0.01, 'warmup_epochs': 1}, 'evaluate': True, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': False, 'entity': 'user', 'project': 'umt'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': 'exp/zero_shot/ret_msrvtt/b16_5m', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 42, 'zero_shot': True, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_models/Unmasked_Teacher/multimodality/l16_5m.pth', 'rank': 0, 'world_size': 1, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2023-12-30T14:45:09 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_train9k.json', '/data1/DATASET/MSRVTT/videos', 'video']
2023-12-30T14:45:09 | INFO | tasks.pretrain : Creating dataset for ret
2023-12-30T14:45:10 | INFO | tasks.shared_utils : Creating model
2023-12-30T14:45:24 | INFO | models.umt : Build vision_encoder: vit_l14
2023-12-30T14:45:24 | INFO | models.backbones.vit.vit : Num of patches: 784
2023-12-30T14:45:24 | INFO | models.backbones.vit.vit : Use checkpoint: True
2023-12-30T14:45:24 | INFO | models.backbones.vit.vit : Checkpoint number: 24
2023-12-30T14:45:24 | INFO | models.backbones.vit.vit : Student return index: []
2023-12-30T14:45:33 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_models/Unmasked_Teacher/l16_ptk710_f8_res224.pth
2023-12-30T14:46:18 | INFO | umt : Logging to: exp/zero_shot/ret_msrvtt/b16_5m/train.log
2023-12-30T14:46:18 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_train9k.json', '/data1/DATASET/MSRVTT/videos', 'video']
  test_file: {
      test: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_test1k.json', '/data1/DATASET/MSRVTT/videos', 'video'] }
  test_types: ['test']
  num_workers: 6
  stop_key: test/
  is_paragraph_retrieval: False
  num_frames: 4
  num_frames_test: 4
  batch_size: 32
  max_txt_l: 32
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 4
          sample_type: rand
          num_frames_test: 4
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 32
          video: 32 }
      batch_size: {
          image: 32
          video: 32 }
      batch_size_test: {
          image: 32
          video: 32 } }
  text_enc: bert_large
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_l14
          img_size: 224
          patch_size: 16
          d_model: 1024
          encoder_embed_dim: 1024
          encoder_depth: 24
          encoder_num_heads: 16
          drop_path_rate: 0.3
          num_frames: 4
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 24
          clip_decoder_embed_dim: 1024
          clip_output_dim: 768
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 196
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 }
      multimodal: {
          enable: True }
      embed_dim: 768
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 2e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 7
      min_lr_multi: 0.01
      warmup_epochs: 1 }
  evaluate: True
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: user
      project: umt }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/zero_shot/ret_msrvtt/b16_5m
  resume: False
  debug: False
  log_freq: 100
  seed: 42
  zero_shot: True
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_models/Unmasked_Teacher/multimodality/l16_5m.pth
  rank: 0
  world_size: 1
  gpu: 0
  distributed: True
  dist_backend: nccl }
2023-12-30T14:46:18 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_train9k.json', '/data1/DATASET/MSRVTT/videos', 'video'], 'test_file': {'test': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_test1k.json', '/data1/DATASET/MSRVTT/videos', 'video']}, 'test_types': ['test'], 'num_workers': 6, 'stop_key': 'test/', 'is_paragraph_retrieval': False, 'num_frames': 4, 'num_frames_test': 4, 'batch_size': 32, 'max_txt_l': 32, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 4, 'sample_type': 'rand', 'num_frames_test': 4, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 32, 'video': 32}, 'batch_size': {'image': 32, 'video': 32}, 'batch_size_test': {'image': 32, 'video': 32}}, 'text_enc': 'bert_large', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_l14', 'img_size': 224, 'patch_size': 16, 'd_model': 1024, 'encoder_embed_dim': 1024, 'encoder_depth': 24, 'encoder_num_heads': 16, 'drop_path_rate': 0.3, 'num_frames': 4, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 24, 'clip_decoder_embed_dim': 1024, 'clip_output_dim': 768, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 196, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}, 'multimodal': {'enable': True}, 'embed_dim': 768, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 2e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 7, 'min_lr_multi': 0.01, 'warmup_epochs': 1}, 'evaluate': True, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': False, 'entity': 'user', 'project': 'umt'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': 'exp/zero_shot/ret_msrvtt/b16_5m', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 42, 'zero_shot': True, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_models/Unmasked_Teacher/multimodality/l16_5m.pth', 'rank': 0, 'world_size': 1, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2023-12-30T14:46:18 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_train9k.json', '/data1/DATASET/MSRVTT/videos', 'video']
2023-12-30T14:46:18 | INFO | tasks.pretrain : Creating dataset for ret
2023-12-30T14:46:19 | INFO | tasks.shared_utils : Creating model
2023-12-30T14:46:32 | INFO | models.umt : Build vision_encoder: vit_l14
2023-12-30T14:46:32 | INFO | models.backbones.vit.vit : Num of patches: 784
2023-12-30T14:46:32 | INFO | models.backbones.vit.vit : Use checkpoint: True
2023-12-30T14:46:32 | INFO | models.backbones.vit.vit : Checkpoint number: 24
2023-12-30T14:46:32 | INFO | models.backbones.vit.vit : Student return index: []
2023-12-30T14:46:40 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_models/Unmasked_Teacher/b16_ptk710_f8_res224.pth
2023-12-30T14:52:07 | INFO | umt : Logging to: exp/zero_shot/ret_msrvtt/b16_5m/train.log
2023-12-30T14:52:07 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_train9k.json', '/data1/DATASET/MSRVTT/videos', 'video']
  test_file: {
      test: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_test1k.json', '/data1/DATASET/MSRVTT/videos', 'video'] }
  test_types: ['test']
  num_workers: 6
  stop_key: test/
  is_paragraph_retrieval: False
  num_frames: 4
  num_frames_test: 4
  batch_size: 32
  max_txt_l: 32
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 4
          sample_type: rand
          num_frames_test: 4
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 32
          video: 32 }
      batch_size: {
          image: 32
          video: 32 }
      batch_size_test: {
          image: 32
          video: 32 } }
  text_enc: bert_large
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_l14
          img_size: 224
          patch_size: 16
          d_model: 1024
          encoder_embed_dim: 1024
          encoder_depth: 24
          encoder_num_heads: 16
          drop_path_rate: 0.3
          num_frames: 4
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 24
          clip_decoder_embed_dim: 1024
          clip_output_dim: 768
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_models/Unmasked_Teacher/l16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 196
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 }
      multimodal: {
          enable: True }
      embed_dim: 768
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 2e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 7
      min_lr_multi: 0.01
      warmup_epochs: 1 }
  evaluate: True
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: user
      project: umt }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/zero_shot/ret_msrvtt/b16_5m
  resume: False
  debug: False
  log_freq: 100
  seed: 42
  zero_shot: True
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_models/Unmasked_Teacher/multimodality/l16_5m.pth
  rank: 0
  world_size: 1
  gpu: 0
  distributed: True
  dist_backend: nccl }
2023-12-30T14:52:07 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_train9k.json', '/data1/DATASET/MSRVTT/videos', 'video'], 'test_file': {'test': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_test1k.json', '/data1/DATASET/MSRVTT/videos', 'video']}, 'test_types': ['test'], 'num_workers': 6, 'stop_key': 'test/', 'is_paragraph_retrieval': False, 'num_frames': 4, 'num_frames_test': 4, 'batch_size': 32, 'max_txt_l': 32, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 4, 'sample_type': 'rand', 'num_frames_test': 4, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 32, 'video': 32}, 'batch_size': {'image': 32, 'video': 32}, 'batch_size_test': {'image': 32, 'video': 32}}, 'text_enc': 'bert_large', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_l14', 'img_size': 224, 'patch_size': 16, 'd_model': 1024, 'encoder_embed_dim': 1024, 'encoder_depth': 24, 'encoder_num_heads': 16, 'drop_path_rate': 0.3, 'num_frames': 4, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 24, 'clip_decoder_embed_dim': 1024, 'clip_output_dim': 768, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_models/Unmasked_Teacher/l16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 196, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}, 'multimodal': {'enable': True}, 'embed_dim': 768, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 2e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 7, 'min_lr_multi': 0.01, 'warmup_epochs': 1}, 'evaluate': True, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': False, 'entity': 'user', 'project': 'umt'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': 'exp/zero_shot/ret_msrvtt/b16_5m', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 42, 'zero_shot': True, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_models/Unmasked_Teacher/multimodality/l16_5m.pth', 'rank': 0, 'world_size': 1, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2023-12-30T14:52:07 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_train9k.json', '/data1/DATASET/MSRVTT/videos', 'video']
2023-12-30T14:52:07 | INFO | tasks.pretrain : Creating dataset for ret
2023-12-30T14:52:08 | INFO | tasks.shared_utils : Creating model
2023-12-30T14:52:21 | INFO | models.umt : Build vision_encoder: vit_l14
2023-12-30T14:52:21 | INFO | models.backbones.vit.vit : Num of patches: 784
2023-12-30T14:52:21 | INFO | models.backbones.vit.vit : Use checkpoint: True
2023-12-30T14:52:21 | INFO | models.backbones.vit.vit : Checkpoint number: 24
2023-12-30T14:52:21 | INFO | models.backbones.vit.vit : Student return index: []
2023-12-30T14:52:30 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_models/Unmasked_Teacher/l16_ptk710_f8_res224.pth
2023-12-30T14:54:25 | INFO | umt : Logging to: exp/zero_shot/ret_msrvtt/b16_5m/train.log
2023-12-30T14:54:25 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_train9k.json', '/data1/DATASET/MSRVTT/videos', 'video']
  test_file: {
      test: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_test1k.json', '/data1/DATASET/MSRVTT/videos', 'video'] }
  test_types: ['test']
  num_workers: 6
  stop_key: test/
  is_paragraph_retrieval: False
  num_frames: 4
  num_frames_test: 4
  batch_size: 32
  max_txt_l: 32
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 4
          sample_type: rand
          num_frames_test: 4
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 32
          video: 32 }
      batch_size: {
          image: 32
          video: 32 }
      batch_size_test: {
          image: 32
          video: 32 } }
  text_enc: bert_large
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_l14
          img_size: 224
          patch_size: 16
          d_model: 1024
          encoder_embed_dim: 1024
          encoder_depth: 24
          encoder_num_heads: 16
          drop_path_rate: 0.3
          num_frames: 4
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 24
          clip_decoder_embed_dim: 1024
          clip_output_dim: 768
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_models/Unmasked_Teacher/l16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 196
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 }
      multimodal: {
          enable: True }
      embed_dim: 768
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 2e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 7
      min_lr_multi: 0.01
      warmup_epochs: 1 }
  evaluate: True
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: user
      project: umt }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/zero_shot/ret_msrvtt/b16_5m
  resume: False
  debug: False
  log_freq: 100
  seed: 42
  zero_shot: True
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_models/Unmasked_Teacher/multimodality/l16_5m.pth
  rank: 0
  world_size: 1
  gpu: 0
  distributed: True
  dist_backend: nccl }
2023-12-30T14:54:25 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_train9k.json', '/data1/DATASET/MSRVTT/videos', 'video'], 'test_file': {'test': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_test1k.json', '/data1/DATASET/MSRVTT/videos', 'video']}, 'test_types': ['test'], 'num_workers': 6, 'stop_key': 'test/', 'is_paragraph_retrieval': False, 'num_frames': 4, 'num_frames_test': 4, 'batch_size': 32, 'max_txt_l': 32, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 4, 'sample_type': 'rand', 'num_frames_test': 4, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 32, 'video': 32}, 'batch_size': {'image': 32, 'video': 32}, 'batch_size_test': {'image': 32, 'video': 32}}, 'text_enc': 'bert_large', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_l14', 'img_size': 224, 'patch_size': 16, 'd_model': 1024, 'encoder_embed_dim': 1024, 'encoder_depth': 24, 'encoder_num_heads': 16, 'drop_path_rate': 0.3, 'num_frames': 4, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 24, 'clip_decoder_embed_dim': 1024, 'clip_output_dim': 768, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_models/Unmasked_Teacher/l16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 196, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}, 'multimodal': {'enable': True}, 'embed_dim': 768, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 2e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 7, 'min_lr_multi': 0.01, 'warmup_epochs': 1}, 'evaluate': True, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': False, 'entity': 'user', 'project': 'umt'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': 'exp/zero_shot/ret_msrvtt/b16_5m', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 42, 'zero_shot': True, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_models/Unmasked_Teacher/multimodality/l16_5m.pth', 'rank': 0, 'world_size': 1, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2023-12-30T14:54:25 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_train9k.json', '/data1/DATASET/MSRVTT/videos', 'video']
2023-12-30T14:54:25 | INFO | tasks.pretrain : Creating dataset for ret
2023-12-30T14:54:25 | INFO | tasks.shared_utils : Creating model
2023-12-30T14:54:38 | INFO | models.umt : Build vision_encoder: vit_l14
2023-12-30T14:54:38 | INFO | models.backbones.vit.vit : Num of patches: 784
2023-12-30T14:54:38 | INFO | models.backbones.vit.vit : Use checkpoint: True
2023-12-30T14:54:38 | INFO | models.backbones.vit.vit : Checkpoint number: 24
2023-12-30T14:54:38 | INFO | models.backbones.vit.vit : Student return index: []
2023-12-30T14:54:47 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_models/Unmasked_Teacher/l16_ptk710_f8_res224.pth
2023-12-30T14:54:48 | INFO | models.umt : Build text_encoder bert_large
2023-12-30T14:56:26 | INFO | umt : Logging to: exp/zero_shot/ret_msrvtt/b16_5m/train.log
2023-12-30T14:56:26 | INFO | utils.config_utils : config: {
  data_dir: /data2/dy/code/unmasked_teacher/umt_data
  data_root: /data2/dy/code/unmasked_teacher/umt_data/videos_images
  anno_root_pt: /data2/dy/code/unmasked_teacher/umt_data/anno_pretrain
  anno_root_downstream: /data2/dy/code/unmasked_teacher/umt_data/anno_downstream
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_train9k.json', '/data1/DATASET/MSRVTT/videos', 'video']
  test_file: {
      test: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_test1k.json', '/data1/DATASET/MSRVTT/videos', 'video'] }
  test_types: ['test']
  num_workers: 6
  stop_key: test/
  is_paragraph_retrieval: False
  num_frames: 4
  num_frames_test: 4
  batch_size: 32
  max_txt_l: 32
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 4
          sample_type: rand
          num_frames_test: 4
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 32
          video: 32 }
      batch_size: {
          image: 32
          video: 32 }
      batch_size_test: {
          image: 32
          video: 32 } }
  text_enc: bert_large
  model: {
      model_cls: UMT
      vision_encoder: {
          name: vit_l14
          img_size: 224
          patch_size: 16
          d_model: 1024
          encoder_embed_dim: 1024
          encoder_depth: 24
          encoder_num_heads: 16
          drop_path_rate: 0.3
          num_frames: 4
          tubelet_size: 1
          use_checkpoint: True
          checkpoint_num: 24
          clip_decoder_embed_dim: 1024
          clip_output_dim: 768
          clip_return_layer: 0
          clip_student_return_interval: 1
          pretrained: /datassd2/pretrained_models/Unmasked_Teacher/l16_ptk710_f8_res224.pth
          clip_teacher: none
          clip_img_size: 196
          clip_return_interval: 1
          video_mask_type: attention
          video_mask_ratio: 0.0
          video_double_mask_ratio: 0.0
          image_mask_type: attention
          image_mask_ratio: 0.0
          image_double_mask_ratio: 0.0
          keep_temporal: True }
      text_encoder: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 }
      multimodal: {
          enable: True }
      embed_dim: 768
      temp: 0.07 }
  criterion: {
      loss_weight: {
          vtc: 1.0
          mlm: 0.0
          vtm: 1.0
          uta: 0.0 }
      vtm_hard_neg: True
      mlm_masking_prob: 0.5
      uta_norm_type: l2
      uta_loss_type: l2 }
  optimizer: {
      opt: adamW
      lr: 2e-05
      opt_betas: [0.9, 0.999]
      weight_decay: 0.02
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 7
      min_lr_multi: 0.01
      warmup_epochs: 1 }
  evaluate: True
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: user
      project: umt }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/zero_shot/ret_msrvtt/b16_5m
  resume: False
  debug: False
  log_freq: 100
  seed: 42
  zero_shot: True
  save_latest: True
  auto_resume: True
  pretrained_path: /datassd2/pretrained_models/Unmasked_Teacher/multimodality/l16_5m.pth
  rank: 0
  world_size: 1
  gpu: 0
  distributed: True
  dist_backend: nccl }
2023-12-30T14:56:26 | INFO | __main__ : config: 
{'data_dir': '/data2/dy/code/unmasked_teacher/umt_data', 'data_root': '/data2/dy/code/unmasked_teacher/umt_data/videos_images', 'anno_root_pt': '/data2/dy/code/unmasked_teacher/umt_data/anno_pretrain', 'anno_root_downstream': '/data2/dy/code/unmasked_teacher/umt_data/anno_downstream', 'TextEncoders': {'bert': {'name': 'bert_base', 'pretrained': 'bert-base-uncased', 'config': 'configs/config_bert.json', 'd_model': 768, 'fusion_layer': 9}, 'bert_large': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}}, 'train_file': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_train9k.json', '/data1/DATASET/MSRVTT/videos', 'video'], 'test_file': {'test': ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_test1k.json', '/data1/DATASET/MSRVTT/videos', 'video']}, 'test_types': ['test'], 'num_workers': 6, 'stop_key': 'test/', 'is_paragraph_retrieval': False, 'num_frames': 4, 'num_frames_test': 4, 'batch_size': 32, 'max_txt_l': 32, 'inputs': {'image_res': 224, 'video_input': {'num_frames': 4, 'sample_type': 'rand', 'num_frames_test': 4, 'sample_type_test': 'middle', 'random_aug': False}, 'max_txt_l': {'image': 32, 'video': 32}, 'batch_size': {'image': 32, 'video': 32}, 'batch_size_test': {'image': 32, 'video': 32}}, 'text_enc': 'bert_large', 'model': {'model_cls': 'UMT', 'vision_encoder': {'name': 'vit_l14', 'img_size': 224, 'patch_size': 16, 'd_model': 1024, 'encoder_embed_dim': 1024, 'encoder_depth': 24, 'encoder_num_heads': 16, 'drop_path_rate': 0.3, 'num_frames': 4, 'tubelet_size': 1, 'use_checkpoint': True, 'checkpoint_num': 24, 'clip_decoder_embed_dim': 1024, 'clip_output_dim': 768, 'clip_return_layer': 0, 'clip_student_return_interval': 1, 'pretrained': '/datassd2/pretrained_models/Unmasked_Teacher/l16_ptk710_f8_res224.pth', 'clip_teacher': 'none', 'clip_img_size': 196, 'clip_return_interval': 1, 'video_mask_type': 'attention', 'video_mask_ratio': 0.0, 'video_double_mask_ratio': 0.0, 'image_mask_type': 'attention', 'image_mask_ratio': 0.0, 'image_double_mask_ratio': 0.0, 'keep_temporal': True}, 'text_encoder': {'name': 'bert_large', 'pretrained': 'bert-large-uncased', 'config': 'configs/config_bert_large.json', 'd_model': 1024, 'fusion_layer': 19}, 'multimodal': {'enable': True}, 'embed_dim': 768, 'temp': 0.07}, 'criterion': {'loss_weight': {'vtc': 1.0, 'mlm': 0.0, 'vtm': 1.0, 'uta': 0.0}, 'vtm_hard_neg': True, 'mlm_masking_prob': 0.5, 'uta_norm_type': 'l2', 'uta_loss_type': 'l2'}, 'optimizer': {'opt': 'adamW', 'lr': 2e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 7, 'min_lr_multi': 0.01, 'warmup_epochs': 1}, 'evaluate': True, 'deep_fusion': False, 'evaluation': {'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'k_test': 128, 'eval_offload': True}, 'fp16': True, 'gradient_checkpointing': True, 'wandb': {'enable': False, 'entity': 'user', 'project': 'umt'}, 'dist_url': 'env://', 'device': 'cuda', 'mode': 'pt', 'output_dir': 'exp/zero_shot/ret_msrvtt/b16_5m', 'resume': False, 'debug': False, 'log_freq': 100, 'seed': 42, 'zero_shot': True, 'save_latest': True, 'auto_resume': True, 'pretrained_path': '/datassd2/pretrained_models/Unmasked_Teacher/multimodality/l16_5m.pth', 'rank': 0, 'world_size': 1, 'gpu': 0, 'distributed': True, 'dist_backend': 'nccl'}
2023-12-30T14:56:26 | INFO | __main__ : train_file: ['/data2/dy/code/unmasked_teacher/umt_data/anno_downstream/msrvtt_ret_train9k.json', '/data1/DATASET/MSRVTT/videos', 'video']
2023-12-30T14:56:26 | INFO | tasks.pretrain : Creating dataset for ret
2023-12-30T14:56:27 | INFO | tasks.shared_utils : Creating model
2023-12-30T14:56:39 | INFO | models.umt : Build vision_encoder: vit_l14
2023-12-30T14:56:39 | INFO | models.backbones.vit.vit : Num of patches: 784
2023-12-30T14:56:39 | INFO | models.backbones.vit.vit : Use checkpoint: True
2023-12-30T14:56:39 | INFO | models.backbones.vit.vit : Checkpoint number: 24
2023-12-30T14:56:39 | INFO | models.backbones.vit.vit : Student return index: []
2023-12-30T14:56:48 | INFO | models.backbones.vit.vit : Loading pretrained weights from /datassd2/pretrained_models/Unmasked_Teacher/l16_ptk710_f8_res224.pth
2023-12-30T14:56:49 | INFO | models.umt : Build text_encoder bert_large
2023-12-30T14:58:55 | INFO | models.backbones.bert.xbert : build bert with cross_module: ca
2023-12-30T14:58:57 | INFO | models.criterions : Norm type: l2
2023-12-30T14:58:57 | INFO | models.criterions : Loss type: l2
2023-12-30T14:58:58 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.temp: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.patch_embed.proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.0.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.1.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.2.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.3.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.4.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.5.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.6.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.7.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.8.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.9.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.10.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.11.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.12.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.12.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.12.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.12.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.12.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.12.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.12.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.12.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.12.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.12.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.12.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.12.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.12.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.13.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.13.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.13.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.13.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.13.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.13.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.13.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.13.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.13.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.13.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.13.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.13.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.13.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.14.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.14.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.14.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.14.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.14.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.14.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.14.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.14.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.14.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.14.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.14.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.14.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.14.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.15.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.15.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.15.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.15.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.15.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.15.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.15.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.15.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.15.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.15.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.15.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.15.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.15.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.16.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.16.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.16.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.16.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.16.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.16.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.16.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.16.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.16.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.16.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.16.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.16.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.16.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.17.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.17.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.17.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.17.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.17.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.17.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.17.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.17.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.17.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.17.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.17.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.17.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.17.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.18.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.18.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.18.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.18.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.18.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.18.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.18.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.18.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.18.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.18.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.18.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.18.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.18.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.19.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.19.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.19.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.19.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.19.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.19.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.19.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.19.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.19.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.19.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.19.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.19.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.19.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.20.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.20.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.20.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.20.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.20.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.20.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.20.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.20.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.20.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.20.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.20.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.20.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.20.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.21.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.21.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.21.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.21.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.21.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.21.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.21.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.21.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.21.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.21.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.21.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.21.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.21.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.22.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.22.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.22.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.22.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.22.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.22.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.22.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.22.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.22.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.22.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.22.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.22.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.22.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.23.norm1.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.23.norm1.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.23.attn.q_bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.23.attn.v_bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.23.attn.qkv.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.23.attn.proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.23.attn.proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.23.norm2.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.23.norm2.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.23.mlp.fc1.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.23.mlp.fc1.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.23.mlp.fc2.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.blocks.23.mlp.fc2.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.encoder.norm.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_encoder.pool_norm.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.embeddings.word_embeddings.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.embeddings.position_embeddings.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.embeddings.token_type_embeddings.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.embeddings.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.0.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.1.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.2.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.3.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.4.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.5.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.6.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.7.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.8.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.9.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.10.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.11.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.12.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.12.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.12.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.12.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.12.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.12.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.12.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.12.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.12.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.12.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.12.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.12.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.12.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.12.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.12.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.12.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.13.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.13.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.13.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.13.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.13.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.13.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.13.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.13.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.13.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.13.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.13.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.13.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.13.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.13.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.13.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.13.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.14.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.14.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.14.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.14.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.14.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.14.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.14.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.14.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.14.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.14.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.14.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.14.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.14.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.14.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.14.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.14.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.15.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.15.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.15.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.15.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.15.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.15.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.15.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.15.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.15.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.15.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.15.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.15.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.15.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.15.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.15.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.15.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.16.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.16.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.16.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.16.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.16.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.16.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.16.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.16.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.16.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.16.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.16.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.16.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.16.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.16.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.16.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.16.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.17.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.17.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.17.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.17.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.17.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.17.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.17.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.17.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.17.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.17.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.17.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.17.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.17.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.17.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.17.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.17.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.18.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.18.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.18.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.18.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.18.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.18.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.18.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.18.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.18.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.18.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.18.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.18.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.18.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.18.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.18.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.18.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.19.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.19.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.19.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.19.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.19.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.19.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.19.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.19.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.19.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.19.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.19.crossattention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.19.crossattention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.19.crossattention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.19.crossattention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.19.crossattention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.19.crossattention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.19.crossattention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.19.crossattention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.19.crossattention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.19.crossattention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.19.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.19.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.19.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.19.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.19.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.19.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.20.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.20.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.20.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.20.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.20.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.20.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.20.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.20.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.20.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.20.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.20.crossattention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.20.crossattention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.20.crossattention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.20.crossattention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.20.crossattention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.20.crossattention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.20.crossattention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.20.crossattention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.20.crossattention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.20.crossattention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.20.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.20.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.20.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.20.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.20.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.20.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.21.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.21.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.21.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.21.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.21.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.21.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.21.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.21.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.21.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.21.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.21.crossattention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.21.crossattention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.21.crossattention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.21.crossattention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.21.crossattention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.21.crossattention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.21.crossattention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.21.crossattention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.21.crossattention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.21.crossattention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.21.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.21.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.21.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.21.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.21.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.21.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.22.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.22.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.22.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.22.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.22.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.22.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.22.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.22.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.22.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.22.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.22.crossattention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.22.crossattention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.22.crossattention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.22.crossattention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.22.crossattention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.22.crossattention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.22.crossattention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.22.crossattention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.22.crossattention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.22.crossattention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.22.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.22.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.22.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.22.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.22.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.22.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.23.attention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.23.attention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.23.attention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.23.attention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.23.attention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.23.attention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.23.attention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.23.attention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.23.attention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.23.attention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.23.crossattention.self.query.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.23.crossattention.self.query.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.23.crossattention.self.key.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.23.crossattention.self.key.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.23.crossattention.self.value.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.23.crossattention.self.value.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.23.crossattention.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.23.crossattention.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.23.crossattention.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.23.crossattention.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.23.intermediate.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.23.intermediate.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.23.output.dense.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.23.output.dense.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.23.output.LayerNorm.weight: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_encoder.encoder.layer.23.output.LayerNorm.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.vision_proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_proj.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.text_proj.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.itm_head.weight: wd: 0.02, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : param module.itm_head.bias: wd: 0, lr: 2e-05
2023-12-30T14:58:58 | INFO | utils.optimizer : optimizer -- lr=2e-05 wd=0.02 len(p)=268
2023-12-30T14:58:58 | INFO | utils.optimizer : optimizer -- lr=2e-05 wd=0 len(p)=496
2023-12-30T14:58:58 | INFO | tasks.shared_utils : Auto resuming
2023-12-30T14:58:58 | INFO | tasks.shared_utils : Not found checkpoint in exp/zero_shot/ret_msrvtt/b16_5m
2023-12-30T14:58:58 | WARNING | tasks.shared_utils : No pretrained checkpoint provided, training from scratch
2023-12-30T14:58:58 | INFO | __main__ : Start evaluation
2023-12-30T14:58:58 | INFO | tasks.retrieval_utils : Start evaluation for media_type=video
2023-12-30T14:58:58 | INFO | tasks.retrieval_utils : Computing dual encoder features...
2023-12-30T14:59:05 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2023-12-30T14:59:05 | WARNING | py.warnings : /data2/dy/code/unmasked_teacher/multi_modality/utils/distributed.py:18: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  builtin_warn(*args, **kwargs)

2023-12-30T14:59:06 | INFO | utils.basic_utils : extracting image feats  [ 0/32]  eta: 0:03:38    time: 6.8180  data: 4.1907  max mem: 8553 res mem: 9302
2023-12-30T14:59:23 | INFO | utils.basic_utils : extracting image feats  [31/32]  eta: 0:00:00    time: 0.5803  data: 0.0780  max mem: 8670 res mem: 9302
2023-12-30T14:59:23 | INFO | utils.basic_utils : extracting image feats Total time: 0:00:24 (0.7589 s / it)
2023-12-30T14:59:25 | INFO | tasks.retrieval_utils : Finished feature extraction
2023-12-30T14:59:25 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product]
2023-12-30T14:59:25 | INFO | tasks.retrieval_utils : Computing ITC scores [dot-product], done!
2023-12-30T14:59:25 | INFO | tasks.retrieval_utils : Rerank dual-encoder results with cross-encoder...
2023-12-30T14:59:25 | INFO | tasks.retrieval_utils : i2t_scores.shape torch.Size([1000, 1000])
2023-12-30T14:59:25 | INFO | tasks.retrieval_utils : n_clip_per_video=1, with eval_frame_ensemble=concat
2023-12-30T14:59:25 | INFO | utils.basic_utils : Evaluation:  [   0/1000]  eta: 0:00:36    time: 0.0363  data: 0.0016  max mem: 8670 res mem: 9302
2023-12-30T14:59:32 | INFO | utils.basic_utils : Evaluation:  [ 100/1000]  eta: 0:00:58    time: 0.0653  data: 0.0000  max mem: 8670 res mem: 9302
2023-12-30T14:59:38 | INFO | utils.basic_utils : Evaluation:  [ 200/1000]  eta: 0:00:52    time: 0.0661  data: 0.0000  max mem: 8670 res mem: 9302
2023-12-30T14:59:45 | INFO | utils.basic_utils : Evaluation:  [ 300/1000]  eta: 0:00:45    time: 0.0657  data: 0.0000  max mem: 8670 res mem: 9302
2023-12-30T14:59:52 | INFO | utils.basic_utils : Evaluation:  [ 400/1000]  eta: 0:00:39    time: 0.0665  data: 0.0000  max mem: 8670 res mem: 9302
2023-12-30T14:59:58 | INFO | utils.basic_utils : Evaluation:  [ 500/1000]  eta: 0:00:32    time: 0.0665  data: 0.0000  max mem: 8670 res mem: 9302
2023-12-30T15:00:05 | INFO | utils.basic_utils : Evaluation:  [ 600/1000]  eta: 0:00:26    time: 0.0665  data: 0.0000  max mem: 8670 res mem: 9302
2023-12-30T15:00:12 | INFO | utils.basic_utils : Evaluation:  [ 700/1000]  eta: 0:00:19    time: 0.0669  data: 0.0000  max mem: 8670 res mem: 9302
2023-12-30T15:00:18 | INFO | utils.basic_utils : Evaluation:  [ 800/1000]  eta: 0:00:13    time: 0.0671  data: 0.0000  max mem: 8670 res mem: 9302
2023-12-30T15:00:25 | INFO | utils.basic_utils : Evaluation:  [ 900/1000]  eta: 0:00:06    time: 0.0672  data: 0.0000  max mem: 8670 res mem: 9302
2023-12-30T15:00:32 | INFO | utils.basic_utils : Evaluation:  [ 999/1000]  eta: 0:00:00    time: 0.0669  data: 0.0000  max mem: 8670 res mem: 9302
2023-12-30T15:00:32 | INFO | utils.basic_utils : Evaluation: Total time: 0:01:06 (0.0664 s / it)
2023-12-30T15:00:32 | INFO | tasks.retrieval_utils : t2i_scores.shape torch.Size([1000, 1000])
2023-12-30T15:00:32 | INFO | utils.basic_utils : Evaluation:  [   0/1000]  eta: 0:03:43    time: 0.2236  data: 0.0008  max mem: 8670 res mem: 9302
2023-12-30T15:00:53 | INFO | utils.basic_utils : Evaluation:  [ 100/1000]  eta: 0:03:09    time: 0.2168  data: 0.0000  max mem: 8670 res mem: 9302
2023-12-30T15:01:14 | INFO | utils.basic_utils : Evaluation:  [ 200/1000]  eta: 0:02:47    time: 0.2104  data: 0.0000  max mem: 8670 res mem: 9302
2023-12-30T15:01:35 | INFO | utils.basic_utils : Evaluation:  [ 300/1000]  eta: 0:02:26    time: 0.2110  data: 0.0000  max mem: 8670 res mem: 9302
2023-12-30T15:01:56 | INFO | utils.basic_utils : Evaluation:  [ 400/1000]  eta: 0:02:05    time: 0.2055  data: 0.0000  max mem: 8670 res mem: 9302
2023-12-30T15:02:17 | INFO | utils.basic_utils : Evaluation:  [ 500/1000]  eta: 0:01:44    time: 0.2033  data: 0.0000  max mem: 8670 res mem: 9302
2023-12-30T15:02:38 | INFO | utils.basic_utils : Evaluation:  [ 600/1000]  eta: 0:01:23    time: 0.2104  data: 0.0000  max mem: 8670 res mem: 9302
2023-12-30T15:02:59 | INFO | utils.basic_utils : Evaluation:  [ 700/1000]  eta: 0:01:02    time: 0.2127  data: 0.0000  max mem: 8670 res mem: 9302
2023-12-30T15:03:20 | INFO | utils.basic_utils : Evaluation:  [ 800/1000]  eta: 0:00:41    time: 0.2136  data: 0.0000  max mem: 8670 res mem: 9302
2023-12-30T15:03:41 | INFO | utils.basic_utils : Evaluation:  [ 900/1000]  eta: 0:00:20    time: 0.2109  data: 0.0000  max mem: 8670 res mem: 9302
2023-12-30T15:04:01 | INFO | utils.basic_utils : Evaluation:  [ 999/1000]  eta: 0:00:00    time: 0.2068  data: 0.0000  max mem: 8670 res mem: 9302
2023-12-30T15:04:01 | INFO | utils.basic_utils : Evaluation: Total time: 0:03:29 (0.2096 s / it)
2023-12-30T15:04:01 | INFO | tasks.retrieval_utils : Evaluation time 0:05:03
2023-12-30T15:04:02 | INFO | __main__ : Epoch 0
2023-12-30T15:04:02 | INFO | __main__ : 
           txt_r1  txt_r5  txt_r10  txt_r_mean  img_r1  img_r5  img_r10  img_r_mean  r_mean
test/         0.0     0.3      0.9        0.40     0.0     0.4      0.8        0.40    0.40
test_emb/     0.1     0.2      0.5        0.27     0.1     0.7      1.2        0.67    0.47
2023-12-30T15:04:02 | INFO | __main__ : Training time 0:05:04
2023-12-30T15:04:02 | INFO | __main__ : best epoch 0 [config.stop_key test/]
2023-12-30T15:04:02 | INFO | __main__ : Checkpoints and Logs saved at exp/zero_shot/ret_msrvtt/b16_5m
