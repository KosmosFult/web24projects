# CNN新闻分类

## 1.背景介绍

随着互联网和社交媒体的迅猛发展，新闻资讯的数量呈爆炸式增长。如何高效地处理和分类海量新闻内容，成为信息技术领域的一个重要课题。传统的文本分类方法主要依赖于手工特征提取和机器学习算法，这些方法在面对复杂的语义关系和多样化的表达形式时，表现出一定的局限性。近年来，深度学习技术的兴起为新闻分类任务提供了新的解决方案。

深度学习是一类基于人工神经网络的机器学习技术，具有强大的特征自动学习能力。与传统方法不同，深度学习模型能够自动从原始数据中提取高级特征，无需依赖人工设计特征。这使得深度学习在处理复杂、非结构化的数据方面具有显著优势，尤其适用于自然语言处理（NLP）任务。

在新闻分类领域，深度学习方法主要包括卷积神经网络（CNN）、循环神经网络（RNN）以及其变种，如长短期记忆网络（LSTM）和注意力机制（Attention Mechanism）等。这些模型可以捕捉文本数据中的语义和上下文信息，从而实现高效的新闻分类。

具体而言，CNN擅长从局部窗口中提取关键信息，适用于捕捉文本中的重要特征；RNN及其变种LSTM则能够处理序列数据，擅长捕捉长距离的依赖关系，适合处理新闻文本中的上下文关系。此外，基于注意力机制的Transformer模型近年来表现出色，通过自注意力机制实现了对长文本的高效建模，已经成为NLP领域的主流方法之一。

深度学习模型在新闻分类中的应用不仅提高了分类的准确性和效率，还支持多类别和多标签分类，适应了新闻内容的多样化需求。随着深度学习技术的不断发展和硬件计算能力的提升，新闻分类的自动化、智能化水平将进一步提高，为信息管理和传播提供更强大的技术支持。

## 2.项目介绍

新闻文本分类

数据来源：搜狐新闻语料集，训练集有23549条新闻，测试集则有12000条。

实现：word2vec词向量模型+pytorch实现卷积神经网络

## 3.实现

### 数据预处理：

将原始新闻文本文件按行打乱

使用jieba对所有新闻正文内容进行分词，得到词库(每一行一个词的文本文件)

使用word2vec训练词库生成词向量模型

将原始新闻文本进行分词后，替换为词向量模型中的索引

### 卷积神经网络

CNN模型一共有以下几层:

Embedding层: self.embedding = nn.Embedding(num_embeddings=self.vocab_size, embedding_dim=self.vector_size, padding_idx=0)
用于将文本中的单词映射为词向量。

卷积层组合: self.convs = [nn.Conv1d(...)]*len(kernel_size)
包含了多个1D卷积层,卷积核尺寸由kernel_size参数控制,对应代码是(3,4,5)。

最大池化层: 在conv_and_pool函数中,对每个卷积层的输出使用F.max_pool1d进行最大池化。

全连接层1: self.fc1 = nn.Linear(len(kernel_size) * output_channels, liner_one)

Dropout层: self.dropout = nn.Dropout(dropout)

激活函数ReLU: 在forward函数中对self.fc1的输出使用F.relu激活。

全连接层2(输出层): self.fc2 = nn.Linear(liner_one, class_num)

### 测试结果

#### 测试结果

对12000条新闻测试集进行测试

最终平均准确率为 87.550%

## 4.总结

卷积神经网络相比于神经网络，可以保留原始数据的更多特征，在文本分类上有着不错的表现。

虽然 Word2Vec 在生成静态词嵌入方面有其独特的优势（如计算效率高、资源需求低），但相比之下，Transformer 在上下文处理能力、模型表达能力、处理长文本的能力、预训练和微调、多语言支持和多模态任务处理等方面具有显著优势。这些优势使得 Transformer 成为当前自然语言处理任务中的主流模型。

数据集和模型超过100MB，通过网盘提交：

链接：https://pan.baidu.com/s/1LmaGGHhuNSLlpRLCUObDJg?pwd=aa18 
提取码：aa18